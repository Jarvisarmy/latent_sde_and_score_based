{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4dd7b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/equinox/custom_types.py:112: FutureWarning: jax.tree_structure is deprecated, and will be removed in a future release. Use jax.tree_util.tree_structure instead.\n",
      "  TreeDef = type(jax.tree_structure(0))\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/diffrax/custom_types.py:133: FutureWarning: jax.tree_structure is deprecated, and will be removed in a future release. Use jax.tree_util.tree_structure instead.\n",
      "  PyTreeDef = type(jax.tree_structure(0))\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/equinox/compile_utils.py:12: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.\n",
      "  static_leaves, static_treedef = jax.tree_flatten(static)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/equinox/compile_utils.py:50: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.\n",
      "  leaves, treedef = jax.tree_flatten((args, kwargs))\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/equinox/compile_utils.py:45: FutureWarning: jax.tree_unflatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_unflatten instead.\n",
      "  args, kwargs = jax.tree_unflatten(treedef, leaves)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/diffrax/solver/runge_kutta.py:116: FutureWarning: jax.tree_structure is deprecated, and will be removed in a future release. Use jax.tree_util.tree_structure instead.\n",
      "  term_structure = jax.tree_structure(0)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/diffrax/solver/euler.py:25: FutureWarning: jax.tree_structure is deprecated, and will be removed in a future release. Use jax.tree_util.tree_structure instead.\n",
      "  term_structure = jax.tree_structure(0)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/diffrax/solver/euler_heun.py:23: FutureWarning: jax.tree_structure is deprecated, and will be removed in a future release. Use jax.tree_util.tree_structure instead.\n",
      "  term_structure = jax.tree_structure((0, 0))\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/diffrax/solver/implicit_euler.py:29: FutureWarning: jax.tree_structure is deprecated, and will be removed in a future release. Use jax.tree_util.tree_structure instead.\n",
      "  term_structure = jax.tree_structure(0)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/diffrax/solver/leapfrog_midpoint.py:43: FutureWarning: jax.tree_structure is deprecated, and will be removed in a future release. Use jax.tree_util.tree_structure instead.\n",
      "  term_structure = jax.tree_structure(0)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/diffrax/solver/milstein.py:38: FutureWarning: jax.tree_structure is deprecated, and will be removed in a future release. Use jax.tree_util.tree_structure instead.\n",
      "  term_structure = jax.tree_structure((0, 0))\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/diffrax/solver/milstein.py:86: FutureWarning: jax.tree_structure is deprecated, and will be removed in a future release. Use jax.tree_util.tree_structure instead.\n",
      "  term_structure = jax.tree_structure((0, 0))\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/diffrax/solver/reversible_heun.py:37: FutureWarning: jax.tree_structure is deprecated, and will be removed in a future release. Use jax.tree_util.tree_structure instead.\n",
      "  term_structure = jax.tree_structure(0)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/diffrax/solver/semi_implicit_euler.py:23: FutureWarning: jax.tree_structure is deprecated, and will be removed in a future release. Use jax.tree_util.tree_structure instead.\n",
      "  term_structure = jax.tree_structure((0, 0))\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/chex/_src/pytypes.py:37: FutureWarning: jax.tree_structure is deprecated, and will be removed in a future release. Use jax.tree_util.tree_structure instead.\n",
      "  PyTreeDef = type(jax.tree_structure(None))\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'stax' from 'jax.experimental' (/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/jax/experimental/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3ccb30e8f91f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstax\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBatchNorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRelu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTanh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLogSoftmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#from jax.experimental import optimizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'stax' from 'jax.experimental' (/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/jax/experimental/__init__.py)"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from collections import namedtuple\n",
    "from typing import Optional, Union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import time\n",
    "\n",
    "import diffrax\n",
    "import equinox as eqx\n",
    "import jax\n",
    "import jax.nn as jnn\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jrandom\n",
    "from jax import grad, jit, vmap, value_and_grad\n",
    "import optax\n",
    "\n",
    "from jax.experimental import stax\n",
    "from jax.experimental.stax import (BatchNorm, Conv, Dense, Flatten, Relu, Tanh,LogSoftmax)\n",
    "#from jax.experimental import optimizers\n",
    "from jax.example_libraries import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40420fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output values from 0 to maxval with iters steps\n",
    "class LinearScheduler(object):\n",
    "    def __init__(self, iters, maxval=1.0):\n",
    "        self._iters = max(1,iters)\n",
    "        self._val = maxval/self._iters\n",
    "        self._maxval = maxval\n",
    "    \n",
    "    def step(self):\n",
    "        self._val = min(self._maxval, self._val+self._maxval/self._iters)\n",
    "        \n",
    "    @property\n",
    "    def val(self):\n",
    "        return self._val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c09c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EMAMetric(object):\n",
    "    def __init__(self, gamma: Optional[float]=0.99):\n",
    "        super(EMAMetric, self).__init__()\n",
    "        self._val=None\n",
    "        self._gamma = gamma\n",
    "    def step(self, x):\n",
    "        if self._val is None:\n",
    "            self._val = x\n",
    "        else:\n",
    "            self._val = self._gamma * self._val + (1-self._gamma)*x\n",
    "        return self._val\n",
    "    \n",
    "    @property\n",
    "    def val(self):\n",
    "        return self._val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a2f4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure that the dvision is stable\n",
    "def _stable_division(a,b,epsilon=1e-7):\n",
    "    b = jnp.where(jnp.absolute(b)> epsilon, b, jnp.full_like(b, fill_value=epsilon)*jnp.sign(b))\n",
    "    return a/b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c072bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80736fff",
   "metadata": {},
   "source": [
    "## 5. Simulation of time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf12fb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 240\n",
    "t_end = 24.\n",
    "t_start = 1.\n",
    "t = np.linspace(t_start,t_end,T)\n",
    "\n",
    "gap = 160\n",
    "s = 30\n",
    "mu = 0\n",
    "sigma = 0.1\n",
    "phi = 0.9\n",
    "def make_time_series():\n",
    "    z0 = np.random.normal(0,sigma,1)\n",
    "    z = np.zeros(T)\n",
    "    z[0] = z0\n",
    "    shocks = np.random.normal(mu, sigma, T)\n",
    "    for idx in range(T-1):\n",
    "        idx_t = t[idx]\n",
    "        z[idx+1] = phi*z[idx] + shocks[idx] + 0.2*np.sin(2*10*np.pi*(idx_t)/s)\n",
    "    return z\n",
    "r = make_time_series()\n",
    "r_train = r[:gap]\n",
    "r_test = r[gap:]\n",
    "plt.plot(range(gap),r_train)\n",
    "plt.plot(range(gap,T),r_test)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf9fca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def make_data():\n",
    "    ts_ = jnp.array(t)\n",
    "    ts_ext_ = jnp.array([t_start-0.1] + list(ts_) + [t_end+0.1])\n",
    "    ts_vis_ = jnp.linspace(t_start,t_end, 1000)\n",
    "    ys_ = jnp.array(r[:,None])\n",
    "    return ts_, ts_ext_, ts_vis_, ys_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2a7d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = 1.0\n",
    "mu = 0.\n",
    "sigma = 0.001\n",
    "key = jrandom.PRNGKey(1)\n",
    "logvar = jnp.log(sigma**2/(2.*theta))\n",
    "\n",
    "py0_mean = jnp.array([[mu]])\n",
    "py0_std = jnp.array([[sigma]])\n",
    "qy0_mean = jnp.array([[mu]])\n",
    "qy0_logvar = jnp.array([[logvar]])\n",
    "\n",
    "init_net, net = stax.serial(Dense(200),Tanh,\n",
    "                           Dense(200),Tanh,\n",
    "                           Dense(1))\n",
    "_,net_params = init_net(key,(batch_size,3))\n",
    "params = [qy0_mean,qy0_logvar] + net_params\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_std(logvar):\n",
    "    return jnp.exp(.5 * logvar)\n",
    "\n",
    "@jit\n",
    "def loss(params,ts,ys,key):\n",
    "    zs, kl = forward(ts,batch_size,params,key)\n",
    "    zs = jnp.squeeze(zs)\n",
    "    zs = zs[1:-1] \n",
    "    logpy = jax.scipy.stats.norm.logpdf(ys,loc=zs,scale=0.0001).sum(axis=0).mean(axis=0)\n",
    "    loss = -logpy + kl * kl_scheduler.val\n",
    "    return loss\n",
    "\n",
    "def forward(ts, batch_size,params,key):\n",
    "    def f(t, y,args):\n",
    "        t = jnp.full_like(y, t)\n",
    "        return net(params[2:],jnp.concatenate((jnp.sin(t),jnp.cos(t),jnp.sin(t**2),jnp.cos(t**2),y),axis=-1))\n",
    "\n",
    "    def g(t, y,args):  # Shared diffusion.\n",
    "        return jnp.ones((jnp.size(y,0),1))*sigma\n",
    "\n",
    "    def h(t, y,args):  # Prior drift.\n",
    "        return theta * (mu - y)\n",
    "\n",
    "    def f_aug(t, y,args):  # Drift for augmented dynamics with logqp term.\n",
    "        y = y[:, 0:1] # 提取第一列，保持列的形态\n",
    "        fv, gv, hv = f(t, y,args), g(t, y,args), h(t, y,args)\n",
    "        u = _stable_division(fv - hv, gv) # 计算u(z,t)\n",
    "        f_logqp = .5 * (u ** 2).sum(axis=1, keepdims=True) # 计算integral\n",
    "        return jnp.concatenate([fv, f_logqp], axis=1)\n",
    "\n",
    "    def g_aug(t, y,args):  # Diffusion for augmented dynamics with logqp term.\n",
    "        y = y[:, 0:1]\n",
    "        gv = g(t, y,args)\n",
    "        g_logqp = jnp.zeros_like(y)\n",
    "        return jnp.concatenate([gv, g_logqp], axis=1)\n",
    "    t0 = ts[0]\n",
    "    t1 = ts[-1]\n",
    "    dt0 = 0.01\n",
    "    qy0_mean = params[0]\n",
    "    qy0_std = get_std(params[1])\n",
    "    eps_key,bm_key = jrandom.split(key,2)\n",
    "    eps = jrandom.normal(key=eps_key,shape=(batch_size,1))\n",
    "    y0 = qy0_mean + eps * qy0_std\n",
    "    logqp0 = jnp.log(qy0_std/py0_std+(py0_std**2+(py0_mean-qy0_mean)**2)/(2*qy0_std**2)-0.5)\n",
    "    logqp0 = logqp0.sum(axis=1)\n",
    "    aug_y0 = jnp.concatenate([y0, jnp.zeros((batch_size,1))],axis=1)\n",
    "        \n",
    "    #control = diffrax.VirtualBrownianTree(t0=ts[0],t1=ts[-1],tol=0.5,shape=(),key=bm_key)\n",
    "    #control = diffrax.UnsafeBrownianPath(shape=(),key=bm_key)\n",
    "    control = diffrax.VirtualBrownianTree(t0=t0,t1=t1,tol=dt0/2,shape=(batch_size,2),key=bm_key)\n",
    "    vf = diffrax.ODETerm(f_aug)\n",
    "    cvf = diffrax.ControlTerm(g_aug, control)\n",
    "    terms = diffrax.MultiTerm(vf,cvf)\n",
    "    solver = diffrax.Euler()\n",
    "    saveat=diffrax.SaveAt(ts=ts)\n",
    "    sol = diffrax.diffeqsolve(terms, solver, t0,t1,dt0,y0=aug_y0,saveat=saveat)\n",
    "    aug_ys = sol.ys\n",
    "    ys, logqp_path = aug_ys[:, :, 0:1], aug_ys[-1, :, 1]\n",
    "    logqp = (logqp0+logqp_path).mean()\n",
    "    return ys, logqp\n",
    "def sample_p(ts, batch_size,eps,control,key):\n",
    "    \n",
    "    \n",
    "    def g(t, y,args):  # Shared diffusion.\n",
    "        return jnp.ones((jnp.size(y,0),1))*sigma\n",
    "\n",
    "    def h(t, y,args):  # Prior drift.\n",
    "        return theta * (mu - y)\n",
    "    \n",
    "    t0 = ts[0]\n",
    "    t1 = ts[-1]\n",
    "    dt0 = 0.01\n",
    "    eps_key,bm_key = jrandom.split(key,2)\n",
    "    y0 = py0_mean + eps * py0_std\n",
    "    vf = diffrax.ODETerm(h)\n",
    "    cvf = diffrax.ControlTerm(g, control)\n",
    "    terms = diffrax.MultiTerm(vf,cvf)\n",
    "    solver = diffrax.Euler()\n",
    "    saveat=diffrax.SaveAt(ts=ts)\n",
    "    sol = diffrax.diffeqsolve(terms, solver, t0,t1,dt0,y0=y0,saveat=saveat,adjoint=diffrax.NoAdjoint())\n",
    "    return sol.ys\n",
    "\n",
    "def sample_q(ts, batch_size, params,eps,control,key):\n",
    "    def f(t, y,args):\n",
    "        t = jnp.full_like(y, t)\n",
    "        return net(params[2:],jnp.concatenate((jnp.sin(t),jnp.cos(t),y),axis=-1))\n",
    "\n",
    "    def g(t, y,args):  # Shared diffusion.\n",
    "        return jnp.ones((jnp.size(y,0),1))*sigma\n",
    "    t0 = ts[0]\n",
    "    t1 = ts[-1]\n",
    "    dt0 = 0.01\n",
    "    eps_key,bm_key = jrandom.split(key,2)\n",
    "    qy0_mean = params[0]\n",
    "    qy0_std = get_std(params[1])\n",
    "    y0 = qy0_mean + eps * qy0_std\n",
    "    vf = diffrax.ODETerm(f)\n",
    "    cvf = diffrax.ControlTerm(g, control)\n",
    "    terms = diffrax.MultiTerm(vf,cvf)\n",
    "    solver = diffrax.Euler()\n",
    "    saveat=diffrax.SaveAt(ts=ts)\n",
    "    sol = diffrax.diffeqsolve(terms, solver, t0,t1,dt0,y0=y0,saveat=saveat,adjoint=diffrax.NoAdjoint())\n",
    "    return sol.ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f004c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def update(params, ts, ys, opt_state,key):\n",
    "    value, grads = value_and_grad(loss)(params,ts,ys,key)\n",
    "    opt_state = opt_update(0,grads, opt_state)\n",
    "    return get_params(opt_state),opt_state, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44a3c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_init, opt_update, get_params = optimizers.adam(1e-2)\n",
    "opt_state = opt_init(params)\n",
    "kl_scheduler = LinearScheduler(iters=100)\n",
    "    \n",
    "logpy_metric = EMAMetric()\n",
    "kl_metric = EMAMetric()\n",
    "loss_metric = EMAMetric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a1fc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributions\n",
    "def main(opt_state,num_epochs = 500):\n",
    "    \n",
    "    \n",
    "    ts, ts_ext, ts_vis, ys = make_data()\n",
    "    p_key,eps_key, bm_key,per_key,k1 = jrandom.split(key,5)\n",
    "    vis_batch_size = 1024\n",
    "    ylims = (-0.03, 0.03)\n",
    "    \n",
    "    alphas = [0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.55]\n",
    "    percentiles = [0.999, 0.99, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1]\n",
    "    vis_idx = jrandom.permutation(key=per_key,x=vis_batch_size)\n",
    "    sample_colors = ('#8c96c6', '#8c6bb1', '#810f7c')\n",
    "    fill_color = '#9ebcda'\n",
    "    mean_color = '#4d004b'\n",
    "    num_samples = len(sample_colors)\n",
    "    eps = jrandom.normal(key=eps_key,shape=(vis_batch_size,1))\n",
    "    control = diffrax.VirtualBrownianTree(t0=ts_vis[0],t1=ts_vis[-1],tol=1e-2/2,shape=(vis_batch_size,1),key=jrandom.PRNGKey(1))\n",
    "    #control = diffrax.UnsafeBrownianPath(shape=(),key=bm_key)\n",
    "    sigma = jnp.std(ys)\n",
    "    params = get_params(opt_state)\n",
    "    \n",
    "    # plot prior\n",
    "    zs = sample_p(ts_vis,batch_size,eps,control,p_key).squeeze()\n",
    "    zs = jnp.sort(zs,axis=1)\n",
    "    plt.subplot(frameon=False)\n",
    "    for alpha, percentile in zip(alphas, percentiles):\n",
    "        idx = int((1 - percentile) / 2. * vis_batch_size)\n",
    "        zs_bot = zs[:, idx]\n",
    "        zs_top = zs[:, -idx]\n",
    "        \n",
    "        plt.fill_between(ts_vis, zs_bot, zs_top, alpha=alpha, color=fill_color)\n",
    "\n",
    "    \n",
    "    plt.scatter(ts, ys, marker='x', zorder=3, color='k', s=35)  # Data.\n",
    "    plt.plot(ts, ys, marker='x', zorder=3, color='k',label=\"observed $r_t$\")\n",
    "    #plt.plot(ts, z[:,None], color='g', linewidth=3.0, label=r\"hidden variable $z_t$\")\n",
    "    plt.ylim(ylims)\n",
    "    plt.xlabel('$t$')\n",
    "    plt.ylabel('$Y_t$')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.legend()\n",
    "    #plt.savefig('./img_diffrax/prior.png', dpi=300)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # for loop\n",
    "    for epoch in range(num_epochs):\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            img_path = os.path.join(\"./img_diffrax/\", f'global_step_{epoch+1}.png')\n",
    "            zs = sample_q(ts_vis,batch_size,params,eps,control,p_key).squeeze()\n",
    "            plt.plot(ts_vis, zs.mean(axis=1), color='r',label=r'mean of latent variables')\n",
    "            plt.scatter(ts, ys, marker='x', zorder=3, color='k', s=35)  # Data.\n",
    "            plt.plot(ts, ys, marker='x', zorder=3, color='k',label=\"observed $r_t$\")\n",
    "            #plt.plot(ts, z[:,None], color='g', linewidth=3.0, label=r\"hidden variable $z_t$\")\n",
    "            plt.ylim(ylims)\n",
    "            plt.xlabel('$t$')\n",
    "            plt.ylabel('$Y_t$')\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.legend()\n",
    "            #plt.savefig(img_path, dpi=300)\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "        start_time = time.time()\n",
    "        params, opt_state, loss = update(params, ts_ext,ys, opt_state,k1)\n",
    "        \n",
    "        loss_metric.step(loss)\n",
    "        kl_scheduler.step()\n",
    "        epoch_time = time.time()-start_time\n",
    "        print(\"Epoch {} | T: {:0.2f} | loss {:0.3f}\".format(epoch+1,epoch_time,loss))\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b55c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "main(opt_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c94566",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3af46cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
