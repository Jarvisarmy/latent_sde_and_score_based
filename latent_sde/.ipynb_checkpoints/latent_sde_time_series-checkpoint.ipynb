{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4dd7b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from collections import namedtuple\n",
    "from typing import Optional, Union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import tqdm\n",
    "from torch import distributions, nn, optim\n",
    "\n",
    "import torchsde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0aeebbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the gpu is available or not, if yes, use gpu\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2902c1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the tuple for data, \n",
    "Data = namedtuple('Data', ['ts_', 'ts_ext_', 'ts_vis_', 'ts', 'ts_ext', 'ts_vis', 'ys', 'ys_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9198a09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"train_iters\": 1000,\n",
    "    \"pause_iters\": 50,\n",
    "    \"hide_ticks\": False,\n",
    "    \"save_ckpt\":True,\n",
    "    \"likelihood\":\"laplace\",\n",
    "    \"scale\": 0.05,\n",
    "    \"adjoint\": True,\n",
    "    \"debug\": True,\n",
    "    \"seed\": 42,\n",
    "    'data':'segmented_cosine',\n",
    "    \"dt\": 1e-2,\n",
    "    \"batch_size\": 256,\n",
    "    \"method\": 'euler',\n",
    "    \"adaptive\": 'False',\n",
    "    \"rtol\": 1e-3,\n",
    "    \"atol\": 1e-3\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40420fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output values from 0 to maxval with iters steps\n",
    "class LinearScheduler(object):\n",
    "    def __init__(self, iters, maxval=1.0):\n",
    "        self._iters = max(1,iters)\n",
    "        self._val = maxval/self._iters\n",
    "        self._maxval = maxval\n",
    "    \n",
    "    def step(self):\n",
    "        self._val = min(self._maxval, self._val+self._maxval/self._iters)\n",
    "        \n",
    "    @property\n",
    "    def val(self):\n",
    "        return self._val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93c09c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EMAMetric(object):\n",
    "    def __init__(self, gamma: Optional[float]=0.99):\n",
    "        super(EMAMetric, self).__init__()\n",
    "        self._val=0\n",
    "        self._gamma = gamma\n",
    "    def step(self, x:Union[torch.Tensor, np.ndarray]):\n",
    "        x = x.detach().cpu().numpy() if torch.is_tensor(x) else x\n",
    "        self._val = self._gamma * self._val + (1-self._gamma)*x\n",
    "        return self._val\n",
    "    \n",
    "    @property\n",
    "    def val(self):\n",
    "        return self._val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a4ec86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the seed\n",
    "def manual_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98a2f4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure that the dvision is stable\n",
    "def _stable_division(a,b,epsilon=1e-7):\n",
    "    b = torch.where(b.abs().detach() > epsilon, b, torch.full_like(b, fill_value=epsilon)*b.sign())\n",
    "    return a/b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "522d3e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LatentSDE(torchsde.SDEIto): # sde with ito calculus\n",
    "    def __init__(self, theta=1.0, mu=0.0, sigma=0.5):\n",
    "        super(LatentSDE, self).__init__(noise_type=\"diagonal\")\n",
    "        logvar = math.log(sigma ** 2/(2.*theta))\n",
    "        \n",
    "        # prior drift\n",
    "        self.register_buffer(\"theta\",torch.tensor([[theta]])) # prior parameters, register 成buffer, 参数不会进行更新\n",
    "        self.register_buffer(\"mu\", torch.tensor([[mu]]))\n",
    "        self.register_buffer(\"sigma\",torch.tensor([[sigma]]))\n",
    "        \n",
    "        # p(y0)\n",
    "        self.register_buffer(\"py0_mean\", torch.tensor([[mu]]))\n",
    "        self.register_buffer(\"py0_logvar\", torch.tensor([[logvar]]))\n",
    "        \n",
    "        # approximate posterior drift: Takes in 2 positional encodings and the state\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(3,200),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(200,200),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(200,1)\n",
    "        )\n",
    "        \n",
    "        # Initialization the parameters\n",
    "        self.net[-1].weight.data.fill_(0.) # 初始化最后一层的参数\n",
    "        self.net[-1].bias.data.fill_(0.)\n",
    "            \n",
    "        # q(y0)\n",
    "        self.qy0_mean = nn.Parameter(torch.tensor([[mu]]), requires_grad=True) # 创建parameters\n",
    "        self.qy0_logvar = nn.Parameter(torch.tensor([[logvar]]), requires_grad=True) # 创建parameters\n",
    "            \n",
    "    def f(self, t, y):  # Approximate posterior drift.\n",
    "        if t.dim() == 0:\n",
    "            t = torch.full_like(y, fill_value=t) # create a tensor of t\n",
    "        # Positional encoding in transformers for time-inhomogeneous posterior.\n",
    "        return self.net(torch.cat((torch.sin(t), torch.cos(t), y), dim=-1))\n",
    "\n",
    "    def g(self, t, y):  # Shared diffusion.\n",
    "        return self.sigma.repeat(y.size(0), 1) # 重复复制, 创建一个size为[y.size[0],1]\n",
    "\n",
    "    def h(self, t, y):  # Prior drift.\n",
    "        return self.theta * (self.mu - y)\n",
    "\n",
    "    def f_aug(self, t, y):  # Drift for augmented dynamics with logqp term.\n",
    "        y = y[:, 0:1] # 提取第一列，保持列的形态\n",
    "        f, g, h = self.f(t, y), self.g(t, y), self.h(t, y)\n",
    "        u = _stable_division(f - h, g) # 计算u(z,t)\n",
    "        f_logqp = .5 * (u ** 2).sum(dim=1, keepdim=True) # 计算integral\n",
    "        return torch.cat([f, f_logqp], dim=1)\n",
    "\n",
    "    def g_aug(self, t, y):  # Diffusion for augmented dynamics with logqp term.\n",
    "        y = y[:, 0:1]\n",
    "        g = self.g(t, y)\n",
    "        g_logqp = torch.zeros_like(y)\n",
    "        return torch.cat([g, g_logqp], dim=1)\n",
    "\n",
    "    def forward(self, ts, batch_size, eps=None):\n",
    "        eps = torch.randn(batch_size, 1).to(self.qy0_std) if eps is None else eps\n",
    "        y0 = self.qy0_mean + eps * self.qy0_std # the latent variable\n",
    "        qy0 = distributions.Normal(loc=self.qy0_mean, scale=self.qy0_std) # approximate posterior distribution\n",
    "        py0 = distributions.Normal(loc=self.py0_mean, scale=self.py0_std) # prior distribution\n",
    "        logqp0 = distributions.kl_divergence(qy0, py0).sum(dim=1)  # KL(t=0). calculate the kl divergence\n",
    "        #print(y0.size()) # (256, 1)\n",
    "        aug_y0 = torch.cat([y0, torch.zeros(batch_size, 1).to(y0)], dim=1) # create the augmented initial value\n",
    "        #print(aug_y0.size()) # [256, 2]\n",
    "        aug_ys = sdeint_fn(\n",
    "            sde=self,\n",
    "            y0=aug_y0,\n",
    "            ts=ts,\n",
    "            method=args['method'],\n",
    "            dt=args['dt'],\n",
    "            adaptive=args['adaptive'],\n",
    "            rtol=args['rtol'],\n",
    "            atol=args['atol'],\n",
    "            names={'drift': 'f_aug', 'diffusion': 'g_aug'}\n",
    "        ) # call the sde solver to \n",
    "        # print(aug_ys.size()) # [22, 256, 2]\n",
    "        ys, logqp_path = aug_ys[:, :, 0:1], aug_ys[-1, :, 1] # get the integral of the u(z,t) at the last time\n",
    "        \n",
    "        logqp = (logqp0 + logqp_path).mean(dim=0)  # KL(t=0) + KL(path).\n",
    "        return ys, logqp\n",
    "\n",
    "    def sample_p(self, ts, batch_size, eps=None, bm=None):\n",
    "        eps = torch.randn(batch_size, 1).to(self.py0_mean) if eps is None else eps\n",
    "        y0 = self.py0_mean + eps * self.py0_std\n",
    "        return sdeint_fn(self, y0, ts, bm=bm, method=args['method'], dt=args['dt'], names={'drift': 'h'}) # prior sde\n",
    "\n",
    "    def sample_q(self, ts, batch_size, eps=None, bm=None):\n",
    "        eps = torch.randn(batch_size, 1).to(self.qy0_mean) if eps is None else eps\n",
    "        y0 = self.qy0_mean + eps * self.qy0_std\n",
    "        return sdeint_fn(self, y0, ts, bm=bm, method=args['method'], dt=args['dt']) # posterior sde\n",
    "\n",
    "    @property\n",
    "    def py0_std(self):\n",
    "        return torch.exp(.5 * self.py0_logvar)\n",
    "\n",
    "    @property\n",
    "    def qy0_std(self):\n",
    "        return torch.exp(.5 * self.qy0_logvar)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80736fff",
   "metadata": {},
   "source": [
    "## 5. Simulation of time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd15aaa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "T = 120\n",
    "beta = 0.1694\n",
    "def make_time_series():\n",
    "    \n",
    "    \n",
    "    phi = 0.9805\n",
    "    sigma_v = 0.003342\n",
    "    sigma_u = 0.0528\n",
    "    rho = -0.856\n",
    "    cov_uv = rho * sigma_u * sigma_v\n",
    "\n",
    "    # generating shocks\n",
    "    mu = [0,0]\n",
    "    cov = [[sigma_u**2, cov_uv], [cov_uv, sigma_v**2]]\n",
    "    shocks = np.random.multivariate_normal(mu, cov, T)\n",
    "\n",
    "    z0 = np.random.normal(0, sigma_u**2/(1-phi**2),1)\n",
    "    r0 = shocks[0][0]\n",
    "\n",
    "    z = np.zeros(T)\n",
    "    r = np.zeros(T)\n",
    "    z[0] = z0\n",
    "    r[0] = r0\n",
    "\n",
    "    for idx_t in range(T-1):\n",
    "        z[idx_t+1] = phi*z[idx_t] + shocks[idx_t+1][1]\n",
    "        r[idx_t+1] = beta*z[idx_t] + shocks[idx_t+1][0]\n",
    "    return z, r\n",
    "z, r = make_time_series()\n",
    "plt.figure(figsize=(15,5))\n",
    "xvalues = np.array(range(T))\n",
    "plt.plot(xvalues, r, linestyle='-', color='g', label=\"observed $r_t$\")\n",
    "plt.plot(xvalues, beta*z, linestyle=\"--\", color=\"r\", label=r\"hidden variable $\\beta * z_t$\", linewidth=3.0)\n",
    "\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('%')\n",
    "plt.grid(True)\n",
    "plt.title(r\"Simulated $r_t$ and hidden $\\beta * z_t$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cf9fca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data():\n",
    "    ts_ = np.linspace(0.1,12.0,120)\n",
    "    ts_ext_ = np.array([0.] + list(ts_) + [12.1])\n",
    "    ts_vis_ = np.linspace(0.1, 12.1, 121)\n",
    "    ys_ = r[:,None]\n",
    "    ts = torch.tensor(ts_).float()\n",
    "    ts_ext = torch.tensor(ts_ext_).float()\n",
    "    ts_vis = torch.tensor(ts_vis_).float()\n",
    "    ys = torch.tensor(ys_).float().to(device)\n",
    "    return Data(ts_, ts_ext_, ts_vis_, ts, ts_ext, ts_vis, ys, ys_)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a1fc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Dataset\n",
    "    ts_, ts_ext_, ts_vis_, ts, ts_ext, ts_vis, ys, ys_ = make_data()\n",
    "    \n",
    "    # plotting parameters\n",
    "    vis_batch_size = 128\n",
    "    ylims = (-0.3, 0.3)\n",
    "    alphas = [0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.55]\n",
    "    percentiles = [0.999, 0.99, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1]\n",
    "    vis_idx = np.random.permutation(vis_batch_size)\n",
    "    sample_colors = ('#8c96c6', '#8c6bb1', '#810f7c')\n",
    "    fill_color = '#9ebcda'\n",
    "    mean_color = '#4d004b'\n",
    "    num_samples = len(sample_colors)\n",
    "    \n",
    "    eps = torch.randn(vis_batch_size, 1).to(device)\n",
    "    bm = torchsde.BrownianInterval(\n",
    "        t0=ts_vis[0],\n",
    "        t1=ts_vis[-1],\n",
    "        size=(vis_batch_size,1),\n",
    "        device=device,\n",
    "        levy_area_approximation=\"space-time\")\n",
    "    \n",
    "    # Model\n",
    "    model = LatentSDE().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\n",
    "    kl_scheduler = LinearScheduler(iters=100)\n",
    "    \n",
    "    logpy_metric = EMAMetric()\n",
    "    kl_metric = EMAMetric()\n",
    "    loss_metric = EMAMetric()\n",
    "    \n",
    "    \n",
    "    # show prior\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        zs = model.sample_p(ts=ts_vis, batch_size = vis_batch_size, eps = eps, bm=bm).squeeze()\n",
    "       \n",
    "        ts_vis_, zs_ = ts_vis.cpu().numpy(), zs.cpu().numpy()\n",
    "        #plt.scatter(ts_vis_, ys_, color='r', label=\"prior\")\n",
    "        zs_ = np.sort(zs_,axis=1)\n",
    "        img_dir = os.path.join('./sim/','prior.png')\n",
    "        plt.subplot(frameon=False)\n",
    "        for alpha, percentile in zip(alphas, percentiles):\n",
    "            idx = int((1 - percentile) / 2. * vis_batch_size)\n",
    "            zs_bot_ = zs_[:, idx]\n",
    "            zs_top_ = zs_[:, -idx]\n",
    "            plt.fill_between(ts_vis_, zs_bot_, zs_top_, alpha=alpha, color=fill_color)\n",
    "\n",
    "        # `zorder` determines who's on top; the larger the more at the top.\n",
    "        \n",
    "        plt.scatter(ts_, ys_, marker='x', zorder=3, color='k', s=35)  # Data.\n",
    "        plt.plot(ts_, ys_, marker='x', zorder=3, color='k',label=\"observed $r_t$\")\n",
    "        plt.plot(ts_, z[:,None], color='g', linewidth=3.0, label=r\"hidden variable $z_t$\")\n",
    "        plt.ylim(ylims)\n",
    "        plt.xlabel('$t$')\n",
    "        plt.ylabel('$Y_t$')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.legend()\n",
    "        plt.savefig(img_dir, dpi=300)\n",
    "        plt.close()\n",
    "        logging.info(f'Saved prior figure at: {img_dir}')\n",
    "    \n",
    "    \n",
    "    for global_step in tqdm.tqdm(range(args['train_iters'])):\n",
    "        \n",
    "        # Plot and save.\n",
    "        if global_step % args['pause_iters'] == 0:\n",
    "            img_path = os.path.join(\"./sim/\", f'global_step_{global_step}.png')\n",
    "\n",
    "            with torch.no_grad():\n",
    "                zs = model.sample_q(ts=ts_vis, batch_size=vis_batch_size, eps=eps, bm=bm).squeeze()\n",
    "                samples = zs[:, vis_idx]\n",
    "                ts_vis_, zs_, samples_ = ts_vis.cpu().numpy(), zs.cpu().numpy(), samples.cpu().numpy()\n",
    "                zs_ = np.sort(zs_, axis=1)\n",
    "                plt.subplot(frameon=False)\n",
    "\n",
    "                if True: # args.show_percentiles:\n",
    "                    for alpha, percentile in zip(alphas, percentiles):\n",
    "                        idx = int((1 - percentile) / 2. * vis_batch_size)\n",
    "                        zs_bot_, zs_top_ = zs_[:, idx], zs_[:, -idx]\n",
    "                        plt.fill_between(ts_vis_, zs_bot_, zs_top_, alpha=alpha, color=fill_color)\n",
    "\n",
    "                if True: #args.show_mean:\n",
    "                    plt.plot(ts_vis_, zs_.mean(axis=1), color=mean_color)\n",
    "\n",
    "                if True: #args.show_samples:\n",
    "                    #for j in range(num_samples):\n",
    "                    #    plt.plot(ts_vis_, samples_[:, j], color=sample_colors[j], linewidth=1.0)\n",
    "                    plt.plot(ts_, z[:,None], color='g', linewidth=3.0, label=r\"hidden variable $z_t$\")\n",
    "                    plt.plot(ts_vis_, samples_.mean(axis=1), marker='o', color='r',label=r'mean of latent variables')\n",
    "\n",
    "                if True: #args.show_arrows:\n",
    "                    num, dt = 12, 0.12\n",
    "                    t, y = torch.meshgrid(\n",
    "                        [torch.linspace(0, 12, num).to(device), torch.linspace(-0.3, 0.3, num).to(device)]\n",
    "                    )\n",
    "                    t, y = t.reshape(-1, 1), y.reshape(-1, 1)\n",
    "                    fty = model.f(t=t, y=y).reshape(num, num)\n",
    "                    dt = torch.zeros(num, num).fill_(dt).to(device)\n",
    "                    dy = fty * dt\n",
    "                    dt_, dy_, t_, y_ = dt.cpu().numpy(), dy.cpu().numpy(), t.cpu().numpy(), y.cpu().numpy()\n",
    "                    plt.quiver(t_, y_, dt_, dy_, alpha=0.3, edgecolors='k', width=0.0035, scale=50)\n",
    "\n",
    "                if False: #args.hide_ticks:\n",
    "                    plt.xticks([], [])\n",
    "                    plt.yticks([], [])\n",
    "\n",
    "                plt.scatter(ts_, ys_, marker='x', zorder=3, color='k', s=35)  # Data.\n",
    "                plt.plot(ts_, ys_, marker='x', zorder=3, color='k', label=\"observed $r_t$ \") # new added\n",
    "                plt.ylim(ylims)\n",
    "                plt.xlabel('$t$')\n",
    "                plt.ylabel('$Y_t$')\n",
    "                plt.tight_layout()\n",
    "                plt.legend()\n",
    "                plt.savefig(img_path, dpi=300)\n",
    "                plt.close()\n",
    "                logging.info(f'Saved figure at: {img_path}')\n",
    "\n",
    "                \n",
    "        \n",
    "        # Train.\n",
    "        optimizer.zero_grad() # zero the gradient\n",
    "        zs, kl = model(ts=ts_ext, batch_size=args['batch_size']) # pass through the model, ys, logqp\n",
    "        zs = zs.squeeze() # remove the dimensions of input of size 1\n",
    "        zs = zs[1:-1]  # Drop first and last which are only used to penalize out-of-data region and spread uncertainty.\n",
    "\n",
    "        likelihood_constructor = {\"laplace\": distributions.Laplace, \"normal\": distributions.Normal}[args['likelihood']]\n",
    "        likelihood = likelihood_constructor(loc=zs, scale=args['scale']) # create the laplace distribution\n",
    "        logpy = likelihood.log_prob(ys).sum(dim=0).mean(dim=0) # got the log likelihood\n",
    "\n",
    "        loss = -logpy + kl * kl_scheduler.val\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        kl_scheduler.step()\n",
    "\n",
    "        logpy_metric.step(logpy)\n",
    "        kl_metric.step(kl)\n",
    "        loss_metric.step(loss)\n",
    "\n",
    "        logging.info(\n",
    "            f'global_step: {global_step}, '\n",
    "            f'logpy: {logpy_metric.val:.3f}, '\n",
    "            f'kl: {kl_metric.val:.3f}, '\n",
    "            f'loss: {loss_metric.val:.3f}'\n",
    "        )\n",
    "    torch.save(\n",
    "        {'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'scheduler': scheduler.state_dict(),\n",
    "            'kl_scheduler': kl_scheduler},\n",
    "        os.path.join('./sim/', f'global_step_{global_step}.ckpt')\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74b55c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saved prior figure at: ./sim/prior.png\n",
      "  0%|                                                                                         | 0/1000 [00:00<?, ?it/s]INFO:root:Saved figure at: ./sim/global_step_0.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 0, logpy: -20.419, kl: 0.397, loss: 20.423\n",
      "  0%|                                                                               | 1/1000 [00:07<2:03:53,  7.44s/it]INFO:root:global_step: 1, logpy: -30.834, kl: 0.470, loss: 30.840\n",
      "  0%|▏                                                                              | 2/1000 [00:12<1:40:12,  6.02s/it]INFO:root:global_step: 2, logpy: -37.127, kl: 0.503, loss: 37.133\n",
      "  0%|▏                                                                              | 3/1000 [00:18<1:37:38,  5.88s/it]INFO:root:global_step: 3, logpy: -38.146, kl: 0.549, loss: 38.154\n",
      "  0%|▎                                                                              | 4/1000 [00:25<1:45:52,  6.38s/it]INFO:root:global_step: 4, logpy: -38.652, kl: 0.665, loss: 38.667\n",
      "  0%|▍                                                                              | 5/1000 [00:33<1:58:51,  7.17s/it]INFO:root:global_step: 5, logpy: -39.088, kl: 0.858, loss: 39.114\n",
      "  1%|▍                                                                              | 6/1000 [00:43<2:13:09,  8.04s/it]INFO:root:global_step: 6, logpy: -39.099, kl: 1.129, loss: 39.145\n",
      "  1%|▌                                                                              | 7/1000 [00:54<2:27:59,  8.94s/it]INFO:root:global_step: 7, logpy: -38.532, kl: 1.476, loss: 38.605\n",
      "  1%|▋                                                                              | 8/1000 [01:05<2:39:45,  9.66s/it]INFO:root:global_step: 8, logpy: -37.572, kl: 1.896, loss: 37.684\n",
      "  1%|▋                                                                              | 9/1000 [01:17<2:50:33, 10.33s/it]INFO:root:global_step: 9, logpy: -36.519, kl: 2.402, loss: 36.682\n",
      "  1%|▊                                                                             | 10/1000 [01:30<3:02:58, 11.09s/it]INFO:root:global_step: 10, logpy: -35.470, kl: 2.983, loss: 35.698\n",
      "  1%|▊                                                                             | 11/1000 [01:44<3:18:11, 12.02s/it]INFO:root:global_step: 11, logpy: -34.418, kl: 3.640, loss: 34.727\n",
      "  1%|▉                                                                             | 12/1000 [01:59<3:32:31, 12.91s/it]INFO:root:global_step: 12, logpy: -33.330, kl: 4.380, loss: 33.736\n",
      "  1%|█                                                                             | 13/1000 [02:14<3:45:38, 13.72s/it]INFO:root:global_step: 13, logpy: -32.114, kl: 5.190, loss: 32.636\n",
      "  1%|█                                                                             | 14/1000 [02:30<3:57:10, 14.43s/it]INFO:root:global_step: 14, logpy: -30.820, kl: 6.081, loss: 31.479\n",
      "  2%|█▏                                                                            | 15/1000 [02:47<4:07:43, 15.09s/it]INFO:root:global_step: 15, logpy: -29.460, kl: 7.035, loss: 30.274\n",
      "  2%|█▏                                                                            | 16/1000 [03:04<4:17:59, 15.73s/it]INFO:root:global_step: 16, logpy: -28.084, kl: 8.048, loss: 29.074\n",
      "  2%|█▎                                                                            | 17/1000 [03:22<4:26:59, 16.30s/it]INFO:root:global_step: 17, logpy: -26.699, kl: 9.106, loss: 27.884\n",
      "  2%|█▍                                                                            | 18/1000 [03:40<4:34:56, 16.80s/it]INFO:root:global_step: 18, logpy: -25.325, kl: 10.241, loss: 26.731\n",
      "  2%|█▍                                                                            | 19/1000 [03:58<4:42:41, 17.29s/it]INFO:root:global_step: 19, logpy: -23.947, kl: 11.425, loss: 25.597\n",
      "  2%|█▌                                                                            | 20/1000 [04:17<4:49:37, 17.73s/it]INFO:root:global_step: 20, logpy: -22.564, kl: 12.659, loss: 24.480\n",
      "  2%|█▋                                                                            | 21/1000 [04:36<4:56:02, 18.14s/it]INFO:root:global_step: 21, logpy: -21.161, kl: 13.924, loss: 23.364\n",
      "  2%|█▋                                                                            | 22/1000 [04:56<5:03:03, 18.59s/it]INFO:root:global_step: 22, logpy: -19.739, kl: 15.229, loss: 22.252\n",
      "  2%|█▊                                                                            | 23/1000 [05:15<5:07:49, 18.90s/it]INFO:root:global_step: 23, logpy: -18.302, kl: 16.552, loss: 21.144\n",
      "  2%|█▊                                                                            | 24/1000 [05:35<5:13:12, 19.25s/it]INFO:root:global_step: 24, logpy: -16.885, kl: 17.886, loss: 20.073\n",
      "  2%|█▉                                                                            | 25/1000 [05:55<5:12:17, 19.22s/it]INFO:root:global_step: 25, logpy: -15.471, kl: 19.246, loss: 19.028\n",
      "  3%|██                                                                            | 26/1000 [06:14<5:12:33, 19.25s/it]INFO:root:global_step: 26, logpy: -14.078, kl: 20.611, loss: 18.019\n",
      "  3%|██                                                                            | 27/1000 [06:33<5:13:07, 19.31s/it]INFO:root:global_step: 27, logpy: -12.699, kl: 21.980, loss: 17.042\n",
      "  3%|██▏                                                                           | 28/1000 [06:53<5:13:59, 19.38s/it]INFO:root:global_step: 28, logpy: -11.317, kl: 23.352, loss: 16.078\n",
      "  3%|██▎                                                                           | 29/1000 [07:13<5:16:09, 19.54s/it]INFO:root:global_step: 29, logpy: -9.926, kl: 24.716, loss: 15.119\n",
      "  3%|██▎                                                                           | 30/1000 [07:32<5:16:16, 19.56s/it]INFO:root:global_step: 30, logpy: -8.548, kl: 26.080, loss: 14.188\n",
      "  3%|██▍                                                                           | 31/1000 [07:52<5:17:57, 19.69s/it]INFO:root:global_step: 31, logpy: -7.180, kl: 27.414, loss: 13.275\n",
      "  3%|██▍                                                                           | 32/1000 [08:12<5:17:29, 19.68s/it]INFO:root:global_step: 32, logpy: -5.833, kl: 28.718, loss: 12.387\n",
      "  3%|██▌                                                                           | 33/1000 [08:32<5:18:26, 19.76s/it]INFO:root:global_step: 33, logpy: -4.503, kl: 30.009, loss: 11.529\n",
      "  3%|██▋                                                                           | 34/1000 [08:52<5:17:21, 19.71s/it]INFO:root:global_step: 34, logpy: -3.191, kl: 31.261, loss: 10.689\n",
      "  4%|██▋                                                                           | 35/1000 [09:11<5:16:46, 19.70s/it]INFO:root:global_step: 35, logpy: -1.901, kl: 32.480, loss: 9.875\n",
      "  4%|██▊                                                                           | 36/1000 [09:31<5:14:40, 19.59s/it]INFO:root:global_step: 36, logpy: -0.621, kl: 33.652, loss: 9.070\n",
      "  4%|██▉                                                                           | 37/1000 [09:50<5:14:11, 19.58s/it]INFO:root:global_step: 37, logpy: 0.647, kl: 34.786, loss: 8.277\n",
      "  4%|██▉                                                                           | 38/1000 [10:09<5:12:15, 19.48s/it]INFO:root:global_step: 38, logpy: 1.909, kl: 35.865, loss: 7.481\n",
      "  4%|███                                                                           | 39/1000 [10:29<5:10:24, 19.38s/it]INFO:root:global_step: 39, logpy: 3.151, kl: 36.911, loss: 6.707\n",
      "  4%|███                                                                           | 40/1000 [10:48<5:08:38, 19.29s/it]INFO:root:global_step: 40, logpy: 4.372, kl: 37.912, loss: 5.949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▏                                                                          | 41/1000 [11:06<5:05:55, 19.14s/it]INFO:root:global_step: 41, logpy: 5.572, kl: 38.855, loss: 5.202\n",
      "  4%|███▎                                                                          | 42/1000 [11:25<5:01:23, 18.88s/it]INFO:root:global_step: 42, logpy: 6.744, kl: 39.758, loss: 4.477\n",
      "  4%|███▎                                                                          | 43/1000 [11:43<4:58:37, 18.72s/it]INFO:root:global_step: 43, logpy: 7.877, kl: 40.612, loss: 3.783\n",
      "  4%|███▍                                                                          | 44/1000 [12:01<4:54:13, 18.47s/it]INFO:root:global_step: 44, logpy: 9.000, kl: 41.409, loss: 3.084\n",
      "  4%|███▌                                                                          | 45/1000 [12:19<4:51:20, 18.30s/it]INFO:root:global_step: 45, logpy: 10.107, kl: 42.175, loss: 2.400\n",
      "  5%|███▌                                                                          | 46/1000 [12:37<4:47:51, 18.10s/it]INFO:root:global_step: 46, logpy: 11.194, kl: 42.886, loss: 1.720\n",
      "  5%|███▋                                                                          | 47/1000 [12:54<4:45:17, 17.96s/it]INFO:root:global_step: 47, logpy: 12.259, kl: 43.560, loss: 1.055\n",
      "  5%|███▋                                                                          | 48/1000 [13:11<4:40:58, 17.71s/it]INFO:root:global_step: 48, logpy: 13.299, kl: 44.190, loss: 0.404\n",
      "  5%|███▊                                                                          | 49/1000 [13:29<4:38:57, 17.60s/it]INFO:root:global_step: 49, logpy: 14.310, kl: 44.785, loss: -0.225\n",
      "  5%|███▉                                                                          | 50/1000 [13:46<4:35:55, 17.43s/it]INFO:root:Saved figure at: ./sim/global_step_50.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 50, logpy: 15.296, kl: 45.342, loss: -0.840\n",
      "  5%|███▉                                                                          | 51/1000 [14:04<4:42:05, 17.84s/it]INFO:root:global_step: 51, logpy: 16.260, kl: 45.872, loss: -1.436\n",
      "  5%|████                                                                          | 52/1000 [14:21<4:34:11, 17.35s/it]INFO:root:global_step: 52, logpy: 17.205, kl: 46.373, loss: -2.021\n",
      "  5%|████▏                                                                         | 53/1000 [14:37<4:28:36, 17.02s/it]INFO:root:global_step: 53, logpy: 18.130, kl: 46.836, loss: -2.598\n",
      "  5%|████▏                                                                         | 54/1000 [14:53<4:24:11, 16.76s/it]INFO:root:global_step: 54, logpy: 19.051, kl: 47.268, loss: -3.179\n",
      "  6%|████▎                                                                         | 55/1000 [15:09<4:19:44, 16.49s/it]INFO:root:global_step: 55, logpy: 19.935, kl: 47.671, loss: -3.732\n",
      "  6%|████▎                                                                         | 56/1000 [15:25<4:15:56, 16.27s/it]INFO:root:global_step: 56, logpy: 20.806, kl: 48.051, loss: -4.276\n",
      "  6%|████▍                                                                         | 57/1000 [15:40<4:12:00, 16.03s/it]INFO:root:global_step: 57, logpy: 21.674, kl: 48.401, loss: -4.828\n",
      "  6%|████▌                                                                         | 58/1000 [15:56<4:09:17, 15.88s/it]INFO:root:global_step: 58, logpy: 22.504, kl: 48.734, loss: -5.345\n",
      "  6%|████▌                                                                         | 59/1000 [16:11<4:07:26, 15.78s/it]INFO:root:global_step: 59, logpy: 23.321, kl: 49.055, loss: -5.848\n",
      "  6%|████▋                                                                         | 60/1000 [16:27<4:05:25, 15.67s/it]INFO:root:global_step: 60, logpy: 24.137, kl: 49.350, loss: -6.359\n",
      "  6%|████▊                                                                         | 61/1000 [16:42<4:03:34, 15.56s/it]INFO:root:global_step: 61, logpy: 24.933, kl: 49.640, loss: -6.847\n",
      "  6%|████▊                                                                         | 62/1000 [16:57<4:01:33, 15.45s/it]INFO:root:global_step: 62, logpy: 25.704, kl: 49.917, loss: -7.311\n",
      "  6%|████▉                                                                         | 63/1000 [17:12<3:59:47, 15.36s/it]INFO:root:global_step: 63, logpy: 26.454, kl: 50.179, loss: -7.758\n",
      "  6%|████▉                                                                         | 64/1000 [17:27<3:58:34, 15.29s/it]INFO:root:global_step: 64, logpy: 27.202, kl: 50.428, loss: -8.205\n",
      "  6%|█████                                                                         | 65/1000 [17:42<3:57:07, 15.22s/it]INFO:root:global_step: 65, logpy: 27.948, kl: 50.670, loss: -8.650\n",
      "  7%|█████▏                                                                        | 66/1000 [17:57<3:55:47, 15.15s/it]INFO:root:global_step: 66, logpy: 28.682, kl: 50.906, loss: -9.078\n",
      "  7%|█████▏                                                                        | 67/1000 [18:12<3:54:28, 15.08s/it]INFO:root:global_step: 67, logpy: 29.408, kl: 51.130, loss: -9.502\n",
      "  7%|█████▎                                                                        | 68/1000 [18:27<3:53:18, 15.02s/it]INFO:root:global_step: 68, logpy: 30.120, kl: 51.342, loss: -9.914\n",
      "  7%|█████▍                                                                        | 69/1000 [18:42<3:52:36, 14.99s/it]INFO:root:global_step: 69, logpy: 30.828, kl: 51.558, loss: -10.314\n",
      "  7%|█████▍                                                                        | 70/1000 [18:57<3:51:34, 14.94s/it]INFO:root:global_step: 70, logpy: 31.532, kl: 51.765, loss: -10.709\n",
      "  7%|█████▌                                                                        | 71/1000 [19:12<3:50:55, 14.91s/it]INFO:root:global_step: 71, logpy: 32.210, kl: 51.967, loss: -11.077\n",
      "  7%|█████▌                                                                        | 72/1000 [19:27<3:50:25, 14.90s/it]INFO:root:global_step: 72, logpy: 32.886, kl: 52.170, loss: -11.438\n",
      "  7%|█████▋                                                                        | 73/1000 [19:42<3:49:53, 14.88s/it]INFO:root:global_step: 73, logpy: 33.542, kl: 52.364, loss: -11.779\n",
      "  7%|█████▊                                                                        | 74/1000 [19:56<3:48:40, 14.82s/it]INFO:root:global_step: 74, logpy: 34.201, kl: 52.559, loss: -12.116\n",
      "  8%|█████▊                                                                        | 75/1000 [20:11<3:47:55, 14.78s/it]INFO:root:global_step: 75, logpy: 34.857, kl: 52.754, loss: -12.445\n",
      "  8%|█████▉                                                                        | 76/1000 [20:26<3:47:33, 14.78s/it]INFO:root:global_step: 76, logpy: 35.509, kl: 52.939, loss: -12.772\n",
      "  8%|██████                                                                        | 77/1000 [20:40<3:47:16, 14.77s/it]INFO:root:global_step: 77, logpy: 36.144, kl: 53.127, loss: -13.075\n",
      "  8%|██████                                                                        | 78/1000 [20:55<3:46:54, 14.77s/it]INFO:root:global_step: 78, logpy: 36.786, kl: 53.310, loss: -13.384\n",
      "  8%|██████▏                                                                       | 79/1000 [21:10<3:46:10, 14.73s/it]INFO:root:global_step: 79, logpy: 37.405, kl: 53.490, loss: -13.666\n",
      "  8%|██████▏                                                                       | 80/1000 [21:25<3:47:02, 14.81s/it]INFO:root:global_step: 80, logpy: 38.010, kl: 53.670, loss: -13.930\n",
      "  8%|██████▎                                                                       | 81/1000 [21:40<3:46:26, 14.78s/it]INFO:root:global_step: 81, logpy: 38.628, kl: 53.847, loss: -14.204\n",
      "  8%|██████▍                                                                       | 82/1000 [21:54<3:46:05, 14.78s/it]INFO:root:global_step: 82, logpy: 39.228, kl: 54.023, loss: -14.454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▍                                                                       | 83/1000 [22:09<3:45:41, 14.77s/it]INFO:root:global_step: 83, logpy: 39.823, kl: 54.199, loss: -14.696\n",
      "  8%|██████▌                                                                       | 84/1000 [22:24<3:45:09, 14.75s/it]INFO:root:global_step: 84, logpy: 40.416, kl: 54.368, loss: -14.935\n",
      "  8%|██████▋                                                                       | 85/1000 [22:39<3:44:53, 14.75s/it]INFO:root:global_step: 85, logpy: 40.998, kl: 54.535, loss: -15.161\n",
      "  9%|██████▋                                                                       | 86/1000 [22:53<3:44:35, 14.74s/it]INFO:root:global_step: 86, logpy: 41.571, kl: 54.699, loss: -15.375\n",
      "  9%|██████▊                                                                       | 87/1000 [23:08<3:44:24, 14.75s/it]INFO:root:global_step: 87, logpy: 42.143, kl: 54.855, loss: -15.591\n",
      "  9%|██████▊                                                                       | 88/1000 [23:23<3:43:29, 14.70s/it]INFO:root:global_step: 88, logpy: 42.697, kl: 55.013, loss: -15.782\n",
      "  9%|██████▉                                                                       | 89/1000 [23:37<3:43:38, 14.73s/it]INFO:root:global_step: 89, logpy: 43.254, kl: 55.166, loss: -15.974\n",
      "  9%|███████                                                                       | 90/1000 [23:52<3:42:17, 14.66s/it]INFO:root:global_step: 90, logpy: 43.802, kl: 55.316, loss: -16.157\n",
      "  9%|███████                                                                       | 91/1000 [24:07<3:41:54, 14.65s/it]INFO:root:global_step: 91, logpy: 44.338, kl: 55.461, loss: -16.327\n",
      "  9%|███████▏                                                                      | 92/1000 [24:21<3:42:00, 14.67s/it]INFO:root:global_step: 92, logpy: 44.868, kl: 55.603, loss: -16.489\n",
      "  9%|███████▎                                                                      | 93/1000 [24:36<3:41:44, 14.67s/it]INFO:root:global_step: 93, logpy: 45.396, kl: 55.737, loss: -16.653\n",
      "  9%|███████▎                                                                      | 94/1000 [24:50<3:40:36, 14.61s/it]INFO:root:global_step: 94, logpy: 45.926, kl: 55.859, loss: -16.824\n",
      " 10%|███████▍                                                                      | 95/1000 [25:05<3:39:51, 14.58s/it]INFO:root:global_step: 95, logpy: 46.438, kl: 55.980, loss: -16.975\n",
      " 10%|███████▍                                                                      | 96/1000 [25:19<3:39:33, 14.57s/it]INFO:root:global_step: 96, logpy: 46.943, kl: 56.097, loss: -17.119\n",
      " 10%|███████▌                                                                      | 97/1000 [25:34<3:39:17, 14.57s/it]INFO:root:global_step: 97, logpy: 47.444, kl: 56.205, loss: -17.262\n",
      " 10%|███████▋                                                                      | 98/1000 [25:49<3:38:48, 14.55s/it]INFO:root:global_step: 98, logpy: 47.925, kl: 56.316, loss: -17.379\n",
      " 10%|███████▋                                                                      | 99/1000 [26:03<3:37:30, 14.48s/it]INFO:root:global_step: 99, logpy: 48.402, kl: 56.417, loss: -17.497\n",
      " 10%|███████▋                                                                     | 100/1000 [26:17<3:36:58, 14.46s/it]INFO:root:Saved figure at: ./sim/global_step_100.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 100, logpy: 48.859, kl: 56.514, loss: -17.602\n",
      " 10%|███████▊                                                                     | 101/1000 [26:34<3:45:35, 15.06s/it]INFO:root:global_step: 101, logpy: 49.322, kl: 56.605, loss: -17.721\n",
      " 10%|███████▊                                                                     | 102/1000 [26:48<3:41:58, 14.83s/it]INFO:root:global_step: 102, logpy: 49.777, kl: 56.689, loss: -17.842\n",
      " 10%|███████▉                                                                     | 103/1000 [27:02<3:39:24, 14.68s/it]INFO:root:global_step: 103, logpy: 50.226, kl: 56.768, loss: -17.965\n",
      " 10%|████████                                                                     | 104/1000 [27:17<3:37:11, 14.54s/it]INFO:root:global_step: 104, logpy: 50.664, kl: 56.845, loss: -18.081\n",
      " 10%|████████                                                                     | 105/1000 [27:31<3:35:36, 14.45s/it]INFO:root:global_step: 105, logpy: 51.095, kl: 56.911, loss: -18.203\n",
      " 11%|████████▏                                                                    | 106/1000 [27:45<3:33:56, 14.36s/it]INFO:root:global_step: 106, logpy: 51.523, kl: 56.982, loss: -18.319\n",
      " 11%|████████▏                                                                    | 107/1000 [27:59<3:32:19, 14.27s/it]INFO:root:global_step: 107, logpy: 51.929, kl: 57.043, loss: -18.427\n",
      " 11%|████████▎                                                                    | 108/1000 [28:13<3:31:53, 14.25s/it]INFO:root:global_step: 108, logpy: 52.344, kl: 57.100, loss: -18.550\n",
      " 11%|████████▍                                                                    | 109/1000 [28:27<3:31:04, 14.21s/it]INFO:root:global_step: 109, logpy: 52.749, kl: 57.153, loss: -18.669\n",
      " 11%|████████▍                                                                    | 110/1000 [28:41<3:30:17, 14.18s/it]INFO:root:global_step: 110, logpy: 53.143, kl: 57.204, loss: -18.781\n",
      " 11%|████████▌                                                                    | 111/1000 [28:55<3:29:23, 14.13s/it]INFO:root:global_step: 111, logpy: 53.537, kl: 57.253, loss: -18.897\n",
      " 11%|████████▌                                                                    | 112/1000 [29:10<3:29:23, 14.15s/it]INFO:root:global_step: 112, logpy: 53.926, kl: 57.297, loss: -19.016\n",
      " 11%|████████▋                                                                    | 113/1000 [29:24<3:28:13, 14.09s/it]INFO:root:global_step: 113, logpy: 54.301, kl: 57.340, loss: -19.124\n",
      " 11%|████████▊                                                                    | 114/1000 [29:37<3:26:49, 14.01s/it]INFO:root:global_step: 114, logpy: 54.667, kl: 57.379, loss: -19.229\n",
      " 12%|████████▊                                                                    | 115/1000 [29:52<3:27:43, 14.08s/it]INFO:root:global_step: 115, logpy: 55.028, kl: 57.419, loss: -19.331\n",
      " 12%|████████▉                                                                    | 116/1000 [30:06<3:26:55, 14.04s/it]INFO:root:global_step: 116, logpy: 55.399, kl: 57.459, loss: -19.445\n",
      " 12%|█████████                                                                    | 117/1000 [30:20<3:26:15, 14.02s/it]INFO:root:global_step: 117, logpy: 55.776, kl: 57.502, loss: -19.564\n",
      " 12%|█████████                                                                    | 118/1000 [30:34<3:25:54, 14.01s/it]INFO:root:global_step: 118, logpy: 56.140, kl: 57.545, loss: -19.672\n",
      " 12%|█████████▏                                                                   | 119/1000 [30:47<3:25:02, 13.96s/it]INFO:root:global_step: 119, logpy: 56.487, kl: 57.589, loss: -19.764\n",
      " 12%|█████████▏                                                                   | 120/1000 [31:01<3:24:29, 13.94s/it]INFO:root:global_step: 120, logpy: 56.847, kl: 57.628, loss: -19.876\n",
      " 12%|█████████▎                                                                   | 121/1000 [31:15<3:23:39, 13.90s/it]INFO:root:global_step: 121, logpy: 57.203, kl: 57.673, loss: -19.982\n",
      " 12%|█████████▍                                                                   | 122/1000 [31:29<3:23:23, 13.90s/it]INFO:root:global_step: 122, logpy: 57.547, kl: 57.715, loss: -20.079\n",
      " 12%|█████████▍                                                                   | 123/1000 [31:43<3:23:32, 13.93s/it]INFO:root:global_step: 123, logpy: 57.889, kl: 57.762, loss: -20.171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████▌                                                                   | 124/1000 [31:57<3:23:53, 13.97s/it]INFO:root:global_step: 124, logpy: 58.226, kl: 57.805, loss: -20.265\n",
      " 12%|█████████▋                                                                   | 125/1000 [32:11<3:24:26, 14.02s/it]INFO:root:global_step: 125, logpy: 58.564, kl: 57.847, loss: -20.362\n",
      " 13%|█████████▋                                                                   | 126/1000 [32:25<3:24:23, 14.03s/it]INFO:root:global_step: 126, logpy: 58.899, kl: 57.896, loss: -20.452\n",
      " 13%|█████████▊                                                                   | 127/1000 [32:39<3:24:45, 14.07s/it]INFO:root:global_step: 127, logpy: 59.240, kl: 57.941, loss: -20.553\n",
      " 13%|█████████▊                                                                   | 128/1000 [32:53<3:24:03, 14.04s/it]INFO:root:global_step: 128, logpy: 59.579, kl: 57.986, loss: -20.655\n",
      " 13%|█████████▉                                                                   | 129/1000 [33:07<3:24:08, 14.06s/it]INFO:root:global_step: 129, logpy: 59.915, kl: 58.031, loss: -20.755\n",
      " 13%|██████████                                                                   | 130/1000 [33:22<3:24:08, 14.08s/it]INFO:root:global_step: 130, logpy: 60.233, kl: 58.075, loss: -20.840\n",
      " 13%|██████████                                                                   | 131/1000 [33:35<3:22:43, 14.00s/it]INFO:root:global_step: 131, logpy: 60.553, kl: 58.124, loss: -20.925\n",
      " 13%|██████████▏                                                                  | 132/1000 [33:50<3:22:56, 14.03s/it]INFO:root:global_step: 132, logpy: 60.873, kl: 58.176, loss: -21.008\n",
      " 13%|██████████▏                                                                  | 133/1000 [34:04<3:23:14, 14.07s/it]INFO:root:global_step: 133, logpy: 61.191, kl: 58.231, loss: -21.087\n",
      " 13%|██████████▎                                                                  | 134/1000 [34:18<3:23:19, 14.09s/it]INFO:root:global_step: 134, logpy: 61.520, kl: 58.281, loss: -21.185\n",
      " 14%|██████████▍                                                                  | 135/1000 [34:32<3:23:20, 14.10s/it]INFO:root:global_step: 135, logpy: 61.833, kl: 58.334, loss: -21.265\n",
      " 14%|██████████▍                                                                  | 136/1000 [34:46<3:23:07, 14.11s/it]INFO:root:global_step: 136, logpy: 62.153, kl: 58.379, loss: -21.363\n",
      " 14%|██████████▌                                                                  | 137/1000 [35:00<3:23:11, 14.13s/it]INFO:root:global_step: 137, logpy: 62.447, kl: 58.433, loss: -21.427\n",
      " 14%|██████████▋                                                                  | 138/1000 [35:14<3:22:34, 14.10s/it]INFO:root:global_step: 138, logpy: 62.755, kl: 58.477, loss: -21.516\n",
      " 14%|██████████▋                                                                  | 139/1000 [35:28<3:22:04, 14.08s/it]INFO:root:global_step: 139, logpy: 63.075, kl: 58.520, loss: -21.622\n",
      " 14%|██████████▊                                                                  | 140/1000 [35:42<3:22:09, 14.10s/it]INFO:root:global_step: 140, logpy: 63.391, kl: 58.560, loss: -21.727\n",
      " 14%|██████████▊                                                                  | 141/1000 [35:57<3:21:55, 14.10s/it]INFO:root:global_step: 141, logpy: 63.685, kl: 58.608, loss: -21.804\n",
      " 14%|██████████▉                                                                  | 142/1000 [36:11<3:21:40, 14.10s/it]INFO:root:global_step: 142, logpy: 63.971, kl: 58.657, loss: -21.873\n",
      " 14%|███████████                                                                  | 143/1000 [36:25<3:21:39, 14.12s/it]INFO:root:global_step: 143, logpy: 64.266, kl: 58.707, loss: -21.953\n",
      " 14%|███████████                                                                  | 144/1000 [36:39<3:21:39, 14.13s/it]INFO:root:global_step: 144, logpy: 64.562, kl: 58.756, loss: -22.036\n",
      " 14%|███████████▏                                                                 | 145/1000 [36:53<3:21:15, 14.12s/it]INFO:root:global_step: 145, logpy: 64.837, kl: 58.801, loss: -22.103\n",
      " 15%|███████████▏                                                                 | 146/1000 [37:07<3:20:27, 14.08s/it]INFO:root:global_step: 146, logpy: 65.130, kl: 58.842, loss: -22.195\n",
      " 15%|███████████▎                                                                 | 147/1000 [37:21<3:21:12, 14.15s/it]INFO:root:global_step: 147, logpy: 65.408, kl: 58.883, loss: -22.273\n",
      " 15%|███████████▍                                                                 | 148/1000 [37:36<3:20:53, 14.15s/it]INFO:root:global_step: 148, logpy: 65.678, kl: 58.926, loss: -22.342\n",
      " 15%|███████████▍                                                                 | 149/1000 [37:50<3:21:00, 14.17s/it]INFO:root:global_step: 149, logpy: 65.949, kl: 58.970, loss: -22.414\n",
      " 15%|███████████▌                                                                 | 150/1000 [38:04<3:21:04, 14.19s/it]INFO:root:Saved figure at: ./sim/global_step_150.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 150, logpy: 66.213, kl: 59.008, loss: -22.486\n",
      " 15%|███████████▋                                                                 | 151/1000 [38:20<3:29:41, 14.82s/it]INFO:root:global_step: 151, logpy: 66.492, kl: 59.048, loss: -22.572\n",
      " 15%|███████████▋                                                                 | 152/1000 [38:34<3:26:24, 14.60s/it]INFO:root:global_step: 152, logpy: 66.754, kl: 59.089, loss: -22.642\n",
      " 15%|███████████▊                                                                 | 153/1000 [38:48<3:23:19, 14.40s/it]INFO:root:global_step: 153, logpy: 67.026, kl: 59.126, loss: -22.726\n",
      " 15%|███████████▊                                                                 | 154/1000 [39:02<3:21:42, 14.31s/it]INFO:root:global_step: 154, logpy: 67.288, kl: 59.156, loss: -22.811\n",
      " 16%|███████████▉                                                                 | 155/1000 [39:16<3:20:03, 14.21s/it]INFO:root:global_step: 155, logpy: 67.545, kl: 59.192, loss: -22.885\n",
      " 16%|████████████                                                                 | 156/1000 [39:30<3:19:04, 14.15s/it]INFO:root:global_step: 156, logpy: 67.786, kl: 59.233, loss: -22.939\n",
      " 16%|████████████                                                                 | 157/1000 [39:45<3:19:17, 14.18s/it]INFO:root:global_step: 157, logpy: 68.036, kl: 59.268, loss: -23.010\n",
      " 16%|████████████▏                                                                | 158/1000 [39:59<3:19:00, 14.18s/it]INFO:root:global_step: 158, logpy: 68.296, kl: 59.302, loss: -23.094\n",
      " 16%|████████████▏                                                                | 159/1000 [40:13<3:19:01, 14.20s/it]INFO:root:global_step: 159, logpy: 68.531, kl: 59.342, loss: -23.148\n",
      " 16%|████████████▎                                                                | 160/1000 [40:27<3:18:34, 14.18s/it]INFO:root:global_step: 160, logpy: 68.773, kl: 59.375, loss: -23.218\n",
      " 16%|████████████▍                                                                | 161/1000 [40:41<3:17:41, 14.14s/it]INFO:root:global_step: 161, logpy: 69.015, kl: 59.409, loss: -23.286\n",
      " 16%|████████████▍                                                                | 162/1000 [40:55<3:17:31, 14.14s/it]INFO:root:global_step: 162, logpy: 69.257, kl: 59.446, loss: -23.356\n",
      " 16%|████████████▌                                                                | 163/1000 [41:09<3:16:58, 14.12s/it]INFO:root:global_step: 163, logpy: 69.498, kl: 59.479, loss: -23.428\n",
      " 16%|████████████▋                                                                | 164/1000 [41:24<3:16:52, 14.13s/it]INFO:root:global_step: 164, logpy: 69.741, kl: 59.512, loss: -23.505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████▋                                                                | 165/1000 [41:38<3:16:03, 14.09s/it]INFO:root:global_step: 165, logpy: 69.973, kl: 59.546, loss: -23.570\n",
      " 17%|████████████▊                                                                | 166/1000 [41:52<3:15:51, 14.09s/it]INFO:root:global_step: 166, logpy: 70.209, kl: 59.577, loss: -23.643\n",
      " 17%|████████████▊                                                                | 167/1000 [42:06<3:15:59, 14.12s/it]INFO:root:global_step: 167, logpy: 70.439, kl: 59.609, loss: -23.711\n",
      " 17%|████████████▉                                                                | 168/1000 [42:20<3:15:44, 14.12s/it]INFO:root:global_step: 168, logpy: 70.672, kl: 59.642, loss: -23.782\n",
      " 17%|█████████████                                                                | 169/1000 [42:34<3:15:52, 14.14s/it]INFO:root:global_step: 169, logpy: 70.899, kl: 59.667, loss: -23.856\n",
      " 17%|█████████████                                                                | 170/1000 [42:48<3:15:45, 14.15s/it]INFO:root:global_step: 170, logpy: 71.124, kl: 59.699, loss: -23.923\n",
      " 17%|█████████████▏                                                               | 171/1000 [43:02<3:14:50, 14.10s/it]INFO:root:global_step: 171, logpy: 71.340, kl: 59.734, loss: -23.979\n",
      " 17%|█████████████▏                                                               | 172/1000 [43:16<3:14:43, 14.11s/it]INFO:root:global_step: 172, logpy: 71.553, kl: 59.760, loss: -24.042\n",
      " 17%|█████████████▎                                                               | 173/1000 [43:31<3:14:53, 14.14s/it]INFO:root:global_step: 173, logpy: 71.767, kl: 59.792, loss: -24.101\n",
      " 17%|█████████████▍                                                               | 174/1000 [43:45<3:14:46, 14.15s/it]INFO:root:global_step: 174, logpy: 71.979, kl: 59.820, loss: -24.165\n",
      " 18%|█████████████▍                                                               | 175/1000 [43:59<3:13:54, 14.10s/it]INFO:root:global_step: 175, logpy: 72.181, kl: 59.848, loss: -24.219\n",
      " 18%|█████████████▌                                                               | 176/1000 [44:13<3:13:03, 14.06s/it]INFO:root:global_step: 176, logpy: 72.389, kl: 59.879, loss: -24.277\n",
      " 18%|█████████████▋                                                               | 177/1000 [44:27<3:13:13, 14.09s/it]INFO:root:global_step: 177, logpy: 72.589, kl: 59.910, loss: -24.328\n",
      " 18%|█████████████▋                                                               | 178/1000 [44:41<3:13:25, 14.12s/it]INFO:root:global_step: 178, logpy: 72.802, kl: 59.941, loss: -24.394\n",
      " 18%|█████████████▊                                                               | 179/1000 [44:55<3:12:40, 14.08s/it]INFO:root:global_step: 179, logpy: 73.004, kl: 59.970, loss: -24.451\n",
      " 18%|█████████████▊                                                               | 180/1000 [45:09<3:12:02, 14.05s/it]INFO:root:global_step: 180, logpy: 73.208, kl: 59.999, loss: -24.513\n",
      " 18%|█████████████▉                                                               | 181/1000 [45:23<3:12:03, 14.07s/it]INFO:root:global_step: 181, logpy: 73.418, kl: 60.025, loss: -24.582\n",
      " 18%|██████████████                                                               | 182/1000 [45:37<3:12:28, 14.12s/it]INFO:root:global_step: 182, logpy: 73.606, kl: 60.057, loss: -24.626\n",
      " 18%|██████████████                                                               | 183/1000 [45:52<3:12:16, 14.12s/it]INFO:root:global_step: 183, logpy: 73.811, kl: 60.081, loss: -24.697\n",
      " 18%|██████████████▏                                                              | 184/1000 [46:06<3:12:28, 14.15s/it]INFO:root:global_step: 184, logpy: 74.010, kl: 60.106, loss: -24.762\n",
      " 18%|██████████████▏                                                              | 185/1000 [46:20<3:12:12, 14.15s/it]INFO:root:global_step: 185, logpy: 74.214, kl: 60.130, loss: -24.833\n",
      " 19%|██████████████▎                                                              | 186/1000 [46:34<3:12:12, 14.17s/it]INFO:root:global_step: 186, logpy: 74.408, kl: 60.154, loss: -24.896\n",
      " 19%|██████████████▍                                                              | 187/1000 [46:48<3:12:25, 14.20s/it]INFO:root:global_step: 187, logpy: 74.602, kl: 60.178, loss: -24.959\n",
      " 19%|██████████████▍                                                              | 188/1000 [47:03<3:11:47, 14.17s/it]INFO:root:global_step: 188, logpy: 74.797, kl: 60.198, loss: -25.029\n",
      " 19%|██████████████▌                                                              | 189/1000 [47:17<3:11:54, 14.20s/it]INFO:root:global_step: 189, logpy: 74.969, kl: 60.231, loss: -25.063\n",
      " 19%|██████████████▋                                                              | 190/1000 [47:31<3:12:05, 14.23s/it]INFO:root:global_step: 190, logpy: 75.153, kl: 60.255, loss: -25.120\n",
      " 19%|██████████████▋                                                              | 191/1000 [47:45<3:11:36, 14.21s/it]INFO:root:global_step: 191, logpy: 75.327, kl: 60.282, loss: -25.165\n",
      " 19%|██████████████▊                                                              | 192/1000 [48:00<3:11:27, 14.22s/it]INFO:root:global_step: 192, logpy: 75.510, kl: 60.301, loss: -25.228\n",
      " 19%|██████████████▊                                                              | 193/1000 [48:14<3:11:24, 14.23s/it]INFO:root:global_step: 193, logpy: 75.688, kl: 60.318, loss: -25.289\n",
      " 19%|██████████████▉                                                              | 194/1000 [48:28<3:11:39, 14.27s/it]INFO:root:global_step: 194, logpy: 75.849, kl: 60.341, loss: -25.327\n",
      " 20%|███████████████                                                              | 195/1000 [48:42<3:10:31, 14.20s/it]INFO:root:global_step: 195, logpy: 76.025, kl: 60.366, loss: -25.381\n",
      " 20%|███████████████                                                              | 196/1000 [48:56<3:10:14, 14.20s/it]INFO:root:global_step: 196, logpy: 76.196, kl: 60.383, loss: -25.438\n",
      " 20%|███████████████▏                                                             | 197/1000 [49:11<3:09:53, 14.19s/it]INFO:root:global_step: 197, logpy: 76.373, kl: 60.401, loss: -25.499\n",
      " 20%|███████████████▏                                                             | 198/1000 [49:25<3:09:52, 14.21s/it]INFO:root:global_step: 198, logpy: 76.533, kl: 60.422, loss: -25.544\n",
      " 20%|███████████████▎                                                             | 199/1000 [49:39<3:09:18, 14.18s/it]INFO:root:global_step: 199, logpy: 76.701, kl: 60.443, loss: -25.596\n",
      " 20%|███████████████▍                                                             | 200/1000 [49:53<3:08:18, 14.12s/it]INFO:root:Saved figure at: ./sim/global_step_200.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 200, logpy: 76.872, kl: 60.465, loss: -25.652\n",
      " 20%|███████████████▍                                                             | 201/1000 [50:09<3:17:14, 14.81s/it]INFO:root:global_step: 201, logpy: 77.036, kl: 60.491, loss: -25.698\n",
      " 20%|███████████████▌                                                             | 202/1000 [50:23<3:13:55, 14.58s/it]INFO:root:global_step: 202, logpy: 77.190, kl: 60.515, loss: -25.735\n",
      " 20%|███████████████▋                                                             | 203/1000 [50:37<3:11:37, 14.43s/it]INFO:root:global_step: 203, logpy: 77.347, kl: 60.536, loss: -25.781\n",
      " 20%|███████████████▋                                                             | 204/1000 [50:52<3:10:34, 14.37s/it]INFO:root:global_step: 204, logpy: 77.511, kl: 60.557, loss: -25.835\n",
      " 20%|███████████████▊                                                             | 205/1000 [51:06<3:09:12, 14.28s/it]INFO:root:global_step: 205, logpy: 77.667, kl: 60.577, loss: -25.882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|███████████████▊                                                             | 206/1000 [51:20<3:08:35, 14.25s/it]INFO:root:global_step: 206, logpy: 77.831, kl: 60.598, loss: -25.936\n",
      " 21%|███████████████▉                                                             | 207/1000 [51:34<3:07:52, 14.22s/it]INFO:root:global_step: 207, logpy: 77.983, kl: 60.623, loss: -25.977\n",
      " 21%|████████████████                                                             | 208/1000 [51:48<3:06:58, 14.16s/it]INFO:root:global_step: 208, logpy: 78.118, kl: 60.644, loss: -26.005\n",
      " 21%|████████████████                                                             | 209/1000 [52:02<3:06:50, 14.17s/it]INFO:root:global_step: 209, logpy: 78.269, kl: 60.668, loss: -26.047\n",
      " 21%|████████████████▏                                                            | 210/1000 [52:16<3:06:30, 14.16s/it]INFO:root:global_step: 210, logpy: 78.413, kl: 60.688, loss: -26.086\n",
      " 21%|████████████████▏                                                            | 211/1000 [52:31<3:06:02, 14.15s/it]INFO:root:global_step: 211, logpy: 78.558, kl: 60.711, loss: -26.125\n",
      " 21%|████████████████▎                                                            | 212/1000 [52:45<3:05:32, 14.13s/it]INFO:root:global_step: 212, logpy: 78.696, kl: 60.728, loss: -26.163\n",
      " 21%|████████████████▍                                                            | 213/1000 [52:59<3:05:02, 14.11s/it]INFO:root:global_step: 213, logpy: 78.854, kl: 60.745, loss: -26.222\n",
      " 21%|████████████████▍                                                            | 214/1000 [53:13<3:05:07, 14.13s/it]INFO:root:global_step: 214, logpy: 78.994, kl: 60.764, loss: -26.262\n",
      " 22%|████████████████▌                                                            | 215/1000 [53:27<3:05:25, 14.17s/it]INFO:root:global_step: 215, logpy: 79.136, kl: 60.784, loss: -26.304\n",
      " 22%|████████████████▋                                                            | 216/1000 [53:41<3:05:20, 14.18s/it]INFO:root:global_step: 216, logpy: 79.269, kl: 60.802, loss: -26.338\n",
      " 22%|████████████████▋                                                            | 217/1000 [53:56<3:05:34, 14.22s/it]INFO:root:global_step: 217, logpy: 79.413, kl: 60.817, loss: -26.389\n",
      " 22%|████████████████▊                                                            | 218/1000 [54:10<3:05:10, 14.21s/it]INFO:root:global_step: 218, logpy: 79.542, kl: 60.835, loss: -26.422\n",
      " 22%|████████████████▊                                                            | 219/1000 [54:24<3:05:00, 14.21s/it]INFO:root:global_step: 219, logpy: 79.659, kl: 60.857, loss: -26.439\n",
      " 22%|████████████████▉                                                            | 220/1000 [54:38<3:04:33, 14.20s/it]INFO:root:global_step: 220, logpy: 79.799, kl: 60.868, loss: -26.492\n",
      " 22%|█████████████████                                                            | 221/1000 [54:52<3:04:14, 14.19s/it]INFO:root:global_step: 221, logpy: 79.942, kl: 60.885, loss: -26.542\n",
      " 22%|█████████████████                                                            | 222/1000 [55:07<3:03:58, 14.19s/it]INFO:root:global_step: 222, logpy: 80.058, kl: 60.904, loss: -26.565\n",
      " 22%|█████████████████▏                                                           | 223/1000 [55:21<3:03:25, 14.16s/it]INFO:root:global_step: 223, logpy: 80.186, kl: 60.921, loss: -26.601\n",
      " 22%|█████████████████▏                                                           | 224/1000 [55:35<3:03:18, 14.17s/it]INFO:root:global_step: 224, logpy: 80.311, kl: 60.932, loss: -26.643\n",
      " 22%|█████████████████▎                                                           | 225/1000 [55:49<3:02:46, 14.15s/it]INFO:root:global_step: 225, logpy: 80.444, kl: 60.951, loss: -26.684\n",
      " 23%|█████████████████▍                                                           | 226/1000 [56:03<3:02:22, 14.14s/it]INFO:root:global_step: 226, logpy: 80.565, kl: 60.968, loss: -26.715\n",
      " 23%|█████████████████▍                                                           | 227/1000 [56:17<3:02:23, 14.16s/it]INFO:root:global_step: 227, logpy: 80.688, kl: 60.983, loss: -26.753\n",
      " 23%|█████████████████▌                                                           | 228/1000 [56:31<3:02:16, 14.17s/it]INFO:root:global_step: 228, logpy: 80.800, kl: 60.998, loss: -26.779\n",
      " 23%|█████████████████▋                                                           | 229/1000 [56:46<3:02:02, 14.17s/it]INFO:root:global_step: 229, logpy: 80.913, kl: 61.021, loss: -26.799\n",
      " 23%|█████████████████▋                                                           | 230/1000 [57:00<3:01:34, 14.15s/it]INFO:root:global_step: 230, logpy: 81.028, kl: 61.037, loss: -26.830\n",
      " 23%|█████████████████▊                                                           | 231/1000 [57:14<3:01:35, 14.17s/it]INFO:root:global_step: 231, logpy: 81.158, kl: 61.050, loss: -26.878\n",
      " 23%|█████████████████▊                                                           | 232/1000 [57:28<3:01:11, 14.16s/it]INFO:root:global_step: 232, logpy: 81.273, kl: 61.067, loss: -26.908\n",
      " 23%|█████████████████▉                                                           | 233/1000 [57:42<3:00:28, 14.12s/it]INFO:root:global_step: 233, logpy: 81.408, kl: 61.079, loss: -26.964\n",
      " 23%|██████████████████                                                           | 234/1000 [57:56<3:00:44, 14.16s/it]INFO:root:global_step: 234, logpy: 81.528, kl: 61.093, loss: -27.005\n",
      " 24%|██████████████████                                                           | 235/1000 [58:11<3:00:29, 14.16s/it]INFO:root:global_step: 235, logpy: 81.648, kl: 61.111, loss: -27.040\n",
      " 24%|██████████████████▏                                                          | 236/1000 [58:25<3:00:10, 14.15s/it]INFO:root:global_step: 236, logpy: 81.763, kl: 61.125, loss: -27.077\n",
      " 24%|██████████████████▏                                                          | 237/1000 [58:39<3:00:19, 14.18s/it]INFO:root:global_step: 237, logpy: 81.883, kl: 61.141, loss: -27.116\n",
      " 24%|██████████████████▎                                                          | 238/1000 [58:53<3:00:01, 14.17s/it]INFO:root:global_step: 238, logpy: 82.000, kl: 61.156, loss: -27.154\n",
      " 24%|██████████████████▍                                                          | 239/1000 [59:07<2:59:49, 14.18s/it]INFO:root:global_step: 239, logpy: 82.098, kl: 61.182, loss: -27.163\n",
      " 24%|██████████████████▍                                                          | 240/1000 [59:21<2:58:51, 14.12s/it]INFO:root:global_step: 240, logpy: 82.207, kl: 61.199, loss: -27.192\n",
      " 24%|██████████████████▌                                                          | 241/1000 [59:35<2:58:46, 14.13s/it]INFO:root:global_step: 241, logpy: 82.321, kl: 61.212, loss: -27.232\n",
      " 24%|██████████████████▋                                                          | 242/1000 [59:50<2:58:49, 14.15s/it]INFO:root:global_step: 242, logpy: 82.437, kl: 61.224, loss: -27.275\n",
      " 24%|██████████████████▏                                                        | 243/1000 [1:00:04<2:58:42, 14.16s/it]INFO:root:global_step: 243, logpy: 82.547, kl: 61.242, loss: -27.306\n",
      " 24%|██████████████████▎                                                        | 244/1000 [1:00:18<2:58:52, 14.20s/it]INFO:root:global_step: 244, logpy: 82.655, kl: 61.261, loss: -27.335\n",
      " 24%|██████████████████▍                                                        | 245/1000 [1:00:32<2:58:20, 14.17s/it]INFO:root:global_step: 245, logpy: 82.767, kl: 61.278, loss: -27.371\n",
      " 25%|██████████████████▍                                                        | 246/1000 [1:00:46<2:57:49, 14.15s/it]INFO:root:global_step: 246, logpy: 82.878, kl: 61.298, loss: -27.403\n",
      " 25%|██████████████████▌                                                        | 247/1000 [1:01:01<2:57:47, 14.17s/it]INFO:root:global_step: 247, logpy: 83.006, kl: 61.308, loss: -27.462\n",
      " 25%|██████████████████▌                                                        | 248/1000 [1:01:15<2:57:05, 14.13s/it]INFO:root:global_step: 248, logpy: 83.104, kl: 61.325, loss: -27.486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██████████████████▋                                                        | 249/1000 [1:01:29<2:56:44, 14.12s/it]INFO:root:global_step: 249, logpy: 83.206, kl: 61.341, loss: -27.514\n",
      " 25%|██████████████████▊                                                        | 250/1000 [1:01:43<2:57:02, 14.16s/it]INFO:root:Saved figure at: ./sim/global_step_250.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 250, logpy: 83.307, kl: 61.353, loss: -27.547\n",
      " 25%|██████████████████▊                                                        | 251/1000 [1:01:59<3:05:20, 14.85s/it]INFO:root:global_step: 251, logpy: 83.409, kl: 61.367, loss: -27.579\n",
      " 25%|██████████████████▉                                                        | 252/1000 [1:02:13<3:01:54, 14.59s/it]INFO:root:global_step: 252, logpy: 83.518, kl: 61.378, loss: -27.622\n",
      " 25%|██████████████████▉                                                        | 253/1000 [1:02:27<2:59:29, 14.42s/it]INFO:root:global_step: 253, logpy: 83.612, kl: 61.386, loss: -27.653\n",
      " 25%|███████████████████                                                        | 254/1000 [1:02:42<2:58:35, 14.36s/it]INFO:root:global_step: 254, logpy: 83.710, kl: 61.397, loss: -27.686\n",
      " 26%|███████████████████▏                                                       | 255/1000 [1:02:56<2:57:31, 14.30s/it]INFO:root:global_step: 255, logpy: 83.812, kl: 61.415, loss: -27.716\n",
      " 26%|███████████████████▏                                                       | 256/1000 [1:03:10<2:56:30, 14.23s/it]INFO:root:global_step: 256, logpy: 83.885, kl: 61.428, loss: -27.723\n",
      " 26%|███████████████████▎                                                       | 257/1000 [1:03:24<2:55:59, 14.21s/it]INFO:root:global_step: 257, logpy: 83.980, kl: 61.441, loss: -27.752\n",
      " 26%|███████████████████▎                                                       | 258/1000 [1:03:38<2:55:12, 14.17s/it]INFO:root:global_step: 258, logpy: 84.071, kl: 61.453, loss: -27.779\n",
      " 26%|███████████████████▍                                                       | 259/1000 [1:03:52<2:54:28, 14.13s/it]INFO:root:global_step: 259, logpy: 84.156, kl: 61.468, loss: -27.797\n",
      " 26%|███████████████████▌                                                       | 260/1000 [1:04:06<2:54:14, 14.13s/it]INFO:root:global_step: 260, logpy: 84.247, kl: 61.481, loss: -27.824\n",
      " 26%|███████████████████▌                                                       | 261/1000 [1:04:20<2:54:02, 14.13s/it]INFO:root:global_step: 261, logpy: 84.331, kl: 61.495, loss: -27.844\n",
      " 26%|███████████████████▋                                                       | 262/1000 [1:04:34<2:53:32, 14.11s/it]INFO:root:global_step: 262, logpy: 84.419, kl: 61.511, loss: -27.866\n",
      " 26%|███████████████████▋                                                       | 263/1000 [1:04:49<2:53:29, 14.12s/it]INFO:root:global_step: 263, logpy: 84.509, kl: 61.521, loss: -27.896\n",
      " 26%|███████████████████▊                                                       | 264/1000 [1:05:03<2:53:18, 14.13s/it]INFO:root:global_step: 264, logpy: 84.602, kl: 61.528, loss: -27.933\n",
      " 26%|███████████████████▉                                                       | 265/1000 [1:05:17<2:53:34, 14.17s/it]INFO:root:global_step: 265, logpy: 84.686, kl: 61.543, loss: -27.954\n",
      " 27%|███████████████████▉                                                       | 266/1000 [1:05:31<2:53:12, 14.16s/it]INFO:root:global_step: 266, logpy: 84.769, kl: 61.556, loss: -27.976\n",
      " 27%|████████████████████                                                       | 267/1000 [1:05:45<2:52:37, 14.13s/it]INFO:root:global_step: 267, logpy: 84.842, kl: 61.564, loss: -27.993\n",
      " 27%|████████████████████                                                       | 268/1000 [1:05:59<2:52:50, 14.17s/it]INFO:root:global_step: 268, logpy: 84.914, kl: 61.579, loss: -28.003\n",
      " 27%|████████████████████▏                                                      | 269/1000 [1:06:13<2:52:14, 14.14s/it]INFO:root:global_step: 269, logpy: 85.004, kl: 61.591, loss: -28.034\n",
      " 27%|████████████████████▎                                                      | 270/1000 [1:06:28<2:52:10, 14.15s/it]INFO:root:global_step: 270, logpy: 85.097, kl: 61.601, loss: -28.071\n",
      " 27%|████████████████████▎                                                      | 271/1000 [1:06:42<2:51:45, 14.14s/it]INFO:root:global_step: 271, logpy: 85.185, kl: 61.612, loss: -28.102\n",
      " 27%|████████████████████▍                                                      | 272/1000 [1:06:56<2:51:41, 14.15s/it]INFO:root:global_step: 272, logpy: 85.255, kl: 61.627, loss: -28.112\n",
      " 27%|████████████████████▍                                                      | 273/1000 [1:07:10<2:51:42, 14.17s/it]INFO:root:global_step: 273, logpy: 85.335, kl: 61.641, loss: -28.132\n",
      " 27%|████████████████████▌                                                      | 274/1000 [1:07:24<2:51:46, 14.20s/it]INFO:root:global_step: 274, logpy: 85.407, kl: 61.652, loss: -28.150\n",
      " 28%|████████████████████▋                                                      | 275/1000 [1:07:39<2:51:26, 14.19s/it]INFO:root:global_step: 275, logpy: 85.499, kl: 61.659, loss: -28.190\n",
      " 28%|████████████████████▋                                                      | 276/1000 [1:07:53<2:51:26, 14.21s/it]INFO:root:global_step: 276, logpy: 85.584, kl: 61.670, loss: -28.221\n",
      " 28%|████████████████████▊                                                      | 277/1000 [1:08:07<2:50:55, 14.18s/it]INFO:root:global_step: 277, logpy: 85.655, kl: 61.680, loss: -28.239\n",
      " 28%|████████████████████▊                                                      | 278/1000 [1:08:21<2:50:39, 14.18s/it]INFO:root:global_step: 278, logpy: 85.723, kl: 61.697, loss: -28.247\n",
      " 28%|████████████████████▉                                                      | 279/1000 [1:08:35<2:50:42, 14.21s/it]INFO:root:global_step: 279, logpy: 85.807, kl: 61.708, loss: -28.279\n",
      " 28%|█████████████████████                                                      | 280/1000 [1:08:50<2:50:10, 14.18s/it]INFO:root:global_step: 280, logpy: 85.875, kl: 61.718, loss: -28.295\n",
      " 28%|█████████████████████                                                      | 281/1000 [1:09:04<2:50:04, 14.19s/it]INFO:root:global_step: 281, logpy: 85.950, kl: 61.733, loss: -28.313\n",
      " 28%|█████████████████████▏                                                     | 282/1000 [1:09:18<2:49:25, 14.16s/it]INFO:root:global_step: 282, logpy: 86.006, kl: 61.746, loss: -28.315\n",
      " 28%|█████████████████████▏                                                     | 283/1000 [1:09:32<2:49:36, 14.19s/it]INFO:root:global_step: 283, logpy: 86.096, kl: 61.756, loss: -28.354\n",
      " 28%|█████████████████████▎                                                     | 284/1000 [1:09:46<2:49:46, 14.23s/it]INFO:root:global_step: 284, logpy: 86.172, kl: 61.764, loss: -28.382\n",
      " 28%|█████████████████████▎                                                     | 285/1000 [1:10:01<2:49:25, 14.22s/it]INFO:root:global_step: 285, logpy: 86.248, kl: 61.772, loss: -28.410\n",
      " 29%|█████████████████████▍                                                     | 286/1000 [1:10:15<2:49:27, 14.24s/it]INFO:root:global_step: 286, logpy: 86.330, kl: 61.780, loss: -28.445\n",
      " 29%|█████████████████████▌                                                     | 287/1000 [1:10:29<2:48:51, 14.21s/it]INFO:root:global_step: 287, logpy: 86.404, kl: 61.784, loss: -28.476\n",
      " 29%|█████████████████████▌                                                     | 288/1000 [1:10:43<2:48:41, 14.22s/it]INFO:root:global_step: 288, logpy: 86.473, kl: 61.794, loss: -28.497\n",
      " 29%|█████████████████████▋                                                     | 289/1000 [1:10:57<2:48:27, 14.22s/it]INFO:root:global_step: 289, logpy: 86.546, kl: 61.810, loss: -28.516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|█████████████████████▊                                                     | 290/1000 [1:11:12<2:48:28, 14.24s/it]INFO:root:global_step: 290, logpy: 86.605, kl: 61.823, loss: -28.523\n",
      " 29%|█████████████████████▊                                                     | 291/1000 [1:11:26<2:48:45, 14.28s/it]INFO:root:global_step: 291, logpy: 86.677, kl: 61.831, loss: -28.550\n",
      " 29%|█████████████████████▉                                                     | 292/1000 [1:11:40<2:48:19, 14.27s/it]INFO:root:global_step: 292, logpy: 86.744, kl: 61.839, loss: -28.572\n",
      " 29%|█████████████████████▉                                                     | 293/1000 [1:11:55<2:47:47, 14.24s/it]INFO:root:global_step: 293, logpy: 86.812, kl: 61.852, loss: -28.591\n",
      " 29%|██████████████████████                                                     | 294/1000 [1:12:09<2:47:27, 14.23s/it]INFO:root:global_step: 294, logpy: 86.876, kl: 61.857, loss: -28.613\n",
      " 30%|██████████████████████▏                                                    | 295/1000 [1:12:23<2:47:34, 14.26s/it]INFO:root:global_step: 295, logpy: 86.938, kl: 61.864, loss: -28.632\n",
      " 30%|██████████████████████▏                                                    | 296/1000 [1:12:37<2:47:06, 14.24s/it]INFO:root:global_step: 296, logpy: 86.994, kl: 61.875, loss: -28.642\n",
      " 30%|██████████████████████▎                                                    | 297/1000 [1:12:51<2:46:31, 14.21s/it]INFO:root:global_step: 297, logpy: 87.044, kl: 61.885, loss: -28.647\n",
      " 30%|██████████████████████▎                                                    | 298/1000 [1:13:06<2:46:00, 14.19s/it]INFO:root:global_step: 298, logpy: 87.097, kl: 61.891, loss: -28.659\n",
      " 30%|██████████████████████▍                                                    | 299/1000 [1:13:20<2:46:14, 14.23s/it]INFO:root:global_step: 299, logpy: 87.157, kl: 61.903, loss: -28.671\n",
      " 30%|██████████████████████▌                                                    | 300/1000 [1:13:34<2:45:30, 14.19s/it]INFO:root:Saved figure at: ./sim/global_step_300.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 300, logpy: 87.219, kl: 61.910, loss: -28.692\n",
      " 30%|██████████████████████▌                                                    | 301/1000 [1:13:50<2:53:08, 14.86s/it]INFO:root:global_step: 301, logpy: 87.265, kl: 61.919, loss: -28.696\n",
      " 30%|██████████████████████▋                                                    | 302/1000 [1:14:05<2:50:28, 14.65s/it]INFO:root:global_step: 302, logpy: 87.322, kl: 61.927, loss: -28.712\n",
      " 30%|██████████████████████▋                                                    | 303/1000 [1:14:19<2:48:46, 14.53s/it]INFO:root:global_step: 303, logpy: 87.372, kl: 61.938, loss: -28.717\n",
      " 30%|██████████████████████▊                                                    | 304/1000 [1:14:33<2:47:37, 14.45s/it]INFO:root:global_step: 304, logpy: 87.430, kl: 61.944, loss: -28.737\n",
      " 30%|██████████████████████▉                                                    | 305/1000 [1:14:47<2:46:33, 14.38s/it]INFO:root:global_step: 305, logpy: 87.483, kl: 61.949, loss: -28.752\n",
      " 31%|██████████████████████▉                                                    | 306/1000 [1:15:02<2:45:58, 14.35s/it]INFO:root:global_step: 306, logpy: 87.556, kl: 61.962, loss: -28.779\n",
      " 31%|███████████████████████                                                    | 307/1000 [1:15:16<2:44:51, 14.27s/it]INFO:root:global_step: 307, logpy: 87.614, kl: 61.972, loss: -28.796\n",
      " 31%|███████████████████████                                                    | 308/1000 [1:15:30<2:44:15, 14.24s/it]INFO:root:global_step: 308, logpy: 87.668, kl: 61.977, loss: -28.814\n",
      " 31%|███████████████████████▏                                                   | 309/1000 [1:15:44<2:43:57, 14.24s/it]INFO:root:global_step: 309, logpy: 87.733, kl: 61.989, loss: -28.835\n",
      " 31%|███████████████████████▎                                                   | 310/1000 [1:15:58<2:43:31, 14.22s/it]INFO:root:global_step: 310, logpy: 87.795, kl: 62.000, loss: -28.856\n",
      " 31%|███████████████████████▎                                                   | 311/1000 [1:16:12<2:43:09, 14.21s/it]INFO:root:global_step: 311, logpy: 87.853, kl: 62.009, loss: -28.873\n",
      " 31%|███████████████████████▍                                                   | 312/1000 [1:16:27<2:42:59, 14.22s/it]INFO:root:global_step: 312, logpy: 87.911, kl: 62.014, loss: -28.896\n",
      " 31%|███████████████████████▍                                                   | 313/1000 [1:16:41<2:42:43, 14.21s/it]INFO:root:global_step: 313, logpy: 87.970, kl: 62.024, loss: -28.915\n",
      " 31%|███████████████████████▌                                                   | 314/1000 [1:16:55<2:42:17, 14.20s/it]INFO:root:global_step: 314, logpy: 88.019, kl: 62.034, loss: -28.925\n",
      " 32%|███████████████████████▋                                                   | 315/1000 [1:17:09<2:42:11, 14.21s/it]INFO:root:global_step: 315, logpy: 88.083, kl: 62.051, loss: -28.943\n",
      " 32%|███████████████████████▋                                                   | 316/1000 [1:17:23<2:41:49, 14.19s/it]INFO:root:global_step: 316, logpy: 88.151, kl: 62.054, loss: -28.979\n",
      " 32%|███████████████████████▊                                                   | 317/1000 [1:17:38<2:41:38, 14.20s/it]INFO:root:global_step: 317, logpy: 88.210, kl: 62.059, loss: -29.003\n",
      " 32%|███████████████████████▊                                                   | 318/1000 [1:17:52<2:41:22, 14.20s/it]INFO:root:global_step: 318, logpy: 88.265, kl: 62.066, loss: -29.023\n",
      " 32%|███████████████████████▉                                                   | 319/1000 [1:18:06<2:40:54, 14.18s/it]INFO:root:global_step: 319, logpy: 88.328, kl: 62.075, loss: -29.049\n",
      " 32%|████████████████████████                                                   | 320/1000 [1:18:20<2:40:28, 14.16s/it]INFO:root:global_step: 320, logpy: 88.378, kl: 62.079, loss: -29.066\n",
      " 32%|████████████████████████                                                   | 321/1000 [1:18:34<2:40:30, 14.18s/it]INFO:root:global_step: 321, logpy: 88.427, kl: 62.089, loss: -29.079\n",
      " 32%|████████████████████████▏                                                  | 322/1000 [1:18:49<2:40:35, 14.21s/it]INFO:root:global_step: 322, logpy: 88.475, kl: 62.096, loss: -29.092\n",
      " 32%|████████████████████████▏                                                  | 323/1000 [1:19:03<2:40:10, 14.20s/it]INFO:root:global_step: 323, logpy: 88.524, kl: 62.102, loss: -29.108\n",
      " 32%|████████████████████████▎                                                  | 324/1000 [1:19:17<2:40:05, 14.21s/it]INFO:root:global_step: 324, logpy: 88.576, kl: 62.106, loss: -29.129\n",
      " 32%|████████████████████████▍                                                  | 325/1000 [1:19:31<2:39:37, 14.19s/it]INFO:root:global_step: 325, logpy: 88.639, kl: 62.106, loss: -29.165\n",
      " 33%|████████████████████████▍                                                  | 326/1000 [1:19:45<2:39:18, 14.18s/it]INFO:root:global_step: 326, logpy: 88.690, kl: 62.110, loss: -29.185\n",
      " 33%|████████████████████████▌                                                  | 327/1000 [1:19:59<2:39:01, 14.18s/it]INFO:root:global_step: 327, logpy: 88.721, kl: 62.117, loss: -29.183\n",
      " 33%|████████████████████████▌                                                  | 328/1000 [1:20:14<2:38:27, 14.15s/it]INFO:root:global_step: 328, logpy: 88.768, kl: 62.117, loss: -29.205\n",
      " 33%|████████████████████████▋                                                  | 329/1000 [1:20:28<2:38:15, 14.15s/it]INFO:root:global_step: 329, logpy: 88.815, kl: 62.120, loss: -29.223\n",
      " 33%|████████████████████████▊                                                  | 330/1000 [1:20:42<2:37:57, 14.15s/it]INFO:root:global_step: 330, logpy: 88.851, kl: 62.125, loss: -29.229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|████████████████████████▊                                                  | 331/1000 [1:20:56<2:37:34, 14.13s/it]INFO:root:global_step: 331, logpy: 88.902, kl: 62.126, loss: -29.254\n",
      " 33%|████████████████████████▉                                                  | 332/1000 [1:21:10<2:37:36, 14.16s/it]INFO:root:global_step: 332, logpy: 88.927, kl: 62.125, loss: -29.256\n",
      " 33%|████████████████████████▉                                                  | 333/1000 [1:21:24<2:37:23, 14.16s/it]INFO:root:global_step: 333, logpy: 88.959, kl: 62.129, loss: -29.259\n",
      " 33%|█████████████████████████                                                  | 334/1000 [1:21:39<2:37:10, 14.16s/it]INFO:root:global_step: 334, logpy: 88.997, kl: 62.131, loss: -29.270\n",
      " 34%|█████████████████████████▏                                                 | 335/1000 [1:21:53<2:36:54, 14.16s/it]INFO:root:global_step: 335, logpy: 89.034, kl: 62.136, loss: -29.278\n",
      " 34%|█████████████████████████▏                                                 | 336/1000 [1:22:07<2:36:46, 14.17s/it]INFO:root:global_step: 336, logpy: 89.081, kl: 62.136, loss: -29.301\n",
      " 34%|█████████████████████████▎                                                 | 337/1000 [1:22:21<2:36:41, 14.18s/it]INFO:root:global_step: 337, logpy: 89.122, kl: 62.140, loss: -29.314\n",
      " 34%|█████████████████████████▎                                                 | 338/1000 [1:22:35<2:36:52, 14.22s/it]INFO:root:global_step: 338, logpy: 89.163, kl: 62.147, loss: -29.326\n",
      " 34%|█████████████████████████▍                                                 | 339/1000 [1:22:50<2:36:24, 14.20s/it]INFO:root:global_step: 339, logpy: 89.204, kl: 62.149, loss: -29.341\n",
      " 34%|█████████████████████████▌                                                 | 340/1000 [1:23:04<2:35:48, 14.16s/it]INFO:root:global_step: 340, logpy: 89.234, kl: 62.158, loss: -29.340\n",
      " 34%|█████████████████████████▌                                                 | 341/1000 [1:23:18<2:35:16, 14.14s/it]INFO:root:global_step: 341, logpy: 89.269, kl: 62.164, loss: -29.346\n",
      " 34%|█████████████████████████▋                                                 | 342/1000 [1:23:32<2:35:12, 14.15s/it]INFO:root:global_step: 342, logpy: 89.315, kl: 62.167, loss: -29.367\n",
      " 34%|█████████████████████████▋                                                 | 343/1000 [1:23:46<2:35:08, 14.17s/it]INFO:root:global_step: 343, logpy: 89.358, kl: 62.169, loss: -29.385\n",
      " 34%|█████████████████████████▊                                                 | 344/1000 [1:24:00<2:34:54, 14.17s/it]INFO:root:global_step: 344, logpy: 89.405, kl: 62.172, loss: -29.408\n",
      " 34%|█████████████████████████▊                                                 | 345/1000 [1:24:14<2:34:47, 14.18s/it]INFO:root:global_step: 345, logpy: 89.448, kl: 62.179, loss: -29.422\n",
      " 35%|█████████████████████████▉                                                 | 346/1000 [1:24:28<2:34:08, 14.14s/it]INFO:root:global_step: 346, logpy: 89.487, kl: 62.187, loss: -29.431\n",
      " 35%|██████████████████████████                                                 | 347/1000 [1:24:43<2:33:45, 14.13s/it]INFO:root:global_step: 347, logpy: 89.530, kl: 62.189, loss: -29.451\n",
      " 35%|██████████████████████████                                                 | 348/1000 [1:24:57<2:33:47, 14.15s/it]INFO:root:global_step: 348, logpy: 89.564, kl: 62.195, loss: -29.459\n",
      " 35%|██████████████████████████▏                                                | 349/1000 [1:25:11<2:33:51, 14.18s/it]INFO:root:global_step: 349, logpy: 89.599, kl: 62.199, loss: -29.468\n",
      " 35%|██████████████████████████▎                                                | 350/1000 [1:25:25<2:32:52, 14.11s/it]INFO:root:Saved figure at: ./sim/global_step_350.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 350, logpy: 89.640, kl: 62.198, loss: -29.489\n",
      " 35%|██████████████████████████▎                                                | 351/1000 [1:25:41<2:40:09, 14.81s/it]INFO:root:global_step: 351, logpy: 89.673, kl: 62.204, loss: -29.495\n",
      " 35%|██████████████████████████▍                                                | 352/1000 [1:25:56<2:37:44, 14.61s/it]INFO:root:global_step: 352, logpy: 89.727, kl: 62.204, loss: -29.530\n",
      " 35%|██████████████████████████▍                                                | 353/1000 [1:26:10<2:36:22, 14.50s/it]INFO:root:global_step: 353, logpy: 89.762, kl: 62.207, loss: -29.541\n",
      " 35%|██████████████████████████▌                                                | 354/1000 [1:26:24<2:34:56, 14.39s/it]INFO:root:global_step: 354, logpy: 89.799, kl: 62.212, loss: -29.553\n",
      " 36%|██████████████████████████▋                                                | 355/1000 [1:26:38<2:34:59, 14.42s/it]INFO:root:global_step: 355, logpy: 89.844, kl: 62.211, loss: -29.580\n",
      " 36%|██████████████████████████▋                                                | 356/1000 [1:26:53<2:34:19, 14.38s/it]INFO:root:global_step: 356, logpy: 89.869, kl: 62.215, loss: -29.581\n",
      " 36%|██████████████████████████▊                                                | 357/1000 [1:27:07<2:33:23, 14.31s/it]INFO:root:global_step: 357, logpy: 89.904, kl: 62.211, loss: -29.601\n",
      " 36%|██████████████████████████▊                                                | 358/1000 [1:27:21<2:33:14, 14.32s/it]INFO:root:global_step: 358, logpy: 89.925, kl: 62.218, loss: -29.596\n",
      " 36%|██████████████████████████▉                                                | 359/1000 [1:27:35<2:32:12, 14.25s/it]INFO:root:global_step: 359, logpy: 89.963, kl: 62.221, loss: -29.611\n",
      " 36%|███████████████████████████                                                | 360/1000 [1:27:49<2:31:17, 14.18s/it]INFO:root:global_step: 360, logpy: 89.989, kl: 62.220, loss: -29.620\n",
      " 36%|███████████████████████████                                                | 361/1000 [1:28:04<2:31:17, 14.21s/it]INFO:root:global_step: 361, logpy: 90.023, kl: 62.228, loss: -29.628\n",
      " 36%|███████████████████████████▏                                               | 362/1000 [1:28:18<2:31:05, 14.21s/it]INFO:root:global_step: 362, logpy: 90.044, kl: 62.240, loss: -29.618\n",
      " 36%|███████████████████████████▏                                               | 363/1000 [1:28:32<2:30:29, 14.17s/it]INFO:root:global_step: 363, logpy: 90.070, kl: 62.242, loss: -29.625\n",
      " 36%|███████████████████████████▎                                               | 364/1000 [1:28:46<2:30:42, 14.22s/it]INFO:root:global_step: 364, logpy: 90.105, kl: 62.246, loss: -29.638\n",
      " 36%|███████████████████████████▍                                               | 365/1000 [1:29:00<2:29:57, 14.17s/it]INFO:root:global_step: 365, logpy: 90.137, kl: 62.251, loss: -29.646\n",
      " 37%|███████████████████████████▍                                               | 366/1000 [1:29:15<2:29:56, 14.19s/it]INFO:root:global_step: 366, logpy: 90.161, kl: 62.250, loss: -29.654\n",
      " 37%|███████████████████████████▌                                               | 367/1000 [1:29:29<2:29:28, 14.17s/it]INFO:root:global_step: 367, logpy: 90.201, kl: 62.251, loss: -29.676\n",
      " 37%|███████████████████████████▌                                               | 368/1000 [1:29:43<2:29:16, 14.17s/it]INFO:root:global_step: 368, logpy: 90.227, kl: 62.255, loss: -29.680\n",
      " 37%|███████████████████████████▋                                               | 369/1000 [1:29:57<2:29:16, 14.19s/it]INFO:root:global_step: 369, logpy: 90.260, kl: 62.262, loss: -29.689\n",
      " 37%|███████████████████████████▊                                               | 370/1000 [1:30:11<2:28:55, 14.18s/it]INFO:root:global_step: 370, logpy: 90.285, kl: 62.265, loss: -29.695\n",
      " 37%|███████████████████████████▊                                               | 371/1000 [1:30:25<2:28:42, 14.19s/it]INFO:root:global_step: 371, logpy: 90.319, kl: 62.269, loss: -29.707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███████████████████████████▉                                               | 372/1000 [1:30:40<2:28:42, 14.21s/it]INFO:root:global_step: 372, logpy: 90.353, kl: 62.272, loss: -29.722\n",
      " 37%|███████████████████████████▉                                               | 373/1000 [1:30:54<2:28:32, 14.21s/it]INFO:root:global_step: 373, logpy: 90.377, kl: 62.277, loss: -29.725\n",
      " 37%|████████████████████████████                                               | 374/1000 [1:31:08<2:28:15, 14.21s/it]INFO:root:global_step: 374, logpy: 90.408, kl: 62.281, loss: -29.736\n",
      " 38%|████████████████████████████▏                                              | 375/1000 [1:31:22<2:27:53, 14.20s/it]INFO:root:global_step: 375, logpy: 90.429, kl: 62.287, loss: -29.735\n",
      " 38%|████████████████████████████▏                                              | 376/1000 [1:31:36<2:27:15, 14.16s/it]INFO:root:global_step: 376, logpy: 90.462, kl: 62.292, loss: -29.746\n",
      " 38%|████████████████████████████▎                                              | 377/1000 [1:31:51<2:27:19, 14.19s/it]INFO:root:global_step: 377, logpy: 90.493, kl: 62.297, loss: -29.757\n",
      " 38%|████████████████████████████▎                                              | 378/1000 [1:32:05<2:26:51, 14.17s/it]INFO:root:global_step: 378, logpy: 90.521, kl: 62.300, loss: -29.766\n",
      " 38%|████████████████████████████▍                                              | 379/1000 [1:32:19<2:26:50, 14.19s/it]INFO:root:global_step: 379, logpy: 90.563, kl: 62.301, loss: -29.792\n",
      " 38%|████████████████████████████▌                                              | 380/1000 [1:32:33<2:27:07, 14.24s/it]INFO:root:global_step: 380, logpy: 90.593, kl: 62.312, loss: -29.795\n",
      " 38%|████████████████████████████▌                                              | 381/1000 [1:32:47<2:26:12, 14.17s/it]INFO:root:global_step: 381, logpy: 90.606, kl: 62.318, loss: -29.787\n",
      " 38%|████████████████████████████▋                                              | 382/1000 [1:33:01<2:25:49, 14.16s/it]INFO:root:global_step: 382, logpy: 90.633, kl: 62.322, loss: -29.795\n",
      " 38%|████████████████████████████▋                                              | 383/1000 [1:33:16<2:25:42, 14.17s/it]INFO:root:global_step: 383, logpy: 90.673, kl: 62.324, loss: -29.818\n",
      " 38%|████████████████████████████▊                                              | 384/1000 [1:33:30<2:25:18, 14.15s/it]INFO:root:global_step: 384, logpy: 90.697, kl: 62.327, loss: -29.825\n",
      " 38%|████████████████████████████▉                                              | 385/1000 [1:33:44<2:25:18, 14.18s/it]INFO:root:global_step: 385, logpy: 90.729, kl: 62.329, loss: -29.840\n",
      " 39%|████████████████████████████▉                                              | 386/1000 [1:33:58<2:24:51, 14.16s/it]INFO:root:global_step: 386, logpy: 90.755, kl: 62.329, loss: -29.852\n",
      " 39%|█████████████████████████████                                              | 387/1000 [1:34:12<2:24:46, 14.17s/it]INFO:root:global_step: 387, logpy: 90.785, kl: 62.331, loss: -29.865\n",
      " 39%|█████████████████████████████                                              | 388/1000 [1:34:27<2:24:52, 14.20s/it]INFO:root:global_step: 388, logpy: 90.806, kl: 62.329, loss: -29.874\n",
      " 39%|█████████████████████████████▏                                             | 389/1000 [1:34:41<2:24:32, 14.19s/it]INFO:root:global_step: 389, logpy: 90.832, kl: 62.327, loss: -29.888\n",
      " 39%|█████████████████████████████▎                                             | 390/1000 [1:34:55<2:24:22, 14.20s/it]INFO:root:global_step: 390, logpy: 90.849, kl: 62.330, loss: -29.888\n",
      " 39%|█████████████████████████████▎                                             | 391/1000 [1:35:09<2:23:54, 14.18s/it]INFO:root:global_step: 391, logpy: 90.883, kl: 62.337, loss: -29.902\n",
      " 39%|█████████████████████████████▍                                             | 392/1000 [1:35:23<2:23:18, 14.14s/it]INFO:root:global_step: 392, logpy: 90.905, kl: 62.341, loss: -29.906\n",
      " 39%|█████████████████████████████▍                                             | 393/1000 [1:35:37<2:23:25, 14.18s/it]INFO:root:global_step: 393, logpy: 90.925, kl: 62.350, loss: -29.904\n",
      " 39%|█████████████████████████████▌                                             | 394/1000 [1:35:52<2:23:08, 14.17s/it]INFO:root:global_step: 394, logpy: 90.941, kl: 62.354, loss: -29.902\n",
      " 40%|█████████████████████████████▋                                             | 395/1000 [1:36:06<2:22:56, 14.18s/it]INFO:root:global_step: 395, logpy: 90.958, kl: 62.364, loss: -29.896\n",
      " 40%|█████████████████████████████▋                                             | 396/1000 [1:36:20<2:22:58, 14.20s/it]INFO:root:global_step: 396, logpy: 90.991, kl: 62.369, loss: -29.912\n",
      " 40%|█████████████████████████████▊                                             | 397/1000 [1:36:34<2:23:09, 14.25s/it]INFO:root:global_step: 397, logpy: 91.006, kl: 62.378, loss: -29.904\n",
      " 40%|█████████████████████████████▊                                             | 398/1000 [1:36:49<2:22:38, 14.22s/it]INFO:root:global_step: 398, logpy: 91.035, kl: 62.382, loss: -29.916\n",
      " 40%|█████████████████████████████▉                                             | 399/1000 [1:37:03<2:22:37, 14.24s/it]INFO:root:global_step: 399, logpy: 91.055, kl: 62.385, loss: -29.921\n",
      " 40%|██████████████████████████████                                             | 400/1000 [1:37:17<2:22:42, 14.27s/it]INFO:root:Saved figure at: ./sim/global_step_400.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 400, logpy: 91.069, kl: 62.393, loss: -29.914\n",
      " 40%|██████████████████████████████                                             | 401/1000 [1:37:33<2:28:41, 14.89s/it]INFO:root:global_step: 401, logpy: 91.101, kl: 62.399, loss: -29.929\n",
      " 40%|██████████████████████████████▏                                            | 402/1000 [1:37:48<2:26:28, 14.70s/it]INFO:root:global_step: 402, logpy: 91.132, kl: 62.399, loss: -29.947\n",
      " 40%|██████████████████████████████▏                                            | 403/1000 [1:38:02<2:24:54, 14.56s/it]INFO:root:global_step: 403, logpy: 91.144, kl: 62.407, loss: -29.938\n",
      " 40%|██████████████████████████████▎                                            | 404/1000 [1:38:16<2:23:43, 14.47s/it]INFO:root:global_step: 404, logpy: 91.164, kl: 62.406, loss: -29.947\n",
      " 40%|██████████████████████████████▍                                            | 405/1000 [1:38:30<2:22:48, 14.40s/it]INFO:root:global_step: 405, logpy: 91.178, kl: 62.409, loss: -29.948\n",
      " 41%|██████████████████████████████▍                                            | 406/1000 [1:38:45<2:21:30, 14.29s/it]INFO:root:global_step: 406, logpy: 91.197, kl: 62.411, loss: -29.953\n",
      " 41%|██████████████████████████████▌                                            | 407/1000 [1:38:59<2:20:41, 14.23s/it]INFO:root:global_step: 407, logpy: 91.213, kl: 62.419, loss: -29.948\n",
      " 41%|██████████████████████████████▌                                            | 408/1000 [1:39:13<2:20:08, 14.20s/it]INFO:root:global_step: 408, logpy: 91.235, kl: 62.424, loss: -29.954\n",
      " 41%|██████████████████████████████▋                                            | 409/1000 [1:39:27<2:19:59, 14.21s/it]INFO:root:global_step: 409, logpy: 91.256, kl: 62.424, loss: -29.963\n",
      " 41%|██████████████████████████████▋                                            | 410/1000 [1:39:41<2:19:47, 14.22s/it]INFO:root:global_step: 410, logpy: 91.275, kl: 62.431, loss: -29.964\n",
      " 41%|██████████████████████████████▊                                            | 411/1000 [1:39:55<2:19:36, 14.22s/it]INFO:root:global_step: 411, logpy: 91.296, kl: 62.435, loss: -29.970\n",
      " 41%|██████████████████████████████▉                                            | 412/1000 [1:40:10<2:19:35, 14.24s/it]INFO:root:global_step: 412, logpy: 91.307, kl: 62.442, loss: -29.962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|██████████████████████████████▉                                            | 413/1000 [1:40:24<2:19:09, 14.22s/it]INFO:root:global_step: 413, logpy: 91.336, kl: 62.445, loss: -29.978\n",
      " 41%|███████████████████████████████                                            | 414/1000 [1:40:38<2:18:53, 14.22s/it]INFO:root:global_step: 414, logpy: 91.352, kl: 62.457, loss: -29.972\n",
      " 42%|███████████████████████████████▏                                           | 415/1000 [1:40:52<2:18:54, 14.25s/it]INFO:root:global_step: 415, logpy: 91.371, kl: 62.464, loss: -29.972\n",
      " 42%|███████████████████████████████▏                                           | 416/1000 [1:41:07<2:18:08, 14.19s/it]INFO:root:global_step: 416, logpy: 91.388, kl: 62.472, loss: -29.970\n",
      " 42%|███████████████████████████████▎                                           | 417/1000 [1:41:21<2:18:14, 14.23s/it]INFO:root:global_step: 417, logpy: 91.395, kl: 62.477, loss: -29.962\n",
      " 42%|███████████████████████████████▎                                           | 418/1000 [1:41:35<2:18:14, 14.25s/it]INFO:root:global_step: 418, logpy: 91.418, kl: 62.478, loss: -29.973\n",
      " 42%|███████████████████████████████▍                                           | 419/1000 [1:41:49<2:18:00, 14.25s/it]INFO:root:global_step: 419, logpy: 91.441, kl: 62.481, loss: -29.984\n",
      " 42%|███████████████████████████████▌                                           | 420/1000 [1:42:04<2:17:36, 14.24s/it]INFO:root:global_step: 420, logpy: 91.458, kl: 62.485, loss: -29.986\n",
      " 42%|███████████████████████████████▌                                           | 421/1000 [1:42:18<2:17:19, 14.23s/it]INFO:root:global_step: 421, logpy: 91.481, kl: 62.484, loss: -30.000\n",
      " 42%|███████████████████████████████▋                                           | 422/1000 [1:42:32<2:17:10, 14.24s/it]INFO:root:global_step: 422, logpy: 91.516, kl: 62.482, loss: -30.027\n",
      " 42%|███████████████████████████████▋                                           | 423/1000 [1:42:46<2:16:53, 14.24s/it]INFO:root:global_step: 423, logpy: 91.537, kl: 62.487, loss: -30.032\n",
      " 42%|███████████████████████████████▊                                           | 424/1000 [1:43:00<2:16:13, 14.19s/it]INFO:root:global_step: 424, logpy: 91.558, kl: 62.492, loss: -30.039\n",
      " 42%|███████████████████████████████▉                                           | 425/1000 [1:43:15<2:16:08, 14.21s/it]INFO:root:global_step: 425, logpy: 91.571, kl: 62.498, loss: -30.037\n",
      " 43%|███████████████████████████████▉                                           | 426/1000 [1:43:29<2:16:08, 14.23s/it]INFO:root:global_step: 426, logpy: 91.585, kl: 62.502, loss: -30.037\n",
      " 43%|████████████████████████████████                                           | 427/1000 [1:43:43<2:15:35, 14.20s/it]INFO:root:global_step: 427, logpy: 91.606, kl: 62.503, loss: -30.047\n",
      " 43%|████████████████████████████████                                           | 428/1000 [1:43:57<2:15:37, 14.23s/it]INFO:root:global_step: 428, logpy: 91.627, kl: 62.503, loss: -30.059\n",
      " 43%|████████████████████████████████▏                                          | 429/1000 [1:44:12<2:15:22, 14.23s/it]INFO:root:global_step: 429, logpy: 91.653, kl: 62.503, loss: -30.076\n",
      " 43%|████████████████████████████████▎                                          | 430/1000 [1:44:26<2:15:00, 14.21s/it]INFO:root:global_step: 430, logpy: 91.677, kl: 62.501, loss: -30.093\n",
      " 43%|████████████████████████████████▎                                          | 431/1000 [1:44:40<2:14:38, 14.20s/it]INFO:root:global_step: 431, logpy: 91.696, kl: 62.501, loss: -30.102\n",
      " 43%|████████████████████████████████▍                                          | 432/1000 [1:44:54<2:14:16, 14.18s/it]INFO:root:global_step: 432, logpy: 91.709, kl: 62.503, loss: -30.104\n",
      " 43%|████████████████████████████████▍                                          | 433/1000 [1:45:08<2:13:39, 14.14s/it]INFO:root:global_step: 433, logpy: 91.722, kl: 62.502, loss: -30.109\n",
      " 43%|████████████████████████████████▌                                          | 434/1000 [1:45:22<2:13:48, 14.18s/it]INFO:root:global_step: 434, logpy: 91.742, kl: 62.500, loss: -30.122\n",
      " 44%|████████████████████████████████▋                                          | 435/1000 [1:45:36<2:13:06, 14.13s/it]INFO:root:global_step: 435, logpy: 91.760, kl: 62.502, loss: -30.130\n",
      " 44%|████████████████████████████████▋                                          | 436/1000 [1:45:51<2:12:51, 14.13s/it]INFO:root:global_step: 436, logpy: 91.772, kl: 62.504, loss: -30.131\n",
      " 44%|████████████████████████████████▊                                          | 437/1000 [1:46:05<2:12:43, 14.14s/it]INFO:root:global_step: 437, logpy: 91.796, kl: 62.505, loss: -30.145\n",
      " 44%|████████████████████████████████▊                                          | 438/1000 [1:46:19<2:12:38, 14.16s/it]INFO:root:global_step: 438, logpy: 91.815, kl: 62.502, loss: -30.158\n",
      " 44%|████████████████████████████████▉                                          | 439/1000 [1:46:33<2:12:33, 14.18s/it]INFO:root:global_step: 439, logpy: 91.837, kl: 62.508, loss: -30.166\n",
      " 44%|█████████████████████████████████                                          | 440/1000 [1:46:48<2:13:00, 14.25s/it]INFO:root:global_step: 440, logpy: 91.856, kl: 62.513, loss: -30.172\n",
      " 44%|█████████████████████████████████                                          | 441/1000 [1:47:02<2:12:47, 14.25s/it]INFO:root:global_step: 441, logpy: 91.867, kl: 62.522, loss: -30.166\n",
      " 44%|█████████████████████████████████▏                                         | 442/1000 [1:47:16<2:12:51, 14.29s/it]INFO:root:global_step: 442, logpy: 91.887, kl: 62.522, loss: -30.177\n",
      " 44%|█████████████████████████████████▏                                         | 443/1000 [1:47:30<2:12:46, 14.30s/it]INFO:root:global_step: 443, logpy: 91.911, kl: 62.521, loss: -30.194\n",
      " 44%|█████████████████████████████████▎                                         | 444/1000 [1:47:45<2:12:19, 14.28s/it]INFO:root:global_step: 444, logpy: 91.946, kl: 62.521, loss: -30.220\n",
      " 44%|█████████████████████████████████▍                                         | 445/1000 [1:47:59<2:11:52, 14.26s/it]INFO:root:global_step: 445, logpy: 91.967, kl: 62.520, loss: -30.236\n",
      " 45%|█████████████████████████████████▍                                         | 446/1000 [1:48:13<2:11:30, 14.24s/it]INFO:root:global_step: 446, logpy: 91.986, kl: 62.523, loss: -30.244\n",
      " 45%|█████████████████████████████████▌                                         | 447/1000 [1:48:27<2:11:03, 14.22s/it]INFO:root:global_step: 447, logpy: 92.013, kl: 62.522, loss: -30.262\n",
      " 45%|█████████████████████████████████▌                                         | 448/1000 [1:48:41<2:10:31, 14.19s/it]INFO:root:global_step: 448, logpy: 92.024, kl: 62.523, loss: -30.265\n",
      " 45%|█████████████████████████████████▋                                         | 449/1000 [1:48:56<2:10:25, 14.20s/it]INFO:root:global_step: 449, logpy: 92.050, kl: 62.524, loss: -30.283\n",
      " 45%|█████████████████████████████████▊                                         | 450/1000 [1:49:10<2:09:53, 14.17s/it]INFO:root:Saved figure at: ./sim/global_step_450.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 450, logpy: 92.067, kl: 62.524, loss: -30.293\n",
      " 45%|█████████████████████████████████▊                                         | 451/1000 [1:49:26<2:15:49, 14.84s/it]INFO:root:global_step: 451, logpy: 92.064, kl: 62.525, loss: -30.281\n",
      " 45%|█████████████████████████████████▉                                         | 452/1000 [1:49:40<2:13:30, 14.62s/it]INFO:root:global_step: 452, logpy: 92.089, kl: 62.528, loss: -30.295\n",
      " 45%|█████████████████████████████████▉                                         | 453/1000 [1:49:54<2:12:06, 14.49s/it]INFO:root:global_step: 453, logpy: 92.103, kl: 62.529, loss: -30.301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|██████████████████████████████████                                         | 454/1000 [1:50:09<2:10:52, 14.38s/it]INFO:root:global_step: 454, logpy: 92.110, kl: 62.526, loss: -30.305\n",
      " 46%|██████████████████████████████████▏                                        | 455/1000 [1:50:23<2:09:53, 14.30s/it]INFO:root:global_step: 455, logpy: 92.138, kl: 62.521, loss: -30.330\n",
      " 46%|██████████████████████████████████▏                                        | 456/1000 [1:50:37<2:09:28, 14.28s/it]INFO:root:global_step: 456, logpy: 92.152, kl: 62.523, loss: -30.334\n",
      " 46%|██████████████████████████████████▎                                        | 457/1000 [1:50:51<2:08:32, 14.20s/it]INFO:root:global_step: 457, logpy: 92.164, kl: 62.523, loss: -30.339\n",
      " 46%|██████████████████████████████████▎                                        | 458/1000 [1:51:05<2:08:04, 14.18s/it]INFO:root:global_step: 458, logpy: 92.172, kl: 62.526, loss: -30.338\n",
      " 46%|██████████████████████████████████▍                                        | 459/1000 [1:51:19<2:08:09, 14.21s/it]INFO:root:global_step: 459, logpy: 92.205, kl: 62.523, loss: -30.367\n",
      " 46%|██████████████████████████████████▌                                        | 460/1000 [1:51:33<2:07:45, 14.20s/it]INFO:root:global_step: 460, logpy: 92.226, kl: 62.522, loss: -30.381\n",
      " 46%|██████████████████████████████████▌                                        | 461/1000 [1:51:48<2:07:11, 14.16s/it]INFO:root:global_step: 461, logpy: 92.242, kl: 62.526, loss: -30.388\n",
      " 46%|██████████████████████████████████▋                                        | 462/1000 [1:52:02<2:07:28, 14.22s/it]INFO:root:global_step: 462, logpy: 92.261, kl: 62.527, loss: -30.398\n",
      " 46%|██████████████████████████████████▋                                        | 463/1000 [1:52:16<2:07:12, 14.21s/it]INFO:root:global_step: 463, logpy: 92.266, kl: 62.528, loss: -30.396\n",
      " 46%|██████████████████████████████████▊                                        | 464/1000 [1:52:30<2:07:08, 14.23s/it]INFO:root:global_step: 464, logpy: 92.284, kl: 62.525, loss: -30.410\n",
      " 46%|██████████████████████████████████▉                                        | 465/1000 [1:52:45<2:06:51, 14.23s/it]INFO:root:global_step: 465, logpy: 92.290, kl: 62.528, loss: -30.407\n",
      " 47%|██████████████████████████████████▉                                        | 466/1000 [1:52:59<2:06:39, 14.23s/it]INFO:root:global_step: 466, logpy: 92.292, kl: 62.529, loss: -30.402\n",
      " 47%|███████████████████████████████████                                        | 467/1000 [1:53:13<2:06:16, 14.21s/it]INFO:root:global_step: 467, logpy: 92.299, kl: 62.527, loss: -30.403\n",
      " 47%|███████████████████████████████████                                        | 468/1000 [1:53:27<2:05:57, 14.21s/it]INFO:root:global_step: 468, logpy: 92.316, kl: 62.528, loss: -30.413\n",
      " 47%|███████████████████████████████████▏                                       | 469/1000 [1:53:42<2:05:56, 14.23s/it]INFO:root:global_step: 469, logpy: 92.323, kl: 62.525, loss: -30.417\n",
      " 47%|███████████████████████████████████▎                                       | 470/1000 [1:53:56<2:06:02, 14.27s/it]INFO:root:global_step: 470, logpy: 92.325, kl: 62.530, loss: -30.408\n",
      " 47%|███████████████████████████████████▎                                       | 471/1000 [1:54:10<2:05:52, 14.28s/it]INFO:root:global_step: 471, logpy: 92.337, kl: 62.535, loss: -30.409\n",
      " 47%|███████████████████████████████████▍                                       | 472/1000 [1:54:24<2:05:29, 14.26s/it]INFO:root:global_step: 472, logpy: 92.347, kl: 62.535, loss: -30.413\n",
      " 47%|███████████████████████████████████▍                                       | 473/1000 [1:54:39<2:05:36, 14.30s/it]INFO:root:global_step: 473, logpy: 92.357, kl: 62.536, loss: -30.415\n",
      " 47%|███████████████████████████████████▌                                       | 474/1000 [1:54:53<2:04:45, 14.23s/it]INFO:root:global_step: 474, logpy: 92.368, kl: 62.540, loss: -30.417\n",
      " 48%|███████████████████████████████████▋                                       | 475/1000 [1:55:07<2:04:34, 14.24s/it]INFO:root:global_step: 475, logpy: 92.371, kl: 62.543, loss: -30.411\n",
      " 48%|███████████████████████████████████▋                                       | 476/1000 [1:55:21<2:04:20, 14.24s/it]INFO:root:global_step: 476, logpy: 92.378, kl: 62.543, loss: -30.412\n",
      " 48%|███████████████████████████████████▊                                       | 477/1000 [1:55:36<2:04:06, 14.24s/it]INFO:root:global_step: 477, logpy: 92.403, kl: 62.540, loss: -30.434\n",
      " 48%|███████████████████████████████████▊                                       | 478/1000 [1:55:50<2:03:56, 14.25s/it]INFO:root:global_step: 478, logpy: 92.422, kl: 62.537, loss: -30.451\n",
      " 48%|███████████████████████████████████▉                                       | 479/1000 [1:56:04<2:03:42, 14.25s/it]INFO:root:global_step: 479, logpy: 92.434, kl: 62.538, loss: -30.456\n",
      " 48%|████████████████████████████████████                                       | 480/1000 [1:56:18<2:03:33, 14.26s/it]INFO:root:global_step: 480, logpy: 92.456, kl: 62.537, loss: -30.473\n",
      " 48%|████████████████████████████████████                                       | 481/1000 [1:56:33<2:03:11, 14.24s/it]INFO:root:global_step: 481, logpy: 92.471, kl: 62.533, loss: -30.486\n",
      " 48%|████████████████████████████████████▏                                      | 482/1000 [1:56:47<2:02:39, 14.21s/it]INFO:root:global_step: 482, logpy: 92.481, kl: 62.534, loss: -30.490\n",
      " 48%|████████████████████████████████████▏                                      | 483/1000 [1:57:01<2:02:09, 14.18s/it]INFO:root:global_step: 483, logpy: 92.499, kl: 62.529, loss: -30.508\n",
      " 48%|████████████████████████████████████▎                                      | 484/1000 [1:57:15<2:02:39, 14.26s/it]INFO:root:global_step: 484, logpy: 92.500, kl: 62.533, loss: -30.499\n",
      " 48%|████████████████████████████████████▍                                      | 485/1000 [1:57:30<2:02:33, 14.28s/it]INFO:root:global_step: 485, logpy: 92.494, kl: 62.537, loss: -30.484\n",
      " 49%|████████████████████████████████████▍                                      | 486/1000 [1:57:44<2:02:11, 14.26s/it]INFO:root:global_step: 486, logpy: 92.507, kl: 62.540, loss: -30.488\n",
      " 49%|████████████████████████████████████▌                                      | 487/1000 [1:57:58<2:01:57, 14.26s/it]INFO:root:global_step: 487, logpy: 92.513, kl: 62.541, loss: -30.489\n",
      " 49%|████████████████████████████████████▌                                      | 488/1000 [1:58:12<2:01:35, 14.25s/it]INFO:root:global_step: 488, logpy: 92.525, kl: 62.544, loss: -30.493\n",
      " 49%|████████████████████████████████████▋                                      | 489/1000 [1:58:27<2:01:20, 14.25s/it]INFO:root:global_step: 489, logpy: 92.539, kl: 62.551, loss: -30.494\n",
      " 49%|████████████████████████████████████▊                                      | 490/1000 [1:58:41<2:00:52, 14.22s/it]INFO:root:global_step: 490, logpy: 92.559, kl: 62.547, loss: -30.514\n",
      " 49%|████████████████████████████████████▊                                      | 491/1000 [1:58:55<2:00:38, 14.22s/it]INFO:root:global_step: 491, logpy: 92.575, kl: 62.552, loss: -30.519\n",
      " 49%|████████████████████████████████████▉                                      | 492/1000 [1:59:09<2:00:34, 14.24s/it]INFO:root:global_step: 492, logpy: 92.580, kl: 62.552, loss: -30.520\n",
      " 49%|████████████████████████████████████▉                                      | 493/1000 [1:59:24<2:00:44, 14.29s/it]INFO:root:global_step: 493, logpy: 92.584, kl: 62.558, loss: -30.513\n",
      " 49%|█████████████████████████████████████                                      | 494/1000 [1:59:38<2:00:21, 14.27s/it]INFO:root:global_step: 494, logpy: 92.587, kl: 62.561, loss: -30.507\n",
      " 50%|█████████████████████████████████████▏                                     | 495/1000 [1:59:52<2:00:15, 14.29s/it]INFO:root:global_step: 495, logpy: 92.609, kl: 62.567, loss: -30.519\n",
      " 50%|█████████████████████████████████████▏                                     | 496/1000 [2:00:06<1:59:45, 14.26s/it]INFO:root:global_step: 496, logpy: 92.614, kl: 62.572, loss: -30.515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████▎                                     | 497/1000 [2:00:21<1:59:31, 14.26s/it]INFO:root:global_step: 497, logpy: 92.622, kl: 62.581, loss: -30.508\n",
      " 50%|█████████████████████████████████████▎                                     | 498/1000 [2:00:35<1:59:21, 14.27s/it]INFO:root:global_step: 498, logpy: 92.629, kl: 62.583, loss: -30.509\n",
      " 50%|█████████████████████████████████████▍                                     | 499/1000 [2:00:49<1:59:19, 14.29s/it]INFO:root:global_step: 499, logpy: 92.635, kl: 62.591, loss: -30.502\n",
      " 50%|█████████████████████████████████████▌                                     | 500/1000 [2:01:03<1:58:43, 14.25s/it]INFO:root:Saved figure at: ./sim/global_step_500.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 500, logpy: 92.650, kl: 62.597, loss: -30.506\n",
      " 50%|█████████████████████████████████████▌                                     | 501/1000 [2:01:20<2:03:56, 14.90s/it]INFO:root:global_step: 501, logpy: 92.660, kl: 62.603, loss: -30.506\n",
      " 50%|█████████████████████████████████████▋                                     | 502/1000 [2:01:34<2:02:00, 14.70s/it]INFO:root:global_step: 502, logpy: 92.658, kl: 62.603, loss: -30.499\n",
      " 50%|█████████████████████████████████████▋                                     | 503/1000 [2:01:48<2:00:41, 14.57s/it]INFO:root:global_step: 503, logpy: 92.677, kl: 62.599, loss: -30.519\n",
      " 50%|█████████████████████████████████████▊                                     | 504/1000 [2:02:03<1:59:39, 14.47s/it]INFO:root:global_step: 504, logpy: 92.692, kl: 62.606, loss: -30.521\n",
      " 50%|█████████████████████████████████████▉                                     | 505/1000 [2:02:17<1:58:13, 14.33s/it]INFO:root:global_step: 505, logpy: 92.689, kl: 62.611, loss: -30.509\n",
      " 51%|█████████████████████████████████████▉                                     | 506/1000 [2:02:31<1:57:55, 14.32s/it]INFO:root:global_step: 506, logpy: 92.713, kl: 62.608, loss: -30.532\n",
      " 51%|██████████████████████████████████████                                     | 507/1000 [2:02:45<1:57:16, 14.27s/it]INFO:root:global_step: 507, logpy: 92.709, kl: 62.612, loss: -30.520\n",
      " 51%|██████████████████████████████████████                                     | 508/1000 [2:02:59<1:56:36, 14.22s/it]INFO:root:global_step: 508, logpy: 92.722, kl: 62.611, loss: -30.529\n",
      " 51%|██████████████████████████████████████▏                                    | 509/1000 [2:03:13<1:56:10, 14.20s/it]INFO:root:global_step: 509, logpy: 92.733, kl: 62.611, loss: -30.536\n",
      " 51%|██████████████████████████████████████▎                                    | 510/1000 [2:03:28<1:56:22, 14.25s/it]INFO:root:global_step: 510, logpy: 92.756, kl: 62.609, loss: -30.556\n",
      " 51%|██████████████████████████████████████▎                                    | 511/1000 [2:03:42<1:56:07, 14.25s/it]INFO:root:global_step: 511, logpy: 92.757, kl: 62.605, loss: -30.558\n",
      " 51%|██████████████████████████████████████▍                                    | 512/1000 [2:03:56<1:56:04, 14.27s/it]INFO:root:global_step: 512, logpy: 92.762, kl: 62.605, loss: -30.558\n",
      " 51%|██████████████████████████████████████▍                                    | 513/1000 [2:04:10<1:55:46, 14.26s/it]INFO:root:global_step: 513, logpy: 92.759, kl: 62.604, loss: -30.554\n",
      " 51%|██████████████████████████████████████▌                                    | 514/1000 [2:04:25<1:55:38, 14.28s/it]INFO:root:global_step: 514, logpy: 92.769, kl: 62.607, loss: -30.555\n",
      " 52%|██████████████████████████████████████▋                                    | 515/1000 [2:04:39<1:55:24, 14.28s/it]INFO:root:global_step: 515, logpy: 92.778, kl: 62.606, loss: -30.561\n",
      " 52%|██████████████████████████████████████▋                                    | 516/1000 [2:04:53<1:55:06, 14.27s/it]INFO:root:global_step: 516, logpy: 92.790, kl: 62.609, loss: -30.567\n",
      " 52%|██████████████████████████████████████▊                                    | 517/1000 [2:05:08<1:54:49, 14.26s/it]INFO:root:global_step: 517, logpy: 92.799, kl: 62.612, loss: -30.569\n",
      " 52%|██████████████████████████████████████▊                                    | 518/1000 [2:05:22<1:54:26, 14.25s/it]INFO:root:global_step: 518, logpy: 92.819, kl: 62.616, loss: -30.581\n",
      " 52%|██████████████████████████████████████▉                                    | 519/1000 [2:05:36<1:54:07, 14.24s/it]INFO:root:global_step: 519, logpy: 92.827, kl: 62.618, loss: -30.584\n",
      " 52%|███████████████████████████████████████                                    | 520/1000 [2:05:50<1:54:08, 14.27s/it]INFO:root:global_step: 520, logpy: 92.823, kl: 62.621, loss: -30.573\n",
      " 52%|███████████████████████████████████████                                    | 521/1000 [2:06:04<1:53:31, 14.22s/it]INFO:root:global_step: 521, logpy: 92.830, kl: 62.621, loss: -30.576\n",
      " 52%|███████████████████████████████████████▏                                   | 522/1000 [2:06:19<1:53:22, 14.23s/it]INFO:root:global_step: 522, logpy: 92.850, kl: 62.623, loss: -30.591\n",
      " 52%|███████████████████████████████████████▏                                   | 523/1000 [2:06:33<1:53:09, 14.23s/it]INFO:root:global_step: 523, logpy: 92.862, kl: 62.629, loss: -30.593\n",
      " 52%|███████████████████████████████████████▎                                   | 524/1000 [2:06:47<1:52:42, 14.21s/it]INFO:root:global_step: 524, logpy: 92.865, kl: 62.629, loss: -30.593\n",
      " 52%|███████████████████████████████████████▍                                   | 525/1000 [2:07:01<1:52:07, 14.16s/it]INFO:root:global_step: 525, logpy: 92.867, kl: 62.631, loss: -30.588\n",
      " 53%|███████████████████████████████████████▍                                   | 526/1000 [2:07:15<1:52:16, 14.21s/it]INFO:root:global_step: 526, logpy: 92.887, kl: 62.628, loss: -30.608\n",
      " 53%|███████████████████████████████████████▌                                   | 527/1000 [2:07:30<1:52:04, 14.22s/it]INFO:root:global_step: 527, logpy: 92.901, kl: 62.630, loss: -30.616\n",
      " 53%|███████████████████████████████████████▌                                   | 528/1000 [2:07:44<1:51:48, 14.21s/it]INFO:root:global_step: 528, logpy: 92.909, kl: 62.632, loss: -30.620\n",
      " 53%|███████████████████████████████████████▋                                   | 529/1000 [2:07:58<1:51:09, 14.16s/it]INFO:root:global_step: 529, logpy: 92.913, kl: 62.630, loss: -30.622\n",
      " 53%|███████████████████████████████████████▊                                   | 530/1000 [2:08:12<1:51:21, 14.22s/it]INFO:root:global_step: 530, logpy: 92.919, kl: 62.632, loss: -30.622\n",
      " 53%|███████████████████████████████████████▊                                   | 531/1000 [2:08:27<1:51:33, 14.27s/it]INFO:root:global_step: 531, logpy: 92.917, kl: 62.634, loss: -30.615\n",
      " 53%|███████████████████████████████████████▉                                   | 532/1000 [2:08:41<1:51:24, 14.28s/it]INFO:root:global_step: 532, logpy: 92.921, kl: 62.633, loss: -30.617\n",
      " 53%|███████████████████████████████████████▉                                   | 533/1000 [2:08:55<1:51:07, 14.28s/it]INFO:root:global_step: 533, logpy: 92.934, kl: 62.637, loss: -30.623\n",
      " 53%|████████████████████████████████████████                                   | 534/1000 [2:09:09<1:50:37, 14.24s/it]INFO:root:global_step: 534, logpy: 92.939, kl: 62.641, loss: -30.620\n",
      " 54%|████████████████████████████████████████▏                                  | 535/1000 [2:09:24<1:50:38, 14.28s/it]INFO:root:global_step: 535, logpy: 92.926, kl: 62.641, loss: -30.604\n",
      " 54%|████████████████████████████████████████▏                                  | 536/1000 [2:09:38<1:50:03, 14.23s/it]INFO:root:global_step: 536, logpy: 92.936, kl: 62.637, loss: -30.615\n",
      " 54%|████████████████████████████████████████▎                                  | 537/1000 [2:09:52<1:49:59, 14.25s/it]INFO:root:global_step: 537, logpy: 92.952, kl: 62.632, loss: -30.632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|████████████████████████████████████████▎                                  | 538/1000 [2:10:06<1:49:38, 14.24s/it]INFO:root:global_step: 538, logpy: 92.960, kl: 62.636, loss: -30.633\n",
      " 54%|████████████████████████████████████████▍                                  | 539/1000 [2:10:20<1:49:05, 14.20s/it]INFO:root:global_step: 539, logpy: 92.970, kl: 62.636, loss: -30.640\n",
      " 54%|████████████████████████████████████████▌                                  | 540/1000 [2:10:35<1:48:57, 14.21s/it]INFO:root:global_step: 540, logpy: 92.976, kl: 62.644, loss: -30.635\n",
      " 54%|████████████████████████████████████████▌                                  | 541/1000 [2:10:49<1:48:55, 14.24s/it]INFO:root:global_step: 541, logpy: 92.974, kl: 62.650, loss: -30.624\n",
      " 54%|████████████████████████████████████████▋                                  | 542/1000 [2:11:03<1:49:03, 14.29s/it]INFO:root:global_step: 542, logpy: 92.980, kl: 62.653, loss: -30.624\n",
      " 54%|████████████████████████████████████████▋                                  | 543/1000 [2:11:18<1:48:56, 14.30s/it]INFO:root:global_step: 543, logpy: 92.993, kl: 62.655, loss: -30.632\n",
      " 54%|████████████████████████████████████████▊                                  | 544/1000 [2:11:32<1:48:22, 14.26s/it]INFO:root:global_step: 544, logpy: 93.000, kl: 62.663, loss: -30.628\n",
      " 55%|████████████████████████████████████████▉                                  | 545/1000 [2:11:46<1:48:11, 14.27s/it]INFO:root:global_step: 545, logpy: 92.997, kl: 62.667, loss: -30.618\n",
      " 55%|████████████████████████████████████████▉                                  | 546/1000 [2:12:00<1:47:31, 14.21s/it]INFO:root:global_step: 546, logpy: 93.022, kl: 62.670, loss: -30.638\n",
      " 55%|█████████████████████████████████████████                                  | 547/1000 [2:12:15<1:47:30, 14.24s/it]INFO:root:global_step: 547, logpy: 93.031, kl: 62.669, loss: -30.644\n",
      " 55%|█████████████████████████████████████████                                  | 548/1000 [2:12:29<1:47:42, 14.30s/it]INFO:root:global_step: 548, logpy: 93.031, kl: 62.681, loss: -30.630\n",
      " 55%|█████████████████████████████████████████▏                                 | 549/1000 [2:12:43<1:47:30, 14.30s/it]INFO:root:global_step: 549, logpy: 93.039, kl: 62.682, loss: -30.634\n",
      " 55%|█████████████████████████████████████████▎                                 | 550/1000 [2:12:58<1:47:25, 14.32s/it]INFO:root:Saved figure at: ./sim/global_step_550.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 550, logpy: 93.044, kl: 62.685, loss: -30.633\n",
      " 55%|█████████████████████████████████████████▎                                 | 551/1000 [2:13:14<1:52:05, 14.98s/it]INFO:root:global_step: 551, logpy: 93.060, kl: 62.692, loss: -30.640\n",
      " 55%|█████████████████████████████████████████▍                                 | 552/1000 [2:13:29<1:50:22, 14.78s/it]INFO:root:global_step: 552, logpy: 93.079, kl: 62.688, loss: -30.660\n",
      " 55%|█████████████████████████████████████████▍                                 | 553/1000 [2:13:43<1:49:01, 14.63s/it]INFO:root:global_step: 553, logpy: 93.089, kl: 62.692, loss: -30.663\n",
      " 55%|█████████████████████████████████████████▌                                 | 554/1000 [2:13:57<1:48:01, 14.53s/it]INFO:root:global_step: 554, logpy: 93.096, kl: 62.691, loss: -30.669\n",
      " 56%|█████████████████████████████████████████▋                                 | 555/1000 [2:14:11<1:47:05, 14.44s/it]INFO:root:global_step: 555, logpy: 93.107, kl: 62.692, loss: -30.676\n",
      " 56%|█████████████████████████████████████████▋                                 | 556/1000 [2:14:26<1:46:53, 14.44s/it]INFO:root:global_step: 556, logpy: 93.109, kl: 62.692, loss: -30.675\n",
      " 56%|█████████████████████████████████████████▊                                 | 557/1000 [2:14:40<1:46:16, 14.39s/it]INFO:root:global_step: 557, logpy: 93.122, kl: 62.686, loss: -30.691\n",
      " 56%|█████████████████████████████████████████▊                                 | 558/1000 [2:14:54<1:45:10, 14.28s/it]INFO:root:global_step: 558, logpy: 93.138, kl: 62.685, loss: -30.706\n",
      " 56%|█████████████████████████████████████████▉                                 | 559/1000 [2:15:08<1:45:09, 14.31s/it]INFO:root:global_step: 559, logpy: 93.151, kl: 62.681, loss: -30.720\n",
      " 56%|██████████████████████████████████████████                                 | 560/1000 [2:15:23<1:45:01, 14.32s/it]INFO:root:global_step: 560, logpy: 93.161, kl: 62.678, loss: -30.731\n",
      " 56%|██████████████████████████████████████████                                 | 561/1000 [2:15:37<1:45:05, 14.36s/it]INFO:root:global_step: 561, logpy: 93.164, kl: 62.676, loss: -30.734\n",
      " 56%|██████████████████████████████████████████▏                                | 562/1000 [2:15:52<1:44:39, 14.34s/it]INFO:root:global_step: 562, logpy: 93.173, kl: 62.674, loss: -30.743\n",
      " 56%|██████████████████████████████████████████▏                                | 563/1000 [2:16:06<1:44:39, 14.37s/it]INFO:root:global_step: 563, logpy: 93.173, kl: 62.671, loss: -30.743\n",
      " 56%|██████████████████████████████████████████▎                                | 564/1000 [2:16:20<1:44:27, 14.38s/it]INFO:root:global_step: 564, logpy: 93.167, kl: 62.671, loss: -30.735\n",
      " 56%|██████████████████████████████████████████▎                                | 565/1000 [2:16:35<1:44:01, 14.35s/it]INFO:root:global_step: 565, logpy: 93.162, kl: 62.670, loss: -30.728\n",
      " 57%|██████████████████████████████████████████▍                                | 566/1000 [2:16:49<1:43:28, 14.31s/it]INFO:root:global_step: 566, logpy: 93.163, kl: 62.669, loss: -30.728\n",
      " 57%|██████████████████████████████████████████▌                                | 567/1000 [2:17:03<1:43:09, 14.30s/it]INFO:root:global_step: 567, logpy: 93.166, kl: 62.669, loss: -30.728\n",
      " 57%|██████████████████████████████████████████▌                                | 568/1000 [2:17:17<1:43:01, 14.31s/it]INFO:root:global_step: 568, logpy: 93.172, kl: 62.666, loss: -30.735\n",
      " 57%|██████████████████████████████████████████▋                                | 569/1000 [2:17:32<1:42:29, 14.27s/it]INFO:root:global_step: 569, logpy: 93.173, kl: 62.666, loss: -30.734\n",
      " 57%|██████████████████████████████████████████▋                                | 570/1000 [2:17:46<1:42:33, 14.31s/it]INFO:root:global_step: 570, logpy: 93.165, kl: 62.665, loss: -30.724\n",
      " 57%|██████████████████████████████████████████▊                                | 571/1000 [2:18:00<1:42:09, 14.29s/it]INFO:root:global_step: 571, logpy: 93.178, kl: 62.668, loss: -30.731\n",
      " 57%|██████████████████████████████████████████▉                                | 572/1000 [2:18:15<1:42:14, 14.33s/it]INFO:root:global_step: 572, logpy: 93.173, kl: 62.669, loss: -30.724\n",
      " 57%|██████████████████████████████████████████▉                                | 573/1000 [2:18:29<1:41:57, 14.33s/it]INFO:root:global_step: 573, logpy: 93.184, kl: 62.665, loss: -30.737\n",
      " 57%|███████████████████████████████████████████                                | 574/1000 [2:18:43<1:41:33, 14.30s/it]INFO:root:global_step: 574, logpy: 93.189, kl: 62.670, loss: -30.734\n",
      " 57%|███████████████████████████████████████████▏                               | 575/1000 [2:18:57<1:41:04, 14.27s/it]INFO:root:global_step: 575, logpy: 93.188, kl: 62.676, loss: -30.725\n",
      " 58%|███████████████████████████████████████████▏                               | 576/1000 [2:19:12<1:41:07, 14.31s/it]INFO:root:global_step: 576, logpy: 93.202, kl: 62.676, loss: -30.738\n",
      " 58%|███████████████████████████████████████████▎                               | 577/1000 [2:19:26<1:40:46, 14.29s/it]INFO:root:global_step: 577, logpy: 93.209, kl: 62.678, loss: -30.740\n",
      " 58%|███████████████████████████████████████████▎                               | 578/1000 [2:19:40<1:40:33, 14.30s/it]INFO:root:global_step: 578, logpy: 93.216, kl: 62.682, loss: -30.741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|███████████████████████████████████████████▍                               | 579/1000 [2:19:55<1:40:26, 14.31s/it]INFO:root:global_step: 579, logpy: 93.219, kl: 62.686, loss: -30.738\n",
      " 58%|███████████████████████████████████████████▌                               | 580/1000 [2:20:09<1:40:00, 14.29s/it]INFO:root:global_step: 580, logpy: 93.218, kl: 62.692, loss: -30.729\n",
      " 58%|███████████████████████████████████████████▌                               | 581/1000 [2:20:24<1:40:16, 14.36s/it]INFO:root:global_step: 581, logpy: 93.217, kl: 62.692, loss: -30.726\n",
      " 58%|███████████████████████████████████████████▋                               | 582/1000 [2:20:38<1:39:50, 14.33s/it]INFO:root:global_step: 582, logpy: 93.230, kl: 62.693, loss: -30.736\n",
      " 58%|███████████████████████████████████████████▋                               | 583/1000 [2:20:52<1:39:34, 14.33s/it]INFO:root:global_step: 583, logpy: 93.232, kl: 62.693, loss: -30.736\n",
      " 58%|███████████████████████████████████████████▊                               | 584/1000 [2:21:06<1:39:07, 14.30s/it]INFO:root:global_step: 584, logpy: 93.238, kl: 62.694, loss: -30.739\n",
      " 58%|███████████████████████████████████████████▉                               | 585/1000 [2:21:21<1:39:08, 14.33s/it]INFO:root:global_step: 585, logpy: 93.226, kl: 62.698, loss: -30.721\n",
      " 59%|███████████████████████████████████████████▉                               | 586/1000 [2:21:35<1:39:02, 14.35s/it]INFO:root:global_step: 586, logpy: 93.220, kl: 62.703, loss: -30.709\n",
      " 59%|████████████████████████████████████████████                               | 587/1000 [2:21:49<1:38:33, 14.32s/it]INFO:root:global_step: 587, logpy: 93.227, kl: 62.699, loss: -30.717\n",
      " 59%|████████████████████████████████████████████                               | 588/1000 [2:22:04<1:38:14, 14.31s/it]INFO:root:global_step: 588, logpy: 93.233, kl: 62.699, loss: -30.722\n",
      " 59%|████████████████████████████████████████████▏                              | 589/1000 [2:22:18<1:38:01, 14.31s/it]INFO:root:global_step: 589, logpy: 93.233, kl: 62.695, loss: -30.723\n",
      " 59%|████████████████████████████████████████████▎                              | 590/1000 [2:22:32<1:37:47, 14.31s/it]INFO:root:global_step: 590, logpy: 93.246, kl: 62.693, loss: -30.737\n",
      " 59%|████████████████████████████████████████████▎                              | 591/1000 [2:22:47<1:37:32, 14.31s/it]INFO:root:global_step: 591, logpy: 93.251, kl: 62.693, loss: -30.739\n",
      " 59%|████████████████████████████████████████████▍                              | 592/1000 [2:23:01<1:37:26, 14.33s/it]INFO:root:global_step: 592, logpy: 93.260, kl: 62.693, loss: -30.746\n",
      " 59%|████████████████████████████████████████████▍                              | 593/1000 [2:23:15<1:37:02, 14.31s/it]INFO:root:global_step: 593, logpy: 93.269, kl: 62.690, loss: -30.757\n",
      " 59%|████████████████████████████████████████████▌                              | 594/1000 [2:23:30<1:36:38, 14.28s/it]INFO:root:global_step: 594, logpy: 93.270, kl: 62.689, loss: -30.757\n",
      " 60%|████████████████████████████████████████████▋                              | 595/1000 [2:23:44<1:36:24, 14.28s/it]INFO:root:global_step: 595, logpy: 93.289, kl: 62.691, loss: -30.773\n",
      " 60%|████████████████████████████████████████████▋                              | 596/1000 [2:23:58<1:36:29, 14.33s/it]INFO:root:global_step: 596, logpy: 93.307, kl: 62.690, loss: -30.790\n",
      " 60%|████████████████████████████████████████████▊                              | 597/1000 [2:24:13<1:36:28, 14.36s/it]INFO:root:global_step: 597, logpy: 93.309, kl: 62.689, loss: -30.791\n",
      " 60%|████████████████████████████████████████████▊                              | 598/1000 [2:24:27<1:36:09, 14.35s/it]INFO:root:global_step: 598, logpy: 93.307, kl: 62.691, loss: -30.786\n",
      " 60%|████████████████████████████████████████████▉                              | 599/1000 [2:24:41<1:35:36, 14.30s/it]INFO:root:global_step: 599, logpy: 93.321, kl: 62.683, loss: -30.806\n",
      " 60%|█████████████████████████████████████████████                              | 600/1000 [2:24:55<1:35:07, 14.27s/it]INFO:root:Saved figure at: ./sim/global_step_600.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 600, logpy: 93.331, kl: 62.676, loss: -30.821\n",
      " 60%|█████████████████████████████████████████████                              | 601/1000 [2:25:12<1:39:21, 14.94s/it]INFO:root:global_step: 601, logpy: 93.338, kl: 62.674, loss: -30.829\n",
      " 60%|█████████████████████████████████████████████▏                             | 602/1000 [2:25:26<1:37:35, 14.71s/it]INFO:root:global_step: 602, logpy: 93.358, kl: 62.665, loss: -30.856\n",
      " 60%|█████████████████████████████████████████████▏                             | 603/1000 [2:25:40<1:36:12, 14.54s/it]INFO:root:global_step: 603, logpy: 93.354, kl: 62.667, loss: -30.848\n",
      " 60%|█████████████████████████████████████████████▎                             | 604/1000 [2:25:54<1:35:26, 14.46s/it]INFO:root:global_step: 604, logpy: 93.357, kl: 62.658, loss: -30.858\n",
      " 60%|█████████████████████████████████████████████▍                             | 605/1000 [2:26:09<1:34:50, 14.41s/it]INFO:root:global_step: 605, logpy: 93.375, kl: 62.653, loss: -30.880\n",
      " 61%|█████████████████████████████████████████████▍                             | 606/1000 [2:26:23<1:34:12, 14.35s/it]INFO:root:global_step: 606, logpy: 93.382, kl: 62.647, loss: -30.891\n",
      " 61%|█████████████████████████████████████████████▌                             | 607/1000 [2:26:37<1:33:53, 14.33s/it]INFO:root:global_step: 607, logpy: 93.378, kl: 62.642, loss: -30.890\n",
      " 61%|█████████████████████████████████████████████▌                             | 608/1000 [2:26:51<1:33:22, 14.29s/it]INFO:root:global_step: 608, logpy: 93.377, kl: 62.634, loss: -30.896\n",
      " 61%|█████████████████████████████████████████████▋                             | 609/1000 [2:27:06<1:33:09, 14.30s/it]INFO:root:global_step: 609, logpy: 93.377, kl: 62.633, loss: -30.896\n",
      " 61%|█████████████████████████████████████████████▊                             | 610/1000 [2:27:20<1:33:12, 14.34s/it]INFO:root:global_step: 610, logpy: 93.371, kl: 62.633, loss: -30.889\n",
      " 61%|█████████████████████████████████████████████▊                             | 611/1000 [2:27:34<1:32:46, 14.31s/it]INFO:root:global_step: 611, logpy: 93.373, kl: 62.627, loss: -30.894\n",
      " 61%|█████████████████████████████████████████████▉                             | 612/1000 [2:27:49<1:32:32, 14.31s/it]INFO:root:global_step: 612, logpy: 93.384, kl: 62.625, loss: -30.906\n",
      " 61%|█████████████████████████████████████████████▉                             | 613/1000 [2:28:03<1:32:24, 14.33s/it]INFO:root:global_step: 613, logpy: 93.384, kl: 62.618, loss: -30.912\n",
      " 61%|██████████████████████████████████████████████                             | 614/1000 [2:28:17<1:31:57, 14.29s/it]INFO:root:global_step: 614, logpy: 93.398, kl: 62.606, loss: -30.936\n",
      " 62%|██████████████████████████████████████████████▏                            | 615/1000 [2:28:32<1:31:41, 14.29s/it]INFO:root:global_step: 615, logpy: 93.396, kl: 62.606, loss: -30.933\n",
      " 62%|██████████████████████████████████████████████▏                            | 616/1000 [2:28:46<1:31:25, 14.29s/it]INFO:root:global_step: 616, logpy: 93.402, kl: 62.609, loss: -30.934\n",
      " 62%|██████████████████████████████████████████████▎                            | 617/1000 [2:29:00<1:31:09, 14.28s/it]INFO:root:global_step: 617, logpy: 93.411, kl: 62.610, loss: -30.941\n",
      " 62%|██████████████████████████████████████████████▎                            | 618/1000 [2:29:14<1:30:42, 14.25s/it]INFO:root:global_step: 618, logpy: 93.413, kl: 62.606, loss: -30.946\n",
      " 62%|██████████████████████████████████████████████▍                            | 619/1000 [2:29:29<1:30:47, 14.30s/it]INFO:root:global_step: 619, logpy: 93.413, kl: 62.611, loss: -30.939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████████████████████████████████████████████▌                            | 620/1000 [2:29:43<1:30:30, 14.29s/it]INFO:root:global_step: 620, logpy: 93.412, kl: 62.609, loss: -30.938\n",
      " 62%|██████████████████████████████████████████████▌                            | 621/1000 [2:29:57<1:29:52, 14.23s/it]INFO:root:global_step: 621, logpy: 93.406, kl: 62.609, loss: -30.932\n",
      " 62%|██████████████████████████████████████████████▋                            | 622/1000 [2:30:11<1:29:43, 14.24s/it]INFO:root:global_step: 622, logpy: 93.402, kl: 62.607, loss: -30.928\n",
      " 62%|██████████████████████████████████████████████▋                            | 623/1000 [2:30:26<1:29:33, 14.25s/it]INFO:root:global_step: 623, logpy: 93.401, kl: 62.609, loss: -30.924\n",
      " 62%|██████████████████████████████████████████████▊                            | 624/1000 [2:30:40<1:29:21, 14.26s/it]INFO:root:global_step: 624, logpy: 93.405, kl: 62.618, loss: -30.917\n",
      " 62%|██████████████████████████████████████████████▉                            | 625/1000 [2:30:54<1:29:22, 14.30s/it]INFO:root:global_step: 625, logpy: 93.407, kl: 62.618, loss: -30.918\n",
      " 63%|██████████████████████████████████████████████▉                            | 626/1000 [2:31:09<1:29:11, 14.31s/it]INFO:root:global_step: 626, logpy: 93.419, kl: 62.619, loss: -30.927\n",
      " 63%|███████████████████████████████████████████████                            | 627/1000 [2:31:23<1:28:51, 14.29s/it]INFO:root:global_step: 627, logpy: 93.423, kl: 62.616, loss: -30.934\n",
      " 63%|███████████████████████████████████████████████                            | 628/1000 [2:31:37<1:28:51, 14.33s/it]INFO:root:global_step: 628, logpy: 93.446, kl: 62.622, loss: -30.949\n",
      " 63%|███████████████████████████████████████████████▏                           | 629/1000 [2:31:52<1:28:33, 14.32s/it]INFO:root:global_step: 629, logpy: 93.455, kl: 62.624, loss: -30.956\n",
      " 63%|███████████████████████████████████████████████▎                           | 630/1000 [2:32:06<1:28:32, 14.36s/it]INFO:root:global_step: 630, logpy: 93.465, kl: 62.626, loss: -30.962\n",
      " 63%|███████████████████████████████████████████████▎                           | 631/1000 [2:32:20<1:28:23, 14.37s/it]INFO:root:global_step: 631, logpy: 93.483, kl: 62.628, loss: -30.976\n",
      " 63%|███████████████████████████████████████████████▍                           | 632/1000 [2:32:35<1:27:57, 14.34s/it]INFO:root:global_step: 632, logpy: 93.484, kl: 62.634, loss: -30.970\n",
      " 63%|███████████████████████████████████████████████▍                           | 633/1000 [2:32:49<1:27:24, 14.29s/it]INFO:root:global_step: 633, logpy: 93.485, kl: 62.638, loss: -30.967\n",
      " 63%|███████████████████████████████████████████████▌                           | 634/1000 [2:33:03<1:27:20, 14.32s/it]INFO:root:global_step: 634, logpy: 93.496, kl: 62.637, loss: -30.976\n",
      " 64%|███████████████████████████████████████████████▋                           | 635/1000 [2:33:18<1:26:54, 14.28s/it]INFO:root:global_step: 635, logpy: 93.500, kl: 62.641, loss: -30.976\n",
      " 64%|███████████████████████████████████████████████▋                           | 636/1000 [2:33:32<1:26:36, 14.28s/it]INFO:root:global_step: 636, logpy: 93.500, kl: 62.646, loss: -30.970\n",
      " 64%|███████████████████████████████████████████████▊                           | 637/1000 [2:33:46<1:26:26, 14.29s/it]INFO:root:global_step: 637, logpy: 93.499, kl: 62.647, loss: -30.966\n",
      " 64%|███████████████████████████████████████████████▊                           | 638/1000 [2:34:00<1:26:14, 14.29s/it]INFO:root:global_step: 638, logpy: 93.513, kl: 62.647, loss: -30.980\n",
      " 64%|███████████████████████████████████████████████▉                           | 639/1000 [2:34:14<1:25:30, 14.21s/it]INFO:root:global_step: 639, logpy: 93.524, kl: 62.650, loss: -30.986\n",
      " 64%|████████████████████████████████████████████████                           | 640/1000 [2:34:29<1:25:32, 14.26s/it]INFO:root:global_step: 640, logpy: 93.524, kl: 62.651, loss: -30.984\n",
      " 64%|████████████████████████████████████████████████                           | 641/1000 [2:34:43<1:25:29, 14.29s/it]INFO:root:global_step: 641, logpy: 93.514, kl: 62.650, loss: -30.974\n",
      " 64%|████████████████████████████████████████████████▏                          | 642/1000 [2:34:57<1:25:18, 14.30s/it]INFO:root:global_step: 642, logpy: 93.512, kl: 62.652, loss: -30.968\n",
      " 64%|████████████████████████████████████████████████▏                          | 643/1000 [2:35:12<1:24:56, 14.28s/it]INFO:root:global_step: 643, logpy: 93.536, kl: 62.649, loss: -30.994\n",
      " 64%|████████████████████████████████████████████████▎                          | 644/1000 [2:35:26<1:24:28, 14.24s/it]INFO:root:global_step: 644, logpy: 93.529, kl: 62.647, loss: -30.989\n",
      " 64%|████████████████████████████████████████████████▍                          | 645/1000 [2:35:40<1:24:16, 14.24s/it]INFO:root:global_step: 645, logpy: 93.533, kl: 62.643, loss: -30.996\n",
      " 65%|████████████████████████████████████████████████▍                          | 646/1000 [2:35:54<1:24:03, 14.25s/it]INFO:root:global_step: 646, logpy: 93.547, kl: 62.640, loss: -31.011\n",
      " 65%|████████████████████████████████████████████████▌                          | 647/1000 [2:36:09<1:24:07, 14.30s/it]INFO:root:global_step: 647, logpy: 93.551, kl: 62.642, loss: -31.012\n",
      " 65%|████████████████████████████████████████████████▌                          | 648/1000 [2:36:23<1:24:02, 14.33s/it]INFO:root:global_step: 648, logpy: 93.548, kl: 62.643, loss: -31.007\n",
      " 65%|████████████████████████████████████████████████▋                          | 649/1000 [2:36:37<1:23:44, 14.31s/it]INFO:root:global_step: 649, logpy: 93.545, kl: 62.647, loss: -30.999\n",
      " 65%|████████████████████████████████████████████████▊                          | 650/1000 [2:36:52<1:23:11, 14.26s/it]INFO:root:Saved figure at: ./sim/global_step_650.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 650, logpy: 93.549, kl: 62.650, loss: -31.000\n",
      " 65%|████████████████████████████████████████████████▊                          | 651/1000 [2:37:08<1:27:03, 14.97s/it]INFO:root:global_step: 651, logpy: 93.555, kl: 62.655, loss: -30.999\n",
      " 65%|████████████████████████████████████████████████▉                          | 652/1000 [2:37:23<1:25:49, 14.80s/it]INFO:root:global_step: 652, logpy: 93.560, kl: 62.659, loss: -30.999\n",
      " 65%|████████████████████████████████████████████████▉                          | 653/1000 [2:37:37<1:25:02, 14.70s/it]INFO:root:global_step: 653, logpy: 93.555, kl: 62.666, loss: -30.987\n",
      " 65%|█████████████████████████████████████████████████                          | 654/1000 [2:37:51<1:24:14, 14.61s/it]INFO:root:global_step: 654, logpy: 93.556, kl: 62.674, loss: -30.978\n",
      " 66%|█████████████████████████████████████████████████▏                         | 655/1000 [2:38:06<1:23:22, 14.50s/it]INFO:root:global_step: 655, logpy: 93.560, kl: 62.682, loss: -30.973\n",
      " 66%|█████████████████████████████████████████████████▏                         | 656/1000 [2:38:20<1:23:10, 14.51s/it]INFO:root:global_step: 656, logpy: 93.571, kl: 62.685, loss: -30.980\n",
      " 66%|█████████████████████████████████████████████████▎                         | 657/1000 [2:38:35<1:22:51, 14.50s/it]INFO:root:global_step: 657, logpy: 93.578, kl: 62.695, loss: -30.977\n",
      " 66%|█████████████████████████████████████████████████▎                         | 658/1000 [2:38:49<1:22:21, 14.45s/it]INFO:root:global_step: 658, logpy: 93.592, kl: 62.699, loss: -30.986\n",
      " 66%|█████████████████████████████████████████████████▍                         | 659/1000 [2:39:03<1:22:04, 14.44s/it]INFO:root:global_step: 659, logpy: 93.596, kl: 62.709, loss: -30.979\n",
      " 66%|█████████████████████████████████████████████████▌                         | 660/1000 [2:39:18<1:21:38, 14.41s/it]INFO:root:global_step: 660, logpy: 93.601, kl: 62.716, loss: -30.976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█████████████████████████████████████████████████▌                         | 661/1000 [2:39:32<1:21:05, 14.35s/it]INFO:root:global_step: 661, logpy: 93.612, kl: 62.721, loss: -30.981\n",
      " 66%|█████████████████████████████████████████████████▋                         | 662/1000 [2:39:46<1:20:41, 14.32s/it]INFO:root:global_step: 662, logpy: 93.611, kl: 62.731, loss: -30.969\n",
      " 66%|█████████████████████████████████████████████████▋                         | 663/1000 [2:40:01<1:20:31, 14.34s/it]INFO:root:global_step: 663, logpy: 93.617, kl: 62.741, loss: -30.965\n",
      " 66%|█████████████████████████████████████████████████▊                         | 664/1000 [2:40:15<1:20:22, 14.35s/it]INFO:root:global_step: 664, logpy: 93.607, kl: 62.745, loss: -30.950\n",
      " 66%|█████████████████████████████████████████████████▉                         | 665/1000 [2:40:29<1:20:08, 14.35s/it]INFO:root:global_step: 665, logpy: 93.604, kl: 62.752, loss: -30.938\n",
      " 67%|█████████████████████████████████████████████████▉                         | 666/1000 [2:40:44<1:19:54, 14.36s/it]INFO:root:global_step: 666, logpy: 93.617, kl: 62.757, loss: -30.945\n",
      " 67%|██████████████████████████████████████████████████                         | 667/1000 [2:40:58<1:19:29, 14.32s/it]INFO:root:global_step: 667, logpy: 93.619, kl: 62.762, loss: -30.942\n",
      " 67%|██████████████████████████████████████████████████                         | 668/1000 [2:41:13<1:19:37, 14.39s/it]INFO:root:global_step: 668, logpy: 93.612, kl: 62.770, loss: -30.926\n",
      " 67%|██████████████████████████████████████████████████▏                        | 669/1000 [2:41:27<1:19:16, 14.37s/it]INFO:root:global_step: 669, logpy: 93.627, kl: 62.773, loss: -30.937\n",
      " 67%|██████████████████████████████████████████████████▎                        | 670/1000 [2:41:41<1:18:59, 14.36s/it]INFO:root:global_step: 670, logpy: 93.631, kl: 62.775, loss: -30.938\n",
      " 67%|██████████████████████████████████████████████████▎                        | 671/1000 [2:41:56<1:19:01, 14.41s/it]INFO:root:global_step: 671, logpy: 93.639, kl: 62.780, loss: -30.940\n",
      " 67%|██████████████████████████████████████████████████▍                        | 672/1000 [2:42:10<1:18:27, 14.35s/it]INFO:root:global_step: 672, logpy: 93.651, kl: 62.781, loss: -30.950\n",
      " 67%|██████████████████████████████████████████████████▍                        | 673/1000 [2:42:24<1:18:08, 14.34s/it]INFO:root:global_step: 673, logpy: 93.657, kl: 62.781, loss: -30.956\n",
      " 67%|██████████████████████████████████████████████████▌                        | 674/1000 [2:42:39<1:18:01, 14.36s/it]INFO:root:global_step: 674, logpy: 93.659, kl: 62.785, loss: -30.953\n",
      " 68%|██████████████████████████████████████████████████▋                        | 675/1000 [2:42:53<1:17:33, 14.32s/it]INFO:root:global_step: 675, logpy: 93.660, kl: 62.791, loss: -30.946\n",
      " 68%|██████████████████████████████████████████████████▋                        | 676/1000 [2:43:07<1:17:18, 14.31s/it]INFO:root:global_step: 676, logpy: 93.668, kl: 62.795, loss: -30.950\n",
      " 68%|██████████████████████████████████████████████████▊                        | 677/1000 [2:43:22<1:17:14, 14.35s/it]INFO:root:global_step: 677, logpy: 93.681, kl: 62.798, loss: -30.960\n",
      " 68%|██████████████████████████████████████████████████▊                        | 678/1000 [2:43:36<1:16:43, 14.30s/it]INFO:root:global_step: 678, logpy: 93.694, kl: 62.795, loss: -30.974\n",
      " 68%|██████████████████████████████████████████████████▉                        | 679/1000 [2:43:50<1:16:40, 14.33s/it]INFO:root:global_step: 679, logpy: 93.710, kl: 62.796, loss: -30.989\n",
      " 68%|███████████████████████████████████████████████████                        | 680/1000 [2:44:05<1:16:27, 14.34s/it]INFO:root:global_step: 680, logpy: 93.723, kl: 62.796, loss: -31.002\n",
      " 68%|███████████████████████████████████████████████████                        | 681/1000 [2:44:19<1:16:09, 14.32s/it]INFO:root:global_step: 681, logpy: 93.724, kl: 62.799, loss: -30.999\n",
      " 68%|███████████████████████████████████████████████████▏                       | 682/1000 [2:44:33<1:15:50, 14.31s/it]INFO:root:global_step: 682, logpy: 93.712, kl: 62.805, loss: -30.979\n",
      " 68%|███████████████████████████████████████████████████▏                       | 683/1000 [2:44:48<1:15:46, 14.34s/it]INFO:root:global_step: 683, logpy: 93.728, kl: 62.806, loss: -30.994\n",
      " 68%|███████████████████████████████████████████████████▎                       | 684/1000 [2:45:02<1:15:19, 14.30s/it]INFO:root:global_step: 684, logpy: 93.731, kl: 62.807, loss: -30.995\n",
      " 68%|███████████████████████████████████████████████████▍                       | 685/1000 [2:45:16<1:15:00, 14.29s/it]INFO:root:global_step: 685, logpy: 93.751, kl: 62.806, loss: -31.016\n",
      " 69%|███████████████████████████████████████████████████▍                       | 686/1000 [2:45:30<1:14:50, 14.30s/it]INFO:root:global_step: 686, logpy: 93.749, kl: 62.809, loss: -31.011\n",
      " 69%|███████████████████████████████████████████████████▌                       | 687/1000 [2:45:45<1:14:46, 14.33s/it]INFO:root:global_step: 687, logpy: 93.753, kl: 62.807, loss: -31.015\n",
      " 69%|███████████████████████████████████████████████████▌                       | 688/1000 [2:45:59<1:14:26, 14.32s/it]INFO:root:global_step: 688, logpy: 93.753, kl: 62.809, loss: -31.012\n",
      " 69%|███████████████████████████████████████████████████▋                       | 689/1000 [2:46:14<1:14:37, 14.40s/it]INFO:root:global_step: 689, logpy: 93.758, kl: 62.808, loss: -31.017\n",
      " 69%|███████████████████████████████████████████████████▋                       | 690/1000 [2:46:28<1:14:33, 14.43s/it]INFO:root:global_step: 690, logpy: 93.764, kl: 62.811, loss: -31.020\n",
      " 69%|███████████████████████████████████████████████████▊                       | 691/1000 [2:46:42<1:14:00, 14.37s/it]INFO:root:global_step: 691, logpy: 93.762, kl: 62.814, loss: -31.014\n",
      " 69%|███████████████████████████████████████████████████▉                       | 692/1000 [2:46:57<1:13:45, 14.37s/it]INFO:root:global_step: 692, logpy: 93.773, kl: 62.817, loss: -31.022\n",
      " 69%|███████████████████████████████████████████████████▉                       | 693/1000 [2:47:11<1:13:16, 14.32s/it]INFO:root:global_step: 693, logpy: 93.766, kl: 62.813, loss: -31.018\n",
      " 69%|████████████████████████████████████████████████████                       | 694/1000 [2:47:25<1:13:08, 14.34s/it]INFO:root:global_step: 694, logpy: 93.759, kl: 62.815, loss: -31.008\n",
      " 70%|████████████████████████████████████████████████████                       | 695/1000 [2:47:40<1:13:07, 14.38s/it]INFO:root:global_step: 695, logpy: 93.758, kl: 62.818, loss: -31.003\n",
      " 70%|████████████████████████████████████████████████████▏                      | 696/1000 [2:47:54<1:12:48, 14.37s/it]INFO:root:global_step: 696, logpy: 93.758, kl: 62.817, loss: -31.004\n",
      " 70%|████████████████████████████████████████████████████▎                      | 697/1000 [2:48:08<1:12:23, 14.33s/it]INFO:root:global_step: 697, logpy: 93.767, kl: 62.821, loss: -31.009\n",
      " 70%|████████████████████████████████████████████████████▎                      | 698/1000 [2:48:23<1:12:09, 14.34s/it]INFO:root:global_step: 698, logpy: 93.785, kl: 62.823, loss: -31.024\n",
      " 70%|████████████████████████████████████████████████████▍                      | 699/1000 [2:48:37<1:11:55, 14.34s/it]INFO:root:global_step: 699, logpy: 93.784, kl: 62.826, loss: -31.019\n",
      " 70%|████████████████████████████████████████████████████▌                      | 700/1000 [2:48:51<1:11:38, 14.33s/it]INFO:root:Saved figure at: ./sim/global_step_700.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 700, logpy: 93.784, kl: 62.834, loss: -31.010\n",
      " 70%|████████████████████████████████████████████████████▌                      | 701/1000 [2:49:08<1:14:44, 15.00s/it]INFO:root:global_step: 701, logpy: 93.801, kl: 62.834, loss: -31.027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|████████████████████████████████████████████████████▋                      | 702/1000 [2:49:22<1:13:42, 14.84s/it]INFO:root:global_step: 702, logpy: 93.813, kl: 62.838, loss: -31.034\n",
      " 70%|████████████████████████████████████████████████████▋                      | 703/1000 [2:49:37<1:12:40, 14.68s/it]INFO:root:global_step: 703, logpy: 93.819, kl: 62.840, loss: -31.038\n",
      " 70%|████████████████████████████████████████████████████▊                      | 704/1000 [2:49:51<1:11:58, 14.59s/it]INFO:root:global_step: 704, logpy: 93.820, kl: 62.841, loss: -31.038\n",
      " 70%|████████████████████████████████████████████████████▉                      | 705/1000 [2:50:05<1:11:24, 14.52s/it]INFO:root:global_step: 705, logpy: 93.827, kl: 62.840, loss: -31.045\n",
      " 71%|████████████████████████████████████████████████████▉                      | 706/1000 [2:50:20<1:11:11, 14.53s/it]INFO:root:global_step: 706, logpy: 93.823, kl: 62.850, loss: -31.030\n",
      " 71%|█████████████████████████████████████████████████████                      | 707/1000 [2:50:34<1:10:29, 14.44s/it]INFO:root:global_step: 707, logpy: 93.834, kl: 62.851, loss: -31.040\n",
      " 71%|█████████████████████████████████████████████████████                      | 708/1000 [2:50:49<1:10:16, 14.44s/it]INFO:root:global_step: 708, logpy: 93.836, kl: 62.853, loss: -31.039\n",
      " 71%|█████████████████████████████████████████████████████▏                     | 709/1000 [2:51:03<1:10:08, 14.46s/it]INFO:root:global_step: 709, logpy: 93.834, kl: 62.855, loss: -31.035\n",
      " 71%|█████████████████████████████████████████████████████▎                     | 710/1000 [2:51:18<1:09:39, 14.41s/it]INFO:root:global_step: 710, logpy: 93.847, kl: 62.850, loss: -31.052\n",
      " 71%|█████████████████████████████████████████████████████▎                     | 711/1000 [2:51:32<1:09:06, 14.35s/it]INFO:root:global_step: 711, logpy: 93.856, kl: 62.851, loss: -31.059\n",
      " 71%|█████████████████████████████████████████████████████▍                     | 712/1000 [2:51:46<1:08:59, 14.37s/it]INFO:root:global_step: 712, logpy: 93.845, kl: 62.854, loss: -31.045\n",
      " 71%|█████████████████████████████████████████████████████▍                     | 713/1000 [2:52:00<1:08:25, 14.31s/it]INFO:root:global_step: 713, logpy: 93.835, kl: 62.853, loss: -31.036\n",
      " 71%|█████████████████████████████████████████████████████▌                     | 714/1000 [2:52:15<1:08:24, 14.35s/it]INFO:root:global_step: 714, logpy: 93.851, kl: 62.852, loss: -31.053\n",
      " 72%|█████████████████████████████████████████████████████▋                     | 715/1000 [2:52:30<1:08:48, 14.49s/it]INFO:root:global_step: 715, logpy: 93.864, kl: 62.849, loss: -31.068\n",
      " 72%|█████████████████████████████████████████████████████▋                     | 716/1000 [2:52:44<1:08:57, 14.57s/it]INFO:root:global_step: 716, logpy: 93.883, kl: 62.844, loss: -31.091\n",
      " 72%|█████████████████████████████████████████████████████▊                     | 717/1000 [2:52:58<1:07:50, 14.38s/it]INFO:root:global_step: 717, logpy: 93.898, kl: 62.843, loss: -31.107\n",
      " 72%|█████████████████████████████████████████████████████▊                     | 718/1000 [2:53:13<1:07:26, 14.35s/it]INFO:root:global_step: 718, logpy: 93.912, kl: 62.843, loss: -31.120\n",
      " 72%|█████████████████████████████████████████████████████▉                     | 719/1000 [2:53:27<1:07:10, 14.34s/it]INFO:root:global_step: 719, logpy: 93.914, kl: 62.842, loss: -31.122\n",
      " 72%|██████████████████████████████████████████████████████                     | 720/1000 [2:53:41<1:06:22, 14.22s/it]INFO:root:global_step: 720, logpy: 93.905, kl: 62.845, loss: -31.110\n",
      " 72%|██████████████████████████████████████████████████████                     | 721/1000 [2:53:55<1:06:02, 14.20s/it]INFO:root:global_step: 721, logpy: 93.906, kl: 62.843, loss: -31.113\n",
      " 72%|██████████████████████████████████████████████████████▏                    | 722/1000 [2:54:09<1:05:48, 14.20s/it]INFO:root:global_step: 722, logpy: 93.916, kl: 62.847, loss: -31.118\n",
      " 72%|██████████████████████████████████████████████████████▏                    | 723/1000 [2:54:23<1:05:23, 14.16s/it]INFO:root:global_step: 723, logpy: 93.922, kl: 62.846, loss: -31.123\n",
      " 72%|██████████████████████████████████████████████████████▎                    | 724/1000 [2:54:37<1:05:10, 14.17s/it]INFO:root:global_step: 724, logpy: 93.939, kl: 62.847, loss: -31.140\n",
      " 72%|██████████████████████████████████████████████████████▍                    | 725/1000 [2:54:52<1:04:55, 14.16s/it]INFO:root:global_step: 725, logpy: 93.960, kl: 62.847, loss: -31.160\n",
      " 73%|██████████████████████████████████████████████████████▍                    | 726/1000 [2:55:06<1:04:44, 14.18s/it]INFO:root:global_step: 726, logpy: 93.960, kl: 62.851, loss: -31.156\n",
      " 73%|██████████████████████████████████████████████████████▌                    | 727/1000 [2:55:20<1:04:40, 14.21s/it]INFO:root:global_step: 727, logpy: 93.960, kl: 62.856, loss: -31.150\n",
      " 73%|██████████████████████████████████████████████████████▌                    | 728/1000 [2:55:34<1:04:37, 14.25s/it]INFO:root:global_step: 728, logpy: 93.966, kl: 62.854, loss: -31.158\n",
      " 73%|██████████████████████████████████████████████████████▋                    | 729/1000 [2:55:49<1:04:22, 14.25s/it]INFO:root:global_step: 729, logpy: 93.964, kl: 62.858, loss: -31.151\n",
      " 73%|██████████████████████████████████████████████████████▊                    | 730/1000 [2:56:03<1:04:05, 14.24s/it]INFO:root:global_step: 730, logpy: 93.966, kl: 62.859, loss: -31.152\n",
      " 73%|██████████████████████████████████████████████████████▊                    | 731/1000 [2:56:17<1:03:57, 14.26s/it]INFO:root:global_step: 731, logpy: 93.962, kl: 62.863, loss: -31.143\n",
      " 73%|██████████████████████████████████████████████████████▉                    | 732/1000 [2:56:31<1:03:32, 14.22s/it]INFO:root:global_step: 732, logpy: 93.982, kl: 62.860, loss: -31.167\n",
      " 73%|██████████████████████████████████████████████████████▉                    | 733/1000 [2:56:46<1:03:24, 14.25s/it]INFO:root:global_step: 733, logpy: 93.999, kl: 62.860, loss: -31.183\n",
      " 73%|███████████████████████████████████████████████████████                    | 734/1000 [2:57:00<1:03:05, 14.23s/it]INFO:root:global_step: 734, logpy: 93.994, kl: 62.864, loss: -31.173\n",
      " 74%|███████████████████████████████████████████████████████▏                   | 735/1000 [2:57:14<1:03:07, 14.29s/it]INFO:root:global_step: 735, logpy: 93.995, kl: 62.870, loss: -31.168\n",
      " 74%|███████████████████████████████████████████████████████▏                   | 736/1000 [2:57:29<1:03:02, 14.33s/it]INFO:root:global_step: 736, logpy: 94.001, kl: 62.874, loss: -31.170\n",
      " 74%|███████████████████████████████████████████████████████▎                   | 737/1000 [2:57:43<1:02:24, 14.24s/it]INFO:root:global_step: 737, logpy: 94.012, kl: 62.879, loss: -31.174\n",
      " 74%|███████████████████████████████████████████████████████▎                   | 738/1000 [2:57:57<1:02:08, 14.23s/it]INFO:root:global_step: 738, logpy: 94.020, kl: 62.882, loss: -31.179\n",
      " 74%|███████████████████████████████████████████████████████▍                   | 739/1000 [2:58:11<1:01:44, 14.19s/it]INFO:root:global_step: 739, logpy: 94.030, kl: 62.887, loss: -31.184\n",
      " 74%|███████████████████████████████████████████████████████▌                   | 740/1000 [2:58:25<1:01:37, 14.22s/it]INFO:root:global_step: 740, logpy: 94.044, kl: 62.891, loss: -31.194\n",
      " 74%|███████████████████████████████████████████████████████▌                   | 741/1000 [2:58:40<1:01:23, 14.22s/it]INFO:root:global_step: 741, logpy: 94.057, kl: 62.892, loss: -31.205\n",
      " 74%|███████████████████████████████████████████████████████▋                   | 742/1000 [2:58:54<1:01:19, 14.26s/it]INFO:root:global_step: 742, logpy: 94.069, kl: 62.891, loss: -31.217\n",
      " 74%|███████████████████████████████████████████████████████▋                   | 743/1000 [2:59:08<1:00:55, 14.23s/it]INFO:root:global_step: 743, logpy: 94.081, kl: 62.897, loss: -31.224\n",
      " 74%|███████████████████████████████████████████████████████▊                   | 744/1000 [2:59:22<1:00:37, 14.21s/it]INFO:root:global_step: 744, logpy: 94.086, kl: 62.898, loss: -31.227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████████████████████████████████████████████████████▉                   | 745/1000 [2:59:37<1:00:33, 14.25s/it]INFO:root:global_step: 745, logpy: 94.097, kl: 62.900, loss: -31.236\n",
      " 75%|███████████████████████████████████████████████████████▉                   | 746/1000 [2:59:51<1:00:12, 14.22s/it]INFO:root:global_step: 746, logpy: 94.109, kl: 62.902, loss: -31.244\n",
      " 75%|█████████████████████████████████████████████████████████▌                   | 747/1000 [3:00:05<59:56, 14.22s/it]INFO:root:global_step: 747, logpy: 94.110, kl: 62.911, loss: -31.236\n",
      " 75%|█████████████████████████████████████████████████████████▌                   | 748/1000 [3:00:19<59:44, 14.23s/it]INFO:root:global_step: 748, logpy: 94.108, kl: 62.911, loss: -31.235\n",
      " 75%|█████████████████████████████████████████████████████████▋                   | 749/1000 [3:00:33<59:20, 14.19s/it]INFO:root:global_step: 749, logpy: 94.118, kl: 62.907, loss: -31.248\n",
      " 75%|█████████████████████████████████████████████████████████▊                   | 750/1000 [3:00:48<59:23, 14.25s/it]INFO:root:Saved figure at: ./sim/global_step_750.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 750, logpy: 94.128, kl: 62.908, loss: -31.256\n",
      " 75%|████████████████████████████████████████████████████████▎                  | 751/1000 [3:01:04<1:01:59, 14.94s/it]INFO:root:global_step: 751, logpy: 94.129, kl: 62.911, loss: -31.254\n",
      " 75%|████████████████████████████████████████████████████████▍                  | 752/1000 [3:01:18<1:00:40, 14.68s/it]INFO:root:global_step: 752, logpy: 94.122, kl: 62.917, loss: -31.241\n",
      " 75%|█████████████████████████████████████████████████████████▉                   | 753/1000 [3:01:32<59:50, 14.54s/it]INFO:root:global_step: 753, logpy: 94.154, kl: 62.914, loss: -31.275\n",
      " 75%|██████████████████████████████████████████████████████████                   | 754/1000 [3:01:47<59:11, 14.44s/it]INFO:root:global_step: 754, logpy: 94.166, kl: 62.910, loss: -31.292\n",
      " 76%|██████████████████████████████████████████████████████████▏                  | 755/1000 [3:02:01<58:37, 14.36s/it]INFO:root:global_step: 755, logpy: 94.157, kl: 62.904, loss: -31.288\n",
      " 76%|██████████████████████████████████████████████████████████▏                  | 756/1000 [3:02:15<58:22, 14.35s/it]INFO:root:global_step: 756, logpy: 94.166, kl: 62.898, loss: -31.303\n",
      " 76%|██████████████████████████████████████████████████████████▎                  | 757/1000 [3:02:29<57:50, 14.28s/it]INFO:root:global_step: 757, logpy: 94.160, kl: 62.899, loss: -31.295\n",
      " 76%|██████████████████████████████████████████████████████████▎                  | 758/1000 [3:02:43<57:14, 14.19s/it]INFO:root:global_step: 758, logpy: 94.167, kl: 62.890, loss: -31.311\n",
      " 76%|██████████████████████████████████████████████████████████▍                  | 759/1000 [3:02:58<57:23, 14.29s/it]INFO:root:global_step: 759, logpy: 94.161, kl: 62.889, loss: -31.305\n",
      " 76%|██████████████████████████████████████████████████████████▌                  | 760/1000 [3:03:12<56:51, 14.21s/it]INFO:root:global_step: 760, logpy: 94.163, kl: 62.892, loss: -31.304\n",
      " 76%|██████████████████████████████████████████████████████████▌                  | 761/1000 [3:03:26<56:36, 14.21s/it]INFO:root:global_step: 761, logpy: 94.177, kl: 62.891, loss: -31.319\n",
      " 76%|██████████████████████████████████████████████████████████▋                  | 762/1000 [3:03:40<56:30, 14.25s/it]INFO:root:global_step: 762, logpy: 94.180, kl: 62.891, loss: -31.321\n",
      " 76%|██████████████████████████████████████████████████████████▊                  | 763/1000 [3:03:55<56:20, 14.26s/it]INFO:root:global_step: 763, logpy: 94.189, kl: 62.887, loss: -31.333\n",
      " 76%|██████████████████████████████████████████████████████████▊                  | 764/1000 [3:04:09<56:16, 14.31s/it]INFO:root:global_step: 764, logpy: 94.196, kl: 62.886, loss: -31.341\n",
      " 76%|██████████████████████████████████████████████████████████▉                  | 765/1000 [3:04:24<56:10, 14.34s/it]INFO:root:global_step: 765, logpy: 94.188, kl: 62.886, loss: -31.334\n",
      " 77%|██████████████████████████████████████████████████████████▉                  | 766/1000 [3:04:38<55:54, 14.33s/it]INFO:root:global_step: 766, logpy: 94.198, kl: 62.886, loss: -31.343\n",
      " 77%|███████████████████████████████████████████████████████████                  | 767/1000 [3:04:52<55:50, 14.38s/it]INFO:root:global_step: 767, logpy: 94.215, kl: 62.885, loss: -31.361\n",
      " 77%|███████████████████████████████████████████████████████████▏                 | 768/1000 [3:05:07<55:50, 14.44s/it]INFO:root:global_step: 768, logpy: 94.220, kl: 62.884, loss: -31.367\n",
      " 77%|███████████████████████████████████████████████████████████▏                 | 769/1000 [3:05:21<55:21, 14.38s/it]INFO:root:global_step: 769, logpy: 94.220, kl: 62.891, loss: -31.358\n",
      " 77%|███████████████████████████████████████████████████████████▎                 | 770/1000 [3:05:35<54:53, 14.32s/it]INFO:root:global_step: 770, logpy: 94.241, kl: 62.890, loss: -31.382\n",
      " 77%|███████████████████████████████████████████████████████████▎                 | 771/1000 [3:05:50<54:38, 14.32s/it]INFO:root:global_step: 771, logpy: 94.252, kl: 62.892, loss: -31.390\n",
      " 77%|███████████████████████████████████████████████████████████▍                 | 772/1000 [3:06:04<54:34, 14.36s/it]INFO:root:global_step: 772, logpy: 94.258, kl: 62.894, loss: -31.393\n",
      " 77%|███████████████████████████████████████████████████████████▌                 | 773/1000 [3:06:18<54:09, 14.32s/it]INFO:root:global_step: 773, logpy: 94.262, kl: 62.897, loss: -31.395\n",
      " 77%|███████████████████████████████████████████████████████████▌                 | 774/1000 [3:06:33<53:55, 14.32s/it]INFO:root:global_step: 774, logpy: 94.245, kl: 62.903, loss: -31.371\n",
      " 78%|███████████████████████████████████████████████████████████▋                 | 775/1000 [3:06:47<53:53, 14.37s/it]INFO:root:global_step: 775, logpy: 94.252, kl: 62.906, loss: -31.375\n",
      " 78%|███████████████████████████████████████████████████████████▊                 | 776/1000 [3:07:02<53:42, 14.39s/it]INFO:root:global_step: 776, logpy: 94.272, kl: 62.908, loss: -31.393\n",
      " 78%|███████████████████████████████████████████████████████████▊                 | 777/1000 [3:07:16<53:33, 14.41s/it]INFO:root:global_step: 777, logpy: 94.280, kl: 62.909, loss: -31.400\n",
      " 78%|███████████████████████████████████████████████████████████▉                 | 778/1000 [3:07:30<53:20, 14.42s/it]INFO:root:global_step: 778, logpy: 94.278, kl: 62.911, loss: -31.394\n",
      " 78%|███████████████████████████████████████████████████████████▉                 | 779/1000 [3:07:45<53:06, 14.42s/it]INFO:root:global_step: 779, logpy: 94.290, kl: 62.908, loss: -31.410\n",
      " 78%|████████████████████████████████████████████████████████████                 | 780/1000 [3:07:59<52:52, 14.42s/it]INFO:root:global_step: 780, logpy: 94.295, kl: 62.908, loss: -31.415\n",
      " 78%|████████████████████████████████████████████████████████████▏                | 781/1000 [3:08:14<52:36, 14.41s/it]INFO:root:global_step: 781, logpy: 94.306, kl: 62.906, loss: -31.427\n",
      " 78%|████████████████████████████████████████████████████████████▏                | 782/1000 [3:08:28<52:23, 14.42s/it]INFO:root:global_step: 782, logpy: 94.315, kl: 62.904, loss: -31.438\n",
      " 78%|████████████████████████████████████████████████████████████▎                | 783/1000 [3:08:43<52:17, 14.46s/it]INFO:root:global_step: 783, logpy: 94.326, kl: 62.899, loss: -31.454\n",
      " 78%|████████████████████████████████████████████████████████████▎                | 784/1000 [3:08:57<51:59, 14.44s/it]INFO:root:global_step: 784, logpy: 94.326, kl: 62.896, loss: -31.456\n",
      " 78%|████████████████████████████████████████████████████████████▍                | 785/1000 [3:09:12<51:45, 14.45s/it]INFO:root:global_step: 785, logpy: 94.315, kl: 62.902, loss: -31.439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|████████████████████████████████████████████████████████████▌                | 786/1000 [3:09:26<51:34, 14.46s/it]INFO:root:global_step: 786, logpy: 94.327, kl: 62.903, loss: -31.450\n",
      " 79%|████████████████████████████████████████████████████████████▌                | 787/1000 [3:09:40<51:08, 14.41s/it]INFO:root:global_step: 787, logpy: 94.341, kl: 62.902, loss: -31.464\n",
      " 79%|████████████████████████████████████████████████████████████▋                | 788/1000 [3:09:55<50:49, 14.39s/it]INFO:root:global_step: 788, logpy: 94.329, kl: 62.905, loss: -31.449\n",
      " 79%|████████████████████████████████████████████████████████████▊                | 789/1000 [3:10:09<50:34, 14.38s/it]INFO:root:global_step: 789, logpy: 94.344, kl: 62.903, loss: -31.465\n",
      " 79%|████████████████████████████████████████████████████████████▊                | 790/1000 [3:10:23<50:13, 14.35s/it]INFO:root:global_step: 790, logpy: 94.337, kl: 62.909, loss: -31.452\n",
      " 79%|████████████████████████████████████████████████████████████▉                | 791/1000 [3:10:38<50:06, 14.39s/it]INFO:root:global_step: 791, logpy: 94.330, kl: 62.916, loss: -31.438\n",
      " 79%|████████████████████████████████████████████████████████████▉                | 792/1000 [3:10:52<49:57, 14.41s/it]INFO:root:global_step: 792, logpy: 94.341, kl: 62.914, loss: -31.451\n",
      " 79%|█████████████████████████████████████████████████████████████                | 793/1000 [3:11:07<49:41, 14.40s/it]INFO:root:global_step: 793, logpy: 94.352, kl: 62.918, loss: -31.458\n",
      " 79%|█████████████████████████████████████████████████████████████▏               | 794/1000 [3:11:21<49:28, 14.41s/it]INFO:root:global_step: 794, logpy: 94.356, kl: 62.919, loss: -31.460\n",
      " 80%|█████████████████████████████████████████████████████████████▏               | 795/1000 [3:11:36<49:17, 14.43s/it]INFO:root:global_step: 795, logpy: 94.362, kl: 62.926, loss: -31.460\n",
      " 80%|█████████████████████████████████████████████████████████████▎               | 796/1000 [3:11:50<49:02, 14.43s/it]INFO:root:global_step: 796, logpy: 94.368, kl: 62.931, loss: -31.460\n",
      " 80%|█████████████████████████████████████████████████████████████▎               | 797/1000 [3:12:04<48:44, 14.40s/it]INFO:root:global_step: 797, logpy: 94.366, kl: 62.938, loss: -31.451\n",
      " 80%|█████████████████████████████████████████████████████████████▍               | 798/1000 [3:12:19<48:31, 14.41s/it]INFO:root:global_step: 798, logpy: 94.366, kl: 62.937, loss: -31.452\n",
      " 80%|█████████████████████████████████████████████████████████████▌               | 799/1000 [3:12:33<48:12, 14.39s/it]INFO:root:global_step: 799, logpy: 94.366, kl: 62.942, loss: -31.447\n",
      " 80%|█████████████████████████████████████████████████████████████▌               | 800/1000 [3:12:47<48:01, 14.41s/it]INFO:root:Saved figure at: ./sim/global_step_800.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 800, logpy: 94.380, kl: 62.941, loss: -31.462\n",
      " 80%|█████████████████████████████████████████████████████████████▋               | 801/1000 [3:13:04<50:05, 15.10s/it]INFO:root:global_step: 801, logpy: 94.396, kl: 62.944, loss: -31.474\n",
      " 80%|█████████████████████████████████████████████████████████████▊               | 802/1000 [3:13:18<49:01, 14.85s/it]INFO:root:global_step: 802, logpy: 94.406, kl: 62.942, loss: -31.486\n",
      " 80%|█████████████████████████████████████████████████████████████▊               | 803/1000 [3:13:33<48:07, 14.66s/it]INFO:root:global_step: 803, logpy: 94.408, kl: 62.945, loss: -31.485\n",
      " 80%|█████████████████████████████████████████████████████████████▉               | 804/1000 [3:13:47<47:46, 14.63s/it]INFO:root:global_step: 804, logpy: 94.414, kl: 62.945, loss: -31.490\n",
      " 80%|█████████████████████████████████████████████████████████████▉               | 805/1000 [3:14:02<47:14, 14.53s/it]INFO:root:global_step: 805, logpy: 94.435, kl: 62.943, loss: -31.513\n",
      " 81%|██████████████████████████████████████████████████████████████               | 806/1000 [3:14:16<46:51, 14.49s/it]INFO:root:global_step: 806, logpy: 94.444, kl: 62.941, loss: -31.524\n",
      " 81%|██████████████████████████████████████████████████████████████▏              | 807/1000 [3:14:30<46:35, 14.48s/it]INFO:root:global_step: 807, logpy: 94.447, kl: 62.946, loss: -31.522\n",
      " 81%|██████████████████████████████████████████████████████████████▏              | 808/1000 [3:14:45<46:17, 14.47s/it]INFO:root:global_step: 808, logpy: 94.464, kl: 62.945, loss: -31.540\n",
      " 81%|██████████████████████████████████████████████████████████████▎              | 809/1000 [3:14:59<46:01, 14.46s/it]INFO:root:global_step: 809, logpy: 94.460, kl: 62.948, loss: -31.533\n",
      " 81%|██████████████████████████████████████████████████████████████▎              | 810/1000 [3:15:14<45:38, 14.41s/it]INFO:root:global_step: 810, logpy: 94.463, kl: 62.949, loss: -31.533\n",
      " 81%|██████████████████████████████████████████████████████████████▍              | 811/1000 [3:15:28<45:20, 14.39s/it]INFO:root:global_step: 811, logpy: 94.479, kl: 62.946, loss: -31.553\n",
      " 81%|██████████████████████████████████████████████████████████████▌              | 812/1000 [3:15:42<44:50, 14.31s/it]INFO:root:global_step: 812, logpy: 94.490, kl: 62.946, loss: -31.563\n",
      " 81%|██████████████████████████████████████████████████████████████▌              | 813/1000 [3:15:56<44:41, 14.34s/it]INFO:root:global_step: 813, logpy: 94.483, kl: 62.943, loss: -31.559\n",
      " 81%|██████████████████████████████████████████████████████████████▋              | 814/1000 [3:16:11<44:30, 14.36s/it]INFO:root:global_step: 814, logpy: 94.494, kl: 62.945, loss: -31.568\n",
      " 82%|██████████████████████████████████████████████████████████████▊              | 815/1000 [3:16:25<44:04, 14.30s/it]INFO:root:global_step: 815, logpy: 94.499, kl: 62.944, loss: -31.574\n",
      " 82%|██████████████████████████████████████████████████████████████▊              | 816/1000 [3:16:39<43:56, 14.33s/it]INFO:root:global_step: 816, logpy: 94.516, kl: 62.942, loss: -31.593\n",
      " 82%|██████████████████████████████████████████████████████████████▉              | 817/1000 [3:16:54<43:41, 14.32s/it]INFO:root:global_step: 817, logpy: 94.500, kl: 62.947, loss: -31.572\n",
      " 82%|██████████████████████████████████████████████████████████████▉              | 818/1000 [3:17:08<43:31, 14.35s/it]INFO:root:global_step: 818, logpy: 94.498, kl: 62.951, loss: -31.565\n",
      " 82%|███████████████████████████████████████████████████████████████              | 819/1000 [3:17:23<43:20, 14.37s/it]INFO:root:global_step: 819, logpy: 94.513, kl: 62.951, loss: -31.580\n",
      " 82%|███████████████████████████████████████████████████████████████▏             | 820/1000 [3:17:37<43:11, 14.40s/it]INFO:root:global_step: 820, logpy: 94.514, kl: 62.956, loss: -31.576\n",
      " 82%|███████████████████████████████████████████████████████████████▏             | 821/1000 [3:17:51<42:54, 14.39s/it]INFO:root:global_step: 821, logpy: 94.520, kl: 62.963, loss: -31.575\n",
      " 82%|███████████████████████████████████████████████████████████████▎             | 822/1000 [3:18:06<42:47, 14.43s/it]INFO:root:global_step: 822, logpy: 94.532, kl: 62.971, loss: -31.579\n",
      " 82%|███████████████████████████████████████████████████████████████▎             | 823/1000 [3:18:20<42:34, 14.43s/it]INFO:root:global_step: 823, logpy: 94.535, kl: 62.985, loss: -31.568\n",
      " 82%|███████████████████████████████████████████████████████████████▍             | 824/1000 [3:18:35<42:24, 14.46s/it]INFO:root:global_step: 824, logpy: 94.546, kl: 62.989, loss: -31.574\n",
      " 82%|███████████████████████████████████████████████████████████████▌             | 825/1000 [3:18:49<42:15, 14.49s/it]INFO:root:global_step: 825, logpy: 94.561, kl: 62.998, loss: -31.581\n",
      " 83%|███████████████████████████████████████████████████████████████▌             | 826/1000 [3:19:04<41:48, 14.42s/it]INFO:root:global_step: 826, logpy: 94.576, kl: 63.006, loss: -31.587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|███████████████████████████████████████████████████████████████▋             | 827/1000 [3:19:18<41:34, 14.42s/it]INFO:root:global_step: 827, logpy: 94.597, kl: 63.007, loss: -31.607\n",
      " 83%|███████████████████████████████████████████████████████████████▊             | 828/1000 [3:19:32<41:15, 14.39s/it]INFO:root:global_step: 828, logpy: 94.623, kl: 63.006, loss: -31.634\n",
      " 83%|███████████████████████████████████████████████████████████████▊             | 829/1000 [3:19:47<40:54, 14.35s/it]INFO:root:global_step: 829, logpy: 94.623, kl: 63.006, loss: -31.634\n",
      " 83%|███████████████████████████████████████████████████████████████▉             | 830/1000 [3:20:01<40:44, 14.38s/it]INFO:root:global_step: 830, logpy: 94.636, kl: 63.009, loss: -31.644\n",
      " 83%|███████████████████████████████████████████████████████████████▉             | 831/1000 [3:20:15<40:27, 14.37s/it]INFO:root:global_step: 831, logpy: 94.651, kl: 63.008, loss: -31.660\n",
      " 83%|████████████████████████████████████████████████████████████████             | 832/1000 [3:20:30<40:15, 14.38s/it]INFO:root:global_step: 832, logpy: 94.651, kl: 63.009, loss: -31.658\n",
      " 83%|████████████████████████████████████████████████████████████████▏            | 833/1000 [3:20:44<39:55, 14.35s/it]INFO:root:global_step: 833, logpy: 94.654, kl: 63.016, loss: -31.653\n",
      " 83%|████████████████████████████████████████████████████████████████▏            | 834/1000 [3:20:59<39:49, 14.40s/it]INFO:root:global_step: 834, logpy: 94.661, kl: 63.017, loss: -31.659\n",
      " 84%|████████████████████████████████████████████████████████████████▎            | 835/1000 [3:21:13<39:38, 14.41s/it]INFO:root:global_step: 835, logpy: 94.674, kl: 63.021, loss: -31.668\n",
      " 84%|████████████████████████████████████████████████████████████████▎            | 836/1000 [3:21:28<39:22, 14.41s/it]INFO:root:global_step: 836, logpy: 94.671, kl: 63.021, loss: -31.666\n",
      " 84%|████████████████████████████████████████████████████████████████▍            | 837/1000 [3:21:42<39:17, 14.46s/it]INFO:root:global_step: 837, logpy: 94.666, kl: 63.023, loss: -31.659\n",
      " 84%|████████████████████████████████████████████████████████████████▌            | 838/1000 [3:21:57<39:00, 14.45s/it]INFO:root:global_step: 838, logpy: 94.686, kl: 63.026, loss: -31.675\n",
      " 84%|████████████████████████████████████████████████████████████████▌            | 839/1000 [3:22:11<38:53, 14.49s/it]INFO:root:global_step: 839, logpy: 94.698, kl: 63.023, loss: -31.691\n",
      " 84%|████████████████████████████████████████████████████████████████▋            | 840/1000 [3:22:25<38:32, 14.45s/it]INFO:root:global_step: 840, logpy: 94.706, kl: 63.025, loss: -31.696\n",
      " 84%|████████████████████████████████████████████████████████████████▊            | 841/1000 [3:22:40<38:15, 14.44s/it]INFO:root:global_step: 841, logpy: 94.706, kl: 63.027, loss: -31.694\n",
      " 84%|████████████████████████████████████████████████████████████████▊            | 842/1000 [3:22:54<37:49, 14.36s/it]INFO:root:global_step: 842, logpy: 94.716, kl: 63.026, loss: -31.704\n",
      " 84%|████████████████████████████████████████████████████████████████▉            | 843/1000 [3:23:08<37:33, 14.36s/it]INFO:root:global_step: 843, logpy: 94.717, kl: 63.029, loss: -31.702\n",
      " 84%|████████████████████████████████████████████████████████████████▉            | 844/1000 [3:23:23<37:26, 14.40s/it]INFO:root:global_step: 844, logpy: 94.723, kl: 63.030, loss: -31.707\n",
      " 84%|█████████████████████████████████████████████████████████████████            | 845/1000 [3:23:37<37:12, 14.40s/it]INFO:root:global_step: 845, logpy: 94.721, kl: 63.039, loss: -31.696\n",
      " 85%|█████████████████████████████████████████████████████████████████▏           | 846/1000 [3:23:52<37:06, 14.46s/it]INFO:root:global_step: 846, logpy: 94.718, kl: 63.046, loss: -31.686\n",
      " 85%|█████████████████████████████████████████████████████████████████▏           | 847/1000 [3:24:06<36:49, 14.44s/it]INFO:root:global_step: 847, logpy: 94.730, kl: 63.047, loss: -31.697\n",
      " 85%|█████████████████████████████████████████████████████████████████▎           | 848/1000 [3:24:21<36:31, 14.42s/it]INFO:root:global_step: 848, logpy: 94.730, kl: 63.049, loss: -31.695\n",
      " 85%|█████████████████████████████████████████████████████████████████▎           | 849/1000 [3:24:35<36:16, 14.41s/it]INFO:root:global_step: 849, logpy: 94.724, kl: 63.048, loss: -31.690\n",
      " 85%|█████████████████████████████████████████████████████████████████▍           | 850/1000 [3:24:50<36:04, 14.43s/it]INFO:root:Saved figure at: ./sim/global_step_850.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 850, logpy: 94.741, kl: 63.047, loss: -31.708\n",
      " 85%|█████████████████████████████████████████████████████████████████▌           | 851/1000 [3:25:06<37:27, 15.08s/it]INFO:root:global_step: 851, logpy: 94.740, kl: 63.053, loss: -31.701\n",
      " 85%|█████████████████████████████████████████████████████████████████▌           | 852/1000 [3:25:21<36:47, 14.92s/it]INFO:root:global_step: 852, logpy: 94.746, kl: 63.052, loss: -31.708\n",
      " 85%|█████████████████████████████████████████████████████████████████▋           | 853/1000 [3:25:35<36:10, 14.76s/it]INFO:root:global_step: 853, logpy: 94.748, kl: 63.057, loss: -31.704\n",
      " 85%|█████████████████████████████████████████████████████████████████▊           | 854/1000 [3:25:50<35:42, 14.67s/it]INFO:root:global_step: 854, logpy: 94.758, kl: 63.056, loss: -31.715\n",
      " 86%|█████████████████████████████████████████████████████████████████▊           | 855/1000 [3:26:04<35:23, 14.65s/it]INFO:root:global_step: 855, logpy: 94.756, kl: 63.061, loss: -31.708\n",
      " 86%|█████████████████████████████████████████████████████████████████▉           | 856/1000 [3:26:18<34:55, 14.55s/it]INFO:root:global_step: 856, logpy: 94.759, kl: 63.065, loss: -31.706\n",
      " 86%|█████████████████████████████████████████████████████████████████▉           | 857/1000 [3:26:33<34:38, 14.53s/it]INFO:root:global_step: 857, logpy: 94.777, kl: 63.067, loss: -31.723\n",
      " 86%|██████████████████████████████████████████████████████████████████           | 858/1000 [3:26:47<34:24, 14.54s/it]INFO:root:global_step: 858, logpy: 94.773, kl: 63.071, loss: -31.715\n",
      " 86%|██████████████████████████████████████████████████████████████████▏          | 859/1000 [3:27:02<33:58, 14.46s/it]INFO:root:global_step: 859, logpy: 94.793, kl: 63.068, loss: -31.737\n",
      " 86%|██████████████████████████████████████████████████████████████████▏          | 860/1000 [3:27:16<33:42, 14.45s/it]INFO:root:global_step: 860, logpy: 94.798, kl: 63.071, loss: -31.739\n",
      " 86%|██████████████████████████████████████████████████████████████████▎          | 861/1000 [3:27:31<33:24, 14.42s/it]INFO:root:global_step: 861, logpy: 94.803, kl: 63.072, loss: -31.743\n",
      " 86%|██████████████████████████████████████████████████████████████████▎          | 862/1000 [3:27:45<33:14, 14.45s/it]INFO:root:global_step: 862, logpy: 94.795, kl: 63.081, loss: -31.726\n",
      " 86%|██████████████████████████████████████████████████████████████████▍          | 863/1000 [3:28:00<32:59, 14.45s/it]INFO:root:global_step: 863, logpy: 94.796, kl: 63.079, loss: -31.729\n",
      " 86%|██████████████████████████████████████████████████████████████████▌          | 864/1000 [3:28:14<32:45, 14.45s/it]INFO:root:global_step: 864, logpy: 94.804, kl: 63.077, loss: -31.739\n",
      " 86%|██████████████████████████████████████████████████████████████████▌          | 865/1000 [3:28:28<32:30, 14.45s/it]INFO:root:global_step: 865, logpy: 94.817, kl: 63.073, loss: -31.756\n",
      " 87%|██████████████████████████████████████████████████████████████████▋          | 866/1000 [3:28:43<32:15, 14.45s/it]INFO:root:global_step: 866, logpy: 94.832, kl: 63.073, loss: -31.770\n",
      " 87%|██████████████████████████████████████████████████████████████████▊          | 867/1000 [3:28:57<32:05, 14.48s/it]INFO:root:global_step: 867, logpy: 94.825, kl: 63.077, loss: -31.759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|██████████████████████████████████████████████████████████████████▊          | 868/1000 [3:29:12<31:48, 14.46s/it]INFO:root:global_step: 868, logpy: 94.833, kl: 63.079, loss: -31.765\n",
      " 87%|██████████████████████████████████████████████████████████████████▉          | 869/1000 [3:29:26<31:33, 14.45s/it]INFO:root:global_step: 869, logpy: 94.841, kl: 63.084, loss: -31.768\n",
      " 87%|██████████████████████████████████████████████████████████████████▉          | 870/1000 [3:29:41<31:17, 14.44s/it]INFO:root:global_step: 870, logpy: 94.838, kl: 63.093, loss: -31.756\n",
      " 87%|███████████████████████████████████████████████████████████████████          | 871/1000 [3:29:55<31:02, 14.44s/it]INFO:root:global_step: 871, logpy: 94.830, kl: 63.095, loss: -31.746\n",
      " 87%|███████████████████████████████████████████████████████████████████▏         | 872/1000 [3:30:09<30:46, 14.43s/it]INFO:root:global_step: 872, logpy: 94.843, kl: 63.099, loss: -31.754\n",
      " 87%|███████████████████████████████████████████████████████████████████▏         | 873/1000 [3:30:24<30:29, 14.40s/it]INFO:root:global_step: 873, logpy: 94.841, kl: 63.103, loss: -31.749\n",
      " 87%|███████████████████████████████████████████████████████████████████▎         | 874/1000 [3:30:38<30:09, 14.36s/it]INFO:root:global_step: 874, logpy: 94.841, kl: 63.111, loss: -31.741\n",
      " 88%|███████████████████████████████████████████████████████████████████▍         | 875/1000 [3:30:53<29:59, 14.39s/it]INFO:root:global_step: 875, logpy: 94.844, kl: 63.120, loss: -31.734\n",
      " 88%|███████████████████████████████████████████████████████████████████▍         | 876/1000 [3:31:07<29:41, 14.37s/it]INFO:root:global_step: 876, logpy: 94.853, kl: 63.130, loss: -31.733\n",
      " 88%|███████████████████████████████████████████████████████████████████▌         | 877/1000 [3:31:21<29:29, 14.38s/it]INFO:root:global_step: 877, logpy: 94.854, kl: 63.138, loss: -31.726\n",
      " 88%|███████████████████████████████████████████████████████████████████▌         | 878/1000 [3:31:36<29:16, 14.39s/it]INFO:root:global_step: 878, logpy: 94.861, kl: 63.141, loss: -31.730\n",
      " 88%|███████████████████████████████████████████████████████████████████▋         | 879/1000 [3:31:50<29:10, 14.47s/it]INFO:root:global_step: 879, logpy: 94.864, kl: 63.145, loss: -31.729\n",
      " 88%|███████████████████████████████████████████████████████████████████▊         | 880/1000 [3:32:04<28:42, 14.36s/it]INFO:root:global_step: 880, logpy: 94.873, kl: 63.145, loss: -31.738\n",
      " 88%|███████████████████████████████████████████████████████████████████▊         | 881/1000 [3:32:19<28:30, 14.38s/it]INFO:root:global_step: 881, logpy: 94.881, kl: 63.151, loss: -31.740\n",
      " 88%|███████████████████████████████████████████████████████████████████▉         | 882/1000 [3:32:33<28:12, 14.34s/it]INFO:root:global_step: 882, logpy: 94.897, kl: 63.152, loss: -31.754\n",
      " 88%|███████████████████████████████████████████████████████████████████▉         | 883/1000 [3:32:48<28:08, 14.43s/it]INFO:root:global_step: 883, logpy: 94.901, kl: 63.155, loss: -31.756\n",
      " 88%|████████████████████████████████████████████████████████████████████         | 884/1000 [3:33:02<27:59, 14.48s/it]INFO:root:global_step: 884, logpy: 94.909, kl: 63.153, loss: -31.765\n",
      " 88%|████████████████████████████████████████████████████████████████████▏        | 885/1000 [3:33:17<27:50, 14.53s/it]INFO:root:global_step: 885, logpy: 94.922, kl: 63.150, loss: -31.781\n",
      " 89%|████████████████████████████████████████████████████████████████████▏        | 886/1000 [3:33:31<27:34, 14.51s/it]INFO:root:global_step: 886, logpy: 94.929, kl: 63.149, loss: -31.789\n",
      " 89%|████████████████████████████████████████████████████████████████████▎        | 887/1000 [3:33:46<27:13, 14.46s/it]INFO:root:global_step: 887, logpy: 94.938, kl: 63.148, loss: -31.799\n",
      " 89%|████████████████████████████████████████████████████████████████████▍        | 888/1000 [3:34:00<26:55, 14.42s/it]INFO:root:global_step: 888, logpy: 94.934, kl: 63.152, loss: -31.792\n",
      " 89%|████████████████████████████████████████████████████████████████████▍        | 889/1000 [3:34:15<26:39, 14.41s/it]INFO:root:global_step: 889, logpy: 94.935, kl: 63.152, loss: -31.792\n",
      " 89%|████████████████████████████████████████████████████████████████████▌        | 890/1000 [3:34:29<26:31, 14.47s/it]INFO:root:global_step: 890, logpy: 94.949, kl: 63.150, loss: -31.809\n",
      " 89%|████████████████████████████████████████████████████████████████████▌        | 891/1000 [3:34:44<26:18, 14.49s/it]INFO:root:global_step: 891, logpy: 94.959, kl: 63.147, loss: -31.820\n",
      " 89%|████████████████████████████████████████████████████████████████████▋        | 892/1000 [3:34:58<26:04, 14.48s/it]INFO:root:global_step: 892, logpy: 94.973, kl: 63.140, loss: -31.842\n",
      " 89%|████████████████████████████████████████████████████████████████████▊        | 893/1000 [3:35:12<25:42, 14.41s/it]INFO:root:global_step: 893, logpy: 94.990, kl: 63.134, loss: -31.865\n",
      " 89%|████████████████████████████████████████████████████████████████████▊        | 894/1000 [3:35:27<25:30, 14.44s/it]INFO:root:global_step: 894, logpy: 94.998, kl: 63.130, loss: -31.877\n",
      " 90%|████████████████████████████████████████████████████████████████████▉        | 895/1000 [3:35:41<25:12, 14.40s/it]INFO:root:global_step: 895, logpy: 95.004, kl: 63.124, loss: -31.889\n",
      " 90%|████████████████████████████████████████████████████████████████████▉        | 896/1000 [3:35:55<24:51, 14.34s/it]INFO:root:global_step: 896, logpy: 95.007, kl: 63.121, loss: -31.894\n",
      " 90%|█████████████████████████████████████████████████████████████████████        | 897/1000 [3:36:10<24:41, 14.39s/it]INFO:root:global_step: 897, logpy: 95.016, kl: 63.115, loss: -31.910\n",
      " 90%|█████████████████████████████████████████████████████████████████████▏       | 898/1000 [3:36:24<24:30, 14.42s/it]INFO:root:global_step: 898, logpy: 95.026, kl: 63.109, loss: -31.925\n",
      " 90%|█████████████████████████████████████████████████████████████████████▏       | 899/1000 [3:36:39<24:17, 14.43s/it]INFO:root:global_step: 899, logpy: 95.028, kl: 63.111, loss: -31.925\n",
      " 90%|█████████████████████████████████████████████████████████████████████▎       | 900/1000 [3:36:53<24:02, 14.43s/it]INFO:root:Saved figure at: ./sim/global_step_900.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 900, logpy: 95.039, kl: 63.108, loss: -31.939\n",
      " 90%|█████████████████████████████████████████████████████████████████████▍       | 901/1000 [3:37:10<24:47, 15.03s/it]INFO:root:global_step: 901, logpy: 95.046, kl: 63.100, loss: -31.953\n",
      " 90%|█████████████████████████████████████████████████████████████████████▍       | 902/1000 [3:37:24<24:13, 14.83s/it]INFO:root:global_step: 902, logpy: 95.048, kl: 63.099, loss: -31.957\n",
      " 90%|█████████████████████████████████████████████████████████████████████▌       | 903/1000 [3:37:38<23:41, 14.66s/it]INFO:root:global_step: 903, logpy: 95.052, kl: 63.102, loss: -31.958\n",
      " 90%|█████████████████████████████████████████████████████████████████████▌       | 904/1000 [3:37:53<23:18, 14.57s/it]INFO:root:global_step: 904, logpy: 95.050, kl: 63.104, loss: -31.954\n",
      " 90%|█████████████████████████████████████████████████████████████████████▋       | 905/1000 [3:38:07<23:02, 14.56s/it]INFO:root:global_step: 905, logpy: 95.052, kl: 63.104, loss: -31.956\n",
      " 91%|█████████████████████████████████████████████████████████████████████▊       | 906/1000 [3:38:22<22:48, 14.56s/it]INFO:root:global_step: 906, logpy: 95.064, kl: 63.104, loss: -31.968\n",
      " 91%|█████████████████████████████████████████████████████████████████████▊       | 907/1000 [3:38:36<22:33, 14.55s/it]INFO:root:global_step: 907, logpy: 95.083, kl: 63.106, loss: -31.985\n",
      " 91%|█████████████████████████████████████████████████████████████████████▉       | 908/1000 [3:38:51<22:16, 14.53s/it]INFO:root:global_step: 908, logpy: 95.087, kl: 63.111, loss: -31.984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████████████████████████████████████████████████████████████████▉       | 909/1000 [3:39:05<21:58, 14.49s/it]INFO:root:global_step: 909, logpy: 95.105, kl: 63.113, loss: -31.999\n",
      " 91%|██████████████████████████████████████████████████████████████████████       | 910/1000 [3:39:20<21:42, 14.47s/it]INFO:root:global_step: 910, logpy: 95.117, kl: 63.115, loss: -32.010\n",
      " 91%|██████████████████████████████████████████████████████████████████████▏      | 911/1000 [3:39:34<21:28, 14.48s/it]INFO:root:global_step: 911, logpy: 95.124, kl: 63.122, loss: -32.009\n",
      " 91%|██████████████████████████████████████████████████████████████████████▏      | 912/1000 [3:39:49<21:13, 14.47s/it]INFO:root:global_step: 912, logpy: 95.132, kl: 63.123, loss: -32.016\n",
      " 91%|██████████████████████████████████████████████████████████████████████▎      | 913/1000 [3:40:03<20:56, 14.44s/it]INFO:root:global_step: 913, logpy: 95.137, kl: 63.127, loss: -32.018\n",
      " 91%|██████████████████████████████████████████████████████████████████████▍      | 914/1000 [3:40:17<20:44, 14.47s/it]INFO:root:global_step: 914, logpy: 95.133, kl: 63.128, loss: -32.012\n",
      " 92%|██████████████████████████████████████████████████████████████████████▍      | 915/1000 [3:40:32<20:29, 14.46s/it]INFO:root:global_step: 915, logpy: 95.154, kl: 63.127, loss: -32.034\n",
      " 92%|██████████████████████████████████████████████████████████████████████▌      | 916/1000 [3:40:46<20:13, 14.44s/it]INFO:root:global_step: 916, logpy: 95.155, kl: 63.128, loss: -32.034\n",
      " 92%|██████████████████████████████████████████████████████████████████████▌      | 917/1000 [3:41:01<19:56, 14.41s/it]INFO:root:global_step: 917, logpy: 95.174, kl: 63.127, loss: -32.054\n",
      " 92%|██████████████████████████████████████████████████████████████████████▋      | 918/1000 [3:41:15<19:39, 14.39s/it]INFO:root:global_step: 918, logpy: 95.165, kl: 63.134, loss: -32.038\n",
      " 92%|██████████████████████████████████████████████████████████████████████▊      | 919/1000 [3:41:30<19:28, 14.43s/it]INFO:root:global_step: 919, logpy: 95.184, kl: 63.138, loss: -32.052\n",
      " 92%|██████████████████████████████████████████████████████████████████████▊      | 920/1000 [3:41:44<19:15, 14.44s/it]INFO:root:global_step: 920, logpy: 95.192, kl: 63.143, loss: -32.055\n",
      " 92%|██████████████████████████████████████████████████████████████████████▉      | 921/1000 [3:41:58<18:59, 14.42s/it]INFO:root:global_step: 921, logpy: 95.191, kl: 63.144, loss: -32.053\n",
      " 92%|██████████████████████████████████████████████████████████████████████▉      | 922/1000 [3:42:13<18:46, 14.44s/it]INFO:root:global_step: 922, logpy: 95.198, kl: 63.149, loss: -32.055\n",
      " 92%|███████████████████████████████████████████████████████████████████████      | 923/1000 [3:42:27<18:32, 14.45s/it]INFO:root:global_step: 923, logpy: 95.205, kl: 63.150, loss: -32.061\n",
      " 92%|███████████████████████████████████████████████████████████████████████▏     | 924/1000 [3:42:42<18:21, 14.49s/it]INFO:root:global_step: 924, logpy: 95.211, kl: 63.156, loss: -32.061\n",
      " 92%|███████████████████████████████████████████████████████████████████████▏     | 925/1000 [3:42:56<18:09, 14.53s/it]INFO:root:global_step: 925, logpy: 95.221, kl: 63.159, loss: -32.068\n",
      " 93%|███████████████████████████████████████████████████████████████████████▎     | 926/1000 [3:43:11<17:53, 14.51s/it]INFO:root:global_step: 926, logpy: 95.238, kl: 63.157, loss: -32.088\n",
      " 93%|███████████████████████████████████████████████████████████████████████▍     | 927/1000 [3:43:25<17:35, 14.46s/it]INFO:root:global_step: 927, logpy: 95.243, kl: 63.157, loss: -32.093\n",
      " 93%|███████████████████████████████████████████████████████████████████████▍     | 928/1000 [3:43:40<17:21, 14.47s/it]INFO:root:global_step: 928, logpy: 95.233, kl: 63.163, loss: -32.077\n",
      " 93%|███████████████████████████████████████████████████████████████████████▌     | 929/1000 [3:43:54<17:06, 14.46s/it]INFO:root:global_step: 929, logpy: 95.233, kl: 63.165, loss: -32.074\n",
      " 93%|███████████████████████████████████████████████████████████████████████▌     | 930/1000 [3:44:09<16:51, 14.45s/it]INFO:root:global_step: 930, logpy: 95.237, kl: 63.168, loss: -32.076\n",
      " 93%|███████████████████████████████████████████████████████████████████████▋     | 931/1000 [3:44:23<16:37, 14.45s/it]INFO:root:global_step: 931, logpy: 95.245, kl: 63.167, loss: -32.084\n",
      " 93%|███████████████████████████████████████████████████████████████████████▊     | 932/1000 [3:44:38<16:23, 14.46s/it]INFO:root:global_step: 932, logpy: 95.258, kl: 63.175, loss: -32.089\n",
      " 93%|███████████████████████████████████████████████████████████████████████▊     | 933/1000 [3:44:52<16:12, 14.52s/it]INFO:root:global_step: 933, logpy: 95.275, kl: 63.180, loss: -32.101\n",
      " 93%|███████████████████████████████████████████████████████████████████████▉     | 934/1000 [3:45:07<15:58, 14.53s/it]INFO:root:global_step: 934, logpy: 95.300, kl: 63.182, loss: -32.124\n",
      " 94%|███████████████████████████████████████████████████████████████████████▉     | 935/1000 [3:45:21<15:44, 14.54s/it]INFO:root:global_step: 935, logpy: 95.305, kl: 63.184, loss: -32.126\n",
      " 94%|████████████████████████████████████████████████████████████████████████     | 936/1000 [3:45:36<15:27, 14.49s/it]INFO:root:global_step: 936, logpy: 95.317, kl: 63.187, loss: -32.135\n",
      " 94%|████████████████████████████████████████████████████████████████████████▏    | 937/1000 [3:45:50<15:12, 14.49s/it]INFO:root:global_step: 937, logpy: 95.321, kl: 63.191, loss: -32.136\n",
      " 94%|████████████████████████████████████████████████████████████████████████▏    | 938/1000 [3:46:05<14:58, 14.49s/it]INFO:root:global_step: 938, logpy: 95.325, kl: 63.193, loss: -32.137\n",
      " 94%|████████████████████████████████████████████████████████████████████████▎    | 939/1000 [3:46:19<14:43, 14.48s/it]INFO:root:global_step: 939, logpy: 95.341, kl: 63.193, loss: -32.153\n",
      " 94%|████████████████████████████████████████████████████████████████████████▍    | 940/1000 [3:46:34<14:29, 14.49s/it]INFO:root:global_step: 940, logpy: 95.332, kl: 63.202, loss: -32.136\n",
      " 94%|████████████████████████████████████████████████████████████████████████▍    | 941/1000 [3:46:48<14:12, 14.44s/it]INFO:root:global_step: 941, logpy: 95.340, kl: 63.200, loss: -32.146\n",
      " 94%|████████████████████████████████████████████████████████████████████████▌    | 942/1000 [3:47:02<13:55, 14.41s/it]INFO:root:global_step: 942, logpy: 95.353, kl: 63.201, loss: -32.157\n",
      " 94%|████████████████████████████████████████████████████████████████████████▌    | 943/1000 [3:47:17<13:45, 14.48s/it]INFO:root:global_step: 943, logpy: 95.360, kl: 63.206, loss: -32.160\n",
      " 94%|████████████████████████████████████████████████████████████████████████▋    | 944/1000 [3:47:32<13:31, 14.49s/it]INFO:root:global_step: 944, logpy: 95.358, kl: 63.207, loss: -32.156\n",
      " 94%|████████████████████████████████████████████████████████████████████████▊    | 945/1000 [3:47:46<13:17, 14.49s/it]INFO:root:global_step: 945, logpy: 95.353, kl: 63.210, loss: -32.148\n",
      " 95%|████████████████████████████████████████████████████████████████████████▊    | 946/1000 [3:48:01<13:04, 14.52s/it]INFO:root:global_step: 946, logpy: 95.354, kl: 63.212, loss: -32.147\n",
      " 95%|████████████████████████████████████████████████████████████████████████▉    | 947/1000 [3:48:15<12:49, 14.52s/it]INFO:root:global_step: 947, logpy: 95.348, kl: 63.209, loss: -32.144\n",
      " 95%|████████████████████████████████████████████████████████████████████████▉    | 948/1000 [3:48:30<12:36, 14.55s/it]INFO:root:global_step: 948, logpy: 95.352, kl: 63.212, loss: -32.145\n",
      " 95%|█████████████████████████████████████████████████████████████████████████    | 949/1000 [3:48:44<12:20, 14.51s/it]INFO:root:global_step: 949, logpy: 95.352, kl: 63.221, loss: -32.136\n",
      " 95%|█████████████████████████████████████████████████████████████████████████▏   | 950/1000 [3:48:59<12:03, 14.47s/it]INFO:root:Saved figure at: ./sim/global_step_950.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:global_step: 950, logpy: 95.360, kl: 63.225, loss: -32.140\n",
      " 95%|█████████████████████████████████████████████████████████████████████████▏   | 951/1000 [3:49:15<12:20, 15.12s/it]INFO:root:global_step: 951, logpy: 95.365, kl: 63.231, loss: -32.138\n",
      " 95%|█████████████████████████████████████████████████████████████████████████▎   | 952/1000 [3:49:30<11:59, 14.98s/it]INFO:root:global_step: 952, logpy: 95.364, kl: 63.241, loss: -32.128\n",
      " 95%|█████████████████████████████████████████████████████████████████████████▍   | 953/1000 [3:49:44<11:38, 14.85s/it]INFO:root:global_step: 953, logpy: 95.372, kl: 63.246, loss: -32.131\n",
      " 95%|█████████████████████████████████████████████████████████████████████████▍   | 954/1000 [3:49:59<11:16, 14.71s/it]INFO:root:global_step: 954, logpy: 95.369, kl: 63.248, loss: -32.125\n",
      " 96%|█████████████████████████████████████████████████████████████████████████▌   | 955/1000 [3:50:13<10:59, 14.65s/it]INFO:root:global_step: 955, logpy: 95.357, kl: 63.252, loss: -32.109\n",
      " 96%|█████████████████████████████████████████████████████████████████████████▌   | 956/1000 [3:50:28<10:39, 14.55s/it]INFO:root:global_step: 956, logpy: 95.374, kl: 63.254, loss: -32.124\n",
      " 96%|█████████████████████████████████████████████████████████████████████████▋   | 957/1000 [3:50:42<10:24, 14.52s/it]INFO:root:global_step: 957, logpy: 95.392, kl: 63.258, loss: -32.138\n",
      " 96%|█████████████████████████████████████████████████████████████████████████▊   | 958/1000 [3:50:56<10:08, 14.49s/it]INFO:root:global_step: 958, logpy: 95.392, kl: 63.263, loss: -32.134\n",
      " 96%|█████████████████████████████████████████████████████████████████████████▊   | 959/1000 [3:51:11<09:53, 14.47s/it]INFO:root:global_step: 959, logpy: 95.417, kl: 63.264, loss: -32.158\n",
      " 96%|█████████████████████████████████████████████████████████████████████████▉   | 960/1000 [3:51:25<09:37, 14.43s/it]INFO:root:global_step: 960, logpy: 95.436, kl: 63.266, loss: -32.174\n",
      " 96%|█████████████████████████████████████████████████████████████████████████▉   | 961/1000 [3:51:40<09:24, 14.48s/it]INFO:root:global_step: 961, logpy: 95.444, kl: 63.272, loss: -32.177\n",
      " 96%|██████████████████████████████████████████████████████████████████████████   | 962/1000 [3:51:54<09:08, 14.45s/it]INFO:root:global_step: 962, logpy: 95.463, kl: 63.268, loss: -32.200\n",
      " 96%|██████████████████████████████████████████████████████████████████████████▏  | 963/1000 [3:52:09<08:55, 14.48s/it]INFO:root:global_step: 963, logpy: 95.470, kl: 63.269, loss: -32.206\n",
      " 96%|██████████████████████████████████████████████████████████████████████████▏  | 964/1000 [3:52:23<08:41, 14.48s/it]INFO:root:global_step: 964, logpy: 95.474, kl: 63.271, loss: -32.207\n",
      " 96%|██████████████████████████████████████████████████████████████████████████▎  | 965/1000 [3:52:38<08:25, 14.44s/it]INFO:root:global_step: 965, logpy: 95.488, kl: 63.271, loss: -32.221\n",
      " 97%|██████████████████████████████████████████████████████████████████████████▍  | 966/1000 [3:52:52<08:10, 14.43s/it]INFO:root:global_step: 966, logpy: 95.488, kl: 63.268, loss: -32.224\n",
      " 97%|██████████████████████████████████████████████████████████████████████████▍  | 967/1000 [3:53:07<07:59, 14.53s/it]INFO:root:global_step: 967, logpy: 95.494, kl: 63.262, loss: -32.236\n",
      " 97%|██████████████████████████████████████████████████████████████████████████▌  | 968/1000 [3:53:21<07:45, 14.53s/it]INFO:root:global_step: 968, logpy: 95.490, kl: 63.267, loss: -32.228\n",
      " 97%|██████████████████████████████████████████████████████████████████████████▌  | 969/1000 [3:53:36<07:29, 14.49s/it]INFO:root:global_step: 969, logpy: 95.498, kl: 63.266, loss: -32.236\n",
      " 97%|██████████████████████████████████████████████████████████████████████████▋  | 970/1000 [3:53:50<07:15, 14.50s/it]INFO:root:global_step: 970, logpy: 95.501, kl: 63.265, loss: -32.240\n",
      " 97%|██████████████████████████████████████████████████████████████████████████▊  | 971/1000 [3:54:05<06:59, 14.47s/it]INFO:root:global_step: 971, logpy: 95.512, kl: 63.266, loss: -32.251\n",
      " 97%|██████████████████████████████████████████████████████████████████████████▊  | 972/1000 [3:54:19<06:45, 14.48s/it]INFO:root:global_step: 972, logpy: 95.524, kl: 63.267, loss: -32.261\n",
      " 97%|██████████████████████████████████████████████████████████████████████████▉  | 973/1000 [3:54:33<06:28, 14.39s/it]INFO:root:global_step: 973, logpy: 95.524, kl: 63.264, loss: -32.265\n",
      " 97%|██████████████████████████████████████████████████████████████████████████▉  | 974/1000 [3:54:48<06:17, 14.52s/it]INFO:root:global_step: 974, logpy: 95.524, kl: 63.267, loss: -32.261\n",
      " 98%|███████████████████████████████████████████████████████████████████████████  | 975/1000 [3:55:03<06:02, 14.52s/it]INFO:root:global_step: 975, logpy: 95.542, kl: 63.264, loss: -32.282\n",
      " 98%|███████████████████████████████████████████████████████████████████████████▏ | 976/1000 [3:55:17<05:49, 14.55s/it]INFO:root:global_step: 976, logpy: 95.555, kl: 63.265, loss: -32.294\n",
      " 98%|███████████████████████████████████████████████████████████████████████████▏ | 977/1000 [3:55:32<05:35, 14.57s/it]INFO:root:global_step: 977, logpy: 95.563, kl: 63.271, loss: -32.296\n",
      " 98%|███████████████████████████████████████████████████████████████████████████▎ | 978/1000 [3:55:46<05:20, 14.55s/it]INFO:root:global_step: 978, logpy: 95.561, kl: 63.271, loss: -32.294\n",
      " 98%|███████████████████████████████████████████████████████████████████████████▍ | 979/1000 [3:56:01<05:06, 14.57s/it]INFO:root:global_step: 979, logpy: 95.582, kl: 63.264, loss: -32.321\n",
      " 98%|███████████████████████████████████████████████████████████████████████████▍ | 980/1000 [3:56:15<04:50, 14.54s/it]INFO:root:global_step: 980, logpy: 95.578, kl: 63.267, loss: -32.314\n",
      " 98%|███████████████████████████████████████████████████████████████████████████▌ | 981/1000 [3:56:30<04:35, 14.52s/it]INFO:root:global_step: 981, logpy: 95.586, kl: 63.270, loss: -32.320\n",
      " 98%|███████████████████████████████████████████████████████████████████████████▌ | 982/1000 [3:56:45<04:21, 14.55s/it]INFO:root:global_step: 982, logpy: 95.591, kl: 63.273, loss: -32.322\n",
      " 98%|███████████████████████████████████████████████████████████████████████████▋ | 983/1000 [3:56:59<04:07, 14.53s/it]INFO:root:global_step: 983, logpy: 95.608, kl: 63.272, loss: -32.339\n",
      " 98%|███████████████████████████████████████████████████████████████████████████▊ | 984/1000 [3:57:14<03:52, 14.55s/it]INFO:root:global_step: 984, logpy: 95.603, kl: 63.277, loss: -32.330\n",
      " 98%|███████████████████████████████████████████████████████████████████████████▊ | 985/1000 [3:57:28<03:38, 14.58s/it]INFO:root:global_step: 985, logpy: 95.609, kl: 63.283, loss: -32.329\n",
      " 99%|███████████████████████████████████████████████████████████████████████████▉ | 986/1000 [3:57:43<03:24, 14.59s/it]INFO:root:global_step: 986, logpy: 95.625, kl: 63.279, loss: -32.350\n",
      " 99%|███████████████████████████████████████████████████████████████████████████▉ | 987/1000 [3:57:57<03:09, 14.55s/it]INFO:root:global_step: 987, logpy: 95.625, kl: 63.281, loss: -32.347\n",
      " 99%|████████████████████████████████████████████████████████████████████████████ | 988/1000 [3:58:12<02:54, 14.52s/it]INFO:root:global_step: 988, logpy: 95.614, kl: 63.283, loss: -32.335\n",
      " 99%|████████████████████████████████████████████████████████████████████████████▏| 989/1000 [3:58:26<02:39, 14.53s/it]INFO:root:global_step: 989, logpy: 95.622, kl: 63.281, loss: -32.345\n",
      " 99%|████████████████████████████████████████████████████████████████████████████▏| 990/1000 [3:58:41<02:24, 14.49s/it]INFO:root:global_step: 990, logpy: 95.628, kl: 63.283, loss: -32.348\n",
      " 99%|████████████████████████████████████████████████████████████████████████████▎| 991/1000 [3:58:55<02:10, 14.51s/it]INFO:root:global_step: 991, logpy: 95.633, kl: 63.290, loss: -32.346\n",
      " 99%|████████████████████████████████████████████████████████████████████████████▍| 992/1000 [3:59:10<01:56, 14.54s/it]INFO:root:global_step: 992, logpy: 95.663, kl: 63.286, loss: -32.380\n",
      " 99%|████████████████████████████████████████████████████████████████████████████▍| 993/1000 [3:59:24<01:41, 14.54s/it]INFO:root:global_step: 993, logpy: 95.673, kl: 63.286, loss: -32.390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|████████████████████████████████████████████████████████████████████████████▌| 994/1000 [3:59:39<01:26, 14.49s/it]INFO:root:global_step: 994, logpy: 95.676, kl: 63.288, loss: -32.391\n",
      "100%|████████████████████████████████████████████████████████████████████████████▌| 995/1000 [3:59:53<01:12, 14.48s/it]INFO:root:global_step: 995, logpy: 95.682, kl: 63.288, loss: -32.397\n",
      "100%|████████████████████████████████████████████████████████████████████████████▋| 996/1000 [4:00:08<00:58, 14.52s/it]INFO:root:global_step: 996, logpy: 95.697, kl: 63.287, loss: -32.413\n",
      "100%|████████████████████████████████████████████████████████████████████████████▊| 997/1000 [4:00:22<00:43, 14.52s/it]INFO:root:global_step: 997, logpy: 95.698, kl: 63.295, loss: -32.406\n",
      "100%|████████████████████████████████████████████████████████████████████████████▊| 998/1000 [4:00:37<00:28, 14.46s/it]INFO:root:global_step: 998, logpy: 95.704, kl: 63.295, loss: -32.411\n",
      "100%|████████████████████████████████████████████████████████████████████████████▉| 999/1000 [4:00:51<00:14, 14.49s/it]INFO:root:global_step: 999, logpy: 95.707, kl: 63.297, loss: -32.413\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1000/1000 [4:01:06<00:00, 14.47s/it]\n"
     ]
    }
   ],
   "source": [
    "manual_seed(args['seed'])\n",
    "\n",
    "if args['debug']:\n",
    "    logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "ckpt_dir = os.path.join('./sim/', 'ckpts')\n",
    "os.makedirs(ckpt_dir, exist_ok=True)\n",
    "\n",
    "sdeint_fn = torchsde.sdeint_adjoint if args['adjoint'] else torchsde.sdeint\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c356ad31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
