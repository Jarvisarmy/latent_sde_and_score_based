{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4dd7b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from collections import namedtuple\n",
    "from typing import Optional, Union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import tqdm\n",
    "from torch import distributions, nn, optim\n",
    "\n",
    "import torchsde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0aeebbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the gpu is available or not, if yes, use gpu\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2902c1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the tuple for data, \n",
    "Data = namedtuple('Data', ['ts_', 'ts_ext_', 'ts_vis_', 'ts', 'ts_ext', 'ts_vis', 'ys', 'ys_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9198a09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"train_iters\": 1000,\n",
    "    \"pause_iters\": 50,\n",
    "    \"hide_ticks\": False,\n",
    "    \"save_ckpt\":True,\n",
    "    \"likelihood\":\"laplace\",\n",
    "    \"scale\": 0.001,\n",
    "    \"adjoint\": True,\n",
    "    \"debug\": True,\n",
    "    \"seed\": 42,\n",
    "    'data':'segmented_cosine',\n",
    "    \"dt\": 1e-2,\n",
    "    \"batch_size\": 256,\n",
    "    \"method\": 'euler',\n",
    "    \"adaptive\": 'False',\n",
    "    \"rtol\": 1e-3,\n",
    "    \"atol\": 1e-3\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40420fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output values from 0 to maxval with iters steps\n",
    "class LinearScheduler(object):\n",
    "    def __init__(self, iters, maxval=1.0):\n",
    "        self._iters = max(1,iters)\n",
    "        self._val = maxval/self._iters\n",
    "        self._maxval = maxval\n",
    "    \n",
    "    def step(self):\n",
    "        self._val = min(self._maxval, self._val+self._maxval/self._iters)\n",
    "        \n",
    "    @property\n",
    "    def val(self):\n",
    "        return self._val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93c09c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EMAMetric(object):\n",
    "    def __init__(self, gamma: Optional[float]=0.99):\n",
    "        super(EMAMetric, self).__init__()\n",
    "        self._val=0\n",
    "        self._gamma = gamma\n",
    "    def step(self, x:Union[torch.Tensor, np.ndarray]):\n",
    "        x = x.detach().cpu().numpy() if torch.is_tensor(x) else x\n",
    "        self._val = self._gamma * self._val + (1-self._gamma)*x\n",
    "        return self._val\n",
    "    \n",
    "    @property\n",
    "    def val(self):\n",
    "        return self._val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a4ec86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the seed\n",
    "def manual_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98a2f4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure that the dvision is stable\n",
    "def _stable_division(a,b,epsilon=1e-7):\n",
    "    b = torch.where(b.abs().detach() > epsilon, b, torch.full_like(b, fill_value=epsilon)*b.sign())\n",
    "    return a/b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "522d3e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LatentSDE(torchsde.SDEIto): # sde with ito calculus\n",
    "    def __init__(self, theta=1.0, mu=0.0, sigma=1):\n",
    "        super(LatentSDE, self).__init__(noise_type=\"diagonal\")\n",
    "        logvar = math.log(sigma ** 2/(2.*theta))\n",
    "        \n",
    "        # prior drift\n",
    "        #self.register_buffer(\"theta\",torch.tensor([[theta]])) # prior parameters, register 成buffer, 参数不会进行更新\n",
    "        self.register_buffer(\"mu\", torch.tensor([[mu]]))\n",
    "        self.register_buffer(\"sigma\",torch.tensor([[sigma]]))\n",
    "        \n",
    "        # p(y0)\n",
    "        self.register_buffer(\"py0_mean\", torch.tensor([[mu]]))\n",
    "        self.register_buffer(\"py0_logvar\", torch.tensor([[logvar]]))\n",
    "        \n",
    "        # approximate posterior drift: Takes in 2 positional encodings and the state\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(3,200),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(200,200),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(200,1)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Initialization the parameters\n",
    "        self.net[-1].weight.data.fill_(0.) # 初始化最后一层的参数\n",
    "        self.net[-1].bias.data.fill_(0.)\n",
    "            \n",
    "        # q(y0)\n",
    "        self.qy0_mean = nn.Parameter(torch.tensor([[mu]]), requires_grad=True) # 创建parameters\n",
    "        self.qy0_logvar = nn.Parameter(torch.tensor([[logvar]]), requires_grad=True) # 创建parameters\n",
    "        self.theta = nn.Parameter(torch.tensor([[theta]]),requires_grad=True)\n",
    "        #self.theta = nn.Parameter(torch.tensor([[theta]]),requires_grad=True)\n",
    "            \n",
    "    def f(self, t, y):  # Approximate posterior drift.\n",
    "        if t.dim() == 0:\n",
    "            t = torch.full_like(y, fill_value=t) # create a tensor of t\n",
    "        # Positional encoding in transformers for time-inhomogeneous posterior.\n",
    "        return self.net(torch.cat((torch.sin(t), torch.cos(t), y), dim=-1))\n",
    "\n",
    "    def g(self, t, y):  # Shared diffusion.\n",
    "        return self.sigma.repeat(y.size(0), 1) # 重复复制, 创建一个size为[y.size[0],1]\n",
    "\n",
    "    def h(self, t, y):  # Prior drift.\n",
    "        return self.theta * (self.mu - y)\n",
    "\n",
    "    def f_aug(self, t, y):  # Drift for augmented dynamics with logqp term.\n",
    "        y = y[:, 0:1] # 提取第一列，保持列的形态\n",
    "        f, g, h = self.f(t, y), self.g(t, y), self.h(t, y)\n",
    "        u = _stable_division(f - h, g) # 计算u(z,t)\n",
    "        f_logqp = .5 * (u ** 2).sum(dim=1, keepdim=True) # 计算integral\n",
    "        return torch.cat([f, f_logqp], dim=1)\n",
    "\n",
    "    def g_aug(self, t, y):  # Diffusion for augmented dynamics with logqp term.\n",
    "        y = y[:, 0:1]\n",
    "        g = self.g(t, y)\n",
    "        g_logqp = torch.zeros_like(y)\n",
    "        return torch.cat([g, g_logqp], dim=1)\n",
    "\n",
    "    def forward(self, ts, batch_size, eps=None):\n",
    "        eps = torch.randn(batch_size, 1).to(self.qy0_std) if eps is None else eps\n",
    "        y0 = self.qy0_mean + eps * self.qy0_std # the latent variable\n",
    "        qy0 = distributions.Normal(loc=self.qy0_mean, scale=self.qy0_std) # approximate posterior distribution\n",
    "        py0 = distributions.Normal(loc=self.py0_mean, scale=self.py0_std) # prior distribution\n",
    "        logqp0 = distributions.kl_divergence(qy0, py0).sum(dim=1)  # KL(t=0). calculate the kl divergence\n",
    "        #print(y0.size()) # (256, 1)\n",
    "        aug_y0 = torch.cat([y0, torch.zeros(batch_size, 1).to(y0)], dim=1) # create the augmented initial value\n",
    "        #print(aug_y0.size()) # [256, 2]\n",
    "        aug_ys = sdeint_fn(\n",
    "            sde=self,\n",
    "            y0=aug_y0,\n",
    "            ts=ts,\n",
    "            method=args['method'],\n",
    "            dt=args['dt'],\n",
    "            adaptive=args['adaptive'],\n",
    "            rtol=args['rtol'],\n",
    "            atol=args['atol'],\n",
    "            names={'drift': 'f_aug', 'diffusion': 'g_aug'}\n",
    "        ) # call the sde solver to \n",
    "        # print(aug_ys.size()) # [22, 256, 2]\n",
    "        ys, logqp_path = aug_ys[:, :, 0:1], aug_ys[-1, :, 1] # get the integral of the u(z,t) at the last time\n",
    "        \n",
    "        logqp = (logqp0 + logqp_path).mean(dim=0)  # KL(t=0) + KL(path).\n",
    "        return ys, logqp\n",
    "\n",
    "    def sample_p(self, ts, batch_size, eps=None, bm=None):\n",
    "        eps = torch.randn(batch_size, 1).to(self.py0_mean) if eps is None else eps\n",
    "        y0 = self.py0_mean + eps * self.py0_std\n",
    "        return sdeint_fn(self, y0, ts, bm=bm, method=args['method'], dt=args['dt'], names={'drift': 'h'}) # prior sde\n",
    "\n",
    "    def sample_q(self, ts, batch_size, eps=None, bm=None):\n",
    "        eps = torch.randn(batch_size, 1).to(self.qy0_mean) if eps is None else eps\n",
    "        y0 = self.qy0_mean + eps * self.qy0_std\n",
    "        return sdeint_fn(self, y0, ts, bm=bm, method=args['method'], dt=args['dt']) # posterior sde\n",
    "\n",
    "    @property\n",
    "    def py0_std(self):\n",
    "        return torch.exp(.5 * self.py0_logvar)\n",
    "\n",
    "    @property\n",
    "    def qy0_std(self):\n",
    "        return torch.exp(.5 * self.qy0_logvar)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80736fff",
   "metadata": {},
   "source": [
    "## 5. Simulation of time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd15aaa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "T = 120\n",
    "#beta = 0.1694\n",
    "beta=1\n",
    "def make_time_series():\n",
    "    \n",
    "    \n",
    "    phi = 0.99\n",
    "    sigma_v = 0.003342\n",
    "    sigma_u = 0.00328\n",
    "    rho = -0.856\n",
    "    cov_uv = rho * sigma_u * sigma_v\n",
    "\n",
    "    # generating shocks\n",
    "    mu = [0,0]\n",
    "    cov = [[sigma_u**2, cov_uv], [cov_uv, sigma_v**2]]\n",
    "    shocks = np.random.multivariate_normal(mu, cov, T)\n",
    "\n",
    "    z0 = np.random.normal(0, sigma_u**2/(1-phi**2),1)\n",
    "    r0 = shocks[0][0]\n",
    "\n",
    "    z = np.zeros(T)\n",
    "    r = np.zeros(T)\n",
    "    z[0] = z0\n",
    "    r[0] = r0\n",
    "\n",
    "    for idx_t in range(T-1):\n",
    "        z[idx_t+1] = phi*z[idx_t] + shocks[idx_t+1][1]\n",
    "        r[idx_t+1] = beta*z[idx_t+1] + shocks[idx_t+1][0]\n",
    "    return z, r\n",
    "z, r = make_time_series()\n",
    "plt.figure(figsize=(15,5))\n",
    "xvalues = np.array(range(T))\n",
    "plt.plot(xvalues, r, linestyle='-', color='g', label=\"observed $r_t$\")\n",
    "plt.plot(xvalues, z, linestyle=\"--\", color=\"r\", label=r\"hidden variable $\\beta * z_t$\", linewidth=3.0)\n",
    "\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('%')\n",
    "plt.grid(True)\n",
    "plt.title(r\"Simulated $r_t$ and hidden $\\beta * z_t$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0cf9fca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data():\n",
    "    ts_ = np.linspace(0.1,3.0,120)\n",
    "    ts_ext_ = np.array([0.] + list(ts_) + [3.1])\n",
    "    ts_vis_ = np.linspace(0.1, 3.1, 121)\n",
    "    ys_ = r[:,None]\n",
    "    ts = torch.tensor(ts_).float()\n",
    "    ts_ext = torch.tensor(ts_ext_).float()\n",
    "    ts_vis = torch.tensor(ts_vis_).float()\n",
    "    ys = torch.tensor(ys_).float().to(device)\n",
    "    return Data(ts_, ts_ext_, ts_vis_, ts, ts_ext, ts_vis, ys, ys_)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "99a1fc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Dataset\n",
    "    ts_, ts_ext_, ts_vis_, ts, ts_ext, ts_vis, ys, ys_ = make_data()\n",
    "    mu = torch.mean(ys)\n",
    "    sigma = torch.std(ys)\n",
    "    \n",
    "    # plotting parameters\n",
    "    vis_batch_size = 1024\n",
    "    ylims = (-0.02, 0.02)\n",
    "    alphas = [0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.55]\n",
    "    percentiles = [0.999, 0.99, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1]\n",
    "    vis_idx = np.random.permutation(vis_batch_size)\n",
    "    sample_colors = ('#8c96c6', '#8c6bb1', '#810f7c')\n",
    "    fill_color = '#9ebcda'\n",
    "    mean_color = '#4d004b'\n",
    "    num_samples = len(sample_colors)\n",
    "    \n",
    "    eps = torch.randn(vis_batch_size, 1).to(device)\n",
    "    bm = torchsde.BrownianInterval(\n",
    "        t0=ts_vis[0],\n",
    "        t1=ts_vis[-1],\n",
    "        size=(vis_batch_size,1),\n",
    "        device=device,\n",
    "        levy_area_approximation=\"space-time\")\n",
    "    \n",
    "    # Model\n",
    "    model = LatentSDE(theta=0.01,mu=mu,sigma=sigma).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\n",
    "    kl_scheduler = LinearScheduler(iters=100)\n",
    "    criterion = nn.BCELoss(reduction='sum')\n",
    "    \n",
    "    logpy_metric = EMAMetric()\n",
    "    kl_metric = EMAMetric()\n",
    "    loss_metric = EMAMetric()\n",
    "    \n",
    "    \n",
    "    # show prior\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        zs = model.sample_p(ts=ts_vis, batch_size = vis_batch_size, eps = eps, bm=bm).squeeze()\n",
    "       \n",
    "        ts_vis_, zs_ = ts_vis.cpu().numpy(), zs.cpu().numpy()\n",
    "        #plt.scatter(ts_vis_, ys_, color='r', label=\"prior\")\n",
    "        zs_ = np.sort(zs_,axis=1)\n",
    "        img_dir = os.path.join('./sim/','prior.png')\n",
    "        plt.subplot(frameon=False)\n",
    "        for alpha, percentile in zip(alphas, percentiles):\n",
    "            idx = int((1 - percentile) / 2. * vis_batch_size)\n",
    "            zs_bot_ = zs_[:, idx]\n",
    "            zs_top_ = zs_[:, -idx]\n",
    "            plt.fill_between(ts_vis_, zs_bot_, zs_top_, alpha=alpha, color=fill_color)\n",
    "\n",
    "        # `zorder` determines who's on top; the larger the more at the top.\n",
    "        \n",
    "        plt.scatter(ts_, ys_, marker='x', zorder=3, color='k', s=35)  # Data.\n",
    "        plt.plot(ts_, ys_, marker='x', zorder=3, color='k',label=\"observed $r_t$\")\n",
    "        plt.plot(ts_, z[:,None], color='g', linewidth=3.0, label=r\"hidden variable $z_t$\")\n",
    "        plt.ylim(ylims)\n",
    "        plt.xlabel('$t$')\n",
    "        plt.ylabel('$Y_t$')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.legend()\n",
    "        plt.savefig(img_dir, dpi=300)\n",
    "        plt.close()\n",
    "        logging.info(f'Saved prior figure at: {img_dir}')\n",
    "    \n",
    "    \n",
    "    for global_step in tqdm.tqdm(range(args['train_iters'])):\n",
    "        \n",
    "        # Plot and save.\n",
    "        if global_step % args['pause_iters'] == 0:\n",
    "            img_path = os.path.join(\"./sim/\", f'global_step_{global_step}.png')\n",
    "\n",
    "            with torch.no_grad():\n",
    "                zs = model.sample_q(ts=ts_vis, batch_size=vis_batch_size, eps=eps, bm=bm).squeeze()\n",
    "                samples = zs[:, vis_idx]\n",
    "                ts_vis_, zs_, samples_ = ts_vis.cpu().numpy(), zs.cpu().numpy(), samples.cpu().numpy()\n",
    "                zs_ = np.sort(zs_, axis=1)\n",
    "                plt.subplot(frameon=False)\n",
    "\n",
    "                if True: # args.show_percentiles:\n",
    "                    for alpha, percentile in zip(alphas, percentiles):\n",
    "                        idx = int((1 - percentile) / 2. * vis_batch_size)\n",
    "                        zs_bot_, zs_top_ = zs_[:, idx], zs_[:, -idx]\n",
    "                        plt.fill_between(ts_vis_, zs_bot_, zs_top_, alpha=alpha, color=fill_color)\n",
    "\n",
    "                if True: #args.show_mean:\n",
    "                    plt.plot(ts_vis_, zs_.mean(axis=1), color=mean_color)\n",
    "\n",
    "                if True: #args.show_samples:\n",
    "                    #for j in range(num_samples):\n",
    "                    #    plt.plot(ts_vis_, samples_[:, j], color=sample_colors[j], linewidth=1.0)\n",
    "                    plt.plot(ts_, z[:,None], color='g', linewidth=3.0, label=r\"hidden variable $z_t$\")\n",
    "                    plt.plot(ts_vis_, samples_.mean(axis=1), color='r',label=r'mean of latent variables')\n",
    "\n",
    "                if True: #args.show_arrows:\n",
    "                    num, dt = 3, 0.12\n",
    "                    t, y = torch.meshgrid(\n",
    "                        [torch.linspace(0, 3, num).to(device), torch.linspace(-0.3, 0.3, num).to(device)]\n",
    "                    )\n",
    "                    t, y = t.reshape(-1, 1), y.reshape(-1, 1)\n",
    "                    fty = model.f(t=t, y=y).reshape(num, num)\n",
    "                    dt = torch.zeros(num, num).fill_(dt).to(device)\n",
    "                    dy = fty * dt\n",
    "                    dt_, dy_, t_, y_ = dt.cpu().numpy(), dy.cpu().numpy(), t.cpu().numpy(), y.cpu().numpy()\n",
    "                    plt.quiver(t_, y_, dt_, dy_, alpha=0.3, edgecolors='k', width=0.0035, scale=50)\n",
    "\n",
    "                if False: #args.hide_ticks:\n",
    "                    plt.xticks([], [])\n",
    "                    plt.yticks([], [])\n",
    "\n",
    "                plt.scatter(ts_, ys_, marker='x', zorder=3, color='k', s=35)  # Data.\n",
    "                plt.plot(ts_, ys_, marker='x', zorder=3, color='k', label=\"observed $r_t$ \") # new added\n",
    "            \n",
    "\n",
    "                \n",
    "                plt.ylim(ylims)\n",
    "                plt.xlabel('$t$')\n",
    "                plt.ylabel('$Y_t$')\n",
    "                plt.tight_layout()\n",
    "                plt.legend()\n",
    "                plt.savefig(img_path, dpi=300)\n",
    "                plt.close()\n",
    "                logging.info(f'Saved figure at: {img_path}')\n",
    "\n",
    "                \n",
    "        \n",
    "        # Train.\n",
    "        optimizer.zero_grad() # zero the gradient\n",
    "        zs, kl = model(ts=ts_ext, batch_size=args['batch_size']) # pass through the model, ys, logqp\n",
    "        zs = zs.squeeze() # remove the dimensions of input of size 1\n",
    "        zs = zs[1:-1]  # Drop first and last which are only used to penalize out-of-data region and spread uncertainty.\n",
    "\n",
    "        likelihood_constructor = {\"laplace\": distributions.Laplace, \"normal\": distributions.Normal}[args['likelihood']]\n",
    "        likelihood = likelihood_constructor(loc=zs, scale=args['scale']) # create the laplace distribution\n",
    "        logpy = likelihood.log_prob(ys).sum(dim=0).mean(dim=0) # got the log likelihood\n",
    "\n",
    "        loss = -logpy + kl * kl_scheduler.val\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        kl_scheduler.step()\n",
    "\n",
    "        logpy_metric.step(logpy)\n",
    "        kl_metric.step(kl)\n",
    "        loss_metric.step(loss)\n",
    "\n",
    "        logging.info(\n",
    "            f'global_step: {global_step}, '\n",
    "            f'logpy: {logpy_metric.val:.3f}, '\n",
    "            f'kl: {kl_metric.val:.3f}, '\n",
    "            f'loss: {loss_metric.val:.3f}'\n",
    "        )\n",
    "    torch.save(\n",
    "        {'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'scheduler': scheduler.state_dict(),\n",
    "            'kl_scheduler': kl_scheduler},\n",
    "        os.path.join('./sim/', f'global_step_{global_step}.ckpt')\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74b55c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saved prior figure at: ./sim/prior.png\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]INFO:root:Saved figure at: ./sim/global_step_0.png\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_core/sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 0, logpy: -67.360, kl: 0.000, loss: 67.360\n",
      "  0%|          | 1/1000 [00:02<41:44,  2.51s/it]INFO:root:global_step: 1, logpy: -613.835, kl: 8.932, loss: 614.014\n",
      "  0%|          | 2/1000 [00:03<36:12,  2.18s/it]INFO:root:global_step: 2, logpy: -1265.473, kl: 21.580, loss: 1266.032\n",
      "  0%|          | 3/1000 [00:05<32:24,  1.95s/it]INFO:root:global_step: 3, logpy: -1322.173, kl: 21.551, loss: 1322.733\n",
      "  0%|          | 4/1000 [00:06<29:54,  1.80s/it]INFO:root:global_step: 4, logpy: -3054.785, kl: 133.533, loss: 3060.950\n",
      "  0%|          | 5/1000 [00:08<27:32,  1.66s/it]INFO:root:global_step: 5, logpy: -4048.048, kl: 166.413, loss: 4056.204\n",
      "  1%|          | 6/1000 [00:09<25:25,  1.53s/it]INFO:root:global_step: 6, logpy: -4231.069, kl: 167.273, loss: 4239.321\n",
      "  1%|          | 7/1000 [00:10<25:28,  1.54s/it]INFO:root:global_step: 7, logpy: -4321.950, kl: 169.084, loss: 4330.398\n",
      "  1%|          | 8/1000 [00:12<24:39,  1.49s/it]INFO:root:global_step: 8, logpy: -4467.759, kl: 172.573, loss: 4476.589\n",
      "  1%|          | 9/1000 [00:13<24:30,  1.48s/it]INFO:root:global_step: 9, logpy: -4542.071, kl: 175.644, loss: 4551.292\n",
      "  1%|          | 10/1000 [00:15<24:14,  1.47s/it]INFO:root:global_step: 10, logpy: -4572.104, kl: 177.287, loss: 4581.606\n",
      "  1%|          | 11/1000 [00:16<24:53,  1.51s/it]INFO:root:global_step: 11, logpy: -4622.610, kl: 177.592, loss: 4632.266\n",
      "  1%|          | 12/1000 [00:18<25:49,  1.57s/it]INFO:root:global_step: 12, logpy: -4689.870, kl: 177.648, loss: 4699.669\n",
      "  1%|▏         | 13/1000 [00:20<26:23,  1.60s/it]INFO:root:global_step: 13, logpy: -4741.496, kl: 178.554, loss: 4751.572\n",
      "  1%|▏         | 14/1000 [00:21<26:45,  1.63s/it]INFO:root:global_step: 14, logpy: -4779.090, kl: 180.843, loss: 4789.677\n",
      "  2%|▏         | 15/1000 [00:23<27:07,  1.65s/it]INFO:root:global_step: 15, logpy: -4823.106, kl: 183.509, loss: 4834.303\n",
      "  2%|▏         | 16/1000 [00:25<27:36,  1.68s/it]INFO:root:global_step: 16, logpy: -4863.257, kl: 185.037, loss: 4874.913\n",
      "  2%|▏         | 17/1000 [00:27<28:20,  1.73s/it]INFO:root:global_step: 17, logpy: -4884.755, kl: 185.644, loss: 4896.737\n",
      "  2%|▏         | 18/1000 [00:29<29:28,  1.80s/it]INFO:root:global_step: 18, logpy: -4884.054, kl: 184.908, loss: 4896.129\n",
      "  2%|▏         | 19/1000 [00:31<30:25,  1.86s/it]INFO:root:global_step: 19, logpy: -4861.321, kl: 184.087, loss: 4873.481\n",
      "  2%|▏         | 20/1000 [00:33<31:21,  1.92s/it]INFO:root:global_step: 20, logpy: -4849.910, kl: 183.730, loss: 4862.259\n",
      "  2%|▏         | 21/1000 [00:35<31:40,  1.94s/it]INFO:root:global_step: 21, logpy: -4861.834, kl: 183.797, loss: 4874.480\n",
      "  2%|▏         | 22/1000 [00:37<31:28,  1.93s/it]INFO:root:global_step: 22, logpy: -4877.262, kl: 183.835, loss: 4890.213\n",
      "  2%|▏         | 23/1000 [00:39<32:35,  2.00s/it]INFO:root:global_step: 23, logpy: -4880.067, kl: 183.806, loss: 4893.322\n",
      "  2%|▏         | 24/1000 [00:41<32:56,  2.03s/it]INFO:root:global_step: 24, logpy: -4857.813, kl: 183.513, loss: 4871.322\n",
      "  2%|▎         | 25/1000 [00:43<33:35,  2.07s/it]INFO:root:global_step: 25, logpy: -4816.431, kl: 183.192, loss: 4830.199\n",
      "  3%|▎         | 26/1000 [00:45<34:11,  2.11s/it]INFO:root:global_step: 26, logpy: -4791.561, kl: 183.917, loss: 4805.881\n",
      "  3%|▎         | 27/1000 [00:47<33:45,  2.08s/it]INFO:root:global_step: 27, logpy: -4777.990, kl: 185.039, loss: 4792.996\n",
      "  3%|▎         | 28/1000 [00:49<33:18,  2.06s/it]INFO:root:global_step: 28, logpy: -4762.526, kl: 186.248, loss: 4778.269\n",
      "  3%|▎         | 29/1000 [00:51<33:54,  2.10s/it]INFO:root:global_step: 29, logpy: -4735.934, kl: 187.519, loss: 4752.460\n",
      "  3%|▎         | 30/1000 [00:54<34:10,  2.11s/it]INFO:root:global_step: 30, logpy: -4700.704, kl: 188.453, loss: 4717.936\n",
      "  3%|▎         | 31/1000 [00:56<34:30,  2.14s/it]INFO:root:global_step: 31, logpy: -4668.312, kl: 188.570, loss: 4686.012\n",
      "  3%|▎         | 32/1000 [00:58<35:18,  2.19s/it]INFO:root:global_step: 32, logpy: -4637.648, kl: 188.534, loss: 4655.781\n",
      "  3%|▎         | 33/1000 [01:00<36:16,  2.25s/it]INFO:root:global_step: 33, logpy: -4608.799, kl: 188.248, loss: 4627.295\n",
      "  3%|▎         | 34/1000 [01:03<37:21,  2.32s/it]INFO:root:global_step: 34, logpy: -4581.090, kl: 187.991, loss: 4599.969\n",
      "  4%|▎         | 35/1000 [01:06<38:28,  2.39s/it]INFO:root:global_step: 35, logpy: -4550.462, kl: 187.935, loss: 4569.809\n",
      "  4%|▎         | 36/1000 [01:08<38:29,  2.40s/it]INFO:root:global_step: 36, logpy: -4511.404, kl: 187.878, loss: 4531.232\n",
      "  4%|▎         | 37/1000 [01:10<38:13,  2.38s/it]INFO:root:global_step: 37, logpy: -4471.597, kl: 188.408, loss: 4492.142\n",
      "  4%|▍         | 38/1000 [01:13<37:41,  2.35s/it]INFO:root:global_step: 38, logpy: -4437.139, kl: 188.985, loss: 4458.439\n",
      "  4%|▍         | 39/1000 [01:15<38:07,  2.38s/it]INFO:root:global_step: 39, logpy: -4405.484, kl: 189.712, loss: 4427.617\n",
      "  4%|▍         | 40/1000 [01:17<37:49,  2.36s/it]INFO:root:global_step: 40, logpy: -4373.089, kl: 190.363, loss: 4396.045\n",
      "  4%|▍         | 41/1000 [01:20<37:40,  2.36s/it]INFO:root:global_step: 41, logpy: -4337.276, kl: 190.566, loss: 4360.887\n",
      "  4%|▍         | 42/1000 [01:22<38:18,  2.40s/it]INFO:root:global_step: 42, logpy: -4297.891, kl: 190.753, loss: 4322.167\n",
      "  4%|▍         | 43/1000 [01:24<37:57,  2.38s/it]INFO:root:global_step: 43, logpy: -4260.369, kl: 190.860, loss: 4285.288\n",
      "  4%|▍         | 44/1000 [01:27<38:08,  2.39s/it]INFO:root:global_step: 44, logpy: -4225.814, kl: 190.878, loss: 4251.351\n",
      "  4%|▍         | 45/1000 [01:29<38:20,  2.41s/it]INFO:root:global_step: 45, logpy: -4192.418, kl: 191.087, loss: 4218.674\n",
      "  5%|▍         | 46/1000 [01:32<37:41,  2.37s/it]INFO:root:global_step: 46, logpy: -4158.540, kl: 190.932, loss: 4185.358\n",
      "  5%|▍         | 47/1000 [01:34<37:09,  2.34s/it]INFO:root:global_step: 47, logpy: -4122.441, kl: 190.921, loss: 4149.903\n",
      "  5%|▍         | 48/1000 [01:36<36:47,  2.32s/it]INFO:root:global_step: 48, logpy: -4084.549, kl: 191.330, loss: 4112.872\n",
      "  5%|▍         | 49/1000 [01:39<38:31,  2.43s/it]INFO:root:global_step: 49, logpy: -4048.235, kl: 191.729, loss: 4077.431\n",
      "  5%|▌         | 50/1000 [01:41<38:10,  2.41s/it]INFO:root:Saved figure at: ./sim/global_step_50.png\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_core/sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 50, logpy: -4013.632, kl: 191.936, loss: 4043.619\n",
      "  5%|▌         | 51/1000 [01:45<43:21,  2.74s/it]INFO:root:global_step: 51, logpy: -3978.778, kl: 192.417, loss: 4009.714\n",
      "  5%|▌         | 52/1000 [01:48<44:28,  2.82s/it]INFO:root:global_step: 52, logpy: -3942.067, kl: 192.679, loss: 3973.851\n",
      "  5%|▌         | 53/1000 [01:51<45:18,  2.87s/it]INFO:root:global_step: 53, logpy: -3904.840, kl: 192.862, loss: 3937.446\n",
      "  5%|▌         | 54/1000 [01:53<43:34,  2.76s/it]INFO:root:global_step: 54, logpy: -3869.205, kl: 193.007, loss: 3902.626\n",
      "  6%|▌         | 55/1000 [01:56<43:14,  2.75s/it]INFO:root:global_step: 55, logpy: -3834.194, kl: 193.318, loss: 3868.536\n",
      "  6%|▌         | 56/1000 [01:59<42:39,  2.71s/it]INFO:root:global_step: 56, logpy: -3798.971, kl: 193.494, loss: 3834.171\n",
      "  6%|▌         | 57/1000 [02:01<41:25,  2.64s/it]INFO:root:global_step: 57, logpy: -3763.260, kl: 193.815, loss: 3799.417\n",
      "  6%|▌         | 58/1000 [02:04<40:42,  2.59s/it]INFO:root:global_step: 58, logpy: -3727.917, kl: 194.518, loss: 3765.271\n",
      "  6%|▌         | 59/1000 [02:06<40:18,  2.57s/it]INFO:root:global_step: 59, logpy: -3693.337, kl: 194.835, loss: 3731.674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 60/1000 [02:09<40:51,  2.61s/it]INFO:root:global_step: 60, logpy: -3659.163, kl: 195.354, loss: 3698.622\n",
      "  6%|▌         | 61/1000 [02:11<39:42,  2.54s/it]INFO:root:global_step: 61, logpy: -3624.363, kl: 195.462, loss: 3664.706\n",
      "  6%|▌         | 62/1000 [02:14<38:59,  2.49s/it]INFO:root:global_step: 62, logpy: -3589.429, kl: 195.922, loss: 3630.889\n",
      "  6%|▋         | 63/1000 [02:16<38:16,  2.45s/it]INFO:root:global_step: 63, logpy: -3555.285, kl: 196.282, loss: 3597.815\n",
      "  6%|▋         | 64/1000 [02:18<38:17,  2.46s/it]INFO:root:global_step: 64, logpy: -3521.320, kl: 196.439, loss: 3564.802\n",
      "  6%|▋         | 65/1000 [02:21<38:54,  2.50s/it]INFO:root:global_step: 65, logpy: -3487.169, kl: 196.370, loss: 3531.468\n",
      "  7%|▋         | 66/1000 [02:24<39:45,  2.55s/it]INFO:root:global_step: 66, logpy: -3453.404, kl: 196.684, loss: 3498.785\n",
      "  7%|▋         | 67/1000 [02:26<39:08,  2.52s/it]INFO:root:global_step: 67, logpy: -3420.192, kl: 196.884, loss: 3466.593\n",
      "  7%|▋         | 68/1000 [02:29<38:50,  2.50s/it]INFO:root:global_step: 68, logpy: -3387.253, kl: 197.451, loss: 3434.940\n",
      "  7%|▋         | 69/1000 [02:31<39:37,  2.55s/it]INFO:root:global_step: 69, logpy: -3354.273, kl: 197.570, loss: 3402.949\n",
      "  7%|▋         | 70/1000 [02:34<41:33,  2.68s/it]INFO:root:global_step: 70, logpy: -3321.528, kl: 197.743, loss: 3371.242\n",
      "  7%|▋         | 71/1000 [02:37<41:01,  2.65s/it]INFO:root:global_step: 71, logpy: -3289.193, kl: 197.981, loss: 3340.006\n",
      "  7%|▋         | 72/1000 [02:39<40:12,  2.60s/it]INFO:root:global_step: 72, logpy: -3256.889, kl: 198.098, loss: 3308.723\n",
      "  7%|▋         | 73/1000 [02:42<42:23,  2.74s/it]INFO:root:global_step: 73, logpy: -3224.639, kl: 198.515, loss: 3277.730\n",
      "  7%|▋         | 74/1000 [02:45<42:55,  2.78s/it]INFO:root:global_step: 74, logpy: -3192.698, kl: 198.861, loss: 3247.006\n",
      "  8%|▊         | 75/1000 [02:48<42:19,  2.75s/it]INFO:root:global_step: 75, logpy: -3161.141, kl: 199.168, loss: 3216.651\n",
      "  8%|▊         | 76/1000 [02:50<41:44,  2.71s/it]INFO:root:global_step: 76, logpy: -3129.810, kl: 199.425, loss: 3186.497\n",
      "  8%|▊         | 77/1000 [02:53<40:43,  2.65s/it]INFO:root:global_step: 77, logpy: -3098.673, kl: 199.484, loss: 3156.395\n",
      "  8%|▊         | 78/1000 [02:55<39:35,  2.58s/it]INFO:root:global_step: 78, logpy: -3067.933, kl: 199.528, loss: 3126.687\n",
      "  8%|▊         | 79/1000 [02:58<40:07,  2.61s/it]INFO:root:global_step: 79, logpy: -3037.407, kl: 199.422, loss: 3097.085\n",
      "  8%|▊         | 80/1000 [03:01<40:09,  2.62s/it]INFO:root:global_step: 80, logpy: -3007.003, kl: 199.486, loss: 3067.752\n",
      "  8%|▊         | 81/1000 [03:03<39:56,  2.61s/it]INFO:root:global_step: 81, logpy: -2976.858, kl: 199.597, loss: 3038.726\n",
      "  8%|▊         | 82/1000 [03:06<41:02,  2.68s/it]INFO:root:global_step: 82, logpy: -2947.009, kl: 199.533, loss: 3009.863\n",
      "  8%|▊         | 83/1000 [03:09<39:42,  2.60s/it]INFO:root:global_step: 83, logpy: -2917.433, kl: 199.498, loss: 2981.304\n",
      "  8%|▊         | 84/1000 [03:11<40:31,  2.65s/it]INFO:root:global_step: 84, logpy: -2888.116, kl: 199.709, loss: 2953.224\n",
      "  8%|▊         | 85/1000 [03:14<39:51,  2.61s/it]INFO:root:global_step: 85, logpy: -2859.081, kl: 199.777, loss: 2925.314\n",
      "  9%|▊         | 86/1000 [03:16<39:06,  2.57s/it]INFO:root:global_step: 86, logpy: -2830.357, kl: 199.647, loss: 2897.552\n",
      "  9%|▊         | 87/1000 [03:19<38:29,  2.53s/it]INFO:root:global_step: 87, logpy: -2801.864, kl: 199.758, loss: 2870.242\n",
      "  9%|▉         | 88/1000 [03:21<38:32,  2.54s/it]INFO:root:global_step: 88, logpy: -2773.600, kl: 199.867, loss: 2843.168\n",
      "  9%|▉         | 89/1000 [03:24<38:36,  2.54s/it]INFO:root:global_step: 89, logpy: -2745.598, kl: 199.983, loss: 2816.375\n",
      "  9%|▉         | 90/1000 [03:27<39:10,  2.58s/it]INFO:root:global_step: 90, logpy: -2717.838, kl: 199.941, loss: 2789.688\n",
      "  9%|▉         | 91/1000 [03:29<38:45,  2.56s/it]INFO:root:global_step: 91, logpy: -2690.319, kl: 199.901, loss: 2763.253\n",
      "  9%|▉         | 92/1000 [03:32<38:39,  2.55s/it]INFO:root:global_step: 92, logpy: -2663.095, kl: 199.889, loss: 2737.148\n",
      "  9%|▉         | 93/1000 [03:34<38:09,  2.52s/it]INFO:root:global_step: 93, logpy: -2636.111, kl: 199.908, loss: 2711.320\n",
      "  9%|▉         | 94/1000 [03:37<38:27,  2.55s/it]INFO:root:global_step: 94, logpy: -2609.402, kl: 200.012, loss: 2685.857\n",
      " 10%|▉         | 95/1000 [03:39<38:08,  2.53s/it]INFO:root:global_step: 95, logpy: -2582.909, kl: 199.770, loss: 2660.288\n",
      " 10%|▉         | 96/1000 [03:42<37:52,  2.51s/it]INFO:root:global_step: 96, logpy: -2556.682, kl: 199.755, loss: 2635.209\n",
      " 10%|▉         | 97/1000 [03:44<37:44,  2.51s/it]INFO:root:global_step: 97, logpy: -2530.683, kl: 199.671, loss: 2610.301\n",
      " 10%|▉         | 98/1000 [03:47<38:15,  2.55s/it]INFO:root:global_step: 98, logpy: -2504.918, kl: 199.185, loss: 2585.235\n",
      " 10%|▉         | 99/1000 [03:49<38:13,  2.55s/it]INFO:root:global_step: 99, logpy: -2479.465, kl: 199.243, loss: 2561.030\n",
      " 10%|█         | 100/1000 [03:52<38:14,  2.55s/it]INFO:root:Saved figure at: ./sim/global_step_100.png\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_core/sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 100, logpy: -2454.239, kl: 199.090, loss: 2536.826\n",
      " 10%|█         | 101/1000 [03:56<44:48,  2.99s/it]INFO:root:global_step: 101, logpy: -2429.312, kl: 199.040, loss: 2513.014\n",
      " 10%|█         | 102/1000 [03:59<43:59,  2.94s/it]INFO:root:global_step: 102, logpy: -2404.519, kl: 198.835, loss: 2489.170\n",
      " 10%|█         | 103/1000 [04:01<43:20,  2.90s/it]INFO:root:global_step: 103, logpy: -2380.007, kl: 198.591, loss: 2465.556\n",
      " 10%|█         | 104/1000 [04:04<42:07,  2.82s/it]INFO:root:global_step: 104, logpy: -2355.763, kl: 198.682, loss: 2442.533\n",
      " 10%|█         | 105/1000 [04:07<40:38,  2.73s/it]INFO:root:global_step: 105, logpy: -2331.728, kl: 198.544, loss: 2419.480\n",
      " 11%|█         | 106/1000 [04:09<39:46,  2.67s/it]INFO:root:global_step: 106, logpy: -2307.903, kl: 198.163, loss: 2396.381\n",
      " 11%|█         | 107/1000 [04:12<39:12,  2.63s/it]INFO:root:global_step: 107, logpy: -2284.340, kl: 197.914, loss: 2373.666\n",
      " 11%|█         | 108/1000 [04:14<38:50,  2.61s/it]INFO:root:global_step: 108, logpy: -2260.975, kl: 197.557, loss: 2351.029\n",
      " 11%|█         | 109/1000 [04:17<38:04,  2.56s/it]INFO:root:global_step: 109, logpy: -2237.839, kl: 197.059, loss: 2328.472\n",
      " 11%|█         | 110/1000 [04:19<38:01,  2.56s/it]INFO:root:global_step: 110, logpy: -2214.927, kl: 196.826, loss: 2306.391\n",
      " 11%|█         | 111/1000 [04:22<38:18,  2.59s/it]INFO:root:global_step: 111, logpy: -2192.223, kl: 196.370, loss: 2284.285\n",
      " 11%|█         | 112/1000 [04:24<37:44,  2.55s/it]INFO:root:global_step: 112, logpy: -2169.795, kl: 196.132, loss: 2262.661\n",
      " 11%|█▏        | 113/1000 [04:27<36:53,  2.50s/it]INFO:root:global_step: 113, logpy: -2147.521, kl: 195.786, loss: 2241.073\n",
      " 11%|█▏        | 114/1000 [04:29<36:57,  2.50s/it]INFO:root:global_step: 114, logpy: -2125.530, kl: 195.699, loss: 2220.018\n",
      " 12%|█▏        | 115/1000 [04:32<37:04,  2.51s/it]INFO:root:global_step: 115, logpy: -2103.690, kl: 195.331, loss: 2198.822\n",
      " 12%|█▏        | 116/1000 [04:34<36:42,  2.49s/it]INFO:root:global_step: 116, logpy: -2082.067, kl: 194.996, loss: 2177.867\n",
      " 12%|█▏        | 117/1000 [04:37<36:59,  2.51s/it]INFO:root:global_step: 117, logpy: -2060.691, kl: 194.849, loss: 2157.336\n",
      " 12%|█▏        | 118/1000 [04:39<36:47,  2.50s/it]INFO:root:global_step: 118, logpy: -2039.490, kl: 194.517, loss: 2136.784\n",
      " 12%|█▏        | 119/1000 [04:42<37:44,  2.57s/it]INFO:root:global_step: 119, logpy: -2018.552, kl: 194.258, loss: 2116.559\n",
      " 12%|█▏        | 120/1000 [04:44<37:08,  2.53s/it]INFO:root:global_step: 120, logpy: -1997.806, kl: 193.972, loss: 2096.489\n",
      " 12%|█▏        | 121/1000 [04:47<36:57,  2.52s/it]INFO:root:global_step: 121, logpy: -1977.216, kl: 193.715, loss: 2076.596\n",
      " 12%|█▏        | 122/1000 [04:49<36:41,  2.51s/it]INFO:root:global_step: 122, logpy: -1956.835, kl: 193.244, loss: 2056.687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 123/1000 [04:52<36:37,  2.51s/it]INFO:root:global_step: 123, logpy: -1936.649, kl: 192.931, loss: 2037.122\n",
      " 12%|█▏        | 124/1000 [04:54<36:25,  2.49s/it]INFO:root:global_step: 124, logpy: -1916.693, kl: 192.677, loss: 2017.837\n",
      " 12%|█▎        | 125/1000 [04:57<36:40,  2.51s/it]INFO:root:global_step: 125, logpy: -1896.876, kl: 192.194, loss: 1998.452\n",
      " 13%|█▎        | 126/1000 [05:00<36:49,  2.53s/it]INFO:root:global_step: 126, logpy: -1877.259, kl: 191.703, loss: 1979.250\n",
      " 13%|█▎        | 127/1000 [05:02<37:42,  2.59s/it]INFO:root:global_step: 127, logpy: -1857.813, kl: 191.209, loss: 1960.208\n",
      " 13%|█▎        | 128/1000 [05:05<37:57,  2.61s/it]INFO:root:global_step: 128, logpy: -1838.596, kl: 190.768, loss: 1941.437\n",
      " 13%|█▎        | 129/1000 [05:07<37:33,  2.59s/it]INFO:root:global_step: 129, logpy: -1819.545, kl: 190.415, loss: 1922.912\n",
      " 13%|█▎        | 130/1000 [05:10<37:02,  2.55s/it]INFO:root:global_step: 130, logpy: -1800.731, kl: 190.114, loss: 1904.669\n",
      " 13%|█▎        | 131/1000 [05:13<37:22,  2.58s/it]INFO:root:global_step: 131, logpy: -1782.111, kl: 190.026, loss: 1886.822\n",
      " 13%|█▎        | 132/1000 [05:15<36:54,  2.55s/it]INFO:root:global_step: 132, logpy: -1763.614, kl: 189.621, loss: 1868.773\n",
      " 13%|█▎        | 133/1000 [05:18<36:27,  2.52s/it]INFO:root:global_step: 133, logpy: -1745.305, kl: 189.105, loss: 1850.792\n",
      " 13%|█▎        | 134/1000 [05:20<36:23,  2.52s/it]INFO:root:global_step: 134, logpy: -1727.214, kl: 188.808, loss: 1833.241\n",
      " 14%|█▎        | 135/1000 [05:22<36:01,  2.50s/it]INFO:root:global_step: 135, logpy: -1709.227, kl: 188.361, loss: 1815.634\n",
      " 14%|█▎        | 136/1000 [05:25<35:52,  2.49s/it]INFO:root:global_step: 136, logpy: -1691.416, kl: 187.961, loss: 1798.242\n",
      " 14%|█▎        | 137/1000 [05:27<35:26,  2.46s/it]INFO:root:global_step: 137, logpy: -1673.836, kl: 187.580, loss: 1781.094\n",
      " 14%|█▍        | 138/1000 [05:30<35:35,  2.48s/it]INFO:root:global_step: 138, logpy: -1656.370, kl: 187.133, loss: 1763.984\n",
      " 14%|█▍        | 139/1000 [05:32<35:39,  2.48s/it]INFO:root:global_step: 139, logpy: -1639.110, kl: 186.851, loss: 1747.237\n",
      " 14%|█▍        | 140/1000 [05:35<35:16,  2.46s/it]INFO:root:global_step: 140, logpy: -1621.994, kl: 186.624, loss: 1730.682\n",
      " 14%|█▍        | 141/1000 [05:37<35:11,  2.46s/it]INFO:root:global_step: 141, logpy: -1605.099, kl: 186.432, loss: 1714.374\n",
      " 14%|█▍        | 142/1000 [05:40<35:14,  2.46s/it]INFO:root:global_step: 142, logpy: -1588.287, kl: 185.902, loss: 1697.803\n",
      " 14%|█▍        | 143/1000 [05:43<37:14,  2.61s/it]INFO:root:global_step: 143, logpy: -1571.656, kl: 185.650, loss: 1681.684\n",
      " 14%|█▍        | 144/1000 [05:45<36:37,  2.57s/it]INFO:root:global_step: 144, logpy: -1555.180, kl: 185.147, loss: 1665.461\n",
      " 14%|█▍        | 145/1000 [05:48<36:04,  2.53s/it]INFO:root:global_step: 145, logpy: -1538.894, kl: 184.822, loss: 1649.599\n",
      " 15%|█▍        | 146/1000 [05:50<36:02,  2.53s/it]INFO:root:global_step: 146, logpy: -1522.701, kl: 184.247, loss: 1633.572\n",
      " 15%|█▍        | 147/1000 [05:53<36:31,  2.57s/it]INFO:root:global_step: 147, logpy: -1506.717, kl: 183.752, loss: 1617.827\n",
      " 15%|█▍        | 148/1000 [05:55<36:43,  2.59s/it]INFO:root:global_step: 148, logpy: -1490.896, kl: 183.346, loss: 1602.326\n",
      " 15%|█▍        | 149/1000 [05:58<35:52,  2.53s/it]INFO:root:global_step: 149, logpy: -1475.169, kl: 182.879, loss: 1586.852\n",
      " 15%|█▌        | 150/1000 [06:00<35:27,  2.50s/it]INFO:root:Saved figure at: ./sim/global_step_150.png\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_core/sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 150, logpy: -1459.621, kl: 182.416, loss: 1571.552\n",
      " 15%|█▌        | 151/1000 [06:04<42:00,  2.97s/it]INFO:root:global_step: 151, logpy: -1444.245, kl: 181.946, loss: 1556.411\n",
      " 15%|█▌        | 152/1000 [06:07<39:49,  2.82s/it]INFO:root:global_step: 152, logpy: -1429.021, kl: 181.661, loss: 1541.601\n",
      " 15%|█▌        | 153/1000 [06:09<38:17,  2.71s/it]INFO:root:global_step: 153, logpy: -1414.008, kl: 181.207, loss: 1526.824\n",
      " 15%|█▌        | 154/1000 [06:12<37:32,  2.66s/it]INFO:root:global_step: 154, logpy: -1399.050, kl: 180.691, loss: 1512.034\n",
      " 16%|█▌        | 155/1000 [06:14<36:55,  2.62s/it]INFO:root:global_step: 155, logpy: -1384.255, kl: 180.236, loss: 1497.461\n",
      " 16%|█▌        | 156/1000 [06:17<36:18,  2.58s/it]INFO:root:global_step: 156, logpy: -1369.597, kl: 179.826, loss: 1483.064\n",
      " 16%|█▌        | 157/1000 [06:19<36:05,  2.57s/it]INFO:root:global_step: 157, logpy: -1355.159, kl: 179.458, loss: 1468.921\n",
      " 16%|█▌        | 158/1000 [06:22<36:30,  2.60s/it]INFO:root:global_step: 158, logpy: -1340.788, kl: 179.069, loss: 1454.818\n",
      " 16%|█▌        | 159/1000 [06:24<35:53,  2.56s/it]INFO:root:global_step: 159, logpy: -1326.589, kl: 178.683, loss: 1440.883\n",
      " 16%|█▌        | 160/1000 [06:27<35:50,  2.56s/it]INFO:root:global_step: 160, logpy: -1312.521, kl: 178.419, loss: 1427.195\n",
      " 16%|█▌        | 161/1000 [06:30<35:40,  2.55s/it]INFO:root:global_step: 161, logpy: -1298.583, kl: 178.103, loss: 1413.579\n",
      " 16%|█▌        | 162/1000 [06:32<34:58,  2.50s/it]INFO:root:global_step: 162, logpy: -1284.717, kl: 177.503, loss: 1399.743\n",
      " 16%|█▋        | 163/1000 [06:35<37:38,  2.70s/it]INFO:root:global_step: 163, logpy: -1271.016, kl: 177.085, loss: 1386.250\n",
      " 16%|█▋        | 164/1000 [06:38<36:55,  2.65s/it]INFO:root:global_step: 164, logpy: -1257.460, kl: 176.818, loss: 1373.045\n",
      " 16%|█▋        | 165/1000 [06:40<35:57,  2.58s/it]INFO:root:global_step: 165, logpy: -1243.999, kl: 176.272, loss: 1359.650\n",
      " 17%|█▋        | 166/1000 [06:43<35:43,  2.57s/it]INFO:root:global_step: 166, logpy: -1230.719, kl: 175.771, loss: 1346.475\n",
      " 17%|█▋        | 167/1000 [06:45<35:10,  2.53s/it]INFO:root:global_step: 167, logpy: -1217.580, kl: 175.381, loss: 1333.546\n",
      " 17%|█▋        | 168/1000 [06:47<34:50,  2.51s/it]INFO:root:global_step: 168, logpy: -1204.562, kl: 175.030, loss: 1320.772\n",
      " 17%|█▋        | 169/1000 [06:50<34:32,  2.49s/it]INFO:root:global_step: 169, logpy: -1191.652, kl: 174.470, loss: 1307.890\n",
      " 17%|█▋        | 170/1000 [06:53<35:02,  2.53s/it]INFO:root:global_step: 170, logpy: -1178.876, kl: 174.062, loss: 1295.288\n",
      " 17%|█▋        | 171/1000 [06:55<34:48,  2.52s/it]INFO:root:global_step: 171, logpy: -1166.206, kl: 173.735, loss: 1282.867\n",
      " 17%|█▋        | 172/1000 [06:58<34:27,  2.50s/it]INFO:root:global_step: 172, logpy: -1153.666, kl: 173.320, loss: 1270.484\n",
      " 17%|█▋        | 173/1000 [07:00<34:58,  2.54s/it]INFO:root:global_step: 173, logpy: -1141.187, kl: 172.772, loss: 1258.021\n",
      " 17%|█▋        | 174/1000 [07:03<34:54,  2.54s/it]INFO:root:global_step: 174, logpy: -1128.856, kl: 172.293, loss: 1245.770\n",
      " 18%|█▊        | 175/1000 [07:05<35:14,  2.56s/it]INFO:root:global_step: 175, logpy: -1116.616, kl: 171.769, loss: 1233.560\n",
      " 18%|█▊        | 176/1000 [07:08<35:23,  2.58s/it]INFO:root:global_step: 176, logpy: -1104.527, kl: 171.400, loss: 1221.651\n",
      " 18%|█▊        | 177/1000 [07:10<34:52,  2.54s/it]INFO:root:global_step: 177, logpy: -1092.521, kl: 170.898, loss: 1209.685\n",
      " 18%|█▊        | 178/1000 [07:13<34:30,  2.52s/it]INFO:root:global_step: 178, logpy: -1080.667, kl: 170.369, loss: 1197.840\n",
      " 18%|█▊        | 179/1000 [07:16<35:09,  2.57s/it]INFO:root:global_step: 179, logpy: -1068.955, kl: 169.856, loss: 1186.147\n",
      " 18%|█▊        | 180/1000 [07:18<34:52,  2.55s/it]INFO:root:global_step: 180, logpy: -1057.313, kl: 169.362, loss: 1174.538\n",
      " 18%|█▊        | 181/1000 [07:21<34:55,  2.56s/it]INFO:root:global_step: 181, logpy: -1045.788, kl: 168.804, loss: 1162.975\n",
      " 18%|█▊        | 182/1000 [07:23<35:47,  2.63s/it]INFO:root:global_step: 182, logpy: -1034.379, kl: 168.383, loss: 1151.662\n",
      " 18%|█▊        | 183/1000 [07:26<36:12,  2.66s/it]INFO:root:global_step: 183, logpy: -1023.124, kl: 167.972, loss: 1140.507\n",
      " 18%|█▊        | 184/1000 [07:29<35:33,  2.61s/it]INFO:root:global_step: 184, logpy: -1011.912, kl: 167.465, loss: 1129.293\n",
      " 18%|█▊        | 185/1000 [07:31<34:50,  2.56s/it]INFO:root:global_step: 185, logpy: -1000.854, kl: 167.036, loss: 1118.308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 186/1000 [07:34<34:55,  2.57s/it]INFO:root:global_step: 186, logpy: -989.889, kl: 166.648, loss: 1107.451\n",
      " 19%|█▊        | 187/1000 [07:36<34:28,  2.54s/it]INFO:root:global_step: 187, logpy: -978.933, kl: 165.993, loss: 1096.331\n",
      " 19%|█▉        | 188/1000 [07:39<34:27,  2.55s/it]INFO:root:global_step: 188, logpy: -968.150, kl: 165.523, loss: 1085.564\n",
      " 19%|█▉        | 189/1000 [07:41<34:43,  2.57s/it]INFO:root:global_step: 189, logpy: -957.444, kl: 165.035, loss: 1074.851\n",
      " 19%|█▉        | 190/1000 [07:44<34:53,  2.58s/it]INFO:root:global_step: 190, logpy: -946.890, kl: 164.615, loss: 1064.353\n",
      " 19%|█▉        | 191/1000 [07:46<34:40,  2.57s/it]INFO:root:global_step: 191, logpy: -936.452, kl: 164.257, loss: 1054.029\n",
      " 19%|█▉        | 192/1000 [07:49<34:08,  2.54s/it]INFO:root:global_step: 192, logpy: -926.053, kl: 163.798, loss: 1043.637\n",
      " 19%|█▉        | 193/1000 [07:52<34:20,  2.55s/it]INFO:root:global_step: 193, logpy: -915.730, kl: 163.227, loss: 1033.205\n",
      " 19%|█▉        | 194/1000 [07:54<34:13,  2.55s/it]INFO:root:global_step: 194, logpy: -905.570, kl: 162.819, loss: 1023.094\n",
      " 20%|█▉        | 195/1000 [07:57<33:50,  2.52s/it]INFO:root:global_step: 195, logpy: -895.479, kl: 162.401, loss: 1013.039\n",
      " 20%|█▉        | 196/1000 [07:59<33:44,  2.52s/it]INFO:root:global_step: 196, logpy: -885.487, kl: 161.994, loss: 1003.088\n",
      " 20%|█▉        | 197/1000 [08:02<34:23,  2.57s/it]INFO:root:global_step: 197, logpy: -875.609, kl: 161.581, loss: 993.241\n",
      " 20%|█▉        | 198/1000 [08:05<35:37,  2.66s/it]INFO:root:global_step: 198, logpy: -865.834, kl: 161.193, loss: 983.517\n",
      " 20%|█▉        | 199/1000 [08:07<35:42,  2.67s/it]INFO:root:global_step: 199, logpy: -856.095, kl: 160.640, loss: 973.661\n",
      " 20%|██        | 200/1000 [08:10<35:49,  2.69s/it]INFO:root:Saved figure at: ./sim/global_step_200.png\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_core/sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 200, logpy: -846.440, kl: 160.165, loss: 963.961\n",
      " 20%|██        | 201/1000 [08:14<40:12,  3.02s/it]INFO:root:global_step: 201, logpy: -836.894, kl: 159.699, loss: 954.377\n",
      " 20%|██        | 202/1000 [08:16<38:38,  2.91s/it]INFO:root:global_step: 202, logpy: -827.443, kl: 159.242, loss: 944.890\n",
      " 20%|██        | 203/1000 [08:19<37:35,  2.83s/it]INFO:root:global_step: 203, logpy: -818.165, kl: 159.087, loss: 935.875\n",
      " 20%|██        | 204/1000 [08:22<36:03,  2.72s/it]INFO:root:global_step: 204, logpy: -808.890, kl: 158.659, loss: 926.586\n",
      " 20%|██        | 205/1000 [08:24<36:11,  2.73s/it]INFO:root:global_step: 205, logpy: -799.716, kl: 158.217, loss: 917.380\n",
      " 21%|██        | 206/1000 [08:27<35:43,  2.70s/it]INFO:root:global_step: 206, logpy: -790.603, kl: 157.760, loss: 908.215\n",
      " 21%|██        | 207/1000 [08:30<35:50,  2.71s/it]INFO:root:global_step: 207, logpy: -781.617, kl: 157.262, loss: 899.132\n",
      " 21%|██        | 208/1000 [08:32<34:55,  2.65s/it]INFO:root:global_step: 208, logpy: -772.719, kl: 156.835, loss: 890.205\n",
      " 21%|██        | 209/1000 [08:35<34:30,  2.62s/it]INFO:root:global_step: 209, logpy: -763.855, kl: 156.397, loss: 881.296\n",
      " 21%|██        | 210/1000 [08:37<34:13,  2.60s/it]INFO:root:global_step: 210, logpy: -755.071, kl: 155.911, loss: 872.416\n",
      " 21%|██        | 211/1000 [08:40<34:38,  2.63s/it]INFO:root:global_step: 211, logpy: -746.416, kl: 155.545, loss: 863.781\n",
      " 21%|██        | 212/1000 [08:43<34:13,  2.61s/it]INFO:root:global_step: 212, logpy: -737.830, kl: 155.079, loss: 855.110\n",
      " 21%|██▏       | 213/1000 [08:45<33:38,  2.56s/it]INFO:root:global_step: 213, logpy: -729.352, kl: 154.700, loss: 846.632\n",
      " 21%|██▏       | 214/1000 [08:48<33:35,  2.56s/it]INFO:root:global_step: 214, logpy: -720.940, kl: 154.356, loss: 838.250\n",
      " 22%|██▏       | 215/1000 [08:50<32:47,  2.51s/it]INFO:root:global_step: 215, logpy: -712.588, kl: 153.956, loss: 829.867\n",
      " 22%|██▏       | 216/1000 [08:52<32:31,  2.49s/it]INFO:root:global_step: 216, logpy: -704.333, kl: 153.528, loss: 821.551\n",
      " 22%|██▏       | 217/1000 [08:55<32:17,  2.47s/it]INFO:root:global_step: 217, logpy: -696.146, kl: 153.061, loss: 813.261\n",
      " 22%|██▏       | 218/1000 [08:58<33:14,  2.55s/it]INFO:root:global_step: 218, logpy: -688.020, kl: 152.678, loss: 805.112\n",
      " 22%|██▏       | 219/1000 [09:00<34:07,  2.62s/it]INFO:root:global_step: 219, logpy: -679.968, kl: 152.255, loss: 796.992\n",
      " 22%|██▏       | 220/1000 [09:03<33:47,  2.60s/it]INFO:root:global_step: 220, logpy: -671.939, kl: 151.754, loss: 788.815\n",
      " 22%|██▏       | 221/1000 [09:06<34:27,  2.65s/it]INFO:root:global_step: 221, logpy: -664.073, kl: 151.344, loss: 780.887\n",
      " 22%|██▏       | 222/1000 [09:08<34:32,  2.66s/it]INFO:root:global_step: 222, logpy: -656.269, kl: 150.971, loss: 773.056\n",
      " 22%|██▏       | 223/1000 [09:11<34:06,  2.63s/it]INFO:root:global_step: 223, logpy: -648.502, kl: 150.644, loss: 765.303\n",
      " 22%|██▏       | 224/1000 [09:13<33:38,  2.60s/it]INFO:root:global_step: 224, logpy: -640.796, kl: 150.141, loss: 757.433\n",
      " 22%|██▎       | 225/1000 [09:16<33:26,  2.59s/it]INFO:root:global_step: 225, logpy: -633.196, kl: 149.710, loss: 749.736\n",
      " 23%|██▎       | 226/1000 [09:19<33:39,  2.61s/it]INFO:root:global_step: 226, logpy: -625.688, kl: 149.325, loss: 742.175\n",
      " 23%|██▎       | 227/1000 [09:21<33:26,  2.60s/it]INFO:root:global_step: 227, logpy: -618.219, kl: 148.905, loss: 734.614\n",
      " 23%|██▎       | 228/1000 [09:24<33:28,  2.60s/it]INFO:root:global_step: 228, logpy: -610.761, kl: 148.458, loss: 727.035\n",
      " 23%|██▎       | 229/1000 [09:26<33:06,  2.58s/it]INFO:root:global_step: 229, logpy: -603.418, kl: 148.041, loss: 719.597\n",
      " 23%|██▎       | 230/1000 [09:29<33:08,  2.58s/it]INFO:root:global_step: 230, logpy: -596.144, kl: 147.629, loss: 712.229\n",
      " 23%|██▎       | 231/1000 [09:32<33:17,  2.60s/it]INFO:root:global_step: 231, logpy: -588.900, kl: 147.236, loss: 704.908\n",
      " 23%|██▎       | 232/1000 [09:34<32:50,  2.57s/it]INFO:root:global_step: 232, logpy: -581.774, kl: 146.848, loss: 697.707\n",
      " 23%|██▎       | 233/1000 [09:37<32:38,  2.55s/it]INFO:root:global_step: 233, logpy: -574.735, kl: 146.476, loss: 690.604\n",
      " 23%|██▎       | 234/1000 [09:39<32:27,  2.54s/it]INFO:root:global_step: 234, logpy: -567.702, kl: 146.012, loss: 683.414\n",
      " 24%|██▎       | 235/1000 [09:42<34:49,  2.73s/it]INFO:root:global_step: 235, logpy: -560.734, kl: 145.549, loss: 676.285\n",
      " 24%|██▎       | 236/1000 [09:45<35:30,  2.79s/it]INFO:root:global_step: 236, logpy: -553.841, kl: 145.128, loss: 669.271\n",
      " 24%|██▎       | 237/1000 [09:48<34:32,  2.72s/it]INFO:root:global_step: 237, logpy: -547.017, kl: 144.657, loss: 662.273\n",
      " 24%|██▍       | 238/1000 [09:50<33:34,  2.64s/it]INFO:root:global_step: 238, logpy: -540.221, kl: 144.256, loss: 655.370\n",
      " 24%|██▍       | 239/1000 [09:53<33:02,  2.61s/it]INFO:root:global_step: 239, logpy: -533.503, kl: 143.866, loss: 648.553\n",
      " 24%|██▍       | 240/1000 [09:55<32:52,  2.59s/it]INFO:root:global_step: 240, logpy: -526.861, kl: 143.362, loss: 641.695\n",
      " 24%|██▍       | 241/1000 [09:58<32:38,  2.58s/it]INFO:root:global_step: 241, logpy: -520.301, kl: 142.933, loss: 634.992\n",
      " 24%|██▍       | 242/1000 [10:00<32:11,  2.55s/it]INFO:root:global_step: 242, logpy: -513.802, kl: 142.546, loss: 628.388\n",
      " 24%|██▍       | 243/1000 [10:03<31:44,  2.52s/it]INFO:root:global_step: 243, logpy: -507.323, kl: 142.139, loss: 621.782\n",
      " 24%|██▍       | 244/1000 [10:05<32:02,  2.54s/it]INFO:root:global_step: 244, logpy: -500.901, kl: 141.709, loss: 615.207\n",
      " 24%|██▍       | 245/1000 [10:08<31:42,  2.52s/it]INFO:root:global_step: 245, logpy: -494.576, kl: 141.365, loss: 608.812\n",
      " 25%|██▍       | 246/1000 [10:10<31:20,  2.49s/it]INFO:root:global_step: 246, logpy: -488.305, kl: 140.981, loss: 602.429\n",
      " 25%|██▍       | 247/1000 [10:13<31:21,  2.50s/it]INFO:root:global_step: 247, logpy: -482.091, kl: 140.635, loss: 596.136\n",
      " 25%|██▍       | 248/1000 [10:15<31:33,  2.52s/it]INFO:root:global_step: 248, logpy: -475.879, kl: 140.166, loss: 589.721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 249/1000 [10:18<31:10,  2.49s/it]INFO:root:global_step: 249, logpy: -469.747, kl: 139.729, loss: 583.416\n",
      " 25%|██▌       | 250/1000 [10:20<31:40,  2.53s/it]INFO:root:Saved figure at: ./sim/global_step_250.png\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_core/sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 250, logpy: -463.686, kl: 139.408, loss: 577.294\n",
      " 25%|██▌       | 251/1000 [10:24<35:48,  2.87s/it]INFO:root:global_step: 251, logpy: -457.709, kl: 139.090, loss: 571.257\n",
      " 25%|██▌       | 252/1000 [10:27<35:30,  2.85s/it]INFO:root:global_step: 252, logpy: -451.810, kl: 138.804, loss: 565.327\n",
      " 25%|██▌       | 253/1000 [10:29<33:47,  2.71s/it]INFO:root:global_step: 253, logpy: -445.910, kl: 138.401, loss: 559.277\n",
      " 25%|██▌       | 254/1000 [10:32<32:26,  2.61s/it]INFO:root:global_step: 254, logpy: -440.109, kl: 138.045, loss: 553.371\n",
      " 26%|██▌       | 255/1000 [10:34<31:29,  2.54s/it]INFO:root:global_step: 255, logpy: -434.285, kl: 137.671, loss: 547.420\n",
      " 26%|██▌       | 256/1000 [10:37<31:55,  2.57s/it]INFO:root:global_step: 256, logpy: -428.503, kl: 137.268, loss: 541.482\n",
      " 26%|██▌       | 257/1000 [10:39<31:40,  2.56s/it]INFO:root:global_step: 257, logpy: -422.816, kl: 136.931, loss: 535.699\n",
      " 26%|██▌       | 258/1000 [10:42<31:21,  2.54s/it]INFO:root:global_step: 258, logpy: -417.155, kl: 136.578, loss: 529.927\n",
      " 26%|██▌       | 259/1000 [10:44<31:04,  2.52s/it]INFO:root:global_step: 259, logpy: -411.543, kl: 136.171, loss: 524.146\n",
      " 26%|██▌       | 260/1000 [10:47<30:48,  2.50s/it]INFO:root:global_step: 260, logpy: -406.009, kl: 135.770, loss: 518.446\n",
      " 26%|██▌       | 261/1000 [10:49<31:11,  2.53s/it]INFO:root:global_step: 261, logpy: -400.454, kl: 135.304, loss: 512.659\n",
      " 26%|██▌       | 262/1000 [10:52<30:45,  2.50s/it]INFO:root:global_step: 262, logpy: -395.008, kl: 134.936, loss: 507.076\n",
      " 26%|██▋       | 263/1000 [10:54<30:29,  2.48s/it]INFO:root:global_step: 263, logpy: -389.542, kl: 134.461, loss: 501.364\n",
      " 26%|██▋       | 264/1000 [10:57<30:10,  2.46s/it]INFO:root:global_step: 264, logpy: -384.136, kl: 133.992, loss: 495.715\n",
      " 26%|██▋       | 265/1000 [10:59<30:01,  2.45s/it]INFO:root:global_step: 265, logpy: -378.802, kl: 133.549, loss: 490.162\n",
      " 27%|██▋       | 266/1000 [11:01<30:00,  2.45s/it]INFO:root:global_step: 266, logpy: -373.528, kl: 133.138, loss: 484.699\n",
      " 27%|██▋       | 267/1000 [11:04<30:03,  2.46s/it]INFO:root:global_step: 267, logpy: -368.308, kl: 132.849, loss: 479.409\n",
      " 27%|██▋       | 268/1000 [11:07<31:19,  2.57s/it]INFO:root:global_step: 268, logpy: -363.091, kl: 132.425, loss: 473.985\n",
      " 27%|██▋       | 269/1000 [11:09<32:05,  2.63s/it]INFO:root:global_step: 269, logpy: -357.939, kl: 132.018, loss: 468.642\n",
      " 27%|██▋       | 270/1000 [11:12<31:24,  2.58s/it]INFO:root:global_step: 270, logpy: -352.823, kl: 131.555, loss: 463.277\n",
      " 27%|██▋       | 271/1000 [11:15<31:18,  2.58s/it]INFO:root:global_step: 271, logpy: -347.825, kl: 131.260, loss: 458.194\n",
      " 27%|██▋       | 272/1000 [11:17<30:45,  2.53s/it]INFO:root:global_step: 272, logpy: -342.850, kl: 130.817, loss: 452.985\n",
      " 27%|██▋       | 273/1000 [11:20<30:54,  2.55s/it]INFO:root:global_step: 273, logpy: -337.878, kl: 130.442, loss: 447.845\n",
      " 27%|██▋       | 274/1000 [11:22<31:39,  2.62s/it]INFO:root:global_step: 274, logpy: -332.967, kl: 130.046, loss: 442.743\n",
      " 28%|██▊       | 275/1000 [11:25<31:08,  2.58s/it]INFO:root:global_step: 275, logpy: -328.072, kl: 129.699, loss: 437.703\n",
      " 28%|██▊       | 276/1000 [11:27<30:42,  2.55s/it]INFO:root:global_step: 276, logpy: -323.279, kl: 129.334, loss: 432.746\n",
      " 28%|██▊       | 277/1000 [11:30<30:21,  2.52s/it]INFO:root:global_step: 277, logpy: -318.487, kl: 128.984, loss: 427.802\n",
      " 28%|██▊       | 278/1000 [11:32<30:33,  2.54s/it]INFO:root:global_step: 278, logpy: -313.751, kl: 128.767, loss: 423.046\n",
      " 28%|██▊       | 279/1000 [11:35<30:49,  2.57s/it]INFO:root:global_step: 279, logpy: -309.059, kl: 128.379, loss: 418.162\n",
      " 28%|██▊       | 280/1000 [11:38<31:09,  2.60s/it]INFO:root:global_step: 280, logpy: -304.386, kl: 127.943, loss: 413.245\n",
      " 28%|██▊       | 281/1000 [11:40<30:42,  2.56s/it]INFO:root:global_step: 281, logpy: -299.835, kl: 127.740, loss: 408.682\n",
      " 28%|██▊       | 282/1000 [11:43<31:34,  2.64s/it]INFO:root:global_step: 282, logpy: -295.255, kl: 127.457, loss: 404.008\n",
      " 28%|██▊       | 283/1000 [11:46<32:41,  2.74s/it]INFO:root:global_step: 283, logpy: -290.743, kl: 127.124, loss: 399.350\n",
      " 28%|██▊       | 284/1000 [11:49<32:59,  2.76s/it]INFO:root:global_step: 284, logpy: -286.199, kl: 126.724, loss: 394.591\n",
      " 28%|██▊       | 285/1000 [11:51<31:39,  2.66s/it]INFO:root:global_step: 285, logpy: -281.707, kl: 126.321, loss: 389.879\n",
      " 29%|██▊       | 286/1000 [11:54<31:05,  2.61s/it]INFO:root:global_step: 286, logpy: -277.287, kl: 125.974, loss: 385.294\n",
      " 29%|██▊       | 287/1000 [11:56<30:26,  2.56s/it]INFO:root:global_step: 287, logpy: -272.887, kl: 125.559, loss: 380.659\n",
      " 29%|██▉       | 288/1000 [11:59<30:52,  2.60s/it]INFO:root:global_step: 288, logpy: -268.568, kl: 125.304, loss: 376.262\n",
      " 29%|██▉       | 289/1000 [12:01<30:01,  2.53s/it]INFO:root:global_step: 289, logpy: -264.263, kl: 124.983, loss: 371.812\n",
      " 29%|██▉       | 290/1000 [12:04<29:37,  2.50s/it]INFO:root:global_step: 290, logpy: -260.043, kl: 124.706, loss: 367.490\n",
      " 29%|██▉       | 291/1000 [12:06<29:20,  2.48s/it]INFO:root:global_step: 291, logpy: -255.746, kl: 124.282, loss: 362.941\n",
      " 29%|██▉       | 292/1000 [12:08<29:05,  2.46s/it]INFO:root:global_step: 292, logpy: -251.513, kl: 123.888, loss: 358.485\n",
      " 29%|██▉       | 293/1000 [12:11<28:49,  2.45s/it]INFO:root:global_step: 293, logpy: -247.340, kl: 123.521, loss: 354.114\n",
      " 29%|██▉       | 294/1000 [12:13<29:10,  2.48s/it]INFO:root:global_step: 294, logpy: -243.201, kl: 123.117, loss: 349.739\n",
      " 30%|██▉       | 295/1000 [12:16<29:01,  2.47s/it]INFO:root:global_step: 295, logpy: -239.066, kl: 122.795, loss: 345.448\n",
      " 30%|██▉       | 296/1000 [12:18<29:18,  2.50s/it]INFO:root:global_step: 296, logpy: -235.027, kl: 122.528, loss: 341.306\n",
      " 30%|██▉       | 297/1000 [12:21<29:41,  2.53s/it]INFO:root:global_step: 297, logpy: -231.005, kl: 122.211, loss: 337.129\n",
      " 30%|██▉       | 298/1000 [12:23<29:15,  2.50s/it]INFO:root:global_step: 298, logpy: -226.965, kl: 121.859, loss: 332.899\n",
      " 30%|██▉       | 299/1000 [12:26<29:11,  2.50s/it]INFO:root:global_step: 299, logpy: -222.966, kl: 121.562, loss: 328.761\n",
      " 30%|███       | 300/1000 [12:28<29:23,  2.52s/it]INFO:root:Saved figure at: ./sim/global_step_300.png\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_core/sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 300, logpy: -218.989, kl: 121.132, loss: 324.512\n",
      " 30%|███       | 301/1000 [12:32<33:00,  2.83s/it]INFO:root:global_step: 301, logpy: -215.049, kl: 120.776, loss: 320.372\n",
      " 30%|███       | 302/1000 [12:35<31:59,  2.75s/it]INFO:root:global_step: 302, logpy: -211.160, kl: 120.460, loss: 316.322\n",
      " 30%|███       | 303/1000 [12:37<32:12,  2.77s/it]INFO:root:global_step: 303, logpy: -207.345, kl: 120.136, loss: 312.336\n",
      " 30%|███       | 304/1000 [12:40<31:40,  2.73s/it]INFO:root:global_step: 304, logpy: -203.552, kl: 119.760, loss: 308.318\n",
      " 30%|███       | 305/1000 [12:43<30:50,  2.66s/it]INFO:root:global_step: 305, logpy: -199.787, kl: 119.513, loss: 304.456\n",
      " 31%|███       | 306/1000 [12:45<30:01,  2.60s/it]INFO:root:global_step: 306, logpy: -196.009, kl: 119.206, loss: 300.519\n",
      " 31%|███       | 307/1000 [12:47<29:34,  2.56s/it]INFO:root:global_step: 307, logpy: -192.293, kl: 118.861, loss: 296.606\n",
      " 31%|███       | 308/1000 [12:50<29:11,  2.53s/it]INFO:root:global_step: 308, logpy: -188.613, kl: 118.508, loss: 292.718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 309/1000 [12:53<29:15,  2.54s/it]INFO:root:global_step: 309, logpy: -184.961, kl: 118.178, loss: 288.880\n",
      " 31%|███       | 310/1000 [12:55<28:47,  2.50s/it]INFO:root:global_step: 310, logpy: -181.313, kl: 117.800, loss: 284.997\n",
      " 31%|███       | 311/1000 [12:57<28:52,  2.51s/it]INFO:root:global_step: 311, logpy: -177.715, kl: 117.518, loss: 281.257\n",
      " 31%|███       | 312/1000 [13:00<28:33,  2.49s/it]INFO:root:global_step: 312, logpy: -174.191, kl: 117.217, loss: 277.572\n",
      " 31%|███▏      | 313/1000 [13:02<28:09,  2.46s/it]INFO:root:global_step: 313, logpy: -170.662, kl: 116.930, loss: 273.895\n",
      " 31%|███▏      | 314/1000 [13:05<28:08,  2.46s/it]INFO:root:global_step: 314, logpy: -167.132, kl: 116.651, loss: 270.224\n",
      " 32%|███▏      | 315/1000 [13:07<28:25,  2.49s/it]INFO:root:global_step: 315, logpy: -163.636, kl: 116.335, loss: 266.546\n",
      " 32%|███▏      | 316/1000 [13:10<28:39,  2.51s/it]INFO:root:global_step: 316, logpy: -160.173, kl: 116.043, loss: 262.926\n",
      " 32%|███▏      | 317/1000 [13:12<28:09,  2.47s/it]INFO:root:global_step: 317, logpy: -156.771, kl: 115.784, loss: 259.397\n",
      " 32%|███▏      | 318/1000 [13:15<27:36,  2.43s/it]INFO:root:global_step: 318, logpy: -153.324, kl: 115.389, loss: 255.687\n",
      " 32%|███▏      | 319/1000 [13:17<27:45,  2.45s/it]INFO:root:global_step: 319, logpy: -149.944, kl: 115.142, loss: 252.190\n",
      " 32%|███▏      | 320/1000 [13:20<28:31,  2.52s/it]INFO:root:global_step: 320, logpy: -146.609, kl: 114.863, loss: 248.705\n",
      " 32%|███▏      | 321/1000 [13:22<28:48,  2.55s/it]INFO:root:global_step: 321, logpy: -143.305, kl: 114.590, loss: 245.256\n",
      " 32%|███▏      | 322/1000 [13:25<28:54,  2.56s/it]INFO:root:global_step: 322, logpy: -139.991, kl: 114.268, loss: 241.747\n",
      " 32%|███▏      | 323/1000 [13:28<28:55,  2.56s/it]INFO:root:global_step: 323, logpy: -136.764, kl: 113.997, loss: 238.374\n",
      " 32%|███▏      | 324/1000 [13:30<28:50,  2.56s/it]INFO:root:global_step: 324, logpy: -133.521, kl: 113.739, loss: 234.997\n",
      " 32%|███▎      | 325/1000 [13:33<28:54,  2.57s/it]INFO:root:global_step: 325, logpy: -130.287, kl: 113.455, loss: 231.600\n",
      " 33%|███▎      | 326/1000 [13:35<28:35,  2.54s/it]INFO:root:global_step: 326, logpy: -127.114, kl: 113.229, loss: 228.324\n",
      " 33%|███▎      | 327/1000 [13:38<28:13,  2.52s/it]INFO:root:global_step: 327, logpy: -123.938, kl: 112.960, loss: 224.998\n",
      " 33%|███▎      | 328/1000 [13:40<27:34,  2.46s/it]INFO:root:global_step: 328, logpy: -120.838, kl: 112.716, loss: 221.774\n",
      " 33%|███▎      | 329/1000 [13:42<27:21,  2.45s/it]INFO:root:global_step: 329, logpy: -117.751, kl: 112.470, loss: 218.558\n",
      " 33%|███▎      | 330/1000 [13:45<27:02,  2.42s/it]INFO:root:global_step: 330, logpy: -114.704, kl: 112.210, loss: 215.369\n",
      " 33%|███▎      | 331/1000 [13:47<27:00,  2.42s/it]INFO:root:global_step: 331, logpy: -111.643, kl: 111.876, loss: 212.089\n",
      " 33%|███▎      | 332/1000 [13:49<26:38,  2.39s/it]INFO:root:global_step: 332, logpy: -108.621, kl: 111.608, loss: 208.913\n",
      " 33%|███▎      | 333/1000 [13:52<26:57,  2.42s/it]INFO:root:global_step: 333, logpy: -105.599, kl: 111.318, loss: 205.714\n",
      " 33%|███▎      | 334/1000 [13:54<27:15,  2.46s/it]INFO:root:global_step: 334, logpy: -102.637, kl: 111.123, loss: 202.669\n",
      " 34%|███▎      | 335/1000 [13:58<29:42,  2.68s/it]INFO:root:global_step: 335, logpy: -99.687, kl: 110.918, loss: 199.624\n",
      " 34%|███▎      | 336/1000 [14:00<29:28,  2.66s/it]INFO:root:global_step: 336, logpy: -96.737, kl: 110.570, loss: 196.437\n",
      " 34%|███▎      | 337/1000 [14:03<30:52,  2.79s/it]INFO:root:global_step: 337, logpy: -93.815, kl: 110.285, loss: 193.338\n",
      " 34%|███▍      | 338/1000 [14:07<34:09,  3.10s/it]INFO:root:global_step: 338, logpy: -90.912, kl: 109.998, loss: 190.255\n",
      " 34%|███▍      | 339/1000 [14:11<35:43,  3.24s/it]INFO:root:global_step: 339, logpy: -88.070, kl: 109.821, loss: 187.344\n",
      " 34%|███▍      | 340/1000 [14:14<36:18,  3.30s/it]INFO:root:global_step: 340, logpy: -85.208, kl: 109.504, loss: 184.270\n",
      " 34%|███▍      | 341/1000 [14:17<35:49,  3.26s/it]INFO:root:global_step: 341, logpy: -82.451, kl: 109.255, loss: 181.368\n",
      " 34%|███▍      | 342/1000 [14:21<36:02,  3.29s/it]INFO:root:global_step: 342, logpy: -79.647, kl: 108.985, loss: 178.398\n",
      " 34%|███▍      | 343/1000 [14:24<37:05,  3.39s/it]INFO:root:global_step: 343, logpy: -76.819, kl: 108.636, loss: 175.323\n",
      " 34%|███▍      | 344/1000 [14:28<37:46,  3.45s/it]INFO:root:global_step: 344, logpy: -74.057, kl: 108.393, loss: 172.419\n",
      " 34%|███▍      | 345/1000 [14:31<37:27,  3.43s/it]INFO:root:global_step: 345, logpy: -71.343, kl: 108.074, loss: 169.488\n",
      " 35%|███▍      | 346/1000 [14:35<39:03,  3.58s/it]INFO:root:global_step: 346, logpy: -68.593, kl: 107.765, loss: 166.527\n",
      " 35%|███▍      | 347/1000 [14:40<41:22,  3.80s/it]INFO:root:global_step: 347, logpy: -65.916, kl: 107.556, loss: 163.740\n",
      " 35%|███▍      | 348/1000 [14:44<41:58,  3.86s/it]INFO:root:global_step: 348, logpy: -63.238, kl: 107.279, loss: 160.881\n",
      " 35%|███▍      | 349/1000 [14:48<42:03,  3.88s/it]INFO:root:global_step: 349, logpy: -60.594, kl: 106.986, loss: 158.041\n",
      " 35%|███▌      | 350/1000 [14:52<43:20,  4.00s/it]INFO:root:Saved figure at: ./sim/global_step_350.png\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_core/sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 350, logpy: -57.989, kl: 106.720, loss: 155.265\n",
      " 35%|███▌      | 351/1000 [15:00<57:31,  5.32s/it]INFO:root:global_step: 351, logpy: -55.383, kl: 106.471, loss: 152.505\n",
      " 35%|███▌      | 352/1000 [15:04<52:23,  4.85s/it]INFO:root:global_step: 352, logpy: -52.827, kl: 106.253, loss: 149.824\n",
      " 35%|███▌      | 353/1000 [15:07<46:33,  4.32s/it]INFO:root:global_step: 353, logpy: -50.285, kl: 106.026, loss: 147.148\n",
      " 35%|███▌      | 354/1000 [15:10<41:18,  3.84s/it]INFO:root:global_step: 354, logpy: -47.758, kl: 105.827, loss: 144.514\n",
      " 36%|███▌      | 355/1000 [15:12<36:41,  3.41s/it]INFO:root:global_step: 355, logpy: -45.273, kl: 105.613, loss: 141.906\n",
      " 36%|███▌      | 356/1000 [15:15<33:15,  3.10s/it]INFO:root:global_step: 356, logpy: -42.785, kl: 105.377, loss: 139.271\n",
      " 36%|███▌      | 357/1000 [15:17<31:22,  2.93s/it]INFO:root:global_step: 357, logpy: -40.282, kl: 105.113, loss: 136.594\n",
      " 36%|███▌      | 358/1000 [15:19<29:31,  2.76s/it]INFO:root:global_step: 358, logpy: -37.876, kl: 104.888, loss: 134.051\n",
      " 36%|███▌      | 359/1000 [15:22<28:16,  2.65s/it]INFO:root:global_step: 359, logpy: -35.438, kl: 104.612, loss: 131.422\n",
      " 36%|███▌      | 360/1000 [15:24<27:13,  2.55s/it]INFO:root:global_step: 360, logpy: -33.007, kl: 104.352, loss: 128.818\n",
      " 36%|███▌      | 361/1000 [15:27<27:44,  2.60s/it]INFO:root:global_step: 361, logpy: -30.637, kl: 104.148, loss: 126.329\n",
      " 36%|███▌      | 362/1000 [15:29<27:17,  2.57s/it]INFO:root:global_step: 362, logpy: -28.259, kl: 103.873, loss: 123.761\n",
      " 36%|███▋      | 363/1000 [15:33<29:08,  2.74s/it]INFO:root:global_step: 363, logpy: -25.925, kl: 103.720, loss: 121.359\n",
      " 36%|███▋      | 364/1000 [15:36<30:14,  2.85s/it]INFO:root:global_step: 364, logpy: -23.645, kl: 103.555, loss: 118.996\n",
      " 36%|███▋      | 365/1000 [15:39<32:58,  3.12s/it]INFO:root:global_step: 365, logpy: -21.356, kl: 103.344, loss: 116.577\n",
      " 37%|███▋      | 366/1000 [15:43<34:27,  3.26s/it]INFO:root:global_step: 366, logpy: -19.009, kl: 103.037, loss: 114.005\n",
      " 37%|███▋      | 367/1000 [15:47<35:35,  3.37s/it]INFO:root:global_step: 367, logpy: -16.775, kl: 102.917, loss: 111.732\n",
      " 37%|███▋      | 368/1000 [15:50<35:35,  3.38s/it]INFO:root:global_step: 368, logpy: -14.551, kl: 102.707, loss: 109.378\n",
      " 37%|███▋      | 369/1000 [15:53<35:20,  3.36s/it]INFO:root:global_step: 369, logpy: -12.285, kl: 102.408, loss: 106.891\n",
      " 37%|███▋      | 370/1000 [15:57<36:22,  3.46s/it]INFO:root:global_step: 370, logpy: -10.025, kl: 102.125, loss: 104.426\n",
      " 37%|███▋      | 371/1000 [16:01<37:22,  3.56s/it]INFO:root:global_step: 371, logpy: -7.787, kl: 101.894, loss: 102.035\n",
      " 37%|███▋      | 372/1000 [16:04<36:27,  3.48s/it]INFO:root:global_step: 372, logpy: -5.670, kl: 101.820, loss: 99.919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 373/1000 [16:07<35:47,  3.42s/it]INFO:root:global_step: 373, logpy: -3.542, kl: 101.603, loss: 97.651\n",
      " 37%|███▋      | 374/1000 [16:11<35:21,  3.39s/it]INFO:root:global_step: 374, logpy: -1.396, kl: 101.367, loss: 95.342\n",
      " 38%|███▊      | 375/1000 [16:14<35:02,  3.36s/it]INFO:root:global_step: 375, logpy: 0.707, kl: 101.195, loss: 93.143\n",
      " 38%|███▊      | 376/1000 [16:17<33:17,  3.20s/it]INFO:root:global_step: 376, logpy: 2.848, kl: 100.967, loss: 90.847\n",
      " 38%|███▊      | 377/1000 [16:21<36:06,  3.48s/it]INFO:root:global_step: 377, logpy: 4.965, kl: 100.799, loss: 88.635\n",
      " 38%|███▊      | 378/1000 [16:24<36:08,  3.49s/it]INFO:root:global_step: 378, logpy: 6.990, kl: 100.642, loss: 86.525\n",
      " 38%|███▊      | 379/1000 [16:28<35:38,  3.44s/it]INFO:root:global_step: 379, logpy: 9.031, kl: 100.433, loss: 84.346\n",
      " 38%|███▊      | 380/1000 [16:32<36:41,  3.55s/it]INFO:root:global_step: 380, logpy: 11.023, kl: 100.337, loss: 82.328\n",
      " 38%|███▊      | 381/1000 [16:35<36:52,  3.57s/it]INFO:root:global_step: 381, logpy: 13.035, kl: 100.164, loss: 80.213\n",
      " 38%|███▊      | 382/1000 [16:40<38:59,  3.78s/it]INFO:root:global_step: 382, logpy: 15.045, kl: 100.005, loss: 78.114\n",
      " 38%|███▊      | 383/1000 [16:44<39:43,  3.86s/it]INFO:root:global_step: 383, logpy: 17.046, kl: 99.848, loss: 76.024\n",
      " 38%|███▊      | 384/1000 [16:47<39:43,  3.87s/it]INFO:root:global_step: 384, logpy: 19.036, kl: 99.663, loss: 73.917\n",
      " 38%|███▊      | 385/1000 [16:51<38:23,  3.75s/it]INFO:root:global_step: 385, logpy: 21.027, kl: 99.461, loss: 71.790\n",
      " 39%|███▊      | 386/1000 [16:54<37:20,  3.65s/it]INFO:root:global_step: 386, logpy: 23.001, kl: 99.348, loss: 69.770\n",
      " 39%|███▊      | 387/1000 [16:58<37:16,  3.65s/it]INFO:root:global_step: 387, logpy: 24.947, kl: 99.171, loss: 67.713\n",
      " 39%|███▉      | 388/1000 [17:02<37:15,  3.65s/it]INFO:root:global_step: 388, logpy: 26.878, kl: 99.013, loss: 65.689\n",
      " 39%|███▉      | 389/1000 [17:05<36:33,  3.59s/it]INFO:root:global_step: 389, logpy: 28.763, kl: 98.961, loss: 63.817\n",
      " 39%|███▉      | 390/1000 [17:08<33:47,  3.32s/it]INFO:root:global_step: 390, logpy: 30.628, kl: 98.811, loss: 61.865\n",
      " 39%|███▉      | 391/1000 [17:10<30:54,  3.04s/it]INFO:root:global_step: 391, logpy: 32.513, kl: 98.621, loss: 59.854\n",
      " 39%|███▉      | 392/1000 [17:13<29:07,  2.87s/it]INFO:root:global_step: 392, logpy: 34.330, kl: 98.540, loss: 58.018\n",
      " 39%|███▉      | 393/1000 [17:15<27:24,  2.71s/it]INFO:root:global_step: 393, logpy: 36.155, kl: 98.366, loss: 56.081\n",
      " 39%|███▉      | 394/1000 [17:17<26:13,  2.60s/it]INFO:root:global_step: 394, logpy: 37.997, kl: 98.181, loss: 54.116\n",
      " 40%|███▉      | 395/1000 [17:20<25:44,  2.55s/it]INFO:root:global_step: 395, logpy: 39.803, kl: 98.065, loss: 52.254\n",
      " 40%|███▉      | 396/1000 [17:22<25:10,  2.50s/it]INFO:root:global_step: 396, logpy: 41.593, kl: 97.956, loss: 50.415\n",
      " 40%|███▉      | 397/1000 [17:25<24:48,  2.47s/it]INFO:root:global_step: 397, logpy: 43.301, kl: 97.826, loss: 48.636\n",
      " 40%|███▉      | 398/1000 [17:27<24:39,  2.46s/it]INFO:root:global_step: 398, logpy: 45.042, kl: 97.618, loss: 46.746\n",
      " 40%|███▉      | 399/1000 [17:29<24:45,  2.47s/it]INFO:root:global_step: 399, logpy: 46.765, kl: 97.405, loss: 44.869\n",
      " 40%|████      | 400/1000 [17:32<24:30,  2.45s/it]INFO:root:Saved figure at: ./sim/global_step_400.png\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_core/sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 400, logpy: 48.452, kl: 97.191, loss: 43.025\n",
      " 40%|████      | 401/1000 [17:36<29:02,  2.91s/it]INFO:root:global_step: 401, logpy: 50.045, kl: 97.098, loss: 41.397\n",
      " 40%|████      | 402/1000 [17:38<27:27,  2.75s/it]INFO:root:global_step: 402, logpy: 51.656, kl: 96.955, loss: 39.699\n",
      " 40%|████      | 403/1000 [17:41<26:55,  2.71s/it]INFO:root:global_step: 403, logpy: 53.337, kl: 96.831, loss: 37.950\n",
      " 40%|████      | 404/1000 [17:44<28:11,  2.84s/it]INFO:root:global_step: 404, logpy: 55.064, kl: 96.672, loss: 36.119\n",
      " 40%|████      | 405/1000 [17:47<28:48,  2.91s/it]INFO:root:global_step: 405, logpy: 56.724, kl: 96.518, loss: 34.361\n",
      " 41%|████      | 406/1000 [17:50<28:50,  2.91s/it]INFO:root:global_step: 406, logpy: 58.313, kl: 96.401, loss: 32.709\n",
      " 41%|████      | 407/1000 [17:53<27:44,  2.81s/it]INFO:root:global_step: 407, logpy: 59.779, kl: 96.242, loss: 31.138\n",
      " 41%|████      | 408/1000 [17:55<26:42,  2.71s/it]INFO:root:global_step: 408, logpy: 61.084, kl: 96.118, loss: 29.761\n",
      " 41%|████      | 409/1000 [17:57<25:46,  2.62s/it]INFO:root:global_step: 409, logpy: 62.264, kl: 95.886, loss: 28.403\n",
      " 41%|████      | 410/1000 [18:00<25:23,  2.58s/it]INFO:root:global_step: 410, logpy: 63.491, kl: 95.778, loss: 27.119\n",
      " 41%|████      | 411/1000 [18:02<24:56,  2.54s/it]INFO:root:global_step: 411, logpy: 64.731, kl: 95.670, loss: 25.824\n",
      " 41%|████      | 412/1000 [18:05<24:36,  2.51s/it]INFO:root:global_step: 412, logpy: 66.200, kl: 95.543, loss: 24.279\n",
      " 41%|████▏     | 413/1000 [18:07<24:16,  2.48s/it]INFO:root:global_step: 413, logpy: 67.746, kl: 95.374, loss: 22.614\n",
      " 41%|████▏     | 414/1000 [18:10<23:58,  2.45s/it]INFO:root:global_step: 414, logpy: 69.371, kl: 95.228, loss: 20.894\n",
      " 42%|████▏     | 415/1000 [18:12<24:20,  2.50s/it]INFO:root:global_step: 415, logpy: 70.899, kl: 95.157, loss: 19.343\n",
      " 42%|████▏     | 416/1000 [18:14<23:38,  2.43s/it]INFO:root:global_step: 416, logpy: 72.397, kl: 95.045, loss: 17.783\n",
      " 42%|████▏     | 417/1000 [18:17<23:36,  2.43s/it]INFO:root:global_step: 417, logpy: 73.798, kl: 94.967, loss: 16.352\n",
      " 42%|████▏     | 418/1000 [18:19<23:24,  2.41s/it]INFO:root:global_step: 418, logpy: 75.189, kl: 94.763, loss: 14.807\n",
      " 42%|████▏     | 419/1000 [18:22<23:42,  2.45s/it]INFO:root:global_step: 419, logpy: 76.568, kl: 94.596, loss: 13.308\n",
      " 42%|████▏     | 420/1000 [18:24<23:28,  2.43s/it]INFO:root:global_step: 420, logpy: 77.982, kl: 94.446, loss: 11.791\n",
      " 42%|████▏     | 421/1000 [18:27<23:30,  2.44s/it]INFO:root:global_step: 421, logpy: 79.457, kl: 94.332, loss: 10.249\n",
      " 42%|████▏     | 422/1000 [18:29<23:10,  2.41s/it]INFO:root:global_step: 422, logpy: 80.934, kl: 94.164, loss: 8.650\n",
      " 42%|████▏     | 423/1000 [18:31<23:16,  2.42s/it]INFO:root:global_step: 423, logpy: 82.406, kl: 94.083, loss: 7.143\n",
      " 42%|████▏     | 424/1000 [18:34<23:07,  2.41s/it]INFO:root:global_step: 424, logpy: 83.795, kl: 93.948, loss: 5.664\n",
      " 42%|████▎     | 425/1000 [18:36<23:00,  2.40s/it]INFO:root:global_step: 425, logpy: 84.976, kl: 93.765, loss: 4.344\n",
      " 43%|████▎     | 426/1000 [18:39<22:55,  2.40s/it]INFO:root:global_step: 426, logpy: 85.976, kl: 93.592, loss: 3.217\n",
      " 43%|████▎     | 427/1000 [18:41<23:04,  2.42s/it]INFO:root:global_step: 427, logpy: 86.671, kl: 93.482, loss: 2.455\n",
      " 43%|████▎     | 428/1000 [18:44<23:17,  2.44s/it]INFO:root:global_step: 428, logpy: 87.461, kl: 93.356, loss: 1.583\n",
      " 43%|████▎     | 429/1000 [18:46<23:28,  2.47s/it]INFO:root:global_step: 429, logpy: 88.389, kl: 93.235, loss: 0.577\n",
      " 43%|████▎     | 430/1000 [18:49<23:22,  2.46s/it]INFO:root:global_step: 430, logpy: 89.633, kl: 93.161, loss: -0.698\n",
      " 43%|████▎     | 431/1000 [18:51<23:11,  2.45s/it]INFO:root:global_step: 431, logpy: 91.036, kl: 93.044, loss: -2.176\n",
      " 43%|████▎     | 432/1000 [18:53<23:21,  2.47s/it]INFO:root:global_step: 432, logpy: 92.439, kl: 92.965, loss: -3.616\n",
      " 43%|████▎     | 433/1000 [18:56<23:35,  2.50s/it]INFO:root:global_step: 433, logpy: 93.604, kl: 92.885, loss: -4.819\n",
      " 43%|████▎     | 434/1000 [18:58<23:30,  2.49s/it]INFO:root:global_step: 434, logpy: 94.520, kl: 92.801, loss: -5.779\n",
      " 44%|████▎     | 435/1000 [19:01<23:56,  2.54s/it]INFO:root:global_step: 435, logpy: 95.305, kl: 92.611, loss: -6.713\n",
      " 44%|████▎     | 436/1000 [19:04<23:51,  2.54s/it]INFO:root:global_step: 436, logpy: 95.969, kl: 92.434, loss: -7.515\n",
      " 44%|████▎     | 437/1000 [19:06<23:34,  2.51s/it]INFO:root:global_step: 437, logpy: 96.871, kl: 92.267, loss: -8.544\n",
      " 44%|████▍     | 438/1000 [19:09<23:11,  2.48s/it]INFO:root:global_step: 438, logpy: 98.035, kl: 92.119, loss: -9.815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 439/1000 [19:11<23:10,  2.48s/it]INFO:root:global_step: 439, logpy: 99.342, kl: 91.981, loss: -11.222\n",
      " 44%|████▍     | 440/1000 [19:13<22:55,  2.46s/it]INFO:root:global_step: 440, logpy: 100.705, kl: 91.800, loss: -12.727\n",
      " 44%|████▍     | 441/1000 [19:16<22:47,  2.45s/it]INFO:root:global_step: 441, logpy: 101.896, kl: 91.694, loss: -13.986\n",
      " 44%|████▍     | 442/1000 [19:18<22:37,  2.43s/it]INFO:root:global_step: 442, logpy: 102.820, kl: 91.621, loss: -14.945\n",
      " 44%|████▍     | 443/1000 [19:21<22:33,  2.43s/it]INFO:root:global_step: 443, logpy: 103.445, kl: 91.497, loss: -15.657\n",
      " 44%|████▍     | 444/1000 [19:23<22:22,  2.41s/it]INFO:root:global_step: 444, logpy: 104.016, kl: 91.354, loss: -16.334\n",
      " 44%|████▍     | 445/1000 [19:25<22:02,  2.38s/it]INFO:root:global_step: 445, logpy: 104.573, kl: 91.295, loss: -16.912\n",
      " 45%|████▍     | 446/1000 [19:28<21:59,  2.38s/it]INFO:root:global_step: 446, logpy: 105.694, kl: 91.201, loss: -18.091\n",
      " 45%|████▍     | 447/1000 [19:30<21:54,  2.38s/it]INFO:root:global_step: 447, logpy: 106.987, kl: 91.102, loss: -19.447\n",
      " 45%|████▍     | 448/1000 [19:33<22:36,  2.46s/it]INFO:root:global_step: 448, logpy: 108.151, kl: 90.952, loss: -20.726\n",
      " 45%|████▍     | 449/1000 [19:35<22:39,  2.47s/it]INFO:root:global_step: 449, logpy: 109.069, kl: 90.857, loss: -21.704\n",
      " 45%|████▌     | 450/1000 [19:38<22:20,  2.44s/it]INFO:root:Saved figure at: ./sim/global_step_450.png\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_core/sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 450, logpy: 109.648, kl: 90.794, loss: -22.311\n",
      " 45%|████▌     | 451/1000 [19:41<25:38,  2.80s/it]INFO:root:global_step: 451, logpy: 110.183, kl: 90.686, loss: -22.919\n",
      " 45%|████▌     | 452/1000 [19:44<24:40,  2.70s/it]INFO:root:global_step: 452, logpy: 110.762, kl: 90.566, loss: -23.585\n",
      " 45%|████▌     | 453/1000 [19:46<24:03,  2.64s/it]INFO:root:global_step: 453, logpy: 111.755, kl: 90.483, loss: -24.626\n",
      " 45%|████▌     | 454/1000 [19:49<23:32,  2.59s/it]INFO:root:global_step: 454, logpy: 113.003, kl: 90.333, loss: -25.991\n",
      " 46%|████▌     | 455/1000 [19:51<23:00,  2.53s/it]INFO:root:global_step: 455, logpy: 114.062, kl: 90.241, loss: -27.108\n",
      " 46%|████▌     | 456/1000 [19:54<22:50,  2.52s/it]INFO:root:global_step: 456, logpy: 114.901, kl: 90.133, loss: -28.022\n",
      " 46%|████▌     | 457/1000 [19:57<24:00,  2.65s/it]INFO:root:global_step: 457, logpy: 115.581, kl: 90.054, loss: -28.749\n",
      " 46%|████▌     | 458/1000 [19:59<24:47,  2.74s/it]INFO:root:global_step: 458, logpy: 116.335, kl: 89.935, loss: -29.589\n",
      " 46%|████▌     | 459/1000 [20:03<25:58,  2.88s/it]INFO:root:global_step: 459, logpy: 117.297, kl: 89.876, loss: -30.579\n",
      " 46%|████▌     | 460/1000 [20:06<27:57,  3.11s/it]INFO:root:global_step: 460, logpy: 118.489, kl: 89.746, loss: -31.870\n",
      " 46%|████▌     | 461/1000 [20:10<29:07,  3.24s/it]INFO:root:global_step: 461, logpy: 119.681, kl: 89.580, loss: -33.195\n",
      " 46%|████▌     | 462/1000 [20:13<28:53,  3.22s/it]INFO:root:global_step: 462, logpy: 120.742, kl: 89.472, loss: -34.334\n",
      " 46%|████▋     | 463/1000 [20:17<30:31,  3.41s/it]INFO:root:global_step: 463, logpy: 121.657, kl: 89.318, loss: -35.372\n",
      " 46%|████▋     | 464/1000 [20:21<31:08,  3.49s/it]INFO:root:global_step: 464, logpy: 122.562, kl: 89.246, loss: -36.319\n",
      " 46%|████▋     | 465/1000 [20:24<31:13,  3.50s/it]INFO:root:global_step: 465, logpy: 123.675, kl: 89.052, loss: -37.596\n",
      " 47%|████▋     | 466/1000 [20:28<31:28,  3.54s/it]INFO:root:global_step: 466, logpy: 124.826, kl: 88.958, loss: -38.812\n",
      " 47%|████▋     | 467/1000 [20:31<31:28,  3.54s/it]INFO:root:global_step: 467, logpy: 125.995, kl: 88.901, loss: -40.008\n",
      " 47%|████▋     | 468/1000 [20:35<31:47,  3.59s/it]INFO:root:global_step: 468, logpy: 127.111, kl: 88.881, loss: -41.115\n",
      " 47%|████▋     | 469/1000 [20:39<32:02,  3.62s/it]INFO:root:global_step: 469, logpy: 128.158, kl: 88.782, loss: -42.231\n",
      " 47%|████▋     | 470/1000 [20:43<32:46,  3.71s/it]INFO:root:global_step: 470, logpy: 129.220, kl: 88.677, loss: -43.371\n",
      " 47%|████▋     | 471/1000 [20:46<31:35,  3.58s/it]INFO:root:global_step: 471, logpy: 130.296, kl: 88.612, loss: -44.483\n",
      " 47%|████▋     | 472/1000 [20:49<29:43,  3.38s/it]INFO:root:global_step: 472, logpy: 131.440, kl: 88.480, loss: -45.731\n",
      " 47%|████▋     | 473/1000 [20:52<28:08,  3.20s/it]INFO:root:global_step: 473, logpy: 132.561, kl: 88.383, loss: -46.922\n",
      " 47%|████▋     | 474/1000 [20:55<29:02,  3.31s/it]INFO:root:global_step: 474, logpy: 133.547, kl: 88.290, loss: -47.973\n",
      " 48%|████▊     | 475/1000 [20:58<27:44,  3.17s/it]INFO:root:global_step: 475, logpy: 134.492, kl: 88.173, loss: -49.007\n",
      " 48%|████▊     | 476/1000 [21:01<26:08,  2.99s/it]INFO:root:global_step: 476, logpy: 135.373, kl: 88.167, loss: -49.868\n",
      " 48%|████▊     | 477/1000 [21:03<25:19,  2.91s/it]INFO:root:global_step: 477, logpy: 136.323, kl: 88.114, loss: -50.845\n",
      " 48%|████▊     | 478/1000 [21:07<26:41,  3.07s/it]INFO:root:global_step: 478, logpy: 137.320, kl: 88.004, loss: -51.924\n",
      " 48%|████▊     | 479/1000 [21:10<27:14,  3.14s/it]INFO:root:global_step: 479, logpy: 138.429, kl: 87.918, loss: -53.094\n",
      " 48%|████▊     | 480/1000 [21:14<28:07,  3.24s/it]INFO:root:global_step: 480, logpy: 139.494, kl: 87.810, loss: -54.241\n",
      " 48%|████▊     | 481/1000 [21:17<29:50,  3.45s/it]INFO:root:global_step: 481, logpy: 140.457, kl: 87.721, loss: -55.267\n",
      " 48%|████▊     | 482/1000 [21:21<30:32,  3.54s/it]INFO:root:global_step: 482, logpy: 141.335, kl: 87.654, loss: -56.187\n",
      " 48%|████▊     | 483/1000 [21:25<31:26,  3.65s/it]INFO:root:global_step: 483, logpy: 142.196, kl: 87.584, loss: -57.094\n",
      " 48%|████▊     | 484/1000 [21:28<28:45,  3.34s/it]INFO:root:global_step: 484, logpy: 143.114, kl: 87.449, loss: -58.121\n",
      " 48%|████▊     | 485/1000 [21:31<28:52,  3.36s/it]INFO:root:global_step: 485, logpy: 144.101, kl: 87.400, loss: -59.132\n",
      " 49%|████▊     | 486/1000 [21:35<30:09,  3.52s/it]INFO:root:global_step: 486, logpy: 145.112, kl: 87.348, loss: -60.171\n",
      " 49%|████▊     | 487/1000 [21:38<29:22,  3.44s/it]INFO:root:global_step: 487, logpy: 146.118, kl: 87.217, loss: -61.284\n",
      " 49%|████▉     | 488/1000 [21:42<29:11,  3.42s/it]INFO:root:global_step: 488, logpy: 147.044, kl: 87.258, loss: -62.146\n",
      " 49%|████▉     | 489/1000 [21:45<28:38,  3.36s/it]INFO:root:global_step: 489, logpy: 147.980, kl: 87.246, loss: -63.071\n",
      " 49%|████▉     | 490/1000 [21:48<28:10,  3.31s/it]INFO:root:global_step: 490, logpy: 148.966, kl: 87.160, loss: -64.119\n",
      " 49%|████▉     | 491/1000 [21:51<27:11,  3.21s/it]INFO:root:global_step: 491, logpy: 149.946, kl: 87.098, loss: -65.137\n",
      " 49%|████▉     | 492/1000 [21:54<25:44,  3.04s/it]INFO:root:global_step: 492, logpy: 150.937, kl: 87.056, loss: -66.147\n",
      " 49%|████▉     | 493/1000 [21:56<24:33,  2.91s/it]INFO:root:global_step: 493, logpy: 151.906, kl: 87.000, loss: -67.150\n",
      " 49%|████▉     | 494/1000 [21:59<24:12,  2.87s/it]INFO:root:global_step: 494, logpy: 152.854, kl: 86.986, loss: -68.089\n",
      " 50%|████▉     | 495/1000 [22:02<24:10,  2.87s/it]INFO:root:global_step: 495, logpy: 153.877, kl: 86.850, loss: -69.226\n",
      " 50%|████▉     | 496/1000 [22:05<25:23,  3.02s/it]INFO:root:global_step: 496, logpy: 154.845, kl: 86.853, loss: -70.169\n",
      " 50%|████▉     | 497/1000 [22:08<24:06,  2.88s/it]INFO:root:global_step: 497, logpy: 155.828, kl: 86.818, loss: -71.165\n",
      " 50%|████▉     | 498/1000 [22:10<23:29,  2.81s/it]INFO:root:global_step: 498, logpy: 156.809, kl: 86.699, loss: -72.243\n",
      " 50%|████▉     | 499/1000 [22:14<24:32,  2.94s/it]INFO:root:global_step: 499, logpy: 157.796, kl: 86.606, loss: -73.303\n",
      " 50%|█████     | 500/1000 [22:18<26:40,  3.20s/it]INFO:root:Saved figure at: ./sim/global_step_500.png\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_core/sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:global_step: 500, logpy: 158.743, kl: 86.558, loss: -74.277\n",
      " 50%|█████     | 501/1000 [22:23<33:13,  4.00s/it]INFO:root:global_step: 501, logpy: 159.678, kl: 86.466, loss: -75.282\n",
      " 50%|█████     | 502/1000 [22:28<34:31,  4.16s/it]INFO:root:global_step: 502, logpy: 160.541, kl: 86.491, loss: -76.100\n",
      " 50%|█████     | 503/1000 [22:31<31:40,  3.82s/it]INFO:root:global_step: 503, logpy: 161.439, kl: 86.380, loss: -77.089\n",
      " 50%|█████     | 504/1000 [22:34<29:37,  3.58s/it]INFO:root:global_step: 504, logpy: 162.245, kl: 86.284, loss: -77.970\n",
      " 50%|█████     | 505/1000 [22:37<29:18,  3.55s/it]INFO:root:global_step: 505, logpy: 163.038, kl: 86.211, loss: -78.816\n",
      " 51%|█████     | 506/1000 [22:42<30:35,  3.72s/it]INFO:root:global_step: 506, logpy: 163.774, kl: 86.135, loss: -79.608\n",
      " 51%|█████     | 507/1000 [22:44<28:33,  3.48s/it]INFO:root:global_step: 507, logpy: 164.506, kl: 86.043, loss: -80.413\n",
      " 51%|█████     | 508/1000 [22:48<29:38,  3.61s/it]INFO:root:global_step: 508, logpy: 165.283, kl: 85.972, loss: -81.241\n",
      " 51%|█████     | 509/1000 [22:51<27:07,  3.32s/it]INFO:root:global_step: 509, logpy: 166.075, kl: 85.921, loss: -82.065\n",
      " 51%|█████     | 510/1000 [22:53<24:53,  3.05s/it]INFO:root:global_step: 510, logpy: 166.895, kl: 85.882, loss: -82.904\n",
      " 51%|█████     | 511/1000 [22:56<23:04,  2.83s/it]INFO:root:global_step: 511, logpy: 167.722, kl: 85.787, loss: -83.808\n",
      " 51%|█████     | 512/1000 [22:58<22:06,  2.72s/it]INFO:root:global_step: 512, logpy: 168.583, kl: 85.685, loss: -84.752\n",
      " 51%|█████▏    | 513/1000 [23:01<21:36,  2.66s/it]INFO:root:global_step: 513, logpy: 169.455, kl: 85.627, loss: -85.663\n",
      " 51%|█████▏    | 514/1000 [23:03<20:52,  2.58s/it]INFO:root:global_step: 514, logpy: 170.310, kl: 85.549, loss: -86.577\n",
      " 52%|█████▏    | 515/1000 [23:06<20:38,  2.55s/it]INFO:root:global_step: 515, logpy: 171.126, kl: 85.506, loss: -87.419\n",
      " 52%|█████▏    | 516/1000 [23:08<20:19,  2.52s/it]INFO:root:global_step: 516, logpy: 171.962, kl: 85.374, loss: -88.369\n",
      " 52%|█████▏    | 517/1000 [23:11<20:05,  2.50s/it]INFO:root:global_step: 517, logpy: 172.730, kl: 85.364, loss: -89.129\n",
      " 52%|█████▏    | 518/1000 [23:13<20:01,  2.49s/it]INFO:root:global_step: 518, logpy: 173.482, kl: 85.395, loss: -89.832\n",
      " 52%|█████▏    | 519/1000 [23:16<20:46,  2.59s/it]INFO:root:global_step: 519, logpy: 174.189, kl: 85.420, loss: -90.496\n",
      " 52%|█████▏    | 520/1000 [23:19<22:13,  2.78s/it]INFO:root:global_step: 520, logpy: 174.930, kl: 85.344, loss: -91.297\n",
      " 52%|█████▏    | 521/1000 [23:23<24:04,  3.01s/it]INFO:root:global_step: 521, logpy: 175.699, kl: 85.258, loss: -92.134\n",
      " 52%|█████▏    | 522/1000 [23:27<26:05,  3.28s/it]INFO:root:global_step: 522, logpy: 176.521, kl: 85.183, loss: -93.014\n",
      " 52%|█████▏    | 523/1000 [23:30<25:55,  3.26s/it]INFO:root:global_step: 523, logpy: 177.323, kl: 85.110, loss: -93.873\n",
      " 52%|█████▏    | 524/1000 [23:33<26:18,  3.32s/it]INFO:root:global_step: 524, logpy: 178.161, kl: 84.998, loss: -94.806\n",
      " 52%|█████▎    | 525/1000 [23:37<26:33,  3.35s/it]INFO:root:global_step: 525, logpy: 178.967, kl: 84.958, loss: -95.635\n",
      " 53%|█████▎    | 526/1000 [23:40<26:01,  3.29s/it]INFO:root:global_step: 526, logpy: 179.767, kl: 84.944, loss: -96.433\n",
      " 53%|█████▎    | 527/1000 [23:43<25:15,  3.20s/it]INFO:root:global_step: 527, logpy: 180.519, kl: 84.887, loss: -97.226\n",
      " 53%|█████▎    | 528/1000 [23:46<25:18,  3.22s/it]INFO:root:global_step: 528, logpy: 181.250, kl: 84.864, loss: -97.964\n",
      " 53%|█████▎    | 529/1000 [23:50<27:19,  3.48s/it]INFO:root:global_step: 529, logpy: 182.012, kl: 84.783, loss: -98.792\n",
      " 53%|█████▎    | 530/1000 [23:53<26:46,  3.42s/it]INFO:root:global_step: 530, logpy: 182.780, kl: 84.725, loss: -99.602\n",
      " 53%|█████▎    | 531/1000 [23:56<24:50,  3.18s/it]INFO:root:global_step: 531, logpy: 183.517, kl: 84.655, loss: -100.394\n",
      " 53%|█████▎    | 532/1000 [23:58<23:09,  2.97s/it]INFO:root:global_step: 532, logpy: 184.312, kl: 84.514, loss: -101.315\n",
      " 53%|█████▎    | 533/1000 [24:02<25:24,  3.26s/it]INFO:root:global_step: 533, logpy: 185.020, kl: 84.488, loss: -102.033\n",
      " 53%|█████▎    | 534/1000 [24:07<29:00,  3.73s/it]INFO:root:global_step: 534, logpy: 185.685, kl: 84.410, loss: -102.760\n",
      " 54%|█████▎    | 535/1000 [24:10<27:19,  3.53s/it]INFO:root:global_step: 535, logpy: 186.259, kl: 84.410, loss: -103.320\n",
      " 54%|█████▎    | 536/1000 [24:13<24:58,  3.23s/it]INFO:root:global_step: 536, logpy: 186.806, kl: 84.333, loss: -103.930\n",
      " 54%|█████▎    | 537/1000 [24:16<24:10,  3.13s/it]INFO:root:global_step: 537, logpy: 187.412, kl: 84.249, loss: -104.605\n",
      " 54%|█████▍    | 538/1000 [24:19<25:30,  3.31s/it]INFO:root:global_step: 538, logpy: 188.079, kl: 84.177, loss: -105.329\n",
      " 54%|█████▍    | 539/1000 [24:23<26:33,  3.46s/it]INFO:root:global_step: 539, logpy: 188.805, kl: 84.048, loss: -106.170\n",
      " 54%|█████▍    | 540/1000 [24:27<27:22,  3.57s/it]INFO:root:global_step: 540, logpy: 189.555, kl: 83.955, loss: -107.000\n",
      " 54%|█████▍    | 541/1000 [24:30<26:23,  3.45s/it]INFO:root:global_step: 541, logpy: 190.239, kl: 83.955, loss: -107.669\n",
      " 54%|█████▍    | 542/1000 [24:34<26:19,  3.45s/it]INFO:root:global_step: 542, logpy: 190.910, kl: 83.913, loss: -108.368\n",
      " 54%|█████▍    | 543/1000 [24:37<25:26,  3.34s/it]INFO:root:global_step: 543, logpy: 191.571, kl: 83.817, loss: -109.112\n",
      " 54%|█████▍    | 544/1000 [24:40<24:29,  3.22s/it]INFO:root:global_step: 544, logpy: 192.172, kl: 83.757, loss: -109.759\n",
      " 55%|█████▍    | 545/1000 [24:43<23:43,  3.13s/it]INFO:root:global_step: 545, logpy: 192.732, kl: 83.725, loss: -110.337\n",
      " 55%|█████▍    | 546/1000 [24:46<20:35,  2.72s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTailCall\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/trampoline/__init__.py\u001b[0m in \u001b[0;36mtrampoline\u001b[0;34m(call)\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0;31m# was yielded.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_brownian/brownian_interval.py\u001b[0m in \u001b[0;36m_loc_inner\u001b[0;34m(self, ta, tb, out)\u001b[0m\n\u001b[1;32m    282\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mtrampoline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTailCall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_left_child\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loc_inner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m             \u001b[0;31m# implies ta > self._start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTailCall\u001b[0m: <generator object _Interval._loc_inner at 0x7fd0c350b040>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-69b973d8e99a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0msdeint_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchsde\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msdeint_adjoint\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'adjoint'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorchsde\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msdeint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-2a88b004317b>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# Train.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# zero the gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mzs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mts_ext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# pass through the model, ys, logqp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0mzs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# remove the dimensions of input of size 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mzs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Drop first and last which are only used to penalize out-of-data region and spread uncertainty.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-69938df2699d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, ts, batch_size, eps)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0maug_y0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# create the augmented initial value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m#print(aug_y0.size()) # [256, 2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         aug_ys = sdeint_fn(\n\u001b[0m\u001b[1;32m     71\u001b[0m             \u001b[0msde\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0my0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maug_y0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_core/adjoint.py\u001b[0m in \u001b[0;36msdeint_adjoint\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mextra_solver_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_extra_solver_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m     ys, *extra_solver_state = _SdeintAdjointMethod.apply(\n\u001b[0m\u001b[1;32m    274\u001b[0m         \u001b[0msde\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madjoint_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madjoint_adaptive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madjoint_rtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madjoint_atol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt_min\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0madjoint_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextra_solver_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mextra_solver_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0madjoint_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_core/adjoint.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, sde, ts, dt, bm, solver, method, adjoint_method, adjoint_adaptive, adjoint_rtol, adjoint_atol, dt_min, adjoint_options, len_extras, y0, *extras_and_adjoint_params)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# Necessary for the same reason\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mextra_solver_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mextra_solver_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_solver_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_solver_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mMETHODS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreversible_heun\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0madjoint_method\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mMETHODS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjoint_reversible_heun\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_core/base_solver.py\u001b[0m in \u001b[0;36mintegrate\u001b[0;34m(self, y0, ts, extra0)\u001b[0m\n\u001b[1;32m    120\u001b[0m                     \u001b[0;31m# Take 2 half steps.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                     \u001b[0mmidpoint_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcurr_t\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnext_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m                     \u001b[0mmidpoint_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmidpoint_extra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmidpoint_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_extra\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m                     \u001b[0mnext_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_extra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmidpoint_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmidpoint_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmidpoint_extra\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_core/methods/euler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mextra0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mI_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_prod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msde\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_and_g_prod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mI_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_brownian/brownian_interval.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, ta, tb, return_U, return_A)\u001b[0m\n\u001b[1;32m    618\u001b[0m                         \u001b[0;31m# bottom of the dependency tree. If we're below halfway then refine the tree by splitting all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m                         \u001b[0;31m# the bottom pieces into two.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_dependency_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m             \u001b[0;31m# Find the intervals that correspond to the query. We start our search at the last interval we accessed in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_brownian/brownian_interval.py\u001b[0m in \u001b[0;36m_create_dependency_tree\u001b[0;34m(self, dt)\u001b[0m\n\u001b[1;32m    696\u001b[0m                 \u001b[0m_set_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_right_child\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m         \u001b[0m_set_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_brownian/brownian_interval.py\u001b[0m in \u001b[0;36m_set_points\u001b[0;34m(interval)\u001b[0m\n\u001b[1;32m    694\u001b[0m                 \u001b[0minterval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmidway\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m                 \u001b[0m_set_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_left_child\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m                 \u001b[0m_set_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_right_child\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0m_set_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_brownian/brownian_interval.py\u001b[0m in \u001b[0;36m_set_points\u001b[0;34m(interval)\u001b[0m\n\u001b[1;32m    694\u001b[0m                 \u001b[0minterval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmidway\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m                 \u001b[0m_set_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_left_child\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m                 \u001b[0m_set_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_right_child\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0m_set_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_brownian/brownian_interval.py\u001b[0m in \u001b[0;36m_set_points\u001b[0;34m(interval)\u001b[0m\n\u001b[1;32m    694\u001b[0m                 \u001b[0minterval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmidway\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m                 \u001b[0m_set_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_left_child\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m                 \u001b[0m_set_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_right_child\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0m_set_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_brownian/brownian_interval.py\u001b[0m in \u001b[0;36m_set_points\u001b[0;34m(interval)\u001b[0m\n\u001b[1;32m    694\u001b[0m                 \u001b[0minterval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmidway\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m                 \u001b[0m_set_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_left_child\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m                 \u001b[0m_set_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_right_child\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0m_set_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_brownian/brownian_interval.py\u001b[0m in \u001b[0;36m_set_points\u001b[0;34m(interval)\u001b[0m\n\u001b[1;32m    694\u001b[0m                 \u001b[0minterval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmidway\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m                 \u001b[0m_set_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_left_child\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m                 \u001b[0m_set_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_right_child\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0m_set_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_brownian/brownian_interval.py\u001b[0m in \u001b[0;36m_set_points\u001b[0;34m(interval)\u001b[0m\n\u001b[1;32m    694\u001b[0m                 \u001b[0minterval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmidway\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m                 \u001b[0m_set_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_left_child\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m                 \u001b[0m_set_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_right_child\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0m_set_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_brownian/brownian_interval.py\u001b[0m in \u001b[0;36m_set_points\u001b[0;34m(interval)\u001b[0m\n\u001b[1;32m    694\u001b[0m                 \u001b[0minterval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmidway\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m                 \u001b[0m_set_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_left_child\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m                 \u001b[0m_set_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_right_child\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0m_set_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_brownian/brownian_interval.py\u001b[0m in \u001b[0;36m_set_points\u001b[0;34m(interval)\u001b[0m\n\u001b[1;32m    694\u001b[0m                 \u001b[0minterval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmidway\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m                 \u001b[0m_set_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_left_child\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m                 \u001b[0m_set_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_right_child\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0m_set_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_brownian/brownian_interval.py\u001b[0m in \u001b[0;36m_set_points\u001b[0;34m(interval)\u001b[0m\n\u001b[1;32m    694\u001b[0m                 \u001b[0minterval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmidway\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m                 \u001b[0m_set_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_left_child\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m                 \u001b[0m_set_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_right_child\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0m_set_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_brownian/brownian_interval.py\u001b[0m in \u001b[0;36m_set_points\u001b[0;34m(interval)\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mpiece_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m                 \u001b[0mmidway\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m                 \u001b[0minterval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmidway\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m                 \u001b[0m_set_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_left_child\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m                 \u001b[0m_set_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_right_child\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_brownian/brownian_interval.py\u001b[0m in \u001b[0;36m_loc\u001b[0;34m(self, ta, tb)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_top\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_round\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_top\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_round\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0mtrampoline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrampoline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loc_inner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/trampoline/__init__.py\u001b[0m in \u001b[0;36mtrampoline\u001b[0;34m(call)\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0;31m# We use next() here for nicer exceptions if an invalid value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0;31m# was yielded.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "manual_seed(args['seed'])\n",
    "\n",
    "if args['debug']:\n",
    "    logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "ckpt_dir = os.path.join('./sim/', 'ckpts')\n",
    "os.makedirs(ckpt_dir, exist_ok=True)\n",
    "\n",
    "sdeint_fn = torchsde.sdeint_adjoint if args['adjoint'] else torchsde.sdeint\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c356ad31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7712260f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
