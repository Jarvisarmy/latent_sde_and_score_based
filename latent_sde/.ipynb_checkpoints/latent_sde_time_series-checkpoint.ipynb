{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4dd7b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from collections import namedtuple\n",
    "from typing import Optional, Union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import tqdm\n",
    "from torch import distributions, nn, optim\n",
    "\n",
    "import torchsde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0aeebbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the gpu is available or not, if yes, use gpu\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2902c1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the tuple for data, \n",
    "Data = namedtuple('Data', ['ts_', 'ts_ext_', 'ts_vis_', 'ts', 'ts_ext', 'ts_vis', 'ys', 'ys_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9198a09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"train_iters\": 500,\n",
    "    \"pause_iters\": 50,\n",
    "    \"hide_ticks\": False,\n",
    "    \"save_ckpt\":True,\n",
    "    \"likelihood\":\"laplace\",\n",
    "    \"scale\": 0.0001,\n",
    "    \"adjoint\": False,\n",
    "    \"debug\": True,\n",
    "    \"seed\": 42,\n",
    "    'data':'segmented_cosine',\n",
    "    \"dt\": 1e-2,\n",
    "    \"batch_size\": 256,\n",
    "    \"method\": 'euler',\n",
    "    \"adaptive\": 'False',\n",
    "    \"rtol\": 1e-3,\n",
    "    \"atol\": 1e-3\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40420fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output values from 0 to maxval with iters steps\n",
    "class LinearScheduler(object):\n",
    "    def __init__(self, iters, maxval=1.0):\n",
    "        self._iters = max(1,iters)\n",
    "        self._val = maxval/self._iters\n",
    "        self._maxval = maxval\n",
    "    \n",
    "    def step(self):\n",
    "        self._val = min(self._maxval, self._val+self._maxval/self._iters)\n",
    "        \n",
    "    @property\n",
    "    def val(self):\n",
    "        return self._val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93c09c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EMAMetric(object):\n",
    "    def __init__(self, gamma: Optional[float]=0.99):\n",
    "        super(EMAMetric, self).__init__()\n",
    "        self._val=None\n",
    "        self._gamma = gamma\n",
    "    def step(self, x:Union[torch.Tensor, np.ndarray]):\n",
    "        x = x.detach().cpu().numpy() if torch.is_tensor(x) else x\n",
    "        if self._val is None:\n",
    "            self._val = x\n",
    "        else: \n",
    "            self._val = self._gamma * self._val + (1-self._gamma)*x\n",
    "        return self._val\n",
    "    \n",
    "    @property\n",
    "    def val(self):\n",
    "        return self._val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f66a9c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matric = EMAMetric()\n",
    "matric.step(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a4ec86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the seed\n",
    "def manual_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98a2f4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure that the dvision is stable\n",
    "def _stable_division(a,b,epsilon=1e-7):\n",
    "    b = torch.where(b.abs().detach() > epsilon, b, torch.full_like(b, fill_value=epsilon)*b.sign())\n",
    "    return a/b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "522d3e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LatentSDE(torchsde.SDEIto): # sde with ito calculus\n",
    "    def __init__(self, theta=1.0, mu=0.0, sigma=1):\n",
    "        super(LatentSDE, self).__init__(noise_type=\"diagonal\")\n",
    "        logvar = math.log(sigma ** 2/(2.*theta))\n",
    "        \n",
    "        # prior drift\n",
    "        self.register_buffer(\"theta\",torch.tensor([[theta]])) # prior parameters, register 成buffer, 参数不会进行更新\n",
    "        self.register_buffer(\"mu\", torch.tensor([[mu]]))\n",
    "        self.register_buffer(\"sigma\",torch.tensor([[sigma]]))\n",
    "        \n",
    "        # p(y0)\n",
    "        self.register_buffer(\"py0_mean\", torch.tensor([[mu]]))\n",
    "        self.register_buffer(\"py0_logvar\", torch.tensor([[logvar]]))\n",
    "        \n",
    "        # approximate posterior drift: Takes in 2 positional encodings and the state\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(3,200),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(200,200),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(200,1)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Initialization the parameters\n",
    "        self.net[-1].weight.data.fill_(0.) # 初始化最后一层的参数\n",
    "        self.net[-1].bias.data.fill_(0.)\n",
    "            \n",
    "        # q(y0)\n",
    "        self.qy0_mean = nn.Parameter(torch.tensor([[mu]]), requires_grad=True) # 创建parameters\n",
    "        self.qy0_logvar = nn.Parameter(torch.tensor([[logvar]]), requires_grad=True) # 创建parameters\n",
    "        #self.theta = nn.Parameter(torch.tensor([[theta]]),requires_grad=True)\n",
    "        #self.theta = nn.Parameter(torch.tensor([[theta]]),requires_grad=True)\n",
    "            \n",
    "    def f(self, t, y):  # Approximate posterior drift.\n",
    "        if t.dim() == 0:\n",
    "            t = torch.full_like(y, fill_value=t) # create a tensor of t\n",
    "        # Positional encoding in transformers for time-inhomogeneous posterior.\n",
    "        return self.net(torch.cat((torch.sin(t), torch.cos(t), y), dim=-1))\n",
    "\n",
    "    def g(self, t, y):  # Shared diffusion.\n",
    "        return self.sigma.repeat(y.size(0), 1) # 重复复制, 创建一个size为[y.size[0],1]\n",
    "\n",
    "    def h(self, t, y):  # Prior drift.\n",
    "        return self.theta * (self.mu - y)\n",
    "\n",
    "    def f_aug(self, t, y):  # Drift for augmented dynamics with logqp term.\n",
    "        y = y[:, 0:1] # 提取第一列，保持列的形态\n",
    "        f, g, h = self.f(t, y), self.g(t, y), self.h(t, y)\n",
    "        u = _stable_division(f - h, g) # 计算u(z,t)\n",
    "        f_logqp = .5 * (u ** 2).sum(dim=1, keepdim=True) # 计算integral\n",
    "        return torch.cat([f, f_logqp], dim=1)\n",
    "\n",
    "    def g_aug(self, t, y):  # Diffusion for augmented dynamics with logqp term.\n",
    "        y = y[:, 0:1]\n",
    "        g = self.g(t, y)\n",
    "        g_logqp = torch.zeros_like(y)\n",
    "        return torch.cat([g, g_logqp], dim=1)\n",
    "\n",
    "    def forward(self, ts, batch_size, eps=None):\n",
    "        eps = torch.randn(batch_size, 1).to(self.qy0_std) if eps is None else eps\n",
    "        y0 = self.qy0_mean + eps * self.qy0_std # the latent variable\n",
    "        qy0 = distributions.Normal(loc=self.qy0_mean, scale=self.qy0_std) # approximate posterior distribution\n",
    "        py0 = distributions.Normal(loc=self.py0_mean, scale=self.py0_std) # prior distribution\n",
    "        logqp0 = distributions.kl_divergence(qy0, py0).sum(dim=1)  # KL(t=0). calculate the kl divergence\n",
    "        #print(y0.size()) # (256, 1)\n",
    "        aug_y0 = torch.cat([y0, torch.zeros(batch_size, 1).to(y0)], dim=1) # create the augmented initial value\n",
    "        #print(aug_y0.size()) # [256, 2]\n",
    "        aug_ys = sdeint_fn(\n",
    "            sde=self,\n",
    "            y0=aug_y0,\n",
    "            ts=ts,\n",
    "            method=args['method'],\n",
    "            dt=args['dt'],\n",
    "            adaptive=args['adaptive'],\n",
    "            rtol=args['rtol'],\n",
    "            atol=args['atol'],\n",
    "            names={'drift': 'f_aug', 'diffusion': 'g_aug'}\n",
    "        ) # call the sde solver to \n",
    "        # print(aug_ys.size()) # [22, 256, 2]\n",
    "        ys, logqp_path = aug_ys[:, :, 0:1], aug_ys[-1, :, 1] # get the integral of the u(z,t) at the last time\n",
    "        \n",
    "        logqp = (logqp0 + logqp_path).mean(dim=0)  # KL(t=0) + KL(path).\n",
    "        return ys, logqp\n",
    "\n",
    "    def sample_p(self, ts, batch_size, eps=None, bm=None):\n",
    "        eps = torch.randn(batch_size, 1).to(self.py0_mean) if eps is None else eps\n",
    "        y0 = self.py0_mean + eps * self.py0_std\n",
    "        return sdeint_fn(self, y0, ts, bm=bm, method=args['method'], dt=args['dt'], names={'drift': 'h'}) # prior sde\n",
    "\n",
    "    def sample_q(self, ts, batch_size, eps=None, bm=None):\n",
    "        eps = torch.randn(batch_size, 1).to(self.qy0_mean) if eps is None else eps\n",
    "        y0 = self.qy0_mean + eps * self.qy0_std\n",
    "        return sdeint_fn(self, y0, ts, bm=bm, method=args['method'], dt=args['dt']) # posterior sde\n",
    "\n",
    "    @property\n",
    "    def py0_std(self):\n",
    "        return torch.exp(.5 * self.py0_logvar)\n",
    "\n",
    "    @property\n",
    "    def qy0_std(self):\n",
    "        return torch.exp(.5 * self.qy0_logvar)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80736fff",
   "metadata": {},
   "source": [
    "## 5. Simulation of time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd15aaa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "T = 30\n",
    "#beta = 0.1694\n",
    "beta=1\n",
    "def make_time_series():\n",
    "    \n",
    "    \n",
    "    phi = 0.99\n",
    "    sigma_v = 0.003342\n",
    "    sigma_u = 0.00328\n",
    "    rho = -0.856\n",
    "    cov_uv = rho * sigma_u * sigma_v\n",
    "\n",
    "    # generating shocks\n",
    "    mu = [0,0]\n",
    "    cov = [[sigma_u**2, cov_uv], [cov_uv, sigma_v**2]]\n",
    "    shocks = np.random.multivariate_normal(mu, cov, T)\n",
    "\n",
    "    z0 = np.random.normal(0, sigma_u**2/(1-phi**2),1)\n",
    "    r0 = shocks[0][0]\n",
    "\n",
    "    z = np.zeros(T)\n",
    "    r = np.zeros(T)\n",
    "    z[0] = z0\n",
    "    r[0] = r0\n",
    "\n",
    "    for idx_t in range(T-1):\n",
    "        z[idx_t+1] = phi*z[idx_t] + shocks[idx_t+1][1]\n",
    "        r[idx_t+1] = beta*z[idx_t+1] + shocks[idx_t+1][0]\n",
    "    return z, r\n",
    "z, r = make_time_series()\n",
    "plt.figure(figsize=(15,5))\n",
    "xvalues = np.array(range(T))\n",
    "plt.plot(xvalues, r, linestyle='-', color='g', label=\"observed $r_t$\")\n",
    "plt.plot(xvalues, z, linestyle=\"--\", color=\"r\", label=r\"hidden variable $\\beta * z_t$\", linewidth=3.0)\n",
    "\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('%')\n",
    "plt.grid(True)\n",
    "plt.title(r\"Simulated $r_t$ and hidden $\\beta * z_t$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0cf9fca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data():\n",
    "    ts_ = np.linspace(0.1,30.0,30)\n",
    "    ts_ext_ = np.array([0.] + list(ts_) + [30.1])\n",
    "    ts_vis_ = np.linspace(0.1, 30.1, 31)\n",
    "    ys_ = r[:,None]\n",
    "    ts = torch.tensor(ts_).float()\n",
    "    ts_ext = torch.tensor(ts_ext_).float()\n",
    "    ts_vis = torch.tensor(ts_vis_).float()\n",
    "    ys = torch.tensor(ys_).float().to(device)\n",
    "    return Data(ts_, ts_ext_, ts_vis_, ts, ts_ext, ts_vis, ys, ys_)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "99a1fc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Dataset\n",
    "    ts_, ts_ext_, ts_vis_, ts, ts_ext, ts_vis, ys, ys_ = make_data()\n",
    "    #mu = torch.mean(ys)\n",
    "    sigma = torch.std(ys)\n",
    "    \n",
    "    # plotting parameters\n",
    "    vis_batch_size = 1024\n",
    "    ylims = (-0.03, 0.03)\n",
    "    alphas = [0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.55]\n",
    "    percentiles = [0.999, 0.99, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1]\n",
    "    vis_idx = np.random.permutation(vis_batch_size)\n",
    "    sample_colors = ('#8c96c6', '#8c6bb1', '#810f7c')\n",
    "    fill_color = '#9ebcda'\n",
    "    mean_color = '#4d004b'\n",
    "    num_samples = len(sample_colors)\n",
    "    \n",
    "    eps = torch.randn(vis_batch_size, 1).to(device)\n",
    "    bm = torchsde.BrownianInterval(\n",
    "        t0=ts_vis[0],\n",
    "        t1=ts_vis[-1],\n",
    "        size=(vis_batch_size,1),\n",
    "        device=device,\n",
    "        levy_area_approximation=\"space-time\")\n",
    "    \n",
    "    # Model\n",
    "    model = LatentSDE(theta=1.0,mu=0.0,sigma=sigma).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "    kl_scheduler = LinearScheduler(iters=100)\n",
    "    criterion = nn.BCELoss(reduction='sum')\n",
    "    \n",
    "    logpy_metric = EMAMetric()\n",
    "    kl_metric = EMAMetric()\n",
    "    loss_metric = EMAMetric()\n",
    "    \n",
    "    \n",
    "    # show prior\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        zs = model.sample_p(ts=ts_vis, batch_size = vis_batch_size, eps = eps, bm=bm).squeeze()\n",
    "       \n",
    "        ts_vis_, zs_ = ts_vis.cpu().numpy(), zs.cpu().numpy()\n",
    "        #plt.scatter(ts_vis_, ys_, color='r', label=\"prior\")\n",
    "        zs_ = np.sort(zs_,axis=1)\n",
    "        img_dir = os.path.join('./sim/','prior.png')\n",
    "        plt.subplot(frameon=False)\n",
    "        for alpha, percentile in zip(alphas, percentiles):\n",
    "            idx = int((1 - percentile) / 2. * vis_batch_size)\n",
    "            zs_bot_ = zs_[:, idx]\n",
    "            zs_top_ = zs_[:, -idx]\n",
    "            plt.fill_between(ts_vis_, zs_bot_, zs_top_, alpha=alpha, color=fill_color)\n",
    "\n",
    "        # `zorder` determines who's on top; the larger the more at the top.\n",
    "        \n",
    "        plt.scatter(ts_, ys_, marker='x', zorder=3, color='k', s=35)  # Data.\n",
    "        plt.plot(ts_, ys_, marker='x', zorder=3, color='k',label=\"observed $r_t$\")\n",
    "        plt.plot(ts_, z[:,None], color='g', linewidth=3.0, label=r\"hidden variable $z_t$\")\n",
    "        plt.ylim(ylims)\n",
    "        plt.xlabel('$t$')\n",
    "        plt.ylabel('$Y_t$')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.legend()\n",
    "        plt.savefig(img_dir, dpi=300)\n",
    "        plt.close()\n",
    "        logging.info(f'Saved prior figure at: {img_dir}')\n",
    "    \n",
    "    \n",
    "    for global_step in tqdm.tqdm(range(args['train_iters'])):\n",
    "        \n",
    "        # Plot and save.\n",
    "        if global_step % args['pause_iters'] == 0:\n",
    "            img_path = os.path.join(\"./sim/\", f'global_step_{global_step}.png')\n",
    "\n",
    "            with torch.no_grad():\n",
    "                zs = model.sample_q(ts=ts_vis, batch_size=vis_batch_size, eps=eps, bm=bm).squeeze()\n",
    "                samples = zs[:, vis_idx]\n",
    "                ts_vis_, zs_, samples_ = ts_vis.cpu().numpy(), zs.cpu().numpy(), samples.cpu().numpy()\n",
    "                zs_ = np.sort(zs_, axis=1)\n",
    "                plt.subplot(frameon=False)\n",
    "\n",
    "                if True: # args.show_percentiles:\n",
    "                    for alpha, percentile in zip(alphas, percentiles):\n",
    "                        idx = int((1 - percentile) / 2. * vis_batch_size)\n",
    "                        zs_bot_, zs_top_ = zs_[:, idx], zs_[:, -idx]\n",
    "                        plt.fill_between(ts_vis_, zs_bot_, zs_top_, alpha=alpha, color=fill_color)\n",
    "\n",
    "                if True: #args.show_mean:\n",
    "                    plt.plot(ts_vis_, zs_.mean(axis=1), color=mean_color)\n",
    "\n",
    "                if True: #args.show_samples:\n",
    "                    #for j in range(num_samples):\n",
    "                    #    plt.plot(ts_vis_, samples_[:, j], color=sample_colors[j], linewidth=1.0)\n",
    "                    plt.plot(ts_, z[:,None], color='g', linewidth=3.0, label=r\"hidden variable $z_t$\")\n",
    "                    plt.plot(ts_vis_, samples_.mean(axis=1), color='r',label=r'mean of latent variables')\n",
    "\n",
    "                if True: #args.show_arrows:\n",
    "                    num, dt = 3, 0.12\n",
    "                    t, y = torch.meshgrid(\n",
    "                        [torch.linspace(0, 3, num).to(device), torch.linspace(-0.3, 0.3, num).to(device)]\n",
    "                    )\n",
    "                    t, y = t.reshape(-1, 1), y.reshape(-1, 1)\n",
    "                    fty = model.f(t=t, y=y).reshape(num, num)\n",
    "                    dt = torch.zeros(num, num).fill_(dt).to(device)\n",
    "                    dy = fty * dt\n",
    "                    dt_, dy_, t_, y_ = dt.cpu().numpy(), dy.cpu().numpy(), t.cpu().numpy(), y.cpu().numpy()\n",
    "                    plt.quiver(t_, y_, dt_, dy_, alpha=0.3, edgecolors='k', width=0.0035, scale=50)\n",
    "\n",
    "                if False: #args.hide_ticks:\n",
    "                    plt.xticks([], [])\n",
    "                    plt.yticks([], [])\n",
    "\n",
    "                #plt.scatter(ts_, ys_, marker='x', zorder=3, color='k', s=35)  # Data.\n",
    "                plt.plot(ts_, ys_, marker='x', zorder=3, color='k', label=\"observed $r_t$ \") # new added\n",
    "            \n",
    "\n",
    "                \n",
    "                plt.ylim(ylims)\n",
    "                plt.xlabel('$t$')\n",
    "                plt.ylabel('$Y_t$')\n",
    "                plt.tight_layout()\n",
    "                plt.legend()\n",
    "                plt.savefig(img_path, dpi=300)\n",
    "                plt.close()\n",
    "                logging.info(f'Saved figure at: {img_path}')\n",
    "\n",
    "                \n",
    "        \n",
    "        # Train.\n",
    "        optimizer.zero_grad() # zero the gradient\n",
    "        zs, kl = model(ts=ts_ext, batch_size=args['batch_size']) # pass through the model, ys, logqp\n",
    "        zs = zs.squeeze() # remove the dimensions of input of size 1\n",
    "        zs = zs[1:-1]  # Drop first and last which are only used to penalize out-of-data region and spread uncertainty.\n",
    "\n",
    "        likelihood_constructor = {\"laplace\": distributions.Laplace, \"normal\": distributions.Normal}[args['likelihood']]\n",
    "        likelihood = likelihood_constructor(loc=zs, scale=args['scale']) # create the laplace distribution\n",
    "        logpy = likelihood.log_prob(ys).sum(dim=0).mean(dim=0) # got the log likelihood\n",
    "\n",
    "        loss = -logpy + kl * kl_scheduler.val\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        kl_scheduler.step()\n",
    "\n",
    "        logpy_metric.step(logpy)\n",
    "        kl_metric.step(kl)\n",
    "        loss_metric.step(loss)\n",
    "\n",
    "        logging.info(\n",
    "            f'global_step: {global_step}, '\n",
    "            f'logpy: {logpy_metric.val:.3f}, '\n",
    "            f'kl: {kl_metric.val:.3f}, '\n",
    "            f'loss: {loss_metric.val:.3f}'\n",
    "        )\n",
    "    torch.save(\n",
    "        {'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'scheduler': scheduler.state_dict(),\n",
    "            'kl_scheduler': kl_scheduler},\n",
    "        os.path.join('./sim/', f'global_step_{global_step}.ckpt')\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74b55c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BrownianInterval(t0=0.100, t1=30.100, size=(1024, 1), dtype=torch.float32, device=device(type='cpu'), entropy=1506362948, dt=None, tol=0.0, pool_size=8, cache_size=45, levy_area_approximation='space-time')\n",
      "(31, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saved prior figure at: ./sim/prior.png\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]INFO:root:Saved figure at: ./sim/global_step_0.png\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_core/sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 0, logpy: -2957.112, kl: 221.514, loss: 2959.327\n",
      "  0%|          | 1/500 [00:11<1:32:19, 11.10s/it]INFO:root:global_step: 1, logpy: -4040.464, kl: 2606.827, loss: 4090.407\n",
      "  0%|          | 2/500 [00:11<1:06:35,  8.02s/it]INFO:root:global_step: 2, logpy: -4349.704, kl: 2823.108, loss: 4406.418\n",
      "  1%|          | 3/500 [00:13<49:17,  5.95s/it]  INFO:root:global_step: 3, logpy: -4524.959, kl: 2883.424, loss: 4584.648\n",
      "  1%|          | 4/500 [00:14<37:08,  4.49s/it]INFO:root:global_step: 4, logpy: -4736.431, kl: 2974.795, loss: 4801.534\n",
      "  1%|          | 5/500 [00:15<28:31,  3.46s/it]INFO:root:global_step: 5, logpy: -4786.913, kl: 2962.828, loss: 4852.431\n",
      "  1%|          | 6/500 [00:16<23:38,  2.87s/it]INFO:root:global_step: 6, logpy: -4867.383, kl: 2969.188, loss: 4934.766\n",
      "  1%|▏         | 7/500 [00:18<19:57,  2.43s/it]INFO:root:global_step: 7, logpy: -5017.788, kl: 3020.518, loss: 5090.979\n",
      "  2%|▏         | 8/500 [00:19<16:57,  2.07s/it]INFO:root:global_step: 8, logpy: -5150.464, kl: 3058.887, loss: 5229.094\n",
      "  2%|▏         | 9/500 [00:20<14:56,  1.83s/it]INFO:root:global_step: 9, logpy: -5213.641, kl: 3056.920, loss: 5294.347\n",
      "  2%|▏         | 10/500 [00:22<14:21,  1.76s/it]INFO:root:global_step: 10, logpy: -5192.004, kl: 3029.088, loss: 5272.204\n",
      "  2%|▏         | 11/500 [00:24<15:17,  1.88s/it]INFO:root:global_step: 11, logpy: -5205.442, kl: 3006.691, loss: 5285.787\n",
      "  2%|▏         | 12/500 [00:25<14:42,  1.81s/it]INFO:root:global_step: 12, logpy: -5257.640, kl: 2996.002, loss: 5339.701\n",
      "  3%|▎         | 13/500 [00:27<14:03,  1.73s/it]INFO:root:global_step: 13, logpy: -5311.268, kl: 2986.015, loss: 5395.305\n",
      "  3%|▎         | 14/500 [00:28<13:05,  1.62s/it]INFO:root:global_step: 14, logpy: -5347.177, kl: 2970.303, loss: 5432.496\n",
      "  3%|▎         | 15/500 [00:30<12:40,  1.57s/it]INFO:root:global_step: 15, logpy: -5350.569, kl: 2946.721, loss: 5436.014\n",
      "  3%|▎         | 16/500 [00:32<13:16,  1.64s/it]INFO:root:global_step: 16, logpy: -5325.015, kl: 2918.912, loss: 5409.887\n",
      "  3%|▎         | 17/500 [00:34<14:36,  1.81s/it]INFO:root:global_step: 17, logpy: -5299.685, kl: 2891.974, loss: 5384.114\n",
      "  4%|▎         | 18/500 [00:36<15:12,  1.89s/it]INFO:root:global_step: 18, logpy: -5290.419, kl: 2868.338, loss: 5375.007\n",
      "  4%|▍         | 19/500 [00:38<15:18,  1.91s/it]INFO:root:global_step: 19, logpy: -5291.515, kl: 2847.257, loss: 5376.778\n",
      "  4%|▍         | 20/500 [00:40<15:21,  1.92s/it]INFO:root:global_step: 20, logpy: -5291.373, kl: 2826.031, loss: 5377.305\n",
      "  4%|▍         | 21/500 [00:42<15:08,  1.90s/it]INFO:root:global_step: 21, logpy: -5283.051, kl: 2803.201, loss: 5369.318\n",
      "  4%|▍         | 22/500 [00:44<15:02,  1.89s/it]INFO:root:global_step: 22, logpy: -5263.623, kl: 2778.488, loss: 5349.791\n",
      "  5%|▍         | 23/500 [00:45<15:02,  1.89s/it]INFO:root:global_step: 23, logpy: -5238.278, kl: 2752.800, loss: 5324.088\n",
      "  5%|▍         | 24/500 [00:48<15:24,  1.94s/it]INFO:root:global_step: 24, logpy: -5208.629, kl: 2726.541, loss: 5293.898\n",
      "  5%|▌         | 25/500 [00:50<15:38,  1.98s/it]INFO:root:global_step: 25, logpy: -5181.519, kl: 2700.601, loss: 5266.279\n",
      "  5%|▌         | 26/500 [00:52<15:51,  2.01s/it]INFO:root:global_step: 26, logpy: -5155.686, kl: 2674.985, loss: 5239.975\n",
      "  5%|▌         | 27/500 [00:54<15:58,  2.03s/it]INFO:root:global_step: 27, logpy: -5134.252, kl: 2650.114, loss: 5218.223\n",
      "  6%|▌         | 28/500 [00:56<15:44,  2.00s/it]INFO:root:global_step: 28, logpy: -5114.072, kl: 2625.538, loss: 5197.763\n",
      "  6%|▌         | 29/500 [00:58<15:27,  1.97s/it]INFO:root:global_step: 29, logpy: -5092.878, kl: 2601.091, loss: 5176.274\n",
      "  6%|▌         | 30/500 [01:00<15:58,  2.04s/it]INFO:root:global_step: 30, logpy: -5070.050, kl: 2576.736, loss: 5153.125\n",
      "  6%|▌         | 31/500 [01:02<16:20,  2.09s/it]INFO:root:global_step: 31, logpy: -5045.150, kl: 2552.318, loss: 5127.827\n",
      "  6%|▋         | 32/500 [01:04<16:18,  2.09s/it]INFO:root:global_step: 32, logpy: -5019.290, kl: 2528.037, loss: 5101.549\n",
      "  7%|▋         | 33/500 [01:06<16:09,  2.07s/it]INFO:root:global_step: 33, logpy: -4991.533, kl: 2503.864, loss: 5073.346\n",
      "  7%|▋         | 34/500 [01:08<16:08,  2.08s/it]INFO:root:global_step: 34, logpy: -4964.928, kl: 2480.005, loss: 5046.336\n",
      "  7%|▋         | 35/500 [01:10<15:48,  2.04s/it]INFO:root:global_step: 35, logpy: -4937.302, kl: 2456.320, loss: 5018.297\n",
      "  7%|▋         | 36/500 [01:12<15:40,  2.03s/it]INFO:root:global_step: 36, logpy: -4909.316, kl: 2432.918, loss: 4989.931\n",
      "  7%|▋         | 37/500 [01:14<15:50,  2.05s/it]INFO:root:global_step: 37, logpy: -4883.224, kl: 2409.941, loss: 4963.547\n",
      "  8%|▊         | 38/500 [01:16<15:39,  2.03s/it]INFO:root:global_step: 38, logpy: -4858.375, kl: 2387.346, loss: 4938.481\n",
      "  8%|▊         | 39/500 [01:18<15:28,  2.01s/it]INFO:root:global_step: 39, logpy: -4832.185, kl: 2364.845, loss: 4912.039\n",
      "  8%|▊         | 40/500 [01:20<15:17,  2.00s/it]INFO:root:global_step: 40, logpy: -4806.624, kl: 2342.567, loss: 4886.241\n",
      "  8%|▊         | 41/500 [01:22<15:15,  1.99s/it]INFO:root:global_step: 41, logpy: -4781.946, kl: 2320.498, loss: 4861.337\n",
      "  8%|▊         | 42/500 [01:24<15:15,  2.00s/it]INFO:root:global_step: 42, logpy: -4757.628, kl: 2298.740, loss: 4836.847\n",
      "  9%|▊         | 43/500 [01:26<15:22,  2.02s/it]INFO:root:global_step: 43, logpy: -4732.687, kl: 2277.213, loss: 4811.757\n",
      "  9%|▉         | 44/500 [01:28<15:11,  2.00s/it]INFO:root:global_step: 44, logpy: -4708.628, kl: 2255.876, loss: 4787.553\n",
      "  9%|▉         | 45/500 [01:30<15:16,  2.01s/it]INFO:root:global_step: 45, logpy: -4683.746, kl: 2234.597, loss: 4762.470\n",
      "  9%|▉         | 46/500 [01:32<15:11,  2.01s/it]INFO:root:global_step: 46, logpy: -4660.159, kl: 2213.677, loss: 4738.766\n",
      "  9%|▉         | 47/500 [01:34<15:20,  2.03s/it]INFO:root:global_step: 47, logpy: -4635.809, kl: 2192.849, loss: 4714.258\n",
      " 10%|▉         | 48/500 [01:36<15:06,  2.01s/it]INFO:root:global_step: 48, logpy: -4611.261, kl: 2172.188, loss: 4689.547\n",
      " 10%|▉         | 49/500 [01:38<15:17,  2.03s/it]INFO:root:global_step: 49, logpy: -4587.409, kl: 2151.750, loss: 4665.554\n",
      " 10%|█         | 50/500 [01:41<15:35,  2.08s/it]INFO:root:Saved figure at: ./sim/global_step_50.png\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_core/sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 50, logpy: -4564.347, kl: 2131.538, loss: 4642.377\n",
      " 10%|█         | 51/500 [01:51<34:09,  4.56s/it]INFO:root:global_step: 51, logpy: -4541.343, kl: 2111.557, loss: 4619.286\n",
      " 10%|█         | 52/500 [01:53<28:40,  3.84s/it]INFO:root:global_step: 52, logpy: -4519.371, kl: 2091.793, loss: 4597.251\n",
      " 11%|█         | 53/500 [01:55<25:19,  3.40s/it]INFO:root:global_step: 53, logpy: -4495.613, kl: 2072.035, loss: 4573.341\n",
      " 11%|█         | 54/500 [01:57<22:10,  2.98s/it]INFO:root:global_step: 54, logpy: -4473.007, kl: 2052.553, loss: 4550.638\n",
      " 11%|█         | 55/500 [02:00<20:12,  2.72s/it]INFO:root:global_step: 55, logpy: -4450.465, kl: 2033.250, loss: 4528.005\n",
      " 11%|█         | 56/500 [02:01<18:25,  2.49s/it]INFO:root:global_step: 56, logpy: -4428.167, kl: 2014.186, loss: 4505.654\n",
      " 11%|█▏        | 57/500 [02:03<17:17,  2.34s/it]INFO:root:global_step: 57, logpy: -4406.660, kl: 1995.325, loss: 4484.115\n",
      " 12%|█▏        | 58/500 [02:05<16:31,  2.24s/it]INFO:root:global_step: 58, logpy: -4384.565, kl: 1976.518, loss: 4461.922\n",
      " 12%|█▏        | 59/500 [02:07<15:54,  2.16s/it]INFO:root:global_step: 59, logpy: -4362.582, kl: 1957.910, loss: 4439.860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 60/500 [02:10<15:56,  2.17s/it]INFO:root:global_step: 60, logpy: -4341.832, kl: 1939.557, loss: 4419.085\n",
      " 12%|█▏        | 61/500 [02:12<15:35,  2.13s/it]INFO:root:global_step: 61, logpy: -4321.140, kl: 1921.371, loss: 4398.370\n",
      " 12%|█▏        | 62/500 [02:14<15:20,  2.10s/it]INFO:root:global_step: 62, logpy: -4300.306, kl: 1903.354, loss: 4377.518\n",
      " 13%|█▎        | 63/500 [02:16<15:08,  2.08s/it]INFO:root:global_step: 63, logpy: -4279.478, kl: 1885.496, loss: 4356.671\n",
      " 13%|█▎        | 64/500 [02:18<14:56,  2.06s/it]INFO:root:global_step: 64, logpy: -4258.554, kl: 1867.780, loss: 4335.714\n",
      " 13%|█▎        | 65/500 [02:20<14:52,  2.05s/it]INFO:root:global_step: 65, logpy: -4237.383, kl: 1850.175, loss: 4314.481\n",
      " 13%|█▎        | 66/500 [02:22<14:50,  2.05s/it]INFO:root:global_step: 66, logpy: -4218.420, kl: 1832.913, loss: 4295.576\n",
      " 13%|█▎        | 67/500 [02:24<14:59,  2.08s/it]INFO:root:global_step: 67, logpy: -4198.536, kl: 1815.785, loss: 4275.738\n",
      " 14%|█▎        | 68/500 [02:26<14:44,  2.05s/it]INFO:root:global_step: 68, logpy: -4179.187, kl: 1798.853, loss: 4256.463\n",
      " 14%|█▍        | 69/500 [02:28<14:51,  2.07s/it]INFO:root:global_step: 69, logpy: -4160.392, kl: 1782.161, loss: 4237.803\n",
      " 14%|█▍        | 70/500 [02:30<14:48,  2.07s/it]INFO:root:global_step: 70, logpy: -4141.096, kl: 1765.497, loss: 4218.554\n",
      " 14%|█▍        | 71/500 [02:32<14:50,  2.07s/it]INFO:root:global_step: 71, logpy: -4121.902, kl: 1749.080, loss: 4199.477\n",
      " 14%|█▍        | 72/500 [02:34<14:58,  2.10s/it]INFO:root:global_step: 72, logpy: -4101.760, kl: 1732.593, loss: 4179.292\n",
      " 15%|█▍        | 73/500 [02:37<15:22,  2.16s/it]INFO:root:global_step: 73, logpy: -4082.734, kl: 1716.413, loss: 4160.339\n",
      " 15%|█▍        | 74/500 [02:39<14:53,  2.10s/it]INFO:root:global_step: 74, logpy: -4064.288, kl: 1700.405, loss: 4141.984\n",
      " 15%|█▌        | 75/500 [02:41<14:51,  2.10s/it]INFO:root:global_step: 75, logpy: -4045.684, kl: 1684.527, loss: 4123.459\n",
      " 15%|█▌        | 76/500 [02:43<14:46,  2.09s/it]INFO:root:global_step: 76, logpy: -4027.733, kl: 1668.888, loss: 4105.659\n",
      " 15%|█▌        | 77/500 [02:45<15:06,  2.14s/it]INFO:root:global_step: 77, logpy: -4009.892, kl: 1653.392, loss: 4087.969\n",
      " 16%|█▌        | 78/500 [02:47<14:44,  2.10s/it]INFO:root:global_step: 78, logpy: -3991.542, kl: 1638.016, loss: 4069.753\n",
      " 16%|█▌        | 79/500 [02:49<14:27,  2.06s/it]INFO:root:global_step: 79, logpy: -3973.930, kl: 1622.810, loss: 4052.298\n",
      " 16%|█▌        | 80/500 [02:51<14:30,  2.07s/it]INFO:root:global_step: 80, logpy: -3956.801, kl: 1607.820, loss: 4035.388\n",
      " 16%|█▌        | 81/500 [02:53<14:17,  2.05s/it]INFO:root:global_step: 81, logpy: -3939.890, kl: 1592.932, loss: 4018.667\n",
      " 16%|█▋        | 82/500 [02:55<14:08,  2.03s/it]INFO:root:global_step: 82, logpy: -3923.086, kl: 1578.206, loss: 4002.075\n",
      " 17%|█▋        | 83/500 [02:57<14:16,  2.05s/it]INFO:root:global_step: 83, logpy: -3904.834, kl: 1563.506, loss: 3983.941\n",
      " 17%|█▋        | 84/500 [02:59<14:21,  2.07s/it]INFO:root:global_step: 84, logpy: -3887.138, kl: 1548.964, loss: 3966.383\n",
      " 17%|█▋        | 85/500 [03:01<14:05,  2.04s/it]INFO:root:global_step: 85, logpy: -3870.271, kl: 1534.601, loss: 3949.693\n",
      " 17%|█▋        | 86/500 [03:03<14:19,  2.08s/it]INFO:root:global_step: 86, logpy: -3853.735, kl: 1520.341, loss: 3933.308\n",
      " 17%|█▋        | 87/500 [03:05<14:07,  2.05s/it]INFO:root:global_step: 87, logpy: -3837.186, kl: 1506.233, loss: 3916.926\n",
      " 18%|█▊        | 88/500 [03:07<13:57,  2.03s/it]INFO:root:global_step: 88, logpy: -3820.653, kl: 1492.358, loss: 3900.654\n",
      " 18%|█▊        | 89/500 [03:10<13:59,  2.04s/it]INFO:root:global_step: 89, logpy: -3804.695, kl: 1478.582, loss: 3884.927\n",
      " 18%|█▊        | 90/500 [03:12<14:09,  2.07s/it]INFO:root:global_step: 90, logpy: -3788.262, kl: 1464.880, loss: 3868.679\n",
      " 18%|█▊        | 91/500 [03:14<14:01,  2.06s/it]INFO:root:global_step: 91, logpy: -3773.774, kl: 1451.573, loss: 3854.621\n",
      " 18%|█▊        | 92/500 [03:16<13:59,  2.06s/it]INFO:root:global_step: 92, logpy: -3758.435, kl: 1438.201, loss: 3839.537\n",
      " 19%|█▊        | 93/500 [03:18<13:52,  2.04s/it]INFO:root:global_step: 93, logpy: -3743.146, kl: 1424.973, loss: 3824.523\n",
      " 19%|█▉        | 94/500 [03:20<14:03,  2.08s/it]INFO:root:global_step: 94, logpy: -3728.461, kl: 1411.987, loss: 3810.224\n",
      " 19%|█▉        | 95/500 [03:22<13:49,  2.05s/it]INFO:root:global_step: 95, logpy: -3713.300, kl: 1398.991, loss: 3795.324\n",
      " 19%|█▉        | 96/500 [03:24<13:33,  2.01s/it]INFO:root:global_step: 96, logpy: -3698.725, kl: 1386.204, loss: 3781.096\n",
      " 19%|█▉        | 97/500 [03:26<13:48,  2.05s/it]INFO:root:global_step: 97, logpy: -3683.761, kl: 1373.439, loss: 3766.383\n",
      " 20%|█▉        | 98/500 [03:28<13:48,  2.06s/it]INFO:root:global_step: 98, logpy: -3669.288, kl: 1360.818, loss: 3752.186\n",
      " 20%|█▉        | 99/500 [03:30<14:02,  2.10s/it]INFO:root:global_step: 99, logpy: -3654.021, kl: 1348.347, loss: 3737.228\n",
      " 20%|██        | 100/500 [03:32<13:57,  2.09s/it]INFO:root:Saved figure at: ./sim/global_step_100.png\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_core/sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 100, logpy: -3640.196, kl: 1336.067, loss: 3723.774\n",
      " 20%|██        | 101/500 [03:43<30:31,  4.59s/it]INFO:root:global_step: 101, logpy: -3625.272, kl: 1323.862, loss: 3709.170\n",
      " 20%|██        | 102/500 [03:45<25:44,  3.88s/it]INFO:root:global_step: 102, logpy: -3611.160, kl: 1311.771, loss: 3695.366\n",
      " 21%|██        | 103/500 [03:47<22:00,  3.33s/it]INFO:root:global_step: 103, logpy: -3598.763, kl: 1299.950, loss: 3683.423\n",
      " 21%|██        | 104/500 [03:49<19:58,  3.03s/it]INFO:root:global_step: 104, logpy: -3585.735, kl: 1288.261, loss: 3670.859\n",
      " 21%|██        | 105/500 [03:51<18:08,  2.75s/it]INFO:root:global_step: 105, logpy: -3572.166, kl: 1276.593, loss: 3657.654\n",
      " 21%|██        | 106/500 [03:54<17:02,  2.60s/it]INFO:root:global_step: 106, logpy: -3558.732, kl: 1264.965, loss: 3644.503\n",
      " 21%|██▏       | 107/500 [03:56<15:48,  2.41s/it]INFO:root:global_step: 107, logpy: -3545.733, kl: 1253.482, loss: 3631.814\n",
      " 22%|██▏       | 108/500 [03:58<14:57,  2.29s/it]INFO:root:global_step: 108, logpy: -3532.732, kl: 1242.107, loss: 3619.111\n",
      " 22%|██▏       | 109/500 [04:00<14:19,  2.20s/it]INFO:root:global_step: 109, logpy: -3519.386, kl: 1230.809, loss: 3606.025\n",
      " 22%|██▏       | 110/500 [04:02<13:50,  2.13s/it]INFO:root:global_step: 110, logpy: -3506.489, kl: 1219.695, loss: 3593.455\n",
      " 22%|██▏       | 111/500 [04:04<14:01,  2.16s/it]INFO:root:global_step: 111, logpy: -3494.597, kl: 1208.750, loss: 3581.946\n",
      " 22%|██▏       | 112/500 [04:06<14:07,  2.18s/it]INFO:root:global_step: 112, logpy: -3480.949, kl: 1197.759, loss: 3568.520\n",
      " 23%|██▎       | 113/500 [04:08<13:44,  2.13s/it]INFO:root:global_step: 113, logpy: -3468.282, kl: 1186.936, loss: 3556.133\n",
      " 23%|██▎       | 114/500 [04:10<13:21,  2.08s/it]INFO:root:global_step: 114, logpy: -3455.502, kl: 1176.252, loss: 3543.659\n",
      " 23%|██▎       | 115/500 [04:12<13:04,  2.04s/it]INFO:root:global_step: 115, logpy: -3443.677, kl: 1165.728, loss: 3532.192\n",
      " 23%|██▎       | 116/500 [04:14<13:26,  2.10s/it]INFO:root:global_step: 116, logpy: -3430.309, kl: 1155.129, loss: 3518.997\n",
      " 23%|██▎       | 117/500 [04:16<13:37,  2.13s/it]INFO:root:global_step: 117, logpy: -3417.741, kl: 1144.704, loss: 3506.668\n",
      " 24%|██▎       | 118/500 [04:18<13:10,  2.07s/it]INFO:root:global_step: 118, logpy: -3405.612, kl: 1134.400, loss: 3494.792\n",
      " 24%|██▍       | 119/500 [04:20<13:04,  2.06s/it]INFO:root:global_step: 119, logpy: -3392.895, kl: 1124.158, loss: 3482.286\n",
      " 24%|██▍       | 120/500 [04:23<13:12,  2.09s/it]INFO:root:global_step: 120, logpy: -3381.245, kl: 1114.119, loss: 3470.944\n",
      " 24%|██▍       | 121/500 [04:25<13:20,  2.11s/it]INFO:root:global_step: 121, logpy: -3369.444, kl: 1104.131, loss: 3459.399\n",
      " 24%|██▍       | 122/500 [04:27<13:04,  2.08s/it]INFO:root:global_step: 122, logpy: -3357.457, kl: 1094.210, loss: 3447.632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 123/500 [04:29<12:59,  2.07s/it]INFO:root:global_step: 123, logpy: -3346.044, kl: 1084.463, loss: 3436.513\n",
      " 25%|██▍       | 124/500 [04:31<12:52,  2.05s/it]INFO:root:global_step: 124, logpy: -3334.519, kl: 1074.772, loss: 3425.237\n",
      " 25%|██▌       | 125/500 [04:33<12:58,  2.08s/it]INFO:root:global_step: 125, logpy: -3323.466, kl: 1065.221, loss: 3414.474\n",
      " 25%|██▌       | 126/500 [04:35<12:56,  2.08s/it]INFO:root:global_step: 126, logpy: -3313.229, kl: 1055.839, loss: 3404.597\n",
      " 25%|██▌       | 127/500 [04:37<12:58,  2.09s/it]INFO:root:global_step: 127, logpy: -3302.928, kl: 1046.542, loss: 3394.644\n",
      " 26%|██▌       | 128/500 [04:39<12:42,  2.05s/it]INFO:root:global_step: 128, logpy: -3292.513, kl: 1037.266, loss: 3384.501\n",
      " 26%|██▌       | 129/500 [04:41<12:37,  2.04s/it]INFO:root:global_step: 129, logpy: -3281.330, kl: 1028.012, loss: 3373.517\n",
      " 26%|██▌       | 130/500 [04:43<12:26,  2.02s/it]INFO:root:global_step: 130, logpy: -3270.397, kl: 1018.844, loss: 3362.774\n",
      " 26%|██▌       | 131/500 [04:45<12:24,  2.02s/it]INFO:root:global_step: 131, logpy: -3259.028, kl: 1009.723, loss: 3351.549\n",
      " 26%|██▋       | 132/500 [04:47<12:39,  2.06s/it]INFO:root:global_step: 132, logpy: -3248.452, kl: 1000.814, loss: 3341.236\n",
      " 27%|██▋       | 133/500 [04:49<12:25,  2.03s/it]INFO:root:global_step: 133, logpy: -3238.946, kl: 992.046, loss: 3332.042\n",
      " 27%|██▋       | 134/500 [04:51<12:19,  2.02s/it]INFO:root:global_step: 134, logpy: -3230.408, kl: 983.443, loss: 3323.891\n",
      " 27%|██▋       | 135/500 [04:53<12:17,  2.02s/it]INFO:root:global_step: 135, logpy: -3219.508, kl: 974.728, loss: 3313.176\n",
      " 27%|██▋       | 136/500 [04:55<12:12,  2.01s/it]INFO:root:global_step: 136, logpy: -3209.584, kl: 966.146, loss: 3303.480\n",
      " 27%|██▋       | 137/500 [04:57<12:11,  2.01s/it]INFO:root:global_step: 137, logpy: -3197.990, kl: 957.471, loss: 3291.933\n",
      " 28%|██▊       | 138/500 [04:59<12:08,  2.01s/it]INFO:root:global_step: 138, logpy: -3187.314, kl: 948.997, loss: 3281.419\n",
      " 28%|██▊       | 139/500 [05:01<12:03,  2.00s/it]INFO:root:global_step: 139, logpy: -3178.392, kl: 940.736, loss: 3272.784\n",
      " 28%|██▊       | 140/500 [05:03<11:55,  1.99s/it]INFO:root:global_step: 140, logpy: -3168.093, kl: 932.432, loss: 3262.645\n",
      " 28%|██▊       | 141/500 [05:05<11:52,  1.98s/it]INFO:root:global_step: 141, logpy: -3158.373, kl: 924.267, loss: 3253.139\n",
      " 28%|██▊       | 142/500 [05:07<11:55,  2.00s/it]INFO:root:global_step: 142, logpy: -3147.313, kl: 916.026, loss: 3242.133\n",
      " 29%|██▊       | 143/500 [05:09<11:53,  2.00s/it]INFO:root:global_step: 143, logpy: -3138.048, kl: 908.009, loss: 3233.063\n",
      " 29%|██▉       | 144/500 [05:11<11:45,  1.98s/it]INFO:root:global_step: 144, logpy: -3128.380, kl: 900.028, loss: 3223.544\n",
      " 29%|██▉       | 145/500 [05:13<11:41,  1.98s/it]INFO:root:global_step: 145, logpy: -3120.119, kl: 892.285, loss: 3215.588\n",
      " 29%|██▉       | 146/500 [05:15<11:41,  1.98s/it]INFO:root:global_step: 146, logpy: -3110.505, kl: 884.447, loss: 3206.104\n",
      " 29%|██▉       | 147/500 [05:17<11:58,  2.04s/it]INFO:root:global_step: 147, logpy: -3101.646, kl: 876.755, loss: 3197.442\n",
      " 30%|██▉       | 148/500 [05:19<11:50,  2.02s/it]INFO:root:global_step: 148, logpy: -3093.739, kl: 869.268, loss: 3189.858\n",
      " 30%|██▉       | 149/500 [05:21<11:47,  2.02s/it]INFO:root:global_step: 149, logpy: -3085.565, kl: 861.800, loss: 3181.947\n",
      " 30%|███       | 150/500 [05:23<11:42,  2.01s/it]INFO:root:Saved figure at: ./sim/global_step_150.png\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_core/sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 150, logpy: -3077.313, kl: 854.417, loss: 3173.967\n",
      " 30%|███       | 151/500 [05:34<26:14,  4.51s/it]INFO:root:global_step: 151, logpy: -3068.479, kl: 847.015, loss: 3165.308\n",
      " 30%|███       | 152/500 [05:36<22:12,  3.83s/it]INFO:root:global_step: 152, logpy: -3059.889, kl: 839.727, loss: 3156.932\n",
      " 31%|███       | 153/500 [05:38<19:14,  3.33s/it]INFO:root:global_step: 153, logpy: -3050.427, kl: 832.427, loss: 3147.597\n",
      " 31%|███       | 154/500 [05:40<16:48,  2.92s/it]INFO:root:global_step: 154, logpy: -3042.826, kl: 825.363, loss: 3140.284\n",
      " 31%|███       | 155/500 [05:42<15:04,  2.62s/it]INFO:root:global_step: 155, logpy: -3034.620, kl: 818.337, loss: 3132.331\n",
      " 31%|███       | 156/500 [05:44<13:56,  2.43s/it]INFO:root:global_step: 156, logpy: -3027.469, kl: 811.500, loss: 3125.550\n",
      " 31%|███▏      | 157/500 [05:46<13:08,  2.30s/it]INFO:root:global_step: 157, logpy: -3019.085, kl: 804.522, loss: 3117.321\n",
      " 32%|███▏      | 158/500 [05:48<13:03,  2.29s/it]INFO:root:global_step: 158, logpy: -3010.431, kl: 797.521, loss: 3108.730\n",
      " 32%|███▏      | 159/500 [05:50<12:34,  2.21s/it]INFO:root:global_step: 159, logpy: -3002.659, kl: 790.764, loss: 3101.193\n",
      " 32%|███▏      | 160/500 [05:52<12:07,  2.14s/it]INFO:root:global_step: 160, logpy: -2995.515, kl: 784.123, loss: 3094.330\n",
      " 32%|███▏      | 161/500 [05:54<11:53,  2.10s/it]INFO:root:global_step: 161, logpy: -2987.758, kl: 777.468, loss: 3086.771\n",
      " 32%|███▏      | 162/500 [05:56<11:32,  2.05s/it]INFO:root:global_step: 162, logpy: -2980.410, kl: 770.882, loss: 3079.622\n",
      " 33%|███▎      | 163/500 [05:58<11:22,  2.03s/it]INFO:root:global_step: 163, logpy: -2973.281, kl: 764.325, loss: 3072.652\n",
      " 33%|███▎      | 164/500 [06:00<11:20,  2.02s/it]INFO:root:global_step: 164, logpy: -2966.604, kl: 757.964, loss: 3066.264\n",
      " 33%|███▎      | 165/500 [06:02<11:14,  2.01s/it]INFO:root:global_step: 165, logpy: -2960.051, kl: 751.635, loss: 3059.965\n",
      " 33%|███▎      | 166/500 [06:04<11:21,  2.04s/it]INFO:root:global_step: 166, logpy: -2953.448, kl: 745.370, loss: 3053.614\n",
      " 33%|███▎      | 167/500 [06:06<11:21,  2.05s/it]INFO:root:global_step: 167, logpy: -2945.892, kl: 739.087, loss: 3046.228\n",
      " 34%|███▎      | 168/500 [06:08<11:34,  2.09s/it]INFO:root:global_step: 168, logpy: -2939.684, kl: 732.952, loss: 3040.272\n",
      " 34%|███▍      | 169/500 [06:11<11:38,  2.11s/it]INFO:root:global_step: 169, logpy: -2932.456, kl: 726.780, loss: 3033.195\n",
      " 34%|███▍      | 170/500 [06:13<11:34,  2.10s/it]INFO:root:global_step: 170, logpy: -2924.635, kl: 720.596, loss: 3025.451\n",
      " 34%|███▍      | 171/500 [06:15<11:16,  2.06s/it]INFO:root:global_step: 171, logpy: -2917.480, kl: 714.523, loss: 3018.420\n",
      " 34%|███▍      | 172/500 [06:17<11:52,  2.17s/it]INFO:root:global_step: 172, logpy: -2911.226, kl: 708.646, loss: 3012.425\n",
      " 35%|███▍      | 173/500 [06:19<11:44,  2.15s/it]INFO:root:global_step: 173, logpy: -2903.367, kl: 702.655, loss: 3004.649\n",
      " 35%|███▍      | 174/500 [06:21<11:39,  2.14s/it]INFO:root:global_step: 174, logpy: -2895.529, kl: 696.688, loss: 2996.858\n",
      " 35%|███▌      | 175/500 [06:23<11:38,  2.15s/it]INFO:root:global_step: 175, logpy: -2888.039, kl: 690.810, loss: 2989.444\n",
      " 35%|███▌      | 176/500 [06:25<11:21,  2.10s/it]INFO:root:global_step: 176, logpy: -2879.767, kl: 684.933, loss: 2981.189\n",
      " 35%|███▌      | 177/500 [06:27<11:12,  2.08s/it]INFO:root:global_step: 177, logpy: -2872.970, kl: 679.206, loss: 2974.500\n",
      " 36%|███▌      | 178/500 [06:30<11:11,  2.08s/it]INFO:root:global_step: 178, logpy: -2866.754, kl: 673.661, loss: 2968.516\n",
      " 36%|███▌      | 179/500 [06:32<11:17,  2.11s/it]INFO:root:global_step: 179, logpy: -2860.103, kl: 668.099, loss: 2962.022\n",
      " 36%|███▌      | 180/500 [06:34<11:10,  2.10s/it]INFO:root:global_step: 180, logpy: -2853.667, kl: 662.579, loss: 2955.729\n",
      " 36%|███▌      | 181/500 [06:36<11:08,  2.09s/it]INFO:root:global_step: 181, logpy: -2847.070, kl: 657.118, loss: 2949.275\n",
      " 36%|███▋      | 182/500 [06:38<10:52,  2.05s/it]INFO:root:global_step: 182, logpy: -2840.583, kl: 651.664, loss: 2942.883\n",
      " 37%|███▋      | 183/500 [06:40<10:50,  2.05s/it]INFO:root:global_step: 183, logpy: -2835.222, kl: 646.438, loss: 2937.790\n",
      " 37%|███▋      | 184/500 [06:42<10:59,  2.09s/it]INFO:root:global_step: 184, logpy: -2829.584, kl: 641.146, loss: 2932.299\n",
      " 37%|███▋      | 185/500 [06:44<10:49,  2.06s/it]INFO:root:global_step: 185, logpy: -2824.085, kl: 635.998, loss: 2927.036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 186/500 [06:46<10:48,  2.06s/it]INFO:root:global_step: 186, logpy: -2818.223, kl: 630.844, loss: 2921.350\n",
      " 37%|███▋      | 187/500 [06:48<10:33,  2.02s/it]INFO:root:global_step: 187, logpy: -2812.250, kl: 625.677, loss: 2915.488\n",
      " 38%|███▊      | 188/500 [06:50<10:31,  2.02s/it]INFO:root:global_step: 188, logpy: -2805.200, kl: 620.484, loss: 2908.468\n",
      " 38%|███▊      | 189/500 [06:52<10:29,  2.02s/it]INFO:root:global_step: 189, logpy: -2800.023, kl: 615.547, loss: 2903.528\n",
      " 38%|███▊      | 190/500 [06:54<10:24,  2.02s/it]INFO:root:global_step: 190, logpy: -2791.931, kl: 610.351, loss: 2895.360\n",
      " 38%|███▊      | 191/500 [06:56<10:17,  2.00s/it]INFO:root:global_step: 191, logpy: -2785.089, kl: 605.276, loss: 2888.512\n",
      " 38%|███▊      | 192/500 [06:58<10:18,  2.01s/it]INFO:root:global_step: 192, logpy: -2779.386, kl: 600.335, loss: 2882.887\n",
      " 39%|███▊      | 193/500 [07:00<10:20,  2.02s/it]INFO:root:global_step: 193, logpy: -2773.336, kl: 595.465, loss: 2876.936\n",
      " 39%|███▉      | 194/500 [07:02<10:14,  2.01s/it]INFO:root:global_step: 194, logpy: -2767.899, kl: 590.704, loss: 2871.655\n",
      " 39%|███▉      | 195/500 [07:04<10:20,  2.04s/it]INFO:root:global_step: 195, logpy: -2761.974, kl: 585.921, loss: 2865.817\n",
      " 39%|███▉      | 196/500 [07:07<10:43,  2.12s/it]INFO:root:global_step: 196, logpy: -2755.900, kl: 581.165, loss: 2859.808\n",
      " 39%|███▉      | 197/500 [07:09<10:30,  2.08s/it]INFO:root:global_step: 197, logpy: -2750.719, kl: 576.465, loss: 2854.699\n",
      " 40%|███▉      | 198/500 [07:11<10:29,  2.08s/it]INFO:root:global_step: 198, logpy: -2744.627, kl: 571.765, loss: 2848.632\n",
      " 40%|███▉      | 199/500 [07:13<10:19,  2.06s/it]INFO:root:global_step: 199, logpy: -2738.020, kl: 567.114, loss: 2842.052\n",
      " 40%|████      | 200/500 [07:15<10:12,  2.04s/it]INFO:root:Saved figure at: ./sim/global_step_200.png\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_core/sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 200, logpy: -2732.860, kl: 562.661, loss: 2837.069\n",
      " 40%|████      | 201/500 [07:26<23:26,  4.70s/it]INFO:root:global_step: 201, logpy: -2727.206, kl: 558.164, loss: 2831.503\n",
      " 40%|████      | 202/500 [07:28<19:48,  3.99s/it]INFO:root:global_step: 202, logpy: -2722.057, kl: 553.758, loss: 2826.486\n",
      " 41%|████      | 203/500 [07:30<17:17,  3.49s/it]INFO:root:global_step: 203, logpy: -2716.466, kl: 549.330, loss: 2820.961\n",
      " 41%|████      | 204/500 [07:32<14:58,  3.04s/it]INFO:root:global_step: 204, logpy: -2712.260, kl: 545.073, loss: 2816.946\n",
      " 41%|████      | 205/500 [07:34<13:24,  2.73s/it]INFO:root:global_step: 205, logpy: -2707.604, kl: 540.797, loss: 2812.418\n",
      " 41%|████      | 206/500 [07:37<12:49,  2.62s/it]INFO:root:global_step: 206, logpy: -2703.712, kl: 536.711, loss: 2808.799\n",
      " 41%|████▏     | 207/500 [07:39<12:18,  2.52s/it]INFO:root:global_step: 207, logpy: -2700.768, kl: 532.684, loss: 2806.146\n",
      " 42%|████▏     | 208/500 [07:41<11:47,  2.42s/it]INFO:root:global_step: 208, logpy: -2696.621, kl: 528.586, loss: 2802.173\n",
      " 42%|████▏     | 209/500 [07:43<11:13,  2.31s/it]INFO:root:global_step: 209, logpy: -2691.693, kl: 524.416, loss: 2797.306\n",
      " 42%|████▏     | 210/500 [07:45<10:45,  2.23s/it]INFO:root:global_step: 210, logpy: -2686.928, kl: 520.318, loss: 2792.631\n",
      " 42%|████▏     | 211/500 [07:47<10:23,  2.16s/it]INFO:root:global_step: 211, logpy: -2683.762, kl: 516.434, loss: 2789.726\n",
      " 42%|████▏     | 212/500 [07:49<10:02,  2.09s/it]INFO:root:global_step: 212, logpy: -2679.907, kl: 512.494, loss: 2786.036\n",
      " 43%|████▎     | 213/500 [07:51<09:59,  2.09s/it]INFO:root:global_step: 213, logpy: -2675.240, kl: 508.605, loss: 2781.544\n",
      " 43%|████▎     | 214/500 [07:53<10:06,  2.12s/it]INFO:root:global_step: 214, logpy: -2671.375, kl: 504.716, loss: 2777.813\n",
      " 43%|████▎     | 215/500 [07:55<09:59,  2.10s/it]INFO:root:global_step: 215, logpy: -2667.944, kl: 500.981, loss: 2774.630\n",
      " 43%|████▎     | 216/500 [07:57<09:47,  2.07s/it]INFO:root:global_step: 216, logpy: -2662.630, kl: 497.035, loss: 2769.313\n",
      " 43%|████▎     | 217/500 [08:00<10:17,  2.18s/it]INFO:root:global_step: 217, logpy: -2658.570, kl: 493.213, loss: 2765.335\n",
      " 44%|████▎     | 218/500 [08:02<10:07,  2.15s/it]INFO:root:global_step: 218, logpy: -2653.630, kl: 489.399, loss: 2760.445\n",
      " 44%|████▍     | 219/500 [08:04<09:58,  2.13s/it]INFO:root:global_step: 219, logpy: -2649.675, kl: 485.725, loss: 2756.642\n",
      " 44%|████▍     | 220/500 [08:06<09:51,  2.11s/it]INFO:root:global_step: 220, logpy: -2644.612, kl: 481.989, loss: 2751.630\n",
      " 44%|████▍     | 221/500 [08:08<09:49,  2.11s/it]INFO:root:global_step: 221, logpy: -2640.484, kl: 478.362, loss: 2747.624\n",
      " 44%|████▍     | 222/500 [08:10<09:55,  2.14s/it]INFO:root:global_step: 222, logpy: -2636.302, kl: 474.728, loss: 2743.522\n",
      " 45%|████▍     | 223/500 [08:12<09:40,  2.10s/it]INFO:root:global_step: 223, logpy: -2632.942, kl: 471.230, loss: 2740.339\n",
      " 45%|████▍     | 224/500 [08:15<09:46,  2.13s/it]INFO:root:global_step: 224, logpy: -2628.831, kl: 467.706, loss: 2736.341\n",
      " 45%|████▌     | 225/500 [08:17<09:42,  2.12s/it]INFO:root:global_step: 225, logpy: -2624.046, kl: 464.138, loss: 2731.590\n",
      " 45%|████▌     | 226/500 [08:19<09:28,  2.07s/it]INFO:root:global_step: 226, logpy: -2619.485, kl: 460.564, loss: 2727.022\n",
      " 45%|████▌     | 227/500 [08:21<09:28,  2.08s/it]INFO:root:global_step: 227, logpy: -2615.850, kl: 457.135, loss: 2723.488\n",
      " 46%|████▌     | 228/500 [08:23<09:19,  2.06s/it]INFO:root:global_step: 228, logpy: -2612.881, kl: 453.863, loss: 2720.743\n",
      " 46%|████▌     | 229/500 [08:25<09:21,  2.07s/it]INFO:root:global_step: 229, logpy: -2609.972, kl: 450.610, loss: 2718.041\n",
      " 46%|████▌     | 230/500 [08:27<09:17,  2.06s/it]INFO:root:global_step: 230, logpy: -2606.025, kl: 447.295, loss: 2714.203\n",
      " 46%|████▌     | 231/500 [08:29<09:06,  2.03s/it]INFO:root:global_step: 231, logpy: -2601.881, kl: 443.957, loss: 2710.113\n",
      " 46%|████▋     | 232/500 [08:31<09:34,  2.14s/it]INFO:root:global_step: 232, logpy: -2599.337, kl: 440.794, loss: 2707.762\n",
      " 47%|████▋     | 233/500 [08:33<09:39,  2.17s/it]INFO:root:global_step: 233, logpy: -2596.520, kl: 437.661, loss: 2705.136\n",
      " 47%|████▋     | 234/500 [08:36<09:33,  2.16s/it]INFO:root:global_step: 234, logpy: -2594.029, kl: 434.587, loss: 2702.862\n",
      " 47%|████▋     | 235/500 [08:38<09:20,  2.11s/it]INFO:root:global_step: 235, logpy: -2589.625, kl: 431.350, loss: 2698.478\n",
      " 47%|████▋     | 236/500 [08:40<09:17,  2.11s/it]INFO:root:global_step: 236, logpy: -2585.820, kl: 428.213, loss: 2694.762\n",
      " 47%|████▋     | 237/500 [08:42<09:10,  2.09s/it]INFO:root:global_step: 237, logpy: -2581.750, kl: 425.017, loss: 2690.688\n",
      " 48%|████▊     | 238/500 [08:44<09:30,  2.18s/it]INFO:root:global_step: 238, logpy: -2577.843, kl: 421.889, loss: 2686.813\n",
      " 48%|████▊     | 239/500 [08:46<09:26,  2.17s/it]INFO:root:global_step: 239, logpy: -2573.695, kl: 418.775, loss: 2682.681\n",
      " 48%|████▊     | 240/500 [08:48<09:09,  2.11s/it]INFO:root:global_step: 240, logpy: -2569.884, kl: 415.766, loss: 2678.959\n",
      " 48%|████▊     | 241/500 [08:50<09:05,  2.11s/it]INFO:root:global_step: 241, logpy: -2566.208, kl: 412.782, loss: 2675.366\n",
      " 48%|████▊     | 242/500 [08:52<09:00,  2.10s/it]INFO:root:global_step: 242, logpy: -2563.401, kl: 409.872, loss: 2672.686\n",
      " 49%|████▊     | 243/500 [08:54<08:45,  2.04s/it]INFO:root:global_step: 243, logpy: -2558.499, kl: 406.771, loss: 2667.687\n",
      " 49%|████▉     | 244/500 [08:56<08:43,  2.05s/it]INFO:root:global_step: 244, logpy: -2554.504, kl: 403.756, loss: 2663.654\n",
      " 49%|████▉     | 245/500 [08:58<08:35,  2.02s/it]INFO:root:global_step: 245, logpy: -2550.759, kl: 400.821, loss: 2659.919\n",
      " 49%|████▉     | 246/500 [09:01<08:43,  2.06s/it]INFO:root:global_step: 246, logpy: -2546.275, kl: 397.901, loss: 2655.433\n",
      " 49%|████▉     | 247/500 [09:03<08:36,  2.04s/it]INFO:root:global_step: 247, logpy: -2541.512, kl: 394.965, loss: 2650.621\n",
      " 50%|████▉     | 248/500 [09:04<08:28,  2.02s/it]INFO:root:global_step: 248, logpy: -2537.944, kl: 392.153, loss: 2647.100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 249/500 [09:06<08:26,  2.02s/it]INFO:root:global_step: 249, logpy: -2534.652, kl: 389.390, loss: 2643.874\n",
      " 50%|█████     | 250/500 [09:08<08:19,  2.00s/it]INFO:root:Saved figure at: ./sim/global_step_250.png\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_core/sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 250, logpy: -2530.529, kl: 386.592, loss: 2639.755\n",
      " 50%|█████     | 251/500 [09:19<19:03,  4.59s/it]INFO:root:global_step: 251, logpy: -2528.212, kl: 383.955, loss: 2637.575\n",
      " 50%|█████     | 252/500 [09:22<16:24,  3.97s/it]INFO:root:global_step: 252, logpy: -2525.958, kl: 381.392, loss: 2635.504\n",
      " 51%|█████     | 253/500 [09:24<14:20,  3.48s/it]INFO:root:global_step: 253, logpy: -2522.222, kl: 378.678, loss: 2631.771\n",
      " 51%|█████     | 254/500 [09:26<13:03,  3.19s/it]INFO:root:global_step: 254, logpy: -2519.230, kl: 376.059, loss: 2628.853\n",
      " 51%|█████     | 255/500 [09:29<11:39,  2.85s/it]INFO:root:global_step: 255, logpy: -2516.122, kl: 373.460, loss: 2625.810\n",
      " 51%|█████     | 256/500 [09:31<10:45,  2.65s/it]INFO:root:global_step: 256, logpy: -2512.467, kl: 370.828, loss: 2622.160\n",
      " 51%|█████▏    | 257/500 [09:33<09:58,  2.46s/it]INFO:root:global_step: 257, logpy: -2509.830, kl: 368.325, loss: 2619.631\n",
      " 52%|█████▏    | 258/500 [09:35<09:18,  2.31s/it]INFO:root:global_step: 258, logpy: -2506.864, kl: 365.827, loss: 2616.753\n",
      " 52%|█████▏    | 259/500 [09:37<09:09,  2.28s/it]INFO:root:global_step: 259, logpy: -2503.156, kl: 363.274, loss: 2613.051\n",
      " 52%|█████▏    | 260/500 [09:39<08:44,  2.19s/it]INFO:root:global_step: 260, logpy: -2499.773, kl: 360.744, loss: 2609.672\n",
      " 52%|█████▏    | 261/500 [09:41<08:42,  2.19s/it]INFO:root:global_step: 261, logpy: -2496.312, kl: 358.248, loss: 2606.224\n",
      " 52%|█████▏    | 262/500 [09:43<08:30,  2.15s/it]INFO:root:global_step: 262, logpy: -2493.649, kl: 355.856, loss: 2603.651\n",
      " 53%|█████▎    | 263/500 [09:45<08:18,  2.10s/it]INFO:root:global_step: 263, logpy: -2491.266, kl: 353.480, loss: 2601.352\n",
      " 53%|█████▎    | 264/500 [09:47<08:04,  2.05s/it]INFO:root:global_step: 264, logpy: -2488.061, kl: 351.083, loss: 2598.184\n",
      " 53%|█████▎    | 265/500 [09:49<08:06,  2.07s/it]INFO:root:global_step: 265, logpy: -2486.159, kl: 348.825, loss: 2596.433\n",
      " 53%|█████▎    | 266/500 [09:51<08:16,  2.12s/it]INFO:root:global_step: 266, logpy: -2483.827, kl: 346.543, loss: 2594.204\n",
      " 53%|█████▎    | 267/500 [09:54<08:17,  2.14s/it]INFO:root:global_step: 267, logpy: -2480.935, kl: 344.181, loss: 2591.312\n",
      " 54%|█████▎    | 268/500 [09:56<08:07,  2.10s/it]INFO:root:global_step: 268, logpy: -2478.298, kl: 341.895, loss: 2588.727\n",
      " 54%|█████▍    | 269/500 [09:58<07:54,  2.06s/it]INFO:root:global_step: 269, logpy: -2475.427, kl: 339.609, loss: 2585.885\n",
      " 54%|█████▍    | 270/500 [10:00<07:52,  2.05s/it]INFO:root:global_step: 270, logpy: -2472.675, kl: 337.351, loss: 2583.166\n",
      " 54%|█████▍    | 271/500 [10:02<07:45,  2.03s/it]INFO:root:global_step: 271, logpy: -2469.352, kl: 335.040, loss: 2579.801\n",
      " 54%|█████▍    | 272/500 [10:04<07:44,  2.04s/it]INFO:root:global_step: 272, logpy: -2468.053, kl: 333.000, loss: 2578.708\n",
      " 55%|█████▍    | 273/500 [10:06<07:52,  2.08s/it]INFO:root:global_step: 273, logpy: -2465.858, kl: 330.852, loss: 2576.588\n",
      " 55%|█████▍    | 274/500 [10:08<07:43,  2.05s/it]INFO:root:global_step: 274, logpy: -2462.717, kl: 328.629, loss: 2573.426\n",
      " 55%|█████▌    | 275/500 [10:10<07:37,  2.03s/it]INFO:root:global_step: 275, logpy: -2460.891, kl: 326.580, loss: 2571.729\n",
      " 55%|█████▌    | 276/500 [10:12<07:33,  2.03s/it]INFO:root:global_step: 276, logpy: -2458.608, kl: 324.505, loss: 2569.529\n",
      " 55%|█████▌    | 277/500 [10:14<07:31,  2.02s/it]INFO:root:global_step: 277, logpy: -2456.943, kl: 322.461, loss: 2567.956\n",
      " 56%|█████▌    | 278/500 [10:16<07:26,  2.01s/it]INFO:root:global_step: 278, logpy: -2454.833, kl: 320.416, loss: 2565.916\n",
      " 56%|█████▌    | 279/500 [10:18<07:30,  2.04s/it]INFO:root:global_step: 279, logpy: -2451.959, kl: 318.299, loss: 2563.017\n",
      " 56%|█████▌    | 280/500 [10:20<07:25,  2.02s/it]INFO:root:global_step: 280, logpy: -2448.798, kl: 316.231, loss: 2559.861\n",
      " 56%|█████▌    | 281/500 [10:22<07:18,  2.00s/it]INFO:root:global_step: 281, logpy: -2446.673, kl: 314.280, loss: 2557.838\n",
      " 56%|█████▋    | 282/500 [10:24<07:18,  2.01s/it]INFO:root:global_step: 282, logpy: -2444.116, kl: 312.270, loss: 2555.301\n",
      " 57%|█████▋    | 283/500 [10:26<07:16,  2.01s/it]INFO:root:global_step: 283, logpy: -2441.721, kl: 310.249, loss: 2552.896\n",
      " 57%|█████▋    | 284/500 [10:28<07:26,  2.07s/it]INFO:root:global_step: 284, logpy: -2439.061, kl: 308.291, loss: 2550.268\n",
      " 57%|█████▋    | 285/500 [10:30<07:24,  2.07s/it]INFO:root:global_step: 285, logpy: -2436.971, kl: 306.390, loss: 2548.248\n",
      " 57%|█████▋    | 286/500 [10:32<07:33,  2.12s/it]INFO:root:global_step: 286, logpy: -2434.583, kl: 304.402, loss: 2545.824\n",
      " 57%|█████▋    | 287/500 [10:35<07:44,  2.18s/it]INFO:root:global_step: 287, logpy: -2433.049, kl: 302.575, loss: 2544.394\n",
      " 58%|█████▊    | 288/500 [10:37<07:29,  2.12s/it]INFO:root:global_step: 288, logpy: -2430.253, kl: 300.635, loss: 2541.570\n",
      " 58%|█████▊    | 289/500 [10:39<07:29,  2.13s/it]INFO:root:global_step: 289, logpy: -2428.046, kl: 298.781, loss: 2539.402\n",
      " 58%|█████▊    | 290/500 [10:41<07:33,  2.16s/it]INFO:root:global_step: 290, logpy: -2425.489, kl: 296.906, loss: 2536.845\n",
      " 58%|█████▊    | 291/500 [10:43<07:19,  2.10s/it]INFO:root:global_step: 291, logpy: -2422.446, kl: 295.021, loss: 2533.773\n",
      " 58%|█████▊    | 292/500 [10:45<07:08,  2.06s/it]INFO:root:global_step: 292, logpy: -2420.965, kl: 293.320, loss: 2532.428\n",
      " 59%|█████▊    | 293/500 [10:47<07:05,  2.05s/it]INFO:root:global_step: 293, logpy: -2419.172, kl: 291.553, loss: 2530.686\n",
      " 59%|█████▉    | 294/500 [10:49<06:58,  2.03s/it]INFO:root:global_step: 294, logpy: -2416.842, kl: 289.779, loss: 2528.382\n",
      " 59%|█████▉    | 295/500 [10:51<06:57,  2.04s/it]INFO:root:global_step: 295, logpy: -2415.224, kl: 288.065, loss: 2526.833\n",
      " 59%|█████▉    | 296/500 [10:54<07:23,  2.17s/it]INFO:root:global_step: 296, logpy: -2412.383, kl: 286.259, loss: 2523.951\n",
      " 59%|█████▉    | 297/500 [10:55<07:07,  2.10s/it]INFO:root:global_step: 297, logpy: -2409.991, kl: 284.524, loss: 2521.570\n",
      " 60%|█████▉    | 298/500 [10:57<06:55,  2.06s/it]INFO:root:global_step: 298, logpy: -2406.957, kl: 282.787, loss: 2518.529\n",
      " 60%|█████▉    | 299/500 [10:59<06:51,  2.05s/it]INFO:root:global_step: 299, logpy: -2404.791, kl: 281.112, loss: 2516.400\n",
      " 60%|██████    | 300/500 [11:01<06:45,  2.03s/it]INFO:root:Saved figure at: ./sim/global_step_300.png\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_core/sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 300, logpy: -2402.653, kl: 279.441, loss: 2514.286\n",
      " 60%|██████    | 301/500 [11:13<15:59,  4.82s/it]INFO:root:global_step: 301, logpy: -2399.861, kl: 277.677, loss: 2511.408\n",
      " 60%|██████    | 302/500 [11:15<13:15,  4.02s/it]INFO:root:global_step: 302, logpy: -2398.472, kl: 276.067, loss: 2510.070\n",
      " 61%|██████    | 303/500 [11:17<11:24,  3.48s/it]INFO:root:global_step: 303, logpy: -2396.043, kl: 274.359, loss: 2507.579\n",
      " 61%|██████    | 304/500 [11:19<09:56,  3.05s/it]INFO:root:global_step: 304, logpy: -2394.085, kl: 272.723, loss: 2505.613\n",
      " 61%|██████    | 305/500 [11:21<08:50,  2.72s/it]INFO:root:global_step: 305, logpy: -2392.285, kl: 271.201, loss: 2503.903\n",
      " 61%|██████    | 306/500 [11:23<08:09,  2.52s/it]INFO:root:global_step: 306, logpy: -2389.677, kl: 269.563, loss: 2501.252\n",
      " 61%|██████▏   | 307/500 [11:25<07:34,  2.35s/it]INFO:root:global_step: 307, logpy: -2387.220, kl: 267.991, loss: 2498.804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 308/500 [11:27<07:14,  2.26s/it]INFO:root:global_step: 308, logpy: -2385.469, kl: 266.463, loss: 2497.088\n",
      " 62%|██████▏   | 309/500 [11:29<07:02,  2.21s/it]INFO:root:global_step: 309, logpy: -2384.549, kl: 265.037, loss: 2496.290\n",
      " 62%|██████▏   | 310/500 [11:32<07:00,  2.21s/it]INFO:root:global_step: 310, logpy: -2384.059, kl: 263.709, loss: 2496.005\n",
      " 62%|██████▏   | 311/500 [11:34<06:48,  2.16s/it]INFO:root:global_step: 311, logpy: -2382.105, kl: 262.182, loss: 2494.041\n",
      " 62%|██████▏   | 312/500 [11:36<06:40,  2.13s/it]INFO:root:global_step: 312, logpy: -2379.826, kl: 260.639, loss: 2491.723\n",
      " 63%|██████▎   | 313/500 [11:38<06:30,  2.09s/it]INFO:root:global_step: 313, logpy: -2377.829, kl: 259.134, loss: 2489.707\n",
      " 63%|██████▎   | 314/500 [11:40<06:25,  2.07s/it]INFO:root:global_step: 314, logpy: -2376.118, kl: 257.728, loss: 2488.064\n",
      " 63%|██████▎   | 315/500 [11:42<06:35,  2.14s/it]INFO:root:global_step: 315, logpy: -2374.018, kl: 256.306, loss: 2485.999\n",
      " 63%|██████▎   | 316/500 [11:44<06:41,  2.18s/it]INFO:root:global_step: 316, logpy: -2371.667, kl: 254.857, loss: 2483.642\n",
      " 63%|██████▎   | 317/500 [11:46<06:26,  2.11s/it]INFO:root:global_step: 317, logpy: -2370.241, kl: 253.432, loss: 2482.221\n",
      " 64%|██████▎   | 318/500 [11:48<06:17,  2.07s/it]INFO:root:global_step: 318, logpy: -2367.451, kl: 251.889, loss: 2479.302\n",
      " 64%|██████▍   | 319/500 [11:50<06:15,  2.07s/it]INFO:root:global_step: 319, logpy: -2366.634, kl: 250.623, loss: 2478.619\n",
      " 64%|██████▍   | 320/500 [11:52<06:14,  2.08s/it]INFO:root:global_step: 320, logpy: -2363.771, kl: 249.179, loss: 2475.699\n",
      " 64%|██████▍   | 321/500 [11:55<06:21,  2.13s/it]INFO:root:global_step: 321, logpy: -2363.643, kl: 247.985, loss: 2475.749\n",
      " 64%|██████▍   | 322/500 [11:57<06:23,  2.15s/it]INFO:root:global_step: 322, logpy: -2361.826, kl: 246.662, loss: 2473.969\n",
      " 65%|██████▍   | 323/500 [11:59<06:17,  2.13s/it]INFO:root:global_step: 323, logpy: -2360.314, kl: 245.375, loss: 2472.514\n",
      " 65%|██████▍   | 324/500 [12:01<06:11,  2.11s/it]INFO:root:global_step: 324, logpy: -2358.671, kl: 244.070, loss: 2470.898\n",
      " 65%|██████▌   | 325/500 [12:03<06:04,  2.08s/it]INFO:root:global_step: 325, logpy: -2356.345, kl: 242.774, loss: 2468.594\n",
      " 65%|██████▌   | 326/500 [12:05<06:02,  2.08s/it]INFO:root:global_step: 326, logpy: -2354.143, kl: 241.408, loss: 2466.332\n",
      " 65%|██████▌   | 327/500 [12:07<06:03,  2.10s/it]INFO:root:global_step: 327, logpy: -2352.264, kl: 240.046, loss: 2464.383\n",
      " 66%|██████▌   | 328/500 [12:09<05:55,  2.06s/it]INFO:root:global_step: 328, logpy: -2350.177, kl: 238.750, loss: 2462.279\n",
      " 66%|██████▌   | 329/500 [12:11<05:47,  2.03s/it]INFO:root:global_step: 329, logpy: -2348.488, kl: 237.479, loss: 2460.586\n",
      " 66%|██████▌   | 330/500 [12:13<05:41,  2.01s/it]INFO:root:global_step: 330, logpy: -2347.742, kl: 236.310, loss: 2459.924\n",
      " 66%|██████▌   | 331/500 [12:15<05:42,  2.02s/it]INFO:root:global_step: 331, logpy: -2346.437, kl: 235.126, loss: 2458.676\n",
      " 66%|██████▋   | 332/500 [12:17<05:47,  2.07s/it]INFO:root:global_step: 332, logpy: -2345.051, kl: 233.947, loss: 2457.341\n",
      " 67%|██████▋   | 333/500 [12:19<05:48,  2.09s/it]INFO:root:global_step: 333, logpy: -2343.925, kl: 232.777, loss: 2456.260\n",
      " 67%|██████▋   | 334/500 [12:22<05:55,  2.14s/it]INFO:root:global_step: 334, logpy: -2343.410, kl: 231.695, loss: 2455.868\n",
      " 67%|██████▋   | 335/500 [12:24<05:54,  2.15s/it]INFO:root:global_step: 335, logpy: -2342.650, kl: 230.553, loss: 2455.158\n",
      " 67%|██████▋   | 336/500 [12:26<05:50,  2.13s/it]INFO:root:global_step: 336, logpy: -2342.986, kl: 229.574, loss: 2455.697\n",
      " 67%|██████▋   | 337/500 [12:28<05:45,  2.12s/it]INFO:root:global_step: 337, logpy: -2340.707, kl: 228.381, loss: 2453.393\n",
      " 68%|██████▊   | 338/500 [12:30<05:41,  2.11s/it]INFO:root:global_step: 338, logpy: -2339.432, kl: 227.232, loss: 2452.126\n",
      " 68%|██████▊   | 339/500 [12:32<05:52,  2.19s/it]INFO:root:global_step: 339, logpy: -2337.805, kl: 226.075, loss: 2450.488\n",
      " 68%|██████▊   | 340/500 [12:35<05:51,  2.20s/it]INFO:root:global_step: 340, logpy: -2338.349, kl: 225.169, loss: 2451.259\n",
      " 68%|██████▊   | 341/500 [12:37<05:46,  2.18s/it]INFO:root:global_step: 341, logpy: -2336.832, kl: 224.052, loss: 2449.747\n",
      " 68%|██████▊   | 342/500 [12:39<05:55,  2.25s/it]INFO:root:global_step: 342, logpy: -2335.761, kl: 222.975, loss: 2448.711\n",
      " 69%|██████▊   | 343/500 [12:41<05:41,  2.17s/it]INFO:root:global_step: 343, logpy: -2335.043, kl: 221.968, loss: 2448.086\n",
      " 69%|██████▉   | 344/500 [12:43<05:34,  2.14s/it]INFO:root:global_step: 344, logpy: -2333.161, kl: 220.829, loss: 2446.155\n",
      " 69%|██████▉   | 345/500 [12:45<05:26,  2.11s/it]INFO:root:global_step: 345, logpy: -2331.591, kl: 219.695, loss: 2444.529\n",
      " 69%|██████▉   | 346/500 [12:47<05:20,  2.08s/it]INFO:root:global_step: 346, logpy: -2330.688, kl: 218.706, loss: 2443.705\n",
      " 69%|██████▉   | 347/500 [12:50<05:30,  2.16s/it]INFO:root:global_step: 347, logpy: -2329.767, kl: 217.730, loss: 2442.864\n",
      " 70%|██████▉   | 348/500 [12:52<05:37,  2.22s/it]INFO:root:global_step: 348, logpy: -2327.614, kl: 216.601, loss: 2440.629\n",
      " 70%|██████▉   | 349/500 [12:54<05:24,  2.15s/it]INFO:root:global_step: 349, logpy: -2325.624, kl: 215.547, loss: 2438.621\n",
      " 70%|███████   | 350/500 [12:56<05:21,  2.15s/it]INFO:root:Saved figure at: ./sim/global_step_350.png\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_core/sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 350, logpy: -2323.537, kl: 214.489, loss: 2436.501\n",
      " 70%|███████   | 351/500 [13:07<11:40,  4.70s/it]INFO:root:global_step: 351, logpy: -2321.840, kl: 213.408, loss: 2434.738\n",
      " 70%|███████   | 352/500 [13:09<09:39,  3.92s/it]INFO:root:global_step: 352, logpy: -2320.553, kl: 212.433, loss: 2433.481\n",
      " 71%|███████   | 353/500 [13:11<08:32,  3.49s/it]INFO:root:global_step: 353, logpy: -2319.712, kl: 211.533, loss: 2432.735\n",
      " 71%|███████   | 354/500 [13:13<07:26,  3.06s/it]INFO:root:global_step: 354, logpy: -2318.014, kl: 210.514, loss: 2431.003\n",
      " 71%|███████   | 355/500 [13:16<06:40,  2.76s/it]INFO:root:global_step: 355, logpy: -2317.470, kl: 209.615, loss: 2430.535\n",
      " 71%|███████   | 356/500 [13:18<06:04,  2.53s/it]INFO:root:global_step: 356, logpy: -2316.675, kl: 208.717, loss: 2429.809\n",
      " 71%|███████▏  | 357/500 [13:19<05:37,  2.36s/it]INFO:root:global_step: 357, logpy: -2315.864, kl: 207.825, loss: 2429.061\n",
      " 72%|███████▏  | 358/500 [13:22<05:21,  2.26s/it]INFO:root:global_step: 358, logpy: -2314.736, kl: 206.881, loss: 2427.935\n",
      " 72%|███████▏  | 359/500 [13:24<05:08,  2.19s/it]INFO:root:global_step: 359, logpy: -2312.308, kl: 205.881, loss: 2425.444\n",
      " 72%|███████▏  | 360/500 [13:26<05:02,  2.16s/it]INFO:root:global_step: 360, logpy: -2310.477, kl: 204.879, loss: 2423.539\n",
      " 72%|███████▏  | 361/500 [13:28<04:52,  2.11s/it]INFO:root:global_step: 361, logpy: -2309.810, kl: 203.963, loss: 2422.874\n",
      " 72%|███████▏  | 362/500 [13:30<04:48,  2.09s/it]INFO:root:global_step: 362, logpy: -2309.176, kl: 203.112, loss: 2422.298\n",
      " 73%|███████▎  | 363/500 [13:32<04:51,  2.13s/it]INFO:root:global_step: 363, logpy: -2307.761, kl: 202.226, loss: 2420.897\n",
      " 73%|███████▎  | 364/500 [13:34<04:45,  2.10s/it]INFO:root:global_step: 364, logpy: -2306.666, kl: 201.309, loss: 2419.776\n",
      " 73%|███████▎  | 365/500 [13:36<04:40,  2.07s/it]INFO:root:global_step: 365, logpy: -2305.164, kl: 200.386, loss: 2418.232\n",
      " 73%|███████▎  | 366/500 [13:38<04:38,  2.08s/it]INFO:root:global_step: 366, logpy: -2304.864, kl: 199.591, loss: 2418.010\n",
      " 73%|███████▎  | 367/500 [13:40<04:30,  2.04s/it]INFO:root:global_step: 367, logpy: -2303.618, kl: 198.751, loss: 2416.790\n",
      " 74%|███████▎  | 368/500 [13:42<04:27,  2.03s/it]INFO:root:global_step: 368, logpy: -2302.907, kl: 197.973, loss: 2416.156\n",
      " 74%|███████▍  | 369/500 [13:44<04:25,  2.03s/it]INFO:root:global_step: 369, logpy: -2301.077, kl: 197.083, loss: 2414.284\n",
      " 74%|███████▍  | 370/500 [13:46<04:30,  2.08s/it]INFO:root:global_step: 370, logpy: -2299.436, kl: 196.162, loss: 2412.561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 371/500 [13:48<04:24,  2.05s/it]INFO:root:global_step: 371, logpy: -2298.204, kl: 195.356, loss: 2411.352\n",
      " 74%|███████▍  | 372/500 [13:50<04:24,  2.07s/it]INFO:root:global_step: 372, logpy: -2297.596, kl: 194.589, loss: 2410.800\n",
      " 75%|███████▍  | 373/500 [13:52<04:19,  2.04s/it]INFO:root:global_step: 373, logpy: -2297.768, kl: 193.874, loss: 2411.070\n",
      " 75%|███████▍  | 374/500 [13:54<04:11,  1.99s/it]INFO:root:global_step: 374, logpy: -2296.718, kl: 193.056, loss: 2410.008\n",
      " 75%|███████▌  | 375/500 [13:56<04:10,  2.01s/it]INFO:root:global_step: 375, logpy: -2295.607, kl: 192.224, loss: 2408.863\n",
      " 75%|███████▌  | 376/500 [13:58<04:06,  1.99s/it]INFO:root:global_step: 376, logpy: -2294.481, kl: 191.439, loss: 2407.741\n",
      " 75%|███████▌  | 377/500 [14:00<04:06,  2.00s/it]INFO:root:global_step: 377, logpy: -2291.875, kl: 190.490, loss: 2404.968\n",
      " 76%|███████▌  | 378/500 [14:02<04:15,  2.09s/it]INFO:root:global_step: 378, logpy: -2291.750, kl: 189.862, loss: 2404.989\n",
      " 76%|███████▌  | 379/500 [14:04<04:09,  2.06s/it]INFO:root:global_step: 379, logpy: -2289.729, kl: 189.017, loss: 2402.889\n",
      " 76%|███████▌  | 380/500 [14:07<04:08,  2.07s/it]INFO:root:global_step: 380, logpy: -2287.677, kl: 188.153, loss: 2400.732\n",
      " 76%|███████▌  | 381/500 [14:09<04:06,  2.07s/it]INFO:root:global_step: 381, logpy: -2288.280, kl: 187.527, loss: 2401.460\n",
      " 76%|███████▋  | 382/500 [14:11<04:02,  2.06s/it]INFO:root:global_step: 382, logpy: -2286.464, kl: 186.749, loss: 2399.609\n",
      " 77%|███████▋  | 383/500 [14:13<03:56,  2.02s/it]INFO:root:global_step: 383, logpy: -2286.498, kl: 186.133, loss: 2399.763\n",
      " 77%|███████▋  | 384/500 [14:15<03:51,  2.00s/it]INFO:root:global_step: 384, logpy: -2286.254, kl: 185.508, loss: 2399.623\n",
      " 77%|███████▋  | 385/500 [14:17<03:50,  2.01s/it]INFO:root:global_step: 385, logpy: -2285.304, kl: 184.769, loss: 2398.655\n",
      " 77%|███████▋  | 386/500 [14:19<03:50,  2.02s/it]INFO:root:global_step: 386, logpy: -2284.915, kl: 184.087, loss: 2398.299\n",
      " 77%|███████▋  | 387/500 [14:21<03:46,  2.00s/it]INFO:root:global_step: 387, logpy: -2283.828, kl: 183.323, loss: 2397.156\n",
      " 78%|███████▊  | 388/500 [14:23<03:48,  2.04s/it]INFO:root:global_step: 388, logpy: -2283.235, kl: 182.650, loss: 2396.589\n",
      " 78%|███████▊  | 389/500 [14:25<03:50,  2.08s/it]INFO:root:global_step: 389, logpy: -2283.150, kl: 182.052, loss: 2396.599\n",
      " 78%|███████▊  | 390/500 [14:27<03:46,  2.06s/it]INFO:root:global_step: 390, logpy: -2282.498, kl: 181.373, loss: 2395.954\n",
      " 78%|███████▊  | 391/500 [14:29<03:44,  2.06s/it]INFO:root:global_step: 391, logpy: -2281.558, kl: 180.714, loss: 2395.034\n",
      " 78%|███████▊  | 392/500 [14:31<03:42,  2.06s/it]INFO:root:global_step: 392, logpy: -2279.946, kl: 179.986, loss: 2393.366\n",
      " 79%|███████▊  | 393/500 [14:33<03:48,  2.13s/it]INFO:root:global_step: 393, logpy: -2280.800, kl: 179.546, loss: 2394.445\n",
      " 79%|███████▉  | 394/500 [14:35<03:43,  2.11s/it]INFO:root:global_step: 394, logpy: -2279.171, kl: 178.852, loss: 2392.782\n",
      " 79%|███████▉  | 395/500 [14:37<03:39,  2.09s/it]INFO:root:global_step: 395, logpy: -2279.513, kl: 178.243, loss: 2393.167\n",
      " 79%|███████▉  | 396/500 [14:39<03:36,  2.08s/it]INFO:root:global_step: 396, logpy: -2279.061, kl: 177.657, loss: 2392.774\n",
      " 79%|███████▉  | 397/500 [14:42<03:34,  2.09s/it]INFO:root:global_step: 397, logpy: -2278.257, kl: 177.025, loss: 2391.979\n",
      " 80%|███████▉  | 398/500 [14:44<03:28,  2.05s/it]INFO:root:global_step: 398, logpy: -2277.561, kl: 176.348, loss: 2391.239\n",
      " 80%|███████▉  | 399/500 [14:45<03:24,  2.03s/it]INFO:root:global_step: 399, logpy: -2277.266, kl: 175.791, loss: 2391.013\n",
      " 80%|████████  | 400/500 [14:48<03:22,  2.03s/it]INFO:root:Saved figure at: ./sim/global_step_400.png\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_core/sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 400, logpy: -2276.189, kl: 175.174, loss: 2389.939\n",
      " 80%|████████  | 401/500 [14:58<07:27,  4.52s/it]INFO:root:global_step: 401, logpy: -2275.906, kl: 174.642, loss: 2389.739\n",
      " 80%|████████  | 402/500 [15:00<06:12,  3.80s/it]INFO:root:global_step: 402, logpy: -2275.772, kl: 174.110, loss: 2389.681\n",
      " 81%|████████  | 403/500 [15:02<05:21,  3.31s/it]INFO:root:global_step: 403, logpy: -2275.400, kl: 173.560, loss: 2389.361\n",
      " 81%|████████  | 404/500 [15:04<04:48,  3.01s/it]INFO:root:global_step: 404, logpy: -2275.339, kl: 173.053, loss: 2389.389\n",
      " 81%|████████  | 405/500 [15:06<04:15,  2.69s/it]INFO:root:global_step: 405, logpy: -2275.383, kl: 172.569, loss: 2389.539\n",
      " 81%|████████  | 406/500 [15:08<03:51,  2.47s/it]INFO:root:global_step: 406, logpy: -2274.558, kl: 171.984, loss: 2388.714\n",
      " 81%|████████▏ | 407/500 [15:10<03:37,  2.34s/it]INFO:root:global_step: 407, logpy: -2275.130, kl: 171.532, loss: 2389.411\n",
      " 82%|████████▏ | 408/500 [15:12<03:27,  2.25s/it]INFO:root:global_step: 408, logpy: -2272.839, kl: 170.826, loss: 2386.987\n",
      " 82%|████████▏ | 409/500 [15:15<03:22,  2.23s/it]INFO:root:global_step: 409, logpy: -2272.483, kl: 170.273, loss: 2386.646\n",
      " 82%|████████▏ | 410/500 [15:17<03:15,  2.18s/it]INFO:root:global_step: 410, logpy: -2270.744, kl: 169.596, loss: 2384.790\n",
      " 82%|████████▏ | 411/500 [15:19<03:08,  2.12s/it]INFO:root:global_step: 411, logpy: -2271.260, kl: 169.229, loss: 2385.494\n",
      " 82%|████████▏ | 412/500 [15:21<03:10,  2.17s/it]INFO:root:global_step: 412, logpy: -2269.822, kl: 168.697, loss: 2384.075\n",
      " 83%|████████▎ | 413/500 [15:23<03:04,  2.12s/it]INFO:root:global_step: 413, logpy: -2269.692, kl: 168.240, loss: 2384.032\n",
      " 83%|████████▎ | 414/500 [15:25<02:58,  2.08s/it]INFO:root:global_step: 414, logpy: -2269.303, kl: 167.762, loss: 2383.704\n",
      " 83%|████████▎ | 415/500 [15:27<02:58,  2.10s/it]INFO:root:global_step: 415, logpy: -2270.055, kl: 167.381, loss: 2384.608\n",
      " 83%|████████▎ | 416/500 [15:29<02:53,  2.07s/it]INFO:root:global_step: 416, logpy: -2268.863, kl: 166.821, loss: 2383.384\n",
      " 83%|████████▎ | 417/500 [15:31<02:50,  2.05s/it]INFO:root:global_step: 417, logpy: -2268.846, kl: 166.403, loss: 2383.473\n",
      " 84%|████████▎ | 418/500 [15:33<02:47,  2.04s/it]INFO:root:global_step: 418, logpy: -2268.153, kl: 165.887, loss: 2382.782\n",
      " 84%|████████▍ | 419/500 [15:35<02:46,  2.06s/it]INFO:root:global_step: 419, logpy: -2266.377, kl: 165.295, loss: 2380.926\n",
      " 84%|████████▍ | 420/500 [15:37<02:48,  2.11s/it]INFO:root:global_step: 420, logpy: -2265.940, kl: 164.861, loss: 2380.562\n",
      " 84%|████████▍ | 421/500 [15:39<02:42,  2.06s/it]INFO:root:global_step: 421, logpy: -2264.368, kl: 164.285, loss: 2378.917\n",
      " 84%|████████▍ | 422/500 [15:41<02:38,  2.03s/it]INFO:root:global_step: 422, logpy: -2263.563, kl: 163.820, loss: 2378.145\n",
      " 85%|████████▍ | 423/500 [15:43<02:35,  2.02s/it]INFO:root:global_step: 423, logpy: -2263.694, kl: 163.378, loss: 2378.326\n",
      " 85%|████████▍ | 424/500 [15:45<02:32,  2.01s/it]INFO:root:global_step: 424, logpy: -2263.937, kl: 162.965, loss: 2378.644\n",
      " 85%|████████▌ | 425/500 [15:47<02:32,  2.03s/it]INFO:root:global_step: 425, logpy: -2263.925, kl: 162.535, loss: 2378.683\n",
      " 85%|████████▌ | 426/500 [15:49<02:30,  2.04s/it]INFO:root:global_step: 426, logpy: -2262.722, kl: 162.025, loss: 2377.449\n",
      " 85%|████████▌ | 427/500 [15:51<02:28,  2.03s/it]INFO:root:global_step: 427, logpy: -2261.569, kl: 161.537, loss: 2376.281\n",
      " 86%|████████▌ | 428/500 [15:54<02:27,  2.05s/it]INFO:root:global_step: 428, logpy: -2260.991, kl: 161.079, loss: 2375.713\n",
      " 86%|████████▌ | 429/500 [15:56<02:24,  2.03s/it]INFO:root:global_step: 429, logpy: -2260.489, kl: 160.660, loss: 2375.255\n",
      " 86%|████████▌ | 430/500 [15:58<02:22,  2.03s/it]INFO:root:global_step: 430, logpy: -2259.575, kl: 160.146, loss: 2374.286\n",
      " 86%|████████▌ | 431/500 [16:00<02:20,  2.04s/it]INFO:root:global_step: 431, logpy: -2258.619, kl: 159.718, loss: 2373.357\n",
      " 86%|████████▋ | 432/500 [16:02<02:18,  2.04s/it]INFO:root:global_step: 432, logpy: -2257.976, kl: 159.282, loss: 2372.727\n",
      " 87%|████████▋ | 433/500 [16:04<02:17,  2.06s/it]INFO:root:global_step: 433, logpy: -2256.775, kl: 158.749, loss: 2371.439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 434/500 [16:06<02:21,  2.14s/it]INFO:root:global_step: 434, logpy: -2256.884, kl: 158.368, loss: 2371.607\n",
      " 87%|████████▋ | 435/500 [16:08<02:21,  2.18s/it]INFO:root:global_step: 435, logpy: -2256.656, kl: 157.998, loss: 2371.446\n",
      " 87%|████████▋ | 436/500 [16:10<02:16,  2.14s/it]INFO:root:global_step: 436, logpy: -2257.522, kl: 157.710, loss: 2372.455\n",
      " 87%|████████▋ | 437/500 [16:12<02:10,  2.07s/it]INFO:root:global_step: 437, logpy: -2258.486, kl: 157.424, loss: 2373.561\n",
      " 88%|████████▊ | 438/500 [16:14<02:06,  2.03s/it]INFO:root:global_step: 438, logpy: -2258.890, kl: 157.105, loss: 2374.070\n",
      " 88%|████████▊ | 439/500 [16:16<02:05,  2.06s/it]INFO:root:global_step: 439, logpy: -2259.527, kl: 156.869, loss: 2374.890\n",
      " 88%|████████▊ | 440/500 [16:19<02:05,  2.08s/it]INFO:root:global_step: 440, logpy: -2259.772, kl: 156.525, loss: 2375.206\n",
      " 88%|████████▊ | 441/500 [16:21<02:02,  2.07s/it]INFO:root:global_step: 441, logpy: -2259.476, kl: 156.183, loss: 2374.979\n",
      " 88%|████████▊ | 442/500 [16:23<01:58,  2.04s/it]INFO:root:global_step: 442, logpy: -2259.464, kl: 155.848, loss: 2375.039\n",
      " 89%|████████▊ | 443/500 [16:25<01:58,  2.08s/it]INFO:root:global_step: 443, logpy: -2259.144, kl: 155.524, loss: 2374.798\n",
      " 89%|████████▉ | 444/500 [16:27<01:54,  2.05s/it]INFO:root:global_step: 444, logpy: -2257.731, kl: 154.996, loss: 2373.256\n",
      " 89%|████████▉ | 445/500 [16:29<01:53,  2.05s/it]INFO:root:global_step: 445, logpy: -2257.170, kl: 154.592, loss: 2372.686\n",
      " 89%|████████▉ | 446/500 [16:31<01:54,  2.11s/it]INFO:root:global_step: 446, logpy: -2256.393, kl: 154.160, loss: 2371.868\n",
      " 89%|████████▉ | 447/500 [16:33<01:53,  2.14s/it]INFO:root:global_step: 447, logpy: -2257.171, kl: 153.928, loss: 2372.801\n",
      " 90%|████████▉ | 448/500 [16:35<01:48,  2.09s/it]INFO:root:global_step: 448, logpy: -2256.029, kl: 153.512, loss: 2371.625\n",
      " 90%|████████▉ | 449/500 [16:37<01:46,  2.08s/it]INFO:root:global_step: 449, logpy: -2255.429, kl: 153.134, loss: 2371.026\n",
      " 90%|█████████ | 450/500 [16:39<01:42,  2.06s/it]INFO:root:Saved figure at: ./sim/global_step_450.png\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_core/sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 450, logpy: -2255.200, kl: 152.756, loss: 2370.794\n",
      " 90%|█████████ | 451/500 [16:50<03:49,  4.68s/it]INFO:root:global_step: 451, logpy: -2256.174, kl: 152.542, loss: 2371.926\n",
      " 90%|█████████ | 452/500 [16:52<03:10,  3.96s/it]INFO:root:global_step: 452, logpy: -2255.761, kl: 152.171, loss: 2371.510\n",
      " 91%|█████████ | 453/500 [16:55<02:41,  3.43s/it]INFO:root:global_step: 453, logpy: -2254.997, kl: 151.794, loss: 2370.734\n",
      " 91%|█████████ | 454/500 [16:57<02:18,  3.02s/it]INFO:root:global_step: 454, logpy: -2255.319, kl: 151.502, loss: 2371.124\n",
      " 91%|█████████ | 455/500 [16:59<02:02,  2.71s/it]INFO:root:global_step: 455, logpy: -2254.402, kl: 151.129, loss: 2370.191\n",
      " 91%|█████████ | 456/500 [17:01<01:50,  2.51s/it]INFO:root:global_step: 456, logpy: -2253.626, kl: 150.689, loss: 2369.329\n",
      " 91%|█████████▏| 457/500 [17:03<01:41,  2.35s/it]INFO:root:global_step: 457, logpy: -2252.983, kl: 150.313, loss: 2368.660\n",
      " 92%|█████████▏| 458/500 [17:05<01:37,  2.32s/it]INFO:root:global_step: 458, logpy: -2253.230, kl: 150.083, loss: 2369.023\n",
      " 92%|█████████▏| 459/500 [17:07<01:31,  2.24s/it]INFO:root:global_step: 459, logpy: -2252.111, kl: 149.665, loss: 2367.828\n",
      " 92%|█████████▏| 460/500 [17:09<01:29,  2.23s/it]INFO:root:global_step: 460, logpy: -2252.411, kl: 149.364, loss: 2368.167\n",
      " 92%|█████████▏| 461/500 [17:11<01:24,  2.16s/it]INFO:root:global_step: 461, logpy: -2250.113, kl: 148.872, loss: 2365.712\n",
      " 92%|█████████▏| 462/500 [17:13<01:20,  2.13s/it]INFO:root:global_step: 462, logpy: -2250.444, kl: 148.637, loss: 2366.142\n",
      " 93%|█████████▎| 463/500 [17:15<01:17,  2.08s/it]INFO:root:global_step: 463, logpy: -2250.374, kl: 148.385, loss: 2366.149\n",
      " 93%|█████████▎| 464/500 [17:18<01:18,  2.19s/it]INFO:root:global_step: 464, logpy: -2250.777, kl: 148.139, loss: 2366.632\n",
      " 93%|█████████▎| 465/500 [17:20<01:15,  2.16s/it]INFO:root:global_step: 465, logpy: -2249.084, kl: 147.665, loss: 2364.788\n",
      " 93%|█████████▎| 466/500 [17:22<01:11,  2.11s/it]INFO:root:global_step: 466, logpy: -2248.461, kl: 147.372, loss: 2364.192\n",
      " 93%|█████████▎| 467/500 [17:24<01:08,  2.07s/it]INFO:root:global_step: 467, logpy: -2246.775, kl: 146.941, loss: 2362.391\n",
      " 94%|█████████▎| 468/500 [17:26<01:05,  2.06s/it]INFO:root:global_step: 468, logpy: -2246.306, kl: 146.586, loss: 2361.879\n",
      " 94%|█████████▍| 469/500 [17:28<01:03,  2.04s/it]INFO:root:global_step: 469, logpy: -2245.925, kl: 146.254, loss: 2361.477\n",
      " 94%|█████████▍| 470/500 [17:30<01:01,  2.05s/it]INFO:root:global_step: 470, logpy: -2246.160, kl: 146.054, loss: 2361.819\n",
      " 94%|█████████▍| 471/500 [17:32<00:59,  2.06s/it]INFO:root:global_step: 471, logpy: -2246.596, kl: 145.858, loss: 2362.363\n",
      " 94%|█████████▍| 472/500 [17:34<00:57,  2.04s/it]INFO:root:global_step: 472, logpy: -2245.103, kl: 145.454, loss: 2360.768\n",
      " 95%|█████████▍| 473/500 [17:36<00:54,  2.02s/it]INFO:root:global_step: 473, logpy: -2244.509, kl: 145.161, loss: 2360.178\n",
      " 95%|█████████▍| 474/500 [17:38<00:52,  2.01s/it]INFO:root:global_step: 474, logpy: -2245.224, kl: 144.973, loss: 2361.000\n",
      " 95%|█████████▌| 475/500 [17:40<00:50,  2.02s/it]INFO:root:global_step: 475, logpy: -2244.264, kl: 144.583, loss: 2359.942\n",
      " 95%|█████████▌| 476/500 [17:42<00:49,  2.06s/it]INFO:root:global_step: 476, logpy: -2243.692, kl: 144.312, loss: 2359.389\n",
      " 95%|█████████▌| 477/500 [17:44<00:47,  2.05s/it]INFO:root:global_step: 477, logpy: -2244.127, kl: 144.095, loss: 2359.893\n",
      " 96%|█████████▌| 478/500 [17:46<00:44,  2.03s/it]INFO:root:global_step: 478, logpy: -2243.545, kl: 143.792, loss: 2359.291\n",
      " 96%|█████████▌| 479/500 [17:48<00:42,  2.04s/it]INFO:root:global_step: 479, logpy: -2243.000, kl: 143.493, loss: 2358.727\n",
      " 96%|█████████▌| 480/500 [17:50<00:41,  2.07s/it]INFO:root:global_step: 480, logpy: -2243.632, kl: 143.325, loss: 2359.468\n",
      " 96%|█████████▌| 481/500 [17:52<00:40,  2.13s/it]INFO:root:global_step: 481, logpy: -2243.891, kl: 143.137, loss: 2359.814\n",
      " 96%|█████████▋| 482/500 [17:54<00:37,  2.09s/it]INFO:root:global_step: 482, logpy: -2244.078, kl: 142.920, loss: 2360.056\n",
      " 97%|█████████▋| 483/500 [17:57<00:35,  2.08s/it]INFO:root:global_step: 483, logpy: -2244.569, kl: 142.833, loss: 2360.730\n",
      " 97%|█████████▋| 484/500 [17:59<00:33,  2.11s/it]INFO:root:global_step: 484, logpy: -2244.881, kl: 142.658, loss: 2361.134\n",
      " 97%|█████████▋| 485/500 [18:01<00:32,  2.16s/it]INFO:root:global_step: 485, logpy: -2246.155, kl: 142.608, loss: 2362.621\n",
      " 97%|█████████▋| 486/500 [18:03<00:30,  2.14s/it]INFO:root:global_step: 486, logpy: -2245.068, kl: 142.285, loss: 2361.473\n",
      " 97%|█████████▋| 487/500 [18:05<00:27,  2.14s/it]INFO:root:global_step: 487, logpy: -2245.175, kl: 142.100, loss: 2361.654\n",
      " 98%|█████████▊| 488/500 [18:07<00:25,  2.09s/it]INFO:root:global_step: 488, logpy: -2244.900, kl: 141.833, loss: 2361.368\n",
      " 98%|█████████▊| 489/500 [18:09<00:22,  2.06s/it]INFO:root:global_step: 489, logpy: -2243.489, kl: 141.476, loss: 2359.854\n",
      " 98%|█████████▊| 490/500 [18:11<00:20,  2.06s/it]INFO:root:global_step: 490, logpy: -2243.182, kl: 141.249, loss: 2359.571\n",
      " 98%|█████████▊| 491/500 [18:13<00:18,  2.09s/it]INFO:root:global_step: 491, logpy: -2243.342, kl: 141.104, loss: 2359.835\n",
      " 98%|█████████▊| 492/500 [18:16<00:16,  2.12s/it]INFO:root:global_step: 492, logpy: -2242.983, kl: 140.799, loss: 2359.417\n",
      " 99%|█████████▊| 493/500 [18:18<00:14,  2.11s/it]INFO:root:global_step: 493, logpy: -2243.160, kl: 140.599, loss: 2359.638\n",
      " 99%|█████████▉| 494/500 [18:20<00:12,  2.08s/it]INFO:root:global_step: 494, logpy: -2242.184, kl: 140.280, loss: 2358.583\n",
      " 99%|█████████▉| 495/500 [18:22<00:10,  2.07s/it]INFO:root:global_step: 495, logpy: -2242.089, kl: 140.087, loss: 2358.535\n",
      " 99%|█████████▉| 496/500 [18:24<00:08,  2.05s/it]INFO:root:global_step: 496, logpy: -2242.706, kl: 139.968, loss: 2359.269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 497/500 [18:26<00:06,  2.02s/it]INFO:root:global_step: 497, logpy: -2241.374, kl: 139.677, loss: 2357.880\n",
      "100%|█████████▉| 498/500 [18:28<00:04,  2.19s/it]INFO:root:global_step: 498, logpy: -2240.646, kl: 139.439, loss: 2357.146\n",
      "100%|█████████▉| 499/500 [18:31<00:02,  2.22s/it]INFO:root:global_step: 499, logpy: -2240.681, kl: 139.277, loss: 2357.247\n",
      "100%|██████████| 500/500 [18:33<00:00,  2.23s/it]\n"
     ]
    }
   ],
   "source": [
    "manual_seed(args['seed'])\n",
    "\n",
    "if args['debug']:\n",
    "    logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "ckpt_dir = os.path.join('./sim/', 'ckpts')\n",
    "os.makedirs(ckpt_dir, exist_ok=True)\n",
    "\n",
    "sdeint_fn = torchsde.sdeint_adjoint if args['adjoint'] else torchsde.sdeint\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c356ad31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7712260f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
