{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c4dd7b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from collections import namedtuple\n",
    "from typing import Optional, Union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import diffrax\n",
    "import equinox as eqx\n",
    "import jax\n",
    "import jax.nn as jnn\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jrandom\n",
    "from jax import grad, jit, vmap, value_and_grad\n",
    "import optax\n",
    "\n",
    "from jax.experimental import stax\n",
    "from jax.experimental.stax import (BatchNorm, Conv, Dense, Flatten, Relu, Tanh,LogSoftmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2902c1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the tuple for data, \n",
    "Data = namedtuple('Data', ['ts_', 'ts_ext_', 'ts_vis_', 'ts', 'ts_ext', 'ts_vis', 'ys', 'ys_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9198a09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"train_iters\": 500,\n",
    "    \"pause_iters\": 50,\n",
    "    \"hide_ticks\": False,\n",
    "    \"save_ckpt\":True,\n",
    "    \"likelihood\":\"laplace\",\n",
    "    \"scale\": 0.0001,\n",
    "    \"adjoint\": False,\n",
    "    \"debug\": True,\n",
    "    \"seed\": 42,\n",
    "    'data':'segmented_cosine',\n",
    "    \"dt\": 1e-2,\n",
    "    \"batch_size\": 256,\n",
    "    \"method\": 'euler',\n",
    "    \"adaptive\": 'False',\n",
    "    \"rtol\": 1e-3,\n",
    "    \"atol\": 1e-3\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "40420fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output values from 0 to maxval with iters steps\n",
    "class LinearScheduler(object):\n",
    "    def __init__(self, iters, maxval=1.0):\n",
    "        self._iters = max(1,iters)\n",
    "        self._val = maxval/self._iters\n",
    "        self._maxval = maxval\n",
    "    \n",
    "    def step(self):\n",
    "        self._val = min(self._maxval, self._val+self._maxval/self._iters)\n",
    "        \n",
    "    @property\n",
    "    def val(self):\n",
    "        return self._val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "93c09c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EMAMetric(object):\n",
    "    def __init__(self, gamma: Optional[float]=0.99):\n",
    "        super(EMAMetric, self).__init__()\n",
    "        self._val=0\n",
    "        self._gamma = gamma\n",
    "    def step(self, x:jnp.ndarray):\n",
    "        self._val = self._gamma * self._val + (1-self._gamma)*x\n",
    "        return self._val\n",
    "    \n",
    "    @property\n",
    "    def val(self):\n",
    "        return self._val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "98a2f4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure that the dvision is stable\n",
    "def _stable_division(a,b,epsilon=1e-7):\n",
    "    b = jnp.where(jnp.absolute(b)> epsilon, b, jnp.full_like(b, fill_value=epsilon)*jnp.sign(b))\n",
    "    return a/b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "72c072bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jrandom.PRNGKey(0)\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80736fff",
   "metadata": {},
   "source": [
    "## 5. Simulation of time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "03ca24fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135 µs ± 12 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "T = 30\n",
    "#beta = 0.1694\n",
    "beta=1\n",
    "def make_time_series():\n",
    "    \n",
    "    \n",
    "    phi = 0.99\n",
    "    sigma_v = 0.003342\n",
    "    sigma_u = 0.00328\n",
    "    rho = -0.856\n",
    "    cov_uv = rho * sigma_u * sigma_v\n",
    "\n",
    "    # generating shocks\n",
    "    mu = [0,0]\n",
    "    cov = [[sigma_u**2, cov_uv], [cov_uv, sigma_v**2]]\n",
    "    shocks = np.random.multivariate_normal(mu, cov, T)\n",
    "\n",
    "    z0 = np.random.normal(0, sigma_u**2/(1-phi**2),1)\n",
    "    r0 = shocks[0][0]\n",
    "\n",
    "    z = np.zeros(T)\n",
    "    r = np.zeros(T)\n",
    "    z[0] = z0\n",
    "    r[0] = r0\n",
    "\n",
    "    for idx_t in range(T-1):\n",
    "        z[idx_t+1] = phi*z[idx_t] + shocks[idx_t+1][1]\n",
    "        r[idx_t+1] = beta*z[idx_t+1] + shocks[idx_t+1][0]\n",
    "    return z, r\n",
    "%timeit z, r = make_time_series()\n",
    "plt.figure(figsize=(15,5))\n",
    "xvalues = np.array(range(T))\n",
    "plt.plot(xvalues, r, linestyle='-', color='g', label=\"observed $r_t$\")\n",
    "plt.plot(xvalues, z, linestyle=\"--\", color=\"r\", label=r\"hidden variable $\\beta * z_t$\", linewidth=3.0)\n",
    "\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('%')\n",
    "plt.grid(True)\n",
    "plt.title(r\"Simulated $r_t$ and hidden $\\beta * z_t$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0cf9fca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data():\n",
    "    ts_ = jnp.linspace(0.1,30.0,30)\n",
    "    ts_ext_ = jnp.array([0.] + list(ts_) + [30.1])\n",
    "    ts_vis_ = jnp.linspace(0.1, 30.1, 31)\n",
    "    ys_ = jnp.array(r[:,None])\n",
    "    return ts_, ts_ext_, ts_vis_, ys_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51f4f54",
   "metadata": {},
   "source": [
    "# initialize the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "0a57f09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LatentSDE(eqx.Module):\n",
    "    net: eqx.nn.MLP\n",
    "    theta: float\n",
    "    mu: float\n",
    "    sigma: float\n",
    "    py0_mean: jnp.array\n",
    "    py0_logvar: jnp.array\n",
    "    qy0_mean: jnp.array\n",
    "    qy0_logvar: jnp.array\n",
    "    \n",
    "        \n",
    "    def __init__(self,theta,mu,sigma,*,key,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        #nkey = jrandom.split(key,1)\n",
    "        \n",
    "        logvar = jnp.log(sigma**2/(2.*theta))\n",
    "        self.theta = theta\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        \n",
    "        self.net = eqx.nn.MLP(\n",
    "            in_size=3,\n",
    "            out_size =1,\n",
    "            width_size=200,\n",
    "            depth = 2,\n",
    "            activation=jnn.tanh,\n",
    "            key=key\n",
    "        )\n",
    "        \n",
    "        self.py0_mean = jnp.array([[mu]])\n",
    "        self.py0_logvar = jnp.array([[logvar]])\n",
    "        \n",
    "        self.qy0_mean = jnp.array([[mu]])\n",
    "        self.qy0_logvar = jnp.array([[logvar]])\n",
    "    \n",
    "    def f(self, t, y,args):\n",
    "        t = t[:,None]\n",
    "        y = y[:,None]\n",
    "        return self.net(jnp.concatenate((jnp.sin(t),jnp.cos(t),y),axis=-1))\n",
    "    @property\n",
    "    def py0_std(self):\n",
    "        return jnp.exp(.5 * self.py0_logvar)\n",
    "\n",
    "    @property\n",
    "    def qy0_std(self):\n",
    "        return jnp.exp(.5 * self.qy0_logvar)\n",
    "    \n",
    "    def __call__(self, t, y, args):\n",
    "        print(\"call\")\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "1884b58c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Incompatible shapes for broadcasting: ((200, 3), (1, 200))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/jax/_src/util.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trace_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/jax/_src/util.py\u001b[0m in \u001b[0;36mcached\u001b[0;34m(_, *args, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36m_broadcast_shapes_cached\u001b[0;34m(*shapes)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_broadcast_shapes_cached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_broadcast_shapes_uncached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36m_broadcast_shapes_uncached\u001b[0;34m(*shapes)\u001b[0m\n\u001b[1;32m    141\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mresult_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m     raise ValueError(\"Incompatible shapes for broadcasting: {}\"\n\u001b[0m\u001b[1;32m    143\u001b[0m                      .format(tuple(shape_list)))\n",
      "\u001b[0;31mValueError\u001b[0m: Incompatible shapes for broadcasting: ((200, 3), (1, 200))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-202-951acc561f88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-201-597a3bb3a35d>\u001b[0m in \u001b[0;36mf\u001b[0;34m(self, t, y, args)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpy0_std\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/equinox/nn/composed.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, key)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \"\"\"\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/equinox/nn/linear.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, key)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36mdeferring_binary_op\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   4584\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_accepted_binop_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4585\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4587\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdeferring_binary_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 14 frame]\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/jax/_src/numpy/ufuncs.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(x1, x2)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_maybe_bool_binop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlax_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool_lax_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlax_doc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_promote_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlax_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mbool_lax_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m   \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/jax/_src/numpy/util.py\u001b[0m in \u001b[0;36m_promote_args\u001b[0;34m(fun_name, *args)\u001b[0m\n\u001b[1;32m    330\u001b[0m   \u001b[0m_check_arraylike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m   \u001b[0m_check_no_float0s\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_promote_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_promote_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/jax/_src/numpy/util.py\u001b[0m in \u001b[0;36m_promote_shapes\u001b[0;34m(fun_name, *args)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_broadcast_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0mresult_rank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m         return [_broadcast_to(arg, (1,) * (result_rank - len(shp)) + shp)\n\u001b[1;32m    238\u001b[0m                 for arg, shp in zip(args, shapes)]\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36m_broadcast_shapes_uncached\u001b[0;34m(*shapes)\u001b[0m\n\u001b[1;32m    140\u001b[0m   \u001b[0mresult_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_try_broadcast_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mresult_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m     raise ValueError(\"Incompatible shapes for broadcasting: {}\"\n\u001b[0m\u001b[1;32m    143\u001b[0m                      .format(tuple(shape_list)))\n\u001b[1;32m    144\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Incompatible shapes for broadcasting: ((200, 3), (1, 200))"
     ]
    }
   ],
   "source": [
    "from jax.tree_util import tree_structure\n",
    "model = LatentSDE(theta=1.0,mu=0,sigma=0.5,key=key)\n",
    "t = jnp.array([1,2,3])\n",
    "y = jnp.array([2,3,4])\n",
    "model.f(t,y,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4067fa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc22a9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(self, t, y):  # Approximate posterior drift.\n",
    "        if t.dim() == 0:\n",
    "            t = torch.full_like(y, fill_value=t) # create a tensor of t\n",
    "        # Positional encoding in transformers for time-inhomogeneous posterior.\n",
    "        return self.net(torch.cat((torch.sin(t), torch.cos(t), y), dim=-1))\n",
    "\n",
    "    def g(self, t, y):  # Shared diffusion.\n",
    "        return self.sigma.repeat(y.size(0), 1) # 重复复制, 创建一个size为[y.size[0],1]\n",
    "\n",
    "    def h(self, t, y):  # Prior drift.\n",
    "        return self.theta * (self.mu - y)\n",
    "\n",
    "    def f_aug(self, t, y):  # Drift for augmented dynamics with logqp term.\n",
    "        y = y[:, 0:1] # 提取第一列，保持列的形态\n",
    "        f, g, h = self.f(t, y), self.g(t, y), self.h(t, y)\n",
    "        u = _stable_division(f - h, g) # 计算u(z,t)\n",
    "        f_logqp = .5 * (u ** 2).sum(dim=1, keepdim=True) # 计算integral\n",
    "        return torch.cat([f, f_logqp], dim=1)\n",
    "\n",
    "    def g_aug(self, t, y):  # Diffusion for augmented dynamics with logqp term.\n",
    "        y = y[:, 0:1]\n",
    "        g = self.g(t, y)\n",
    "        g_logqp = torch.zeros_like(y)\n",
    "        return torch.cat([g, g_logqp], dim=1)\n",
    "\n",
    "    def forward(self, ts, batch_size, eps=None):\n",
    "        eps = torch.randn(batch_size, 1).to(self.qy0_std) if eps is None else eps\n",
    "        y0 = self.qy0_mean + eps * self.qy0_std # the latent variable\n",
    "        qy0 = distributions.Normal(loc=self.qy0_mean, scale=self.qy0_std) # approximate posterior distribution\n",
    "        py0 = distributions.Normal(loc=self.py0_mean, scale=self.py0_std) # prior distribution\n",
    "        logqp0 = distributions.kl_divergence(qy0, py0).sum(dim=1)  # KL(t=0). calculate the kl divergence\n",
    "        #print(y0.size()) # (256, 1)\n",
    "        aug_y0 = torch.cat([y0, torch.zeros(batch_size, 1).to(y0)], dim=1) # create the augmented initial value\n",
    "        #print(aug_y0.size()) # [256, 2]\n",
    "        aug_ys = sdeint_fn(\n",
    "            sde=self,\n",
    "            y0=aug_y0,\n",
    "            ts=ts,\n",
    "            method=args['method'],\n",
    "            dt=args['dt'],\n",
    "            adaptive=args['adaptive'],\n",
    "            rtol=args['rtol'],\n",
    "            atol=args['atol'],\n",
    "            names={'drift': 'f_aug', 'diffusion': 'g_aug'}\n",
    "        ) # call the sde solver to \n",
    "        # print(aug_ys.size()) # [22, 256, 2]\n",
    "        ys, logqp_path = aug_ys[:, :, 0:1], aug_ys[-1, :, 1] # get the integral of the u(z,t) at the last time\n",
    "        \n",
    "        logqp = (logqp0 + logqp_path).mean(dim=0)  # KL(t=0) + KL(path).\n",
    "        return ys, logqp\n",
    "\n",
    "    def sample_p(self, ts, batch_size, eps=None, bm=None):\n",
    "        eps = torch.randn(batch_size, 1).to(self.py0_mean) if eps is None else eps\n",
    "        y0 = self.py0_mean + eps * self.py0_std\n",
    "        return sdeint_fn(self, y0, ts, bm=bm, method=args['method'], dt=args['dt'], names={'drift': 'h'}) # prior sde\n",
    "\n",
    "    def sample_q(self, ts, batch_size, eps=None, bm=None):\n",
    "        eps = torch.randn(batch_size, 1).to(self.qy0_mean) if eps is None else eps\n",
    "        y0 = self.qy0_mean + eps * self.qy0_std\n",
    "        return sdeint_fn(self, y0, ts, bm=bm, method=args['method'], dt=args['dt']) # posterior sde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "522d3e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LatentSDE(torchsde.SDEIto): # sde with ito calculus\n",
    "    def __init__(self, theta=1.0, mu=0.0, sigma=1):\n",
    "        super(LatentSDE, self).__init__(noise_type=\"diagonal\")\n",
    "        logvar = math.log(sigma ** 2/(2.*theta))\n",
    "        \n",
    "        # prior drift\n",
    "        self.register_buffer(\"theta\",torch.tensor([[theta]])) # prior parameters, register 成buffer, 参数不会进行更新\n",
    "        self.register_buffer(\"mu\", torch.tensor([[mu]]))\n",
    "        self.register_buffer(\"sigma\",torch.tensor([[sigma]]))\n",
    "        \n",
    "        # p(y0)\n",
    "        self.register_buffer(\"py0_mean\", torch.tensor([[mu]]))\n",
    "        self.register_buffer(\"py0_logvar\", torch.tensor([[logvar]]))\n",
    "        \n",
    "        # approximate posterior drift: Takes in 2 positional encodings and the state\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(3,200),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(200,200),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(200,1)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Initialization the parameters\n",
    "        self.net[-1].weight.data.fill_(0.) # 初始化最后一层的参数\n",
    "        self.net[-1].bias.data.fill_(0.)\n",
    "            \n",
    "        # q(y0)\n",
    "        self.qy0_mean = nn.Parameter(torch.tensor([[mu]]), requires_grad=True) # 创建parameters\n",
    "        self.qy0_logvar = nn.Parameter(torch.tensor([[logvar]]), requires_grad=True) # 创建parameters\n",
    "        #self.theta = nn.Parameter(torch.tensor([[theta]]),requires_grad=True)\n",
    "        #self.theta = nn.Parameter(torch.tensor([[theta]]),requires_grad=True)\n",
    "            \n",
    "    \n",
    "\n",
    "    @property\n",
    "    def py0_std(self):\n",
    "        return torch.exp(.5 * self.py0_logvar)\n",
    "\n",
    "    @property\n",
    "    def qy0_std(self):\n",
    "        return torch.exp(.5 * self.qy0_logvar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99a1fc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Dataset\n",
    "    ts_, ts_ext_, ts_vis_, ts, ts_ext, ts_vis, ys, ys_ = make_data()\n",
    "    #mu = torch.mean(ys)\n",
    "    sigma = torch.std(ys)\n",
    "    \n",
    "    # plotting parameters\n",
    "    vis_batch_size = 1024\n",
    "    ylims = (-0.03, 0.03)\n",
    "    alphas = [0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.55]\n",
    "    percentiles = [0.999, 0.99, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1]\n",
    "    vis_idx = np.random.permutation(vis_batch_size)\n",
    "    sample_colors = ('#8c96c6', '#8c6bb1', '#810f7c')\n",
    "    fill_color = '#9ebcda'\n",
    "    mean_color = '#4d004b'\n",
    "    num_samples = len(sample_colors)\n",
    "    \n",
    "    eps = torch.randn(vis_batch_size, 1).to(device)\n",
    "    bm = torchsde.BrownianInterval(\n",
    "        t0=ts_vis[0],\n",
    "        t1=ts_vis[-1],\n",
    "        size=(vis_batch_size,1),\n",
    "        device=device,\n",
    "        levy_area_approximation=\"space-time\")\n",
    "    \n",
    "    # Model\n",
    "    model = LatentSDE(theta=1.0,mu=0.0,sigma=sigma).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "    kl_scheduler = LinearScheduler(iters=100)\n",
    "    criterion = nn.BCELoss(reduction='sum')\n",
    "    \n",
    "    logpy_metric = EMAMetric()\n",
    "    kl_metric = EMAMetric()\n",
    "    loss_metric = EMAMetric()\n",
    "    \n",
    "    \n",
    "    # show prior\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        zs = model.sample_p(ts=ts_vis, batch_size = vis_batch_size, eps = eps, bm=bm).squeeze()\n",
    "       \n",
    "        ts_vis_, zs_ = ts_vis.cpu().numpy(), zs.cpu().numpy()\n",
    "        #plt.scatter(ts_vis_, ys_, color='r', label=\"prior\")\n",
    "        zs_ = np.sort(zs_,axis=1)\n",
    "        img_dir = os.path.join('./sim/','prior.png')\n",
    "        plt.subplot(frameon=False)\n",
    "        for alpha, percentile in zip(alphas, percentiles):\n",
    "            idx = int((1 - percentile) / 2. * vis_batch_size)\n",
    "            zs_bot_ = zs_[:, idx]\n",
    "            zs_top_ = zs_[:, -idx]\n",
    "            plt.fill_between(ts_vis_, zs_bot_, zs_top_, alpha=alpha, color=fill_color)\n",
    "\n",
    "        # `zorder` determines who's on top; the larger the more at the top.\n",
    "        \n",
    "        plt.scatter(ts_, ys_, marker='x', zorder=3, color='k', s=35)  # Data.\n",
    "        plt.plot(ts_, ys_, marker='x', zorder=3, color='k',label=\"observed $r_t$\")\n",
    "        plt.plot(ts_, z[:,None], color='g', linewidth=3.0, label=r\"hidden variable $z_t$\")\n",
    "        plt.ylim(ylims)\n",
    "        plt.xlabel('$t$')\n",
    "        plt.ylabel('$Y_t$')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.legend()\n",
    "        plt.savefig(img_dir, dpi=300)\n",
    "        plt.close()\n",
    "        logging.info(f'Saved prior figure at: {img_dir}')\n",
    "    \n",
    "    \n",
    "    for global_step in tqdm.tqdm(range(args['train_iters'])):\n",
    "        \n",
    "        # Plot and save.\n",
    "        if global_step % args['pause_iters'] == 0:\n",
    "            img_path = os.path.join(\"./sim/\", f'global_step_{global_step}.png')\n",
    "\n",
    "            with torch.no_grad():\n",
    "                zs = model.sample_q(ts=ts_vis, batch_size=vis_batch_size, eps=eps, bm=bm).squeeze()\n",
    "                samples = zs[:, vis_idx]\n",
    "                ts_vis_, zs_, samples_ = ts_vis.cpu().numpy(), zs.cpu().numpy(), samples.cpu().numpy()\n",
    "                zs_ = np.sort(zs_, axis=1)\n",
    "                plt.subplot(frameon=False)\n",
    "\n",
    "                if True: # args.show_percentiles:\n",
    "                    for alpha, percentile in zip(alphas, percentiles):\n",
    "                        idx = int((1 - percentile) / 2. * vis_batch_size)\n",
    "                        zs_bot_, zs_top_ = zs_[:, idx], zs_[:, -idx]\n",
    "                        plt.fill_between(ts_vis_, zs_bot_, zs_top_, alpha=alpha, color=fill_color)\n",
    "\n",
    "                if True: #args.show_mean:\n",
    "                    plt.plot(ts_vis_, zs_.mean(axis=1), color=mean_color)\n",
    "\n",
    "                if True: #args.show_samples:\n",
    "                    #for j in range(num_samples):\n",
    "                    #    plt.plot(ts_vis_, samples_[:, j], color=sample_colors[j], linewidth=1.0)\n",
    "                    plt.plot(ts_, z[:,None], color='g', linewidth=3.0, label=r\"hidden variable $z_t$\")\n",
    "                    plt.plot(ts_vis_, samples_.mean(axis=1), color='r',label=r'mean of latent variables')\n",
    "\n",
    "                if True: #args.show_arrows:\n",
    "                    num, dt = 3, 0.12\n",
    "                    t, y = torch.meshgrid(\n",
    "                        [torch.linspace(0, 3, num).to(device), torch.linspace(-0.3, 0.3, num).to(device)]\n",
    "                    )\n",
    "                    t, y = t.reshape(-1, 1), y.reshape(-1, 1)\n",
    "                    fty = model.f(t=t, y=y).reshape(num, num)\n",
    "                    dt = torch.zeros(num, num).fill_(dt).to(device)\n",
    "                    dy = fty * dt\n",
    "                    dt_, dy_, t_, y_ = dt.cpu().numpy(), dy.cpu().numpy(), t.cpu().numpy(), y.cpu().numpy()\n",
    "                    plt.quiver(t_, y_, dt_, dy_, alpha=0.3, edgecolors='k', width=0.0035, scale=50)\n",
    "\n",
    "                if False: #args.hide_ticks:\n",
    "                    plt.xticks([], [])\n",
    "                    plt.yticks([], [])\n",
    "\n",
    "                #plt.scatter(ts_, ys_, marker='x', zorder=3, color='k', s=35)  # Data.\n",
    "                plt.plot(ts_, ys_, marker='x', zorder=3, color='k', label=\"observed $r_t$ \") # new added\n",
    "            \n",
    "\n",
    "                \n",
    "                plt.ylim(ylims)\n",
    "                plt.xlabel('$t$')\n",
    "                plt.ylabel('$Y_t$')\n",
    "                plt.tight_layout()\n",
    "                plt.legend()\n",
    "                plt.savefig(img_path, dpi=300)\n",
    "                plt.close()\n",
    "                logging.info(f'Saved figure at: {img_path}')\n",
    "\n",
    "                \n",
    "        \n",
    "        # Train.\n",
    "        optimizer.zero_grad() # zero the gradient\n",
    "        zs, kl = model(ts=ts_ext, batch_size=args['batch_size']) # pass through the model, ys, logqp\n",
    "        zs = zs.squeeze() # remove the dimensions of input of size 1\n",
    "        zs = zs[1:-1]  # Drop first and last which are only used to penalize out-of-data region and spread uncertainty.\n",
    "\n",
    "        likelihood_constructor = {\"laplace\": distributions.Laplace, \"normal\": distributions.Normal}[args['likelihood']]\n",
    "        likelihood = likelihood_constructor(loc=zs, scale=args['scale']) # create the laplace distribution\n",
    "        logpy = likelihood.log_prob(ys).sum(dim=0).mean(dim=0) # got the log likelihood\n",
    "\n",
    "        loss = -logpy + kl * kl_scheduler.val\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        kl_scheduler.step()\n",
    "\n",
    "        logpy_metric.step(logpy)\n",
    "        kl_metric.step(kl)\n",
    "        loss_metric.step(loss)\n",
    "\n",
    "        logging.info(\n",
    "            f'global_step: {global_step}, '\n",
    "            f'logpy: {logpy_metric.val:.3f}, '\n",
    "            f'kl: {kl_metric.val:.3f}, '\n",
    "            f'loss: {loss_metric.val:.3f}'\n",
    "        )\n",
    "    torch.save(\n",
    "        {'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'scheduler': scheduler.state_dict(),\n",
    "            'kl_scheduler': kl_scheduler},\n",
    "        os.path.join('./sim/', f'global_step_{global_step}.ckpt')\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "74b55c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saved prior figure at: ./sim/prior.png\n",
      "  0%|                                                                                         | 0/1000 [00:00<?, ?it/s]INFO:root:Saved figure at: ./sim/global_step_0.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 0, logpy: -57.971, kl: 2.447, loss: 57.995\n",
      "  0%|                                                                               | 1/1000 [00:08<2:14:48,  8.10s/it]INFO:root:global_step: 1, logpy: -1140.805, kl: 848.256, loss: 1157.746\n",
      "  0%|▏                                                                              | 2/1000 [00:08<1:03:31,  3.82s/it]INFO:root:global_step: 2, logpy: -1578.056, kl: 997.561, loss: 1599.561\n",
      "  0%|▏                                                                                | 3/1000 [00:09<42:04,  2.53s/it]INFO:root:global_step: 3, logpy: -1659.156, kl: 991.488, loss: 1680.602\n",
      "  0%|▎                                                                                | 4/1000 [00:11<36:48,  2.22s/it]INFO:root:global_step: 4, logpy: -1813.230, kl: 995.423, loss: 1835.154\n",
      "  0%|▍                                                                                | 5/1000 [00:13<32:20,  1.95s/it]INFO:root:global_step: 5, logpy: -1861.411, kl: 987.349, loss: 1883.229\n",
      "  1%|▍                                                                                | 6/1000 [00:14<31:14,  1.89s/it]INFO:root:global_step: 6, logpy: -1939.093, kl: 989.836, loss: 1961.558\n",
      "  1%|▌                                                                                | 7/1000 [00:16<28:51,  1.74s/it]INFO:root:global_step: 7, logpy: -2065.277, kl: 1002.555, loss: 2089.327\n",
      "  1%|▋                                                                                | 8/1000 [00:17<26:41,  1.61s/it]INFO:root:global_step: 8, logpy: -2160.211, kl: 1008.489, loss: 2185.457\n",
      "  1%|▋                                                                                | 9/1000 [00:19<25:57,  1.57s/it]INFO:root:global_step: 9, logpy: -2195.208, kl: 1004.029, loss: 2220.763\n",
      "  1%|▊                                                                               | 10/1000 [00:20<26:32,  1.61s/it]INFO:root:global_step: 10, logpy: -2219.914, kl: 995.220, loss: 2245.349\n",
      "  1%|▉                                                                               | 11/1000 [00:22<27:15,  1.65s/it]INFO:root:global_step: 11, logpy: -2272.399, kl: 987.313, loss: 2297.825\n",
      "  1%|▉                                                                               | 12/1000 [00:24<27:30,  1.67s/it]INFO:root:global_step: 12, logpy: -2328.126, kl: 979.679, loss: 2353.589\n",
      "  1%|█                                                                               | 13/1000 [00:26<27:39,  1.68s/it]INFO:root:global_step: 13, logpy: -2369.965, kl: 971.546, loss: 2395.406\n",
      "  1%|█                                                                               | 14/1000 [00:27<28:05,  1.71s/it]INFO:root:global_step: 14, logpy: -2392.284, kl: 963.074, loss: 2417.658\n",
      "  2%|█▏                                                                              | 15/1000 [00:29<28:26,  1.73s/it]INFO:root:global_step: 15, logpy: -2404.577, kl: 955.250, loss: 2429.986\n",
      "  2%|█▎                                                                              | 16/1000 [00:31<28:48,  1.76s/it]INFO:root:global_step: 16, logpy: -2421.357, kl: 948.906, loss: 2447.057\n",
      "  2%|█▎                                                                              | 17/1000 [00:33<28:45,  1.76s/it]INFO:root:global_step: 17, logpy: -2450.673, kl: 944.595, loss: 2477.049\n",
      "  2%|█▍                                                                              | 18/1000 [00:34<28:18,  1.73s/it]INFO:root:global_step: 18, logpy: -2481.687, kl: 940.657, loss: 2508.845\n",
      "  2%|█▌                                                                              | 19/1000 [00:36<28:13,  1.73s/it]INFO:root:global_step: 19, logpy: -2505.503, kl: 935.625, loss: 2533.264\n",
      "  2%|█▌                                                                              | 20/1000 [00:38<28:18,  1.73s/it]INFO:root:global_step: 20, logpy: -2525.190, kl: 929.999, loss: 2553.457\n",
      "  2%|█▋                                                                              | 21/1000 [00:39<28:06,  1.72s/it]INFO:root:global_step: 21, logpy: -2537.772, kl: 923.290, loss: 2566.326\n",
      "  2%|█▊                                                                              | 22/1000 [00:41<28:10,  1.73s/it]INFO:root:global_step: 22, logpy: -2551.402, kl: 916.447, loss: 2580.221\n",
      "  2%|█▊                                                                              | 23/1000 [00:43<28:40,  1.76s/it]INFO:root:global_step: 23, logpy: -2566.035, kl: 908.908, loss: 2594.956\n",
      "  2%|█▉                                                                              | 24/1000 [00:45<29:09,  1.79s/it]INFO:root:global_step: 24, logpy: -2581.057, kl: 901.197, loss: 2610.033\n",
      "  2%|██                                                                              | 25/1000 [00:47<28:58,  1.78s/it]INFO:root:global_step: 25, logpy: -2595.120, kl: 893.334, loss: 2624.105\n",
      "  3%|██                                                                              | 26/1000 [00:48<29:02,  1.79s/it]INFO:root:global_step: 26, logpy: -2611.666, kl: 885.714, loss: 2640.715\n",
      "  3%|██▏                                                                             | 27/1000 [00:50<29:14,  1.80s/it]INFO:root:global_step: 27, logpy: -2629.030, kl: 878.211, loss: 2658.169\n",
      "  3%|██▏                                                                             | 28/1000 [00:52<29:14,  1.81s/it]INFO:root:global_step: 28, logpy: -2642.077, kl: 870.660, loss: 2671.281\n",
      "  3%|██▎                                                                             | 29/1000 [00:54<29:18,  1.81s/it]INFO:root:global_step: 29, logpy: -2655.054, kl: 863.183, loss: 2684.335\n",
      "  3%|██▍                                                                             | 30/1000 [00:56<29:10,  1.80s/it]INFO:root:global_step: 30, logpy: -2667.776, kl: 856.007, loss: 2697.215\n",
      "  3%|██▍                                                                             | 31/1000 [00:58<29:13,  1.81s/it]INFO:root:global_step: 31, logpy: -2681.018, kl: 849.063, loss: 2710.680\n",
      "  3%|██▌                                                                             | 32/1000 [00:59<29:05,  1.80s/it]INFO:root:global_step: 32, logpy: -2692.186, kl: 842.214, loss: 2722.093\n",
      "  3%|██▋                                                                             | 33/1000 [01:01<28:55,  1.79s/it]INFO:root:global_step: 33, logpy: -2702.969, kl: 835.539, loss: 2733.171\n",
      "  3%|██▋                                                                             | 34/1000 [01:03<28:34,  1.77s/it]INFO:root:global_step: 34, logpy: -2712.407, kl: 828.967, loss: 2742.931\n",
      "  4%|██▊                                                                             | 35/1000 [01:05<28:38,  1.78s/it]INFO:root:global_step: 35, logpy: -2723.766, kl: 822.550, loss: 2754.659\n",
      "  4%|██▉                                                                             | 36/1000 [01:06<28:46,  1.79s/it]INFO:root:global_step: 36, logpy: -2734.080, kl: 816.278, loss: 2765.387\n",
      "  4%|██▉                                                                             | 37/1000 [01:08<28:21,  1.77s/it]INFO:root:global_step: 37, logpy: -2744.179, kl: 810.330, loss: 2776.015\n",
      "  4%|███                                                                             | 38/1000 [01:10<28:49,  1.80s/it]INFO:root:global_step: 38, logpy: -2753.880, kl: 804.485, loss: 2786.278\n",
      "  4%|███                                                                             | 39/1000 [01:12<28:36,  1.79s/it]INFO:root:global_step: 39, logpy: -2765.418, kl: 798.510, loss: 2798.320\n",
      "  4%|███▏                                                                            | 40/1000 [01:14<28:19,  1.77s/it]INFO:root:global_step: 40, logpy: -2778.253, kl: 792.953, loss: 2811.821\n",
      "  4%|███▎                                                                            | 41/1000 [01:15<28:24,  1.78s/it]INFO:root:global_step: 41, logpy: -2789.421, kl: 787.320, loss: 2823.618\n",
      "  4%|███▎                                                                            | 42/1000 [01:17<28:09,  1.76s/it]INFO:root:global_step: 42, logpy: -2797.884, kl: 781.488, loss: 2832.617\n",
      "  4%|███▍                                                                            | 43/1000 [01:19<28:15,  1.77s/it]INFO:root:global_step: 43, logpy: -2805.973, kl: 775.766, loss: 2841.279\n",
      "  4%|███▌                                                                            | 44/1000 [01:21<28:18,  1.78s/it]INFO:root:global_step: 44, logpy: -2813.922, kl: 770.069, loss: 2849.803\n",
      "  4%|███▌                                                                            | 45/1000 [01:22<28:10,  1.77s/it]INFO:root:global_step: 45, logpy: -2823.154, kl: 764.566, loss: 2859.688\n",
      "  5%|███▋                                                                            | 46/1000 [01:24<28:13,  1.77s/it]INFO:root:global_step: 46, logpy: -2831.861, kl: 758.958, loss: 2868.986\n",
      "  5%|███▊                                                                            | 47/1000 [01:26<28:04,  1.77s/it]INFO:root:global_step: 47, logpy: -2844.182, kl: 753.631, loss: 2882.022\n",
      "  5%|███▊                                                                            | 48/1000 [01:28<27:59,  1.76s/it]INFO:root:global_step: 48, logpy: -2852.321, kl: 748.104, loss: 2890.767\n",
      "  5%|███▉                                                                            | 49/1000 [01:29<28:02,  1.77s/it]INFO:root:global_step: 49, logpy: -2860.427, kl: 742.535, loss: 2899.444\n",
      "  5%|████                                                                            | 50/1000 [01:31<27:39,  1.75s/it]INFO:root:Saved figure at: ./sim/global_step_50.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 50, logpy: -2867.892, kl: 736.966, loss: 2907.467\n",
      "  5%|████                                                                            | 51/1000 [01:39<58:18,  3.69s/it]INFO:root:global_step: 51, logpy: -2876.504, kl: 731.803, loss: 2916.830\n",
      "  5%|████▏                                                                           | 52/1000 [01:41<49:17,  3.12s/it]INFO:root:global_step: 52, logpy: -2883.961, kl: 726.342, loss: 2924.869\n",
      "  5%|████▏                                                                           | 53/1000 [01:43<43:02,  2.73s/it]INFO:root:global_step: 53, logpy: -2890.421, kl: 721.065, loss: 2931.991\n",
      "  5%|████▎                                                                           | 54/1000 [01:45<38:30,  2.44s/it]INFO:root:global_step: 54, logpy: -2897.978, kl: 715.721, loss: 2940.160\n",
      "  6%|████▍                                                                           | 55/1000 [01:46<35:04,  2.23s/it]INFO:root:global_step: 55, logpy: -2905.231, kl: 710.665, loss: 2948.167\n",
      "  6%|████▍                                                                           | 56/1000 [01:48<33:07,  2.11s/it]INFO:root:global_step: 56, logpy: -2912.816, kl: 705.517, loss: 2956.440\n",
      "  6%|████▌                                                                           | 57/1000 [01:50<31:37,  2.01s/it]INFO:root:global_step: 57, logpy: -2919.663, kl: 700.303, loss: 2963.919\n",
      "  6%|████▋                                                                           | 58/1000 [01:52<30:35,  1.95s/it]INFO:root:global_step: 58, logpy: -2929.468, kl: 695.197, loss: 2974.400\n",
      "  6%|████▋                                                                           | 59/1000 [01:54<29:30,  1.88s/it]INFO:root:global_step: 59, logpy: -2937.804, kl: 690.187, loss: 2983.452\n",
      "  6%|████▊                                                                           | 60/1000 [01:55<28:40,  1.83s/it]INFO:root:global_step: 60, logpy: -2943.558, kl: 685.161, loss: 2989.894\n",
      "  6%|████▉                                                                           | 61/1000 [01:57<28:02,  1.79s/it]INFO:root:global_step: 61, logpy: -2951.115, kl: 680.107, loss: 2998.102\n",
      "  6%|████▉                                                                           | 62/1000 [01:59<27:57,  1.79s/it]INFO:root:global_step: 62, logpy: -2958.440, kl: 675.138, loss: 3006.111\n",
      "  6%|█████                                                                           | 63/1000 [02:01<28:05,  1.80s/it]INFO:root:global_step: 63, logpy: -2965.591, kl: 670.504, loss: 3014.140\n",
      "  6%|█████                                                                           | 64/1000 [02:02<28:05,  1.80s/it]INFO:root:global_step: 64, logpy: -2972.160, kl: 665.587, loss: 3021.386\n",
      "  6%|█████▏                                                                          | 65/1000 [02:04<27:48,  1.78s/it]INFO:root:global_step: 65, logpy: -2980.802, kl: 660.797, loss: 3030.768\n",
      "  7%|█████▎                                                                          | 66/1000 [02:06<27:23,  1.76s/it]INFO:root:global_step: 66, logpy: -2988.668, kl: 656.000, loss: 3039.347\n",
      "  7%|█████▎                                                                          | 67/1000 [02:08<27:13,  1.75s/it]INFO:root:global_step: 67, logpy: -2994.350, kl: 651.165, loss: 3045.695\n",
      "  7%|█████▍                                                                          | 68/1000 [02:09<27:08,  1.75s/it]INFO:root:global_step: 68, logpy: -3000.661, kl: 646.415, loss: 3052.708\n",
      "  7%|█████▌                                                                          | 69/1000 [02:11<27:39,  1.78s/it]INFO:root:global_step: 69, logpy: -3006.916, kl: 641.732, loss: 3059.690\n",
      "  7%|█████▌                                                                          | 70/1000 [02:13<27:53,  1.80s/it]INFO:root:global_step: 70, logpy: -3012.502, kl: 637.155, loss: 3066.055\n",
      "  7%|█████▋                                                                          | 71/1000 [02:15<27:36,  1.78s/it]INFO:root:global_step: 71, logpy: -3019.078, kl: 632.673, loss: 3073.455\n",
      "  7%|█████▊                                                                          | 72/1000 [02:17<27:26,  1.77s/it]INFO:root:global_step: 72, logpy: -3026.206, kl: 628.182, loss: 3081.380\n",
      "  7%|█████▊                                                                          | 73/1000 [02:18<27:27,  1.78s/it]INFO:root:global_step: 73, logpy: -3033.881, kl: 623.799, loss: 3089.908\n",
      "  7%|█████▉                                                                          | 74/1000 [02:20<26:56,  1.75s/it]INFO:root:global_step: 74, logpy: -3038.315, kl: 619.282, loss: 3095.073\n",
      "  8%|██████                                                                          | 75/1000 [02:22<26:38,  1.73s/it]INFO:root:global_step: 75, logpy: -3044.276, kl: 614.899, loss: 3101.842\n",
      "  8%|██████                                                                          | 76/1000 [02:24<27:08,  1.76s/it]INFO:root:global_step: 76, logpy: -3050.545, kl: 610.631, loss: 3108.983\n",
      "  8%|██████▏                                                                         | 77/1000 [02:25<26:58,  1.75s/it]INFO:root:global_step: 77, logpy: -3057.901, kl: 606.490, loss: 3117.288\n",
      "  8%|██████▏                                                                         | 78/1000 [02:27<27:06,  1.76s/it]INFO:root:global_step: 78, logpy: -3064.214, kl: 602.283, loss: 3124.474\n",
      "  8%|██████▎                                                                         | 79/1000 [02:29<27:12,  1.77s/it]INFO:root:global_step: 79, logpy: -3070.031, kl: 598.090, loss: 3131.153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▍                                                                         | 80/1000 [02:31<27:08,  1.77s/it]INFO:root:global_step: 80, logpy: -3074.764, kl: 593.798, loss: 3136.642\n",
      "  8%|██████▍                                                                         | 81/1000 [02:32<27:07,  1.77s/it]INFO:root:global_step: 81, logpy: -3080.606, kl: 589.678, loss: 3143.357\n",
      "  8%|██████▌                                                                         | 82/1000 [02:34<27:03,  1.77s/it]INFO:root:global_step: 82, logpy: -3088.573, kl: 585.860, loss: 3152.421\n",
      "  8%|██████▋                                                                         | 83/1000 [02:36<26:56,  1.76s/it]INFO:root:global_step: 83, logpy: -3095.120, kl: 581.985, loss: 3159.996\n",
      "  8%|██████▋                                                                         | 84/1000 [02:38<27:23,  1.79s/it]INFO:root:global_step: 84, logpy: -3099.781, kl: 577.805, loss: 3165.403\n",
      "  8%|██████▊                                                                         | 85/1000 [02:40<26:58,  1.77s/it]INFO:root:global_step: 85, logpy: -3107.232, kl: 573.973, loss: 3173.871\n",
      "  9%|██████▉                                                                         | 86/1000 [02:41<26:57,  1.77s/it]INFO:root:global_step: 86, logpy: -3112.637, kl: 570.028, loss: 3180.170\n",
      "  9%|██████▉                                                                         | 87/1000 [02:43<27:14,  1.79s/it]INFO:root:global_step: 87, logpy: -3117.622, kl: 566.165, loss: 3186.097\n",
      "  9%|███████                                                                         | 88/1000 [02:45<27:02,  1.78s/it]INFO:root:global_step: 88, logpy: -3123.276, kl: 562.365, loss: 3192.723\n",
      "  9%|███████                                                                         | 89/1000 [02:47<27:14,  1.79s/it]INFO:root:global_step: 89, logpy: -3126.138, kl: 558.455, loss: 3196.434\n",
      "  9%|███████▏                                                                        | 90/1000 [02:48<26:55,  1.78s/it]INFO:root:global_step: 90, logpy: -3132.371, kl: 554.835, loss: 3203.750\n",
      "  9%|███████▎                                                                        | 91/1000 [02:50<26:57,  1.78s/it]INFO:root:global_step: 91, logpy: -3138.490, kl: 551.067, loss: 3210.793\n",
      "  9%|███████▎                                                                        | 92/1000 [02:52<26:57,  1.78s/it]INFO:root:global_step: 92, logpy: -3145.719, kl: 547.520, loss: 3219.127\n",
      "  9%|███████▍                                                                        | 93/1000 [02:54<26:37,  1.76s/it]INFO:root:global_step: 93, logpy: -3151.217, kl: 544.048, loss: 3225.774\n",
      "  9%|███████▌                                                                        | 94/1000 [02:55<26:32,  1.76s/it]INFO:root:global_step: 94, logpy: -3156.416, kl: 540.354, loss: 3231.886\n",
      " 10%|███████▌                                                                        | 95/1000 [02:57<26:39,  1.77s/it]INFO:root:global_step: 95, logpy: -3163.206, kl: 536.792, loss: 3239.689\n",
      " 10%|███████▋                                                                        | 96/1000 [02:59<26:53,  1.78s/it]INFO:root:global_step: 96, logpy: -3169.030, kl: 533.539, loss: 3246.799\n",
      " 10%|███████▊                                                                        | 97/1000 [03:01<26:36,  1.77s/it]INFO:root:global_step: 97, logpy: -3175.298, kl: 530.174, loss: 3254.221\n",
      " 10%|███████▊                                                                        | 98/1000 [03:03<26:40,  1.77s/it]INFO:root:global_step: 98, logpy: -3178.491, kl: 526.684, loss: 3258.418\n",
      " 10%|███████▉                                                                        | 99/1000 [03:04<26:35,  1.77s/it]INFO:root:global_step: 99, logpy: -3183.897, kl: 523.229, loss: 3264.837\n",
      " 10%|███████▉                                                                       | 100/1000 [03:06<26:39,  1.78s/it]INFO:root:Saved figure at: ./sim/global_step_100.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 100, logpy: -3190.107, kl: 519.829, loss: 3272.070\n",
      " 10%|███████▉                                                                       | 101/1000 [03:14<55:08,  3.68s/it]INFO:root:global_step: 101, logpy: -3195.285, kl: 516.560, loss: 3278.358\n",
      " 10%|████████                                                                       | 102/1000 [03:16<46:32,  3.11s/it]INFO:root:global_step: 102, logpy: -3199.869, kl: 513.188, loss: 3283.905\n",
      " 10%|████████▏                                                                      | 103/1000 [03:18<40:27,  2.71s/it]INFO:root:global_step: 103, logpy: -3204.961, kl: 509.803, loss: 3289.902\n",
      " 10%|████████▏                                                                      | 104/1000 [03:20<36:16,  2.43s/it]INFO:root:global_step: 104, logpy: -3212.013, kl: 506.671, loss: 3298.071\n",
      " 10%|████████▎                                                                      | 105/1000 [03:21<33:17,  2.23s/it]INFO:root:global_step: 105, logpy: -3216.207, kl: 503.441, loss: 3303.242\n",
      " 11%|████████▎                                                                      | 106/1000 [03:23<31:03,  2.08s/it]INFO:root:global_step: 106, logpy: -3220.495, kl: 500.072, loss: 3308.324\n",
      " 11%|████████▍                                                                      | 107/1000 [03:25<29:52,  2.01s/it]INFO:root:global_step: 107, logpy: -3224.518, kl: 496.840, loss: 3313.238\n",
      " 11%|████████▌                                                                      | 108/1000 [03:27<28:40,  1.93s/it]INFO:root:global_step: 108, logpy: -3227.882, kl: 493.836, loss: 3317.679\n",
      " 11%|████████▌                                                                      | 109/1000 [03:28<27:53,  1.88s/it]INFO:root:global_step: 109, logpy: -3229.382, kl: 490.437, loss: 3319.821\n",
      " 11%|████████▋                                                                      | 110/1000 [03:30<27:12,  1.83s/it]INFO:root:global_step: 110, logpy: -3233.449, kl: 487.336, loss: 3324.787\n",
      " 11%|████████▊                                                                      | 111/1000 [03:32<27:15,  1.84s/it]INFO:root:global_step: 111, logpy: -3239.953, kl: 484.317, loss: 3332.231\n",
      " 11%|████████▊                                                                      | 112/1000 [03:34<27:05,  1.83s/it]INFO:root:global_step: 112, logpy: -3245.892, kl: 481.176, loss: 3338.950\n",
      " 11%|████████▉                                                                      | 113/1000 [03:36<26:39,  1.80s/it]INFO:root:global_step: 113, logpy: -3248.486, kl: 478.023, loss: 3342.272\n",
      " 11%|█████████                                                                      | 114/1000 [03:37<26:30,  1.79s/it]INFO:root:global_step: 114, logpy: -3253.480, kl: 475.177, loss: 3348.262\n",
      " 12%|█████████                                                                      | 115/1000 [03:39<26:22,  1.79s/it]INFO:root:global_step: 115, logpy: -3257.995, kl: 472.240, loss: 3353.644\n",
      " 12%|█████████▏                                                                     | 116/1000 [03:41<26:29,  1.80s/it]INFO:root:global_step: 116, logpy: -3261.461, kl: 469.374, loss: 3358.011\n",
      " 12%|█████████▏                                                                     | 117/1000 [03:43<26:35,  1.81s/it]INFO:root:global_step: 117, logpy: -3266.785, kl: 466.515, loss: 3364.204\n",
      " 12%|█████████▎                                                                     | 118/1000 [03:45<26:59,  1.84s/it]INFO:root:global_step: 118, logpy: -3269.692, kl: 463.662, loss: 3367.948\n",
      " 12%|█████████▍                                                                     | 119/1000 [03:46<26:46,  1.82s/it]INFO:root:global_step: 119, logpy: -3273.168, kl: 460.863, loss: 3372.281\n",
      " 12%|█████████▍                                                                     | 120/1000 [03:48<26:10,  1.78s/it]INFO:root:global_step: 120, logpy: -3276.276, kl: 458.085, loss: 3376.228\n",
      " 12%|█████████▌                                                                     | 121/1000 [03:50<26:11,  1.79s/it]INFO:root:global_step: 121, logpy: -3280.442, kl: 455.359, loss: 3381.249\n",
      " 12%|█████████▋                                                                     | 122/1000 [03:52<26:10,  1.79s/it]INFO:root:global_step: 122, logpy: -3286.202, kl: 452.824, loss: 3388.019\n",
      " 12%|█████████▋                                                                     | 123/1000 [03:54<26:05,  1.79s/it]INFO:root:global_step: 123, logpy: -3290.308, kl: 450.149, loss: 3392.960\n",
      " 12%|█████████▊                                                                     | 124/1000 [03:55<26:14,  1.80s/it]INFO:root:global_step: 124, logpy: -3295.378, kl: 447.615, loss: 3398.972\n",
      " 12%|█████████▉                                                                     | 125/1000 [03:57<26:01,  1.78s/it]INFO:root:global_step: 125, logpy: -3301.446, kl: 445.085, loss: 3405.949\n",
      " 13%|█████████▉                                                                     | 126/1000 [03:59<25:52,  1.78s/it]INFO:root:global_step: 126, logpy: -3305.765, kl: 442.543, loss: 3411.132\n",
      " 13%|██████████                                                                     | 127/1000 [04:01<25:57,  1.78s/it]INFO:root:global_step: 127, logpy: -3307.980, kl: 439.954, loss: 3414.130\n",
      " 13%|██████████                                                                     | 128/1000 [04:02<25:45,  1.77s/it]INFO:root:global_step: 128, logpy: -3311.783, kl: 437.352, loss: 3418.669\n",
      " 13%|██████████▏                                                                    | 129/1000 [04:04<25:43,  1.77s/it]INFO:root:global_step: 129, logpy: -3313.334, kl: 434.833, loss: 3421.006\n",
      " 13%|██████████▎                                                                    | 130/1000 [04:06<26:00,  1.79s/it]INFO:root:global_step: 130, logpy: -3318.644, kl: 432.407, loss: 3427.161\n",
      " 13%|██████████▎                                                                    | 131/1000 [04:08<25:58,  1.79s/it]INFO:root:global_step: 131, logpy: -3324.888, kl: 430.077, loss: 3434.315\n",
      " 13%|██████████▍                                                                    | 132/1000 [04:10<25:45,  1.78s/it]INFO:root:global_step: 132, logpy: -3327.314, kl: 427.584, loss: 3437.453\n",
      " 13%|██████████▌                                                                    | 133/1000 [04:11<25:35,  1.77s/it]INFO:root:global_step: 133, logpy: -3330.709, kl: 425.088, loss: 3441.527\n",
      " 13%|██████████▌                                                                    | 134/1000 [04:13<25:27,  1.76s/it]INFO:root:global_step: 134, logpy: -3334.760, kl: 422.725, loss: 3446.357\n",
      " 14%|██████████▋                                                                    | 135/1000 [04:15<25:21,  1.76s/it]INFO:root:global_step: 135, logpy: -3335.662, kl: 420.151, loss: 3447.797\n",
      " 14%|██████████▋                                                                    | 136/1000 [04:17<25:13,  1.75s/it]INFO:root:global_step: 136, logpy: -3338.873, kl: 417.861, loss: 3451.798\n",
      " 14%|██████████▊                                                                    | 137/1000 [04:18<25:31,  1.77s/it]INFO:root:global_step: 137, logpy: -3341.509, kl: 415.478, loss: 3455.100\n",
      " 14%|██████████▉                                                                    | 138/1000 [04:20<25:37,  1.78s/it]INFO:root:global_step: 138, logpy: -3344.742, kl: 413.003, loss: 3458.877\n",
      " 14%|██████████▉                                                                    | 139/1000 [04:22<25:25,  1.77s/it]INFO:root:global_step: 139, logpy: -3348.955, kl: 410.940, loss: 3464.016\n",
      " 14%|███████████                                                                    | 140/1000 [04:24<25:32,  1.78s/it]INFO:root:global_step: 140, logpy: -3351.878, kl: 408.740, loss: 3467.699\n",
      " 14%|███████████▏                                                                   | 141/1000 [04:25<25:15,  1.76s/it]INFO:root:global_step: 141, logpy: -3354.457, kl: 406.542, loss: 3471.008\n",
      " 14%|███████████▏                                                                   | 142/1000 [04:27<25:10,  1.76s/it]INFO:root:global_step: 142, logpy: -3358.544, kl: 404.299, loss: 3475.751\n",
      " 14%|███████████▎                                                                   | 143/1000 [04:29<25:24,  1.78s/it]INFO:root:global_step: 143, logpy: -3363.395, kl: 402.206, loss: 3481.381\n",
      " 14%|███████████▍                                                                   | 144/1000 [04:31<25:37,  1.80s/it]INFO:root:global_step: 144, logpy: -3367.727, kl: 400.107, loss: 3486.457\n",
      " 14%|███████████▍                                                                   | 145/1000 [04:33<25:29,  1.79s/it]INFO:root:global_step: 145, logpy: -3372.083, kl: 398.113, loss: 3491.631\n",
      " 15%|███████████▌                                                                   | 146/1000 [04:34<25:28,  1.79s/it]INFO:root:global_step: 146, logpy: -3374.988, kl: 396.000, loss: 3495.210\n",
      " 15%|███████████▌                                                                   | 147/1000 [04:36<25:19,  1.78s/it]INFO:root:global_step: 147, logpy: -3375.492, kl: 393.601, loss: 3496.073\n",
      " 15%|███████████▋                                                                   | 148/1000 [04:38<25:18,  1.78s/it]INFO:root:global_step: 148, logpy: -3377.526, kl: 391.623, loss: 3498.859\n",
      " 15%|███████████▊                                                                   | 149/1000 [04:40<25:40,  1.81s/it]INFO:root:global_step: 149, logpy: -3381.371, kl: 389.550, loss: 3503.333\n",
      " 15%|███████████▊                                                                   | 150/1000 [04:42<25:19,  1.79s/it]INFO:root:Saved figure at: ./sim/global_step_150.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 150, logpy: -3384.117, kl: 387.465, loss: 3506.671\n",
      " 15%|███████████▉                                                                   | 151/1000 [04:50<52:38,  3.72s/it]INFO:root:global_step: 151, logpy: -3389.551, kl: 385.653, loss: 3512.942\n",
      " 15%|████████████                                                                   | 152/1000 [04:52<44:04,  3.12s/it]INFO:root:global_step: 152, logpy: -3390.156, kl: 383.540, loss: 3514.056\n",
      " 15%|████████████                                                                   | 153/1000 [04:53<38:40,  2.74s/it]INFO:root:global_step: 153, logpy: -3391.927, kl: 381.493, loss: 3516.377\n",
      " 15%|████████████▏                                                                  | 154/1000 [04:55<34:51,  2.47s/it]INFO:root:global_step: 154, logpy: -3394.540, kl: 379.562, loss: 3519.629\n",
      " 16%|████████████▏                                                                  | 155/1000 [04:57<31:56,  2.27s/it]INFO:root:global_step: 155, logpy: -3398.875, kl: 377.736, loss: 3524.682\n",
      " 16%|████████████▎                                                                  | 156/1000 [04:59<29:33,  2.10s/it]INFO:root:global_step: 156, logpy: -3401.408, kl: 375.751, loss: 3527.750\n",
      " 16%|████████████▍                                                                  | 157/1000 [05:00<28:01,  1.99s/it]INFO:root:global_step: 157, logpy: -3405.548, kl: 373.864, loss: 3532.497\n",
      " 16%|████████████▍                                                                  | 158/1000 [05:02<27:22,  1.95s/it]INFO:root:global_step: 158, logpy: -3410.193, kl: 372.213, loss: 3537.961\n",
      " 16%|████████████▌                                                                  | 159/1000 [05:04<26:35,  1.90s/it]INFO:root:global_step: 159, logpy: -3413.048, kl: 370.373, loss: 3541.420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████▋                                                                  | 160/1000 [05:06<25:46,  1.84s/it]INFO:root:global_step: 160, logpy: -3415.909, kl: 368.695, loss: 3545.023\n",
      " 16%|████████████▋                                                                  | 161/1000 [05:08<25:39,  1.83s/it]INFO:root:global_step: 161, logpy: -3418.236, kl: 366.815, loss: 3547.865\n",
      " 16%|████████████▊                                                                  | 162/1000 [05:09<25:19,  1.81s/it]INFO:root:global_step: 162, logpy: -3422.826, kl: 365.139, loss: 3553.152\n",
      " 16%|████████████▉                                                                  | 163/1000 [05:11<25:19,  1.82s/it]INFO:root:global_step: 163, logpy: -3427.350, kl: 363.389, loss: 3558.273\n",
      " 16%|████████████▉                                                                  | 164/1000 [05:13<25:01,  1.80s/it]INFO:root:global_step: 164, logpy: -3430.843, kl: 361.587, loss: 3562.289\n",
      " 16%|█████████████                                                                  | 165/1000 [05:15<24:43,  1.78s/it]INFO:root:global_step: 165, logpy: -3435.483, kl: 360.022, loss: 3567.665\n",
      " 17%|█████████████                                                                  | 166/1000 [05:16<24:29,  1.76s/it]INFO:root:global_step: 166, logpy: -3437.948, kl: 358.393, loss: 3570.780\n",
      " 17%|█████████████▏                                                                 | 167/1000 [05:18<24:42,  1.78s/it]INFO:root:global_step: 167, logpy: -3439.722, kl: 356.641, loss: 3573.058\n",
      " 17%|█████████████▎                                                                 | 168/1000 [05:20<24:33,  1.77s/it]INFO:root:global_step: 168, logpy: -3442.270, kl: 354.911, loss: 3576.109\n",
      " 17%|█████████████▎                                                                 | 169/1000 [05:22<24:44,  1.79s/it]INFO:root:global_step: 169, logpy: -3444.689, kl: 353.205, loss: 3579.032\n",
      " 17%|█████████████▍                                                                 | 170/1000 [05:24<24:32,  1.77s/it]INFO:root:global_step: 170, logpy: -3447.842, kl: 351.667, loss: 3582.836\n",
      " 17%|█████████████▌                                                                 | 171/1000 [05:25<24:24,  1.77s/it]INFO:root:global_step: 171, logpy: -3450.590, kl: 349.981, loss: 3586.064\n",
      " 17%|█████████████▌                                                                 | 172/1000 [05:27<25:00,  1.81s/it]INFO:root:global_step: 172, logpy: -3454.008, kl: 348.348, loss: 3589.994\n",
      " 17%|█████████████▋                                                                 | 173/1000 [05:29<24:40,  1.79s/it]INFO:root:global_step: 173, logpy: -3455.992, kl: 346.838, loss: 3592.592\n",
      " 17%|█████████████▋                                                                 | 174/1000 [05:31<24:32,  1.78s/it]INFO:root:global_step: 174, logpy: -3457.522, kl: 345.193, loss: 3594.579\n",
      " 18%|█████████████▊                                                                 | 175/1000 [05:32<24:21,  1.77s/it]INFO:root:global_step: 175, logpy: -3459.491, kl: 343.607, loss: 3597.045\n",
      " 18%|█████████████▉                                                                 | 176/1000 [05:34<24:37,  1.79s/it]INFO:root:global_step: 176, logpy: -3463.098, kl: 342.081, loss: 3601.186\n",
      " 18%|█████████████▉                                                                 | 177/1000 [05:36<24:48,  1.81s/it]INFO:root:global_step: 177, logpy: -3466.364, kl: 340.536, loss: 3604.946\n",
      " 18%|██████████████                                                                 | 178/1000 [05:38<25:49,  1.89s/it]INFO:root:global_step: 178, logpy: -3469.036, kl: 339.073, loss: 3608.174\n",
      " 18%|██████████████▏                                                                | 179/1000 [05:40<25:22,  1.85s/it]INFO:root:global_step: 179, logpy: -3470.254, kl: 337.568, loss: 3609.887\n",
      " 18%|██████████████▏                                                                | 180/1000 [05:42<24:54,  1.82s/it]INFO:root:global_step: 180, logpy: -3474.227, kl: 335.935, loss: 3614.207\n",
      " 18%|██████████████▎                                                                | 181/1000 [05:43<24:27,  1.79s/it]INFO:root:global_step: 181, logpy: -3475.452, kl: 334.311, loss: 3615.767\n",
      " 18%|██████████████▍                                                                | 182/1000 [05:45<24:18,  1.78s/it]INFO:root:global_step: 182, logpy: -3477.003, kl: 332.803, loss: 3617.750\n",
      " 18%|██████████████▍                                                                | 183/1000 [05:47<24:36,  1.81s/it]INFO:root:global_step: 183, logpy: -3477.378, kl: 331.183, loss: 3618.426\n",
      " 18%|██████████████▌                                                                | 184/1000 [05:49<24:20,  1.79s/it]INFO:root:global_step: 184, logpy: -3478.883, kl: 329.686, loss: 3620.336\n",
      " 18%|██████████████▌                                                                | 185/1000 [05:51<24:13,  1.78s/it]INFO:root:global_step: 185, logpy: -3480.245, kl: 328.236, loss: 3622.129\n",
      " 19%|██████████████▋                                                                | 186/1000 [05:52<24:10,  1.78s/it]INFO:root:global_step: 186, logpy: -3481.561, kl: 326.758, loss: 3623.830\n",
      " 19%|██████████████▊                                                                | 187/1000 [05:54<24:10,  1.78s/it]INFO:root:global_step: 187, logpy: -3483.286, kl: 325.379, loss: 3626.021\n",
      " 19%|██████████████▊                                                                | 188/1000 [05:56<24:08,  1.78s/it]INFO:root:global_step: 188, logpy: -3485.011, kl: 323.938, loss: 3628.132\n",
      " 19%|██████████████▉                                                                | 189/1000 [05:58<23:53,  1.77s/it]INFO:root:global_step: 189, logpy: -3487.426, kl: 322.625, loss: 3631.042\n",
      " 19%|███████████████                                                                | 190/1000 [06:00<23:56,  1.77s/it]INFO:root:global_step: 190, logpy: -3489.389, kl: 321.329, loss: 3633.499\n",
      " 19%|███████████████                                                                | 191/1000 [06:01<23:50,  1.77s/it]INFO:root:global_step: 191, logpy: -3491.524, kl: 319.963, loss: 3636.040\n",
      " 19%|███████████████▏                                                               | 192/1000 [06:03<23:55,  1.78s/it]INFO:root:global_step: 192, logpy: -3494.159, kl: 318.572, loss: 3639.039\n",
      " 19%|███████████████▏                                                               | 193/1000 [06:05<23:55,  1.78s/it]INFO:root:global_step: 193, logpy: -3493.808, kl: 317.051, loss: 3638.905\n",
      " 19%|███████████████▎                                                               | 194/1000 [06:07<23:39,  1.76s/it]INFO:root:global_step: 194, logpy: -3495.033, kl: 315.616, loss: 3640.414\n",
      " 20%|███████████████▍                                                               | 195/1000 [06:08<23:42,  1.77s/it]INFO:root:global_step: 195, logpy: -3496.545, kl: 314.124, loss: 3642.136\n",
      " 20%|███████████████▍                                                               | 196/1000 [06:10<23:37,  1.76s/it]INFO:root:global_step: 196, logpy: -3497.043, kl: 312.817, loss: 3643.013\n",
      " 20%|███████████████▌                                                               | 197/1000 [06:12<23:32,  1.76s/it]INFO:root:global_step: 197, logpy: -3499.853, kl: 311.601, loss: 3646.274\n",
      " 20%|███████████████▋                                                               | 198/1000 [06:14<23:33,  1.76s/it]INFO:root:global_step: 198, logpy: -3501.769, kl: 310.483, loss: 3648.725\n",
      " 20%|███████████████▋                                                               | 199/1000 [06:15<23:22,  1.75s/it]INFO:root:global_step: 199, logpy: -3503.289, kl: 309.337, loss: 3650.734\n",
      " 20%|███████████████▊                                                               | 200/1000 [06:17<23:23,  1.75s/it]INFO:root:Saved figure at: ./sim/global_step_200.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:global_step: 200, logpy: -3505.524, kl: 308.134, loss: 3653.384\n",
      " 20%|███████████████▉                                                               | 201/1000 [06:25<49:13,  3.70s/it]INFO:root:global_step: 201, logpy: -3507.645, kl: 306.749, loss: 3655.723\n",
      " 20%|███████████████▉                                                               | 202/1000 [06:27<41:35,  3.13s/it]INFO:root:global_step: 202, logpy: -3510.144, kl: 305.625, loss: 3658.686\n",
      " 20%|████████████████                                                               | 203/1000 [06:29<36:16,  2.73s/it]INFO:root:global_step: 203, logpy: -3511.468, kl: 304.489, loss: 3660.445\n",
      " 20%|████████████████                                                               | 204/1000 [06:31<32:10,  2.43s/it]INFO:root:global_step: 204, logpy: -3512.092, kl: 303.349, loss: 3661.484\n",
      " 20%|████████████████▏                                                              | 205/1000 [06:32<29:30,  2.23s/it]INFO:root:global_step: 205, logpy: -3515.440, kl: 302.274, loss: 3665.295\n",
      " 21%|████████████████▎                                                              | 206/1000 [06:34<27:37,  2.09s/it]INFO:root:global_step: 206, logpy: -3517.083, kl: 301.037, loss: 3667.226\n",
      " 21%|████████████████▎                                                              | 207/1000 [06:36<26:34,  2.01s/it]INFO:root:global_step: 207, logpy: -3519.909, kl: 300.008, loss: 3670.532\n",
      " 21%|████████████████▍                                                              | 208/1000 [06:38<25:25,  1.93s/it]INFO:root:global_step: 208, logpy: -3520.505, kl: 298.776, loss: 3671.389\n",
      " 21%|████████████████▌                                                              | 209/1000 [06:39<24:37,  1.87s/it]INFO:root:global_step: 209, logpy: -3521.921, kl: 297.851, loss: 3673.360\n",
      " 21%|████████████████▌                                                              | 210/1000 [06:41<23:56,  1.82s/it]INFO:root:global_step: 210, logpy: -3524.486, kl: 296.927, loss: 3676.466\n",
      " 21%|████████████████▋                                                              | 211/1000 [06:43<23:51,  1.81s/it]INFO:root:global_step: 211, logpy: -3526.018, kl: 295.656, loss: 3678.175\n",
      " 21%|████████████████▋                                                              | 212/1000 [06:45<23:41,  1.80s/it]INFO:root:global_step: 212, logpy: -3525.958, kl: 294.423, loss: 3678.317\n",
      " 21%|████████████████▊                                                              | 213/1000 [06:47<23:34,  1.80s/it]INFO:root:global_step: 213, logpy: -3528.171, kl: 293.320, loss: 3680.848\n",
      " 21%|████████████████▉                                                              | 214/1000 [06:48<23:15,  1.78s/it]INFO:root:global_step: 214, logpy: -3531.038, kl: 292.090, loss: 3683.892\n",
      " 22%|████████████████▉                                                              | 215/1000 [06:50<23:02,  1.76s/it]INFO:root:global_step: 215, logpy: -3532.377, kl: 291.020, loss: 3685.553\n",
      " 22%|█████████████████                                                              | 216/1000 [06:52<22:56,  1.76s/it]INFO:root:global_step: 216, logpy: -3534.315, kl: 289.982, loss: 3687.831\n",
      " 22%|█████████████████▏                                                             | 217/1000 [06:53<22:55,  1.76s/it]INFO:root:global_step: 217, logpy: -3536.734, kl: 288.936, loss: 3690.569\n",
      " 22%|█████████████████▏                                                             | 218/1000 [06:55<22:56,  1.76s/it]INFO:root:global_step: 218, logpy: -3538.714, kl: 287.882, loss: 3692.846\n",
      " 22%|█████████████████▎                                                             | 219/1000 [06:57<22:43,  1.75s/it]INFO:root:global_step: 219, logpy: -3540.760, kl: 286.804, loss: 3695.152\n",
      " 22%|█████████████████▍                                                             | 220/1000 [06:59<22:36,  1.74s/it]INFO:root:global_step: 220, logpy: -3542.224, kl: 285.792, loss: 3696.928\n",
      " 22%|█████████████████▍                                                             | 221/1000 [07:01<22:57,  1.77s/it]INFO:root:global_step: 221, logpy: -3543.341, kl: 284.802, loss: 3698.365\n",
      " 22%|█████████████████▌                                                             | 222/1000 [07:02<22:54,  1.77s/it]INFO:root:global_step: 222, logpy: -3545.550, kl: 283.845, loss: 3700.915\n",
      " 22%|█████████████████▌                                                             | 223/1000 [07:04<22:41,  1.75s/it]INFO:root:global_step: 223, logpy: -3548.586, kl: 283.091, loss: 3704.482\n",
      " 22%|█████████████████▋                                                             | 224/1000 [07:06<22:37,  1.75s/it]INFO:root:global_step: 224, logpy: -3550.595, kl: 282.152, loss: 3706.824\n",
      " 22%|█████████████████▊                                                             | 225/1000 [07:08<22:40,  1.76s/it]INFO:root:global_step: 225, logpy: -3550.009, kl: 281.039, loss: 3706.384\n",
      " 23%|█████████████████▊                                                             | 226/1000 [07:09<22:31,  1.75s/it]INFO:root:global_step: 226, logpy: -3551.317, kl: 280.137, loss: 3708.037\n",
      " 23%|█████████████████▉                                                             | 227/1000 [07:11<22:25,  1.74s/it]INFO:root:global_step: 227, logpy: -3552.995, kl: 279.115, loss: 3709.927\n",
      " 23%|██████████████████                                                             | 228/1000 [07:13<22:42,  1.76s/it]INFO:root:global_step: 228, logpy: -3553.280, kl: 278.004, loss: 3710.323\n",
      " 23%|██████████████████                                                             | 229/1000 [07:15<22:30,  1.75s/it]INFO:root:global_step: 229, logpy: -3555.704, kl: 277.091, loss: 3713.044\n",
      " 23%|██████████████████▏                                                            | 230/1000 [07:16<22:50,  1.78s/it]INFO:root:global_step: 230, logpy: -3557.777, kl: 276.397, loss: 3715.619\n",
      " 23%|██████████████████▏                                                            | 231/1000 [07:18<22:48,  1.78s/it]INFO:root:global_step: 231, logpy: -3559.898, kl: 275.655, loss: 3718.185\n",
      " 23%|██████████████████▎                                                            | 232/1000 [07:20<22:49,  1.78s/it]INFO:root:global_step: 232, logpy: -3560.351, kl: 274.619, loss: 3718.775\n",
      " 23%|██████████████████▍                                                            | 233/1000 [07:22<22:58,  1.80s/it]INFO:root:global_step: 233, logpy: -3561.817, kl: 273.841, loss: 3720.626\n",
      " 23%|██████████████████▍                                                            | 234/1000 [07:24<23:03,  1.81s/it]INFO:root:global_step: 234, logpy: -3563.165, kl: 272.993, loss: 3722.276\n",
      " 24%|██████████████████▌                                                            | 235/1000 [07:25<23:11,  1.82s/it]INFO:root:global_step: 235, logpy: -3564.578, kl: 272.202, loss: 3724.036\n",
      " 24%|██████████████████▋                                                            | 236/1000 [07:27<22:59,  1.81s/it]INFO:root:global_step: 236, logpy: -3566.875, kl: 271.358, loss: 3726.616\n",
      " 24%|██████████████████▋                                                            | 237/1000 [07:29<22:42,  1.79s/it]INFO:root:global_step: 237, logpy: -3569.770, kl: 270.511, loss: 3729.781\n",
      " 24%|██████████████████▊                                                            | 238/1000 [07:31<22:54,  1.80s/it]INFO:root:global_step: 238, logpy: -3570.976, kl: 269.670, loss: 3731.251\n",
      " 24%|██████████████████▉                                                            | 239/1000 [07:33<22:58,  1.81s/it]INFO:root:global_step: 239, logpy: -3572.166, kl: 268.912, loss: 3732.777\n",
      " 24%|██████████████████▉                                                            | 240/1000 [07:34<22:56,  1.81s/it]INFO:root:global_step: 240, logpy: -3573.477, kl: 268.019, loss: 3734.278\n",
      " 24%|███████████████████                                                            | 241/1000 [07:36<22:49,  1.80s/it]INFO:root:global_step: 241, logpy: -3574.154, kl: 267.293, loss: 3735.301\n",
      " 24%|███████████████████                                                            | 242/1000 [07:38<22:43,  1.80s/it]INFO:root:global_step: 242, logpy: -3575.471, kl: 266.575, loss: 3736.961\n",
      " 24%|███████████████████▏                                                           | 243/1000 [07:40<22:57,  1.82s/it]INFO:root:global_step: 243, logpy: -3577.576, kl: 265.788, loss: 3739.330\n",
      " 24%|███████████████████▎                                                           | 244/1000 [07:42<22:35,  1.79s/it]INFO:root:global_step: 244, logpy: -3578.664, kl: 265.169, loss: 3740.840\n",
      " 24%|███████████████████▎                                                           | 245/1000 [07:43<22:37,  1.80s/it]INFO:root:global_step: 245, logpy: -3579.313, kl: 264.506, loss: 3741.855\n",
      " 25%|███████████████████▍                                                           | 246/1000 [07:45<22:35,  1.80s/it]INFO:root:global_step: 246, logpy: -3581.416, kl: 263.873, loss: 3744.345\n",
      " 25%|███████████████████▌                                                           | 247/1000 [07:47<22:31,  1.79s/it]INFO:root:global_step: 247, logpy: -3582.136, kl: 263.086, loss: 3745.287\n",
      " 25%|███████████████████▌                                                           | 248/1000 [07:49<22:32,  1.80s/it]INFO:root:global_step: 248, logpy: -3583.067, kl: 262.419, loss: 3746.550\n",
      " 25%|███████████████████▋                                                           | 249/1000 [07:51<22:32,  1.80s/it]INFO:root:global_step: 249, logpy: -3583.852, kl: 261.650, loss: 3747.557\n",
      " 25%|███████████████████▊                                                           | 250/1000 [07:52<22:30,  1.80s/it]INFO:root:Saved figure at: ./sim/global_step_250.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 250, logpy: -3586.987, kl: 260.894, loss: 3750.915\n",
      " 25%|███████████████████▊                                                           | 251/1000 [08:01<46:23,  3.72s/it]INFO:root:global_step: 251, logpy: -3588.778, kl: 260.085, loss: 3752.867\n",
      " 25%|███████████████████▉                                                           | 252/1000 [08:02<39:14,  3.15s/it]INFO:root:global_step: 252, logpy: -3590.124, kl: 259.456, loss: 3754.543\n",
      " 25%|███████████████████▉                                                           | 253/1000 [08:04<34:31,  2.77s/it]INFO:root:global_step: 253, logpy: -3591.379, kl: 258.791, loss: 3756.084\n",
      " 25%|████████████████████                                                           | 254/1000 [08:06<31:03,  2.50s/it]INFO:root:global_step: 254, logpy: -3593.485, kl: 258.152, loss: 3758.491\n",
      " 26%|████████████████████▏                                                          | 255/1000 [08:08<28:14,  2.27s/it]INFO:root:global_step: 255, logpy: -3595.213, kl: 257.513, loss: 3760.513\n",
      " 26%|████████████████████▏                                                          | 256/1000 [08:10<26:34,  2.14s/it]INFO:root:global_step: 256, logpy: -3596.424, kl: 256.851, loss: 3761.982\n",
      " 26%|████████████████████▎                                                          | 257/1000 [08:12<25:06,  2.03s/it]INFO:root:global_step: 257, logpy: -3598.740, kl: 256.170, loss: 3764.531\n",
      " 26%|████████████████████▍                                                          | 258/1000 [08:13<24:02,  1.94s/it]INFO:root:global_step: 258, logpy: -3599.692, kl: 255.556, loss: 3765.774\n",
      " 26%|████████████████████▍                                                          | 259/1000 [08:15<23:20,  1.89s/it]INFO:root:global_step: 259, logpy: -3600.291, kl: 254.795, loss: 3766.506\n",
      " 26%|████████████████████▌                                                          | 260/1000 [08:17<22:53,  1.86s/it]INFO:root:global_step: 260, logpy: -3603.252, kl: 254.021, loss: 3769.578\n",
      " 26%|████████████████████▌                                                          | 261/1000 [08:19<22:36,  1.84s/it]INFO:root:global_step: 261, logpy: -3604.416, kl: 253.230, loss: 3770.829\n",
      " 26%|████████████████████▋                                                          | 262/1000 [08:20<22:14,  1.81s/it]INFO:root:global_step: 262, logpy: -3603.947, kl: 252.503, loss: 3770.500\n",
      " 26%|████████████████████▊                                                          | 263/1000 [08:22<22:22,  1.82s/it]INFO:root:global_step: 263, logpy: -3604.198, kl: 251.651, loss: 3770.759\n",
      " 26%|████████████████████▊                                                          | 264/1000 [08:24<22:03,  1.80s/it]INFO:root:global_step: 264, logpy: -3605.220, kl: 251.079, loss: 3772.060\n",
      " 26%|████████████████████▉                                                          | 265/1000 [08:26<21:48,  1.78s/it]INFO:root:global_step: 265, logpy: -3608.156, kl: 250.559, loss: 3775.318\n",
      " 27%|█████████████████████                                                          | 266/1000 [08:27<21:44,  1.78s/it]INFO:root:global_step: 266, logpy: -3608.771, kl: 249.953, loss: 3776.161\n",
      " 27%|█████████████████████                                                          | 267/1000 [08:29<21:54,  1.79s/it]INFO:root:global_step: 267, logpy: -3609.922, kl: 249.319, loss: 3777.505\n",
      " 27%|█████████████████████▏                                                         | 268/1000 [08:31<21:42,  1.78s/it]INFO:root:global_step: 268, logpy: -3608.511, kl: 248.666, loss: 3776.257\n",
      " 27%|█████████████████████▎                                                         | 269/1000 [08:33<21:45,  1.79s/it]INFO:root:global_step: 269, logpy: -3607.614, kl: 247.779, loss: 3775.283\n",
      " 27%|█████████████████████▎                                                         | 270/1000 [08:35<21:29,  1.77s/it]INFO:root:global_step: 270, logpy: -3608.300, kl: 247.300, loss: 3776.291\n",
      " 27%|█████████████████████▍                                                         | 271/1000 [08:36<21:33,  1.77s/it]INFO:root:global_step: 271, logpy: -3608.538, kl: 246.669, loss: 3776.691\n",
      " 27%|█████████████████████▍                                                         | 272/1000 [08:38<21:21,  1.76s/it]INFO:root:global_step: 272, logpy: -3608.307, kl: 245.824, loss: 3776.400\n",
      " 27%|█████████████████████▌                                                         | 273/1000 [08:40<21:15,  1.75s/it]INFO:root:global_step: 273, logpy: -3609.536, kl: 245.239, loss: 3777.822\n",
      " 27%|█████████████████████▋                                                         | 274/1000 [08:42<21:15,  1.76s/it]INFO:root:global_step: 274, logpy: -3609.022, kl: 244.363, loss: 3777.201\n",
      " 28%|█████████████████████▋                                                         | 275/1000 [08:43<21:11,  1.75s/it]INFO:root:global_step: 275, logpy: -3610.493, kl: 243.870, loss: 3778.941\n",
      " 28%|█████████████████████▊                                                         | 276/1000 [08:45<21:26,  1.78s/it]INFO:root:global_step: 276, logpy: -3612.282, kl: 243.416, loss: 3781.030\n",
      " 28%|█████████████████████▉                                                         | 277/1000 [08:47<21:38,  1.80s/it]INFO:root:global_step: 277, logpy: -3613.117, kl: 242.695, loss: 3781.890\n",
      " 28%|█████████████████████▉                                                         | 278/1000 [08:49<21:56,  1.82s/it]INFO:root:global_step: 278, logpy: -3613.292, kl: 242.007, loss: 3782.117\n",
      " 28%|██████████████████████                                                         | 279/1000 [08:51<21:53,  1.82s/it]INFO:root:global_step: 279, logpy: -3616.449, kl: 241.525, loss: 3785.523\n",
      " 28%|██████████████████████                                                         | 280/1000 [08:52<21:41,  1.81s/it]INFO:root:global_step: 280, logpy: -3617.105, kl: 240.808, loss: 3786.186\n",
      " 28%|██████████████████████▏                                                        | 281/1000 [08:54<21:49,  1.82s/it]INFO:root:global_step: 281, logpy: -3618.568, kl: 240.208, loss: 3787.768\n",
      " 28%|██████████████████████▎                                                        | 282/1000 [08:56<21:39,  1.81s/it]INFO:root:global_step: 282, logpy: -3618.809, kl: 239.537, loss: 3788.047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██████████████████████▎                                                        | 283/1000 [08:58<21:35,  1.81s/it]INFO:root:global_step: 283, logpy: -3618.753, kl: 238.903, loss: 3788.060\n",
      " 28%|██████████████████████▍                                                        | 284/1000 [09:00<21:57,  1.84s/it]INFO:root:global_step: 284, logpy: -3619.584, kl: 238.588, loss: 3789.273\n",
      " 28%|██████████████████████▌                                                        | 285/1000 [09:02<21:43,  1.82s/it]INFO:root:global_step: 285, logpy: -3621.406, kl: 238.076, loss: 3791.272\n",
      " 29%|██████████████████████▌                                                        | 286/1000 [09:03<21:28,  1.81s/it]INFO:root:global_step: 286, logpy: -3621.197, kl: 237.418, loss: 3791.086\n",
      " 29%|██████████████████████▋                                                        | 287/1000 [09:05<21:28,  1.81s/it]INFO:root:global_step: 287, logpy: -3622.478, kl: 236.860, loss: 3792.484\n",
      " 29%|██████████████████████▊                                                        | 288/1000 [09:07<21:24,  1.80s/it]INFO:root:global_step: 288, logpy: -3623.496, kl: 236.541, loss: 3793.852\n",
      " 29%|██████████████████████▊                                                        | 289/1000 [09:09<21:14,  1.79s/it]INFO:root:global_step: 289, logpy: -3622.595, kl: 235.968, loss: 3793.041\n",
      " 29%|██████████████████████▉                                                        | 290/1000 [09:11<21:17,  1.80s/it]INFO:root:global_step: 290, logpy: -3624.171, kl: 235.547, loss: 3794.850\n",
      " 29%|██████████████████████▉                                                        | 291/1000 [09:12<21:14,  1.80s/it]INFO:root:global_step: 291, logpy: -3624.791, kl: 235.101, loss: 3795.673\n",
      " 29%|███████████████████████                                                        | 292/1000 [09:14<21:06,  1.79s/it]INFO:root:global_step: 292, logpy: -3624.228, kl: 234.634, loss: 3795.285\n",
      " 29%|███████████████████████▏                                                       | 293/1000 [09:16<21:02,  1.79s/it]INFO:root:global_step: 293, logpy: -3624.912, kl: 234.240, loss: 3796.210\n",
      " 29%|███████████████████████▏                                                       | 294/1000 [09:18<21:06,  1.79s/it]INFO:root:global_step: 294, logpy: -3624.570, kl: 233.795, loss: 3796.052\n",
      " 30%|███████████████████████▎                                                       | 295/1000 [09:19<20:53,  1.78s/it]INFO:root:global_step: 295, logpy: -3623.620, kl: 233.184, loss: 3795.116\n",
      " 30%|███████████████████████▍                                                       | 296/1000 [09:21<21:06,  1.80s/it]INFO:root:global_step: 296, logpy: -3625.761, kl: 232.675, loss: 3797.364\n",
      " 30%|███████████████████████▍                                                       | 297/1000 [09:23<21:21,  1.82s/it]INFO:root:global_step: 297, logpy: -3625.560, kl: 232.151, loss: 3797.250\n",
      " 30%|███████████████████████▌                                                       | 298/1000 [09:25<21:20,  1.82s/it]INFO:root:global_step: 298, logpy: -3625.086, kl: 231.656, loss: 3796.886\n",
      " 30%|███████████████████████▌                                                       | 299/1000 [09:27<21:19,  1.83s/it]INFO:root:global_step: 299, logpy: -3627.071, kl: 231.272, loss: 3799.085\n",
      " 30%|███████████████████████▋                                                       | 300/1000 [09:29<21:18,  1.83s/it]INFO:root:Saved figure at: ./sim/global_step_300.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 300, logpy: -3627.719, kl: 230.853, loss: 3799.907\n",
      " 30%|███████████████████████▊                                                       | 301/1000 [09:37<43:52,  3.77s/it]INFO:root:global_step: 301, logpy: -3631.714, kl: 230.419, loss: 3804.054\n",
      " 30%|███████████████████████▊                                                       | 302/1000 [09:39<36:47,  3.16s/it]INFO:root:global_step: 302, logpy: -3630.839, kl: 230.017, loss: 3803.358\n",
      " 30%|███████████████████████▉                                                       | 303/1000 [09:41<31:53,  2.75s/it]INFO:root:global_step: 303, logpy: -3633.195, kl: 229.749, loss: 3806.022\n",
      " 30%|████████████████████████                                                       | 304/1000 [09:42<28:11,  2.43s/it]INFO:root:global_step: 304, logpy: -3634.652, kl: 229.377, loss: 3807.675\n",
      " 30%|████████████████████████                                                       | 305/1000 [09:44<25:51,  2.23s/it]INFO:root:global_step: 305, logpy: -3636.424, kl: 228.909, loss: 3809.543\n",
      " 31%|████████████████████████▏                                                      | 306/1000 [09:46<24:05,  2.08s/it]INFO:root:global_step: 306, logpy: -3637.300, kl: 228.473, loss: 3810.542\n",
      " 31%|████████████████████████▎                                                      | 307/1000 [09:48<23:10,  2.01s/it]INFO:root:global_step: 307, logpy: -3637.584, kl: 228.011, loss: 3810.916\n",
      " 31%|████████████████████████▎                                                      | 308/1000 [09:49<22:20,  1.94s/it]INFO:root:global_step: 308, logpy: -3638.433, kl: 227.610, loss: 3811.910\n",
      " 31%|████████████████████████▍                                                      | 309/1000 [09:51<21:46,  1.89s/it]INFO:root:global_step: 309, logpy: -3638.109, kl: 227.153, loss: 3811.671\n",
      " 31%|████████████████████████▍                                                      | 310/1000 [09:53<21:30,  1.87s/it]INFO:root:global_step: 310, logpy: -3639.197, kl: 226.755, loss: 3812.897\n",
      " 31%|████████████████████████▌                                                      | 311/1000 [09:55<20:55,  1.82s/it]INFO:root:global_step: 311, logpy: -3638.791, kl: 226.268, loss: 3812.534\n",
      " 31%|████████████████████████▋                                                      | 312/1000 [09:56<20:35,  1.80s/it]INFO:root:global_step: 312, logpy: -3640.061, kl: 225.766, loss: 3813.828\n",
      " 31%|████████████████████████▋                                                      | 313/1000 [09:58<20:29,  1.79s/it]INFO:root:global_step: 313, logpy: -3640.630, kl: 225.215, loss: 3814.365\n",
      " 31%|████████████████████████▊                                                      | 314/1000 [10:00<20:04,  1.76s/it]INFO:root:global_step: 314, logpy: -3642.871, kl: 224.950, loss: 3816.856\n",
      " 32%|████████████████████████▉                                                      | 315/1000 [10:02<20:10,  1.77s/it]INFO:root:global_step: 315, logpy: -3643.352, kl: 224.456, loss: 3817.352\n",
      " 32%|████████████████████████▉                                                      | 316/1000 [10:03<19:54,  1.75s/it]INFO:root:global_step: 316, logpy: -3643.899, kl: 223.962, loss: 3817.910\n",
      " 32%|█████████████████████████                                                      | 317/1000 [10:05<19:56,  1.75s/it]INFO:root:global_step: 317, logpy: -3643.859, kl: 223.483, loss: 3817.890\n",
      " 32%|█████████████████████████                                                      | 318/1000 [10:07<19:53,  1.75s/it]INFO:root:global_step: 318, logpy: -3643.731, kl: 223.195, loss: 3817.969\n",
      " 32%|█████████████████████████▏                                                     | 319/1000 [10:09<19:42,  1.74s/it]INFO:root:global_step: 319, logpy: -3644.071, kl: 222.757, loss: 3818.360\n",
      " 32%|█████████████████████████▎                                                     | 320/1000 [10:10<19:29,  1.72s/it]INFO:root:global_step: 320, logpy: -3642.975, kl: 222.307, loss: 3817.300\n",
      " 32%|█████████████████████████▎                                                     | 321/1000 [10:12<19:34,  1.73s/it]INFO:root:global_step: 321, logpy: -3641.070, kl: 221.883, loss: 3815.450\n",
      " 32%|█████████████████████████▍                                                     | 322/1000 [10:14<19:38,  1.74s/it]INFO:root:global_step: 322, logpy: -3641.570, kl: 221.527, loss: 3816.069\n",
      " 32%|█████████████████████████▌                                                     | 323/1000 [10:16<19:50,  1.76s/it]INFO:root:global_step: 323, logpy: -3642.810, kl: 221.175, loss: 3817.428\n",
      " 32%|█████████████████████████▌                                                     | 324/1000 [10:17<19:44,  1.75s/it]INFO:root:global_step: 324, logpy: -3641.775, kl: 220.611, loss: 3816.294\n",
      " 32%|█████████████████████████▋                                                     | 325/1000 [10:19<19:41,  1.75s/it]INFO:root:global_step: 325, logpy: -3642.258, kl: 220.303, loss: 3816.930\n",
      " 33%|█████████████████████████▊                                                     | 326/1000 [10:21<19:31,  1.74s/it]INFO:root:global_step: 326, logpy: -3642.997, kl: 219.841, loss: 3817.663\n",
      " 33%|█████████████████████████▊                                                     | 327/1000 [10:23<19:42,  1.76s/it]INFO:root:global_step: 327, logpy: -3646.278, kl: 219.646, loss: 3821.200\n",
      " 33%|█████████████████████████▉                                                     | 328/1000 [10:24<19:48,  1.77s/it]INFO:root:global_step: 328, logpy: -3647.523, kl: 219.304, loss: 3822.551\n",
      " 33%|█████████████████████████▉                                                     | 329/1000 [10:26<19:56,  1.78s/it]INFO:root:global_step: 329, logpy: -3646.733, kl: 218.867, loss: 3821.767\n",
      " 33%|██████████████████████████                                                     | 330/1000 [10:28<20:14,  1.81s/it]INFO:root:global_step: 330, logpy: -3644.889, kl: 218.395, loss: 3819.889\n",
      " 33%|██████████████████████████▏                                                    | 331/1000 [10:30<20:02,  1.80s/it]INFO:root:global_step: 331, logpy: -3645.242, kl: 218.007, loss: 3820.288\n",
      " 33%|██████████████████████████▏                                                    | 332/1000 [10:32<20:04,  1.80s/it]INFO:root:global_step: 332, logpy: -3644.821, kl: 217.423, loss: 3819.713\n",
      " 33%|██████████████████████████▎                                                    | 333/1000 [10:33<19:55,  1.79s/it]INFO:root:global_step: 333, logpy: -3646.624, kl: 216.958, loss: 3821.476\n",
      " 33%|██████████████████████████▍                                                    | 334/1000 [10:35<19:37,  1.77s/it]INFO:root:global_step: 334, logpy: -3646.636, kl: 216.755, loss: 3821.706\n",
      " 34%|██████████████████████████▍                                                    | 335/1000 [10:37<19:41,  1.78s/it]INFO:root:global_step: 335, logpy: -3645.647, kl: 216.277, loss: 3820.656\n",
      " 34%|██████████████████████████▌                                                    | 336/1000 [10:39<19:44,  1.78s/it]INFO:root:global_step: 336, logpy: -3648.644, kl: 216.171, loss: 3823.960\n",
      " 34%|██████████████████████████▌                                                    | 337/1000 [10:40<19:45,  1.79s/it]INFO:root:global_step: 337, logpy: -3650.020, kl: 215.945, loss: 3825.518\n",
      " 34%|██████████████████████████▋                                                    | 338/1000 [10:42<19:43,  1.79s/it]INFO:root:global_step: 338, logpy: -3650.069, kl: 215.686, loss: 3825.713\n",
      " 34%|██████████████████████████▊                                                    | 339/1000 [10:44<19:38,  1.78s/it]INFO:root:global_step: 339, logpy: -3650.739, kl: 215.498, loss: 3826.596\n",
      " 34%|██████████████████████████▊                                                    | 340/1000 [10:46<19:33,  1.78s/it]INFO:root:global_step: 340, logpy: -3651.386, kl: 215.125, loss: 3827.265\n",
      " 34%|██████████████████████████▉                                                    | 341/1000 [10:48<19:30,  1.78s/it]INFO:root:global_step: 341, logpy: -3650.924, kl: 214.707, loss: 3826.777\n",
      " 34%|███████████████████████████                                                    | 342/1000 [10:49<19:41,  1.80s/it]INFO:root:global_step: 342, logpy: -3651.210, kl: 214.494, loss: 3827.239\n",
      " 34%|███████████████████████████                                                    | 343/1000 [10:51<19:40,  1.80s/it]INFO:root:global_step: 343, logpy: -3652.197, kl: 214.013, loss: 3828.131\n",
      " 34%|███████████████████████████▏                                                   | 344/1000 [10:53<19:24,  1.77s/it]INFO:root:global_step: 344, logpy: -3651.200, kl: 213.661, loss: 3827.162\n",
      " 34%|███████████████████████████▎                                                   | 345/1000 [10:55<19:19,  1.77s/it]INFO:root:global_step: 345, logpy: -3652.225, kl: 213.330, loss: 3828.233\n",
      " 35%|███████████████████████████▎                                                   | 346/1000 [10:56<19:23,  1.78s/it]INFO:root:global_step: 346, logpy: -3653.249, kl: 213.098, loss: 3829.398\n",
      " 35%|███████████████████████████▍                                                   | 347/1000 [10:58<19:23,  1.78s/it]INFO:root:global_step: 347, logpy: -3654.795, kl: 212.855, loss: 3831.070\n",
      " 35%|███████████████████████████▍                                                   | 348/1000 [11:00<19:32,  1.80s/it]INFO:root:global_step: 348, logpy: -3656.854, kl: 212.669, loss: 3833.310\n",
      " 35%|███████████████████████████▌                                                   | 349/1000 [11:02<19:23,  1.79s/it]INFO:root:global_step: 349, logpy: -3659.055, kl: 212.547, loss: 3835.751\n",
      " 35%|███████████████████████████▋                                                   | 350/1000 [11:04<19:18,  1.78s/it]INFO:root:Saved figure at: ./sim/global_step_350.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 350, logpy: -3658.858, kl: 212.369, loss: 3835.735\n",
      " 35%|███████████████████████████▋                                                   | 351/1000 [11:12<40:21,  3.73s/it]INFO:root:global_step: 351, logpy: -3658.277, kl: 211.998, loss: 3835.138\n",
      " 35%|███████████████████████████▊                                                   | 352/1000 [11:14<34:11,  3.17s/it]INFO:root:global_step: 352, logpy: -3658.099, kl: 211.590, loss: 3834.903\n",
      " 35%|███████████████████████████▉                                                   | 353/1000 [11:16<29:47,  2.76s/it]INFO:root:global_step: 353, logpy: -3658.756, kl: 211.593, loss: 3835.911\n",
      " 35%|███████████████████████████▉                                                   | 354/1000 [11:17<26:37,  2.47s/it]INFO:root:global_step: 354, logpy: -3658.878, kl: 211.284, loss: 3836.068\n",
      " 36%|████████████████████████████                                                   | 355/1000 [11:19<24:37,  2.29s/it]INFO:root:global_step: 355, logpy: -3658.406, kl: 211.041, loss: 3835.694\n",
      " 36%|████████████████████████████                                                   | 356/1000 [11:21<23:08,  2.16s/it]INFO:root:global_step: 356, logpy: -3656.713, kl: 210.593, loss: 3833.891\n",
      " 36%|████████████████████████████▏                                                  | 357/1000 [11:23<21:59,  2.05s/it]INFO:root:global_step: 357, logpy: -3657.658, kl: 210.405, loss: 3834.981\n",
      " 36%|████████████████████████████▎                                                  | 358/1000 [11:25<20:59,  1.96s/it]INFO:root:global_step: 358, logpy: -3658.063, kl: 210.181, loss: 3835.494\n",
      " 36%|████████████████████████████▎                                                  | 359/1000 [11:26<20:24,  1.91s/it]INFO:root:global_step: 359, logpy: -3658.625, kl: 209.930, loss: 3836.132\n",
      " 36%|████████████████████████████▍                                                  | 360/1000 [11:28<19:47,  1.86s/it]INFO:root:global_step: 360, logpy: -3658.674, kl: 209.602, loss: 3836.176\n",
      " 36%|████████████████████████████▌                                                  | 361/1000 [11:30<19:34,  1.84s/it]INFO:root:global_step: 361, logpy: -3659.641, kl: 209.403, loss: 3837.266\n",
      " 36%|████████████████████████████▌                                                  | 362/1000 [11:32<19:26,  1.83s/it]INFO:root:global_step: 362, logpy: -3659.442, kl: 209.239, loss: 3837.221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|████████████████████████████▋                                                  | 363/1000 [11:34<19:20,  1.82s/it]INFO:root:global_step: 363, logpy: -3659.076, kl: 209.061, loss: 3836.991\n",
      " 36%|████████████████████████████▊                                                  | 364/1000 [11:35<19:11,  1.81s/it]INFO:root:global_step: 364, logpy: -3659.568, kl: 208.835, loss: 3837.569\n",
      " 36%|████████████████████████████▊                                                  | 365/1000 [11:37<19:00,  1.80s/it]INFO:root:global_step: 365, logpy: -3659.159, kl: 208.531, loss: 3837.164\n",
      " 37%|████████████████████████████▉                                                  | 366/1000 [11:39<18:50,  1.78s/it]INFO:root:global_step: 366, logpy: -3659.471, kl: 208.497, loss: 3837.748\n",
      " 37%|████████████████████████████▉                                                  | 367/1000 [11:41<18:35,  1.76s/it]INFO:root:global_step: 367, logpy: -3659.165, kl: 208.138, loss: 3837.384\n",
      " 37%|█████████████████████████████                                                  | 368/1000 [11:42<18:39,  1.77s/it]INFO:root:global_step: 368, logpy: -3657.958, kl: 207.906, loss: 3836.245\n",
      " 37%|█████████████████████████████▏                                                 | 369/1000 [11:44<18:26,  1.75s/it]INFO:root:global_step: 369, logpy: -3656.775, kl: 207.782, loss: 3835.234\n",
      " 37%|█████████████████████████████▏                                                 | 370/1000 [11:46<18:25,  1.75s/it]INFO:root:global_step: 370, logpy: -3657.167, kl: 207.652, loss: 3835.788\n",
      " 37%|█████████████████████████████▎                                                 | 371/1000 [11:48<18:11,  1.74s/it]INFO:root:global_step: 371, logpy: -3657.192, kl: 207.412, loss: 3835.864\n",
      " 37%|█████████████████████████████▍                                                 | 372/1000 [11:49<18:15,  1.75s/it]INFO:root:global_step: 372, logpy: -3658.868, kl: 207.238, loss: 3837.655\n",
      " 37%|█████████████████████████████▍                                                 | 373/1000 [11:51<18:17,  1.75s/it]INFO:root:global_step: 373, logpy: -3658.913, kl: 207.081, loss: 3837.826\n",
      " 37%|█████████████████████████████▌                                                 | 374/1000 [11:53<18:25,  1.77s/it]INFO:root:global_step: 374, logpy: -3660.399, kl: 206.992, loss: 3839.506\n",
      " 38%|█████████████████████████████▋                                                 | 375/1000 [11:55<18:35,  1.78s/it]INFO:root:global_step: 375, logpy: -3659.045, kl: 206.482, loss: 3837.921\n",
      " 38%|█████████████████████████████▋                                                 | 376/1000 [11:57<18:38,  1.79s/it]INFO:root:global_step: 376, logpy: -3658.697, kl: 206.343, loss: 3837.708\n",
      " 38%|█████████████████████████████▊                                                 | 377/1000 [11:58<18:27,  1.78s/it]INFO:root:global_step: 377, logpy: -3659.890, kl: 206.098, loss: 3838.930\n",
      " 38%|█████████████████████████████▊                                                 | 378/1000 [12:00<18:27,  1.78s/it]INFO:root:global_step: 378, logpy: -3657.871, kl: 205.925, loss: 3837.008\n",
      " 38%|█████████████████████████████▉                                                 | 379/1000 [12:02<18:19,  1.77s/it]INFO:root:global_step: 379, logpy: -3658.583, kl: 205.637, loss: 3837.700\n",
      " 38%|██████████████████████████████                                                 | 380/1000 [12:04<18:46,  1.82s/it]INFO:root:global_step: 380, logpy: -3658.351, kl: 205.339, loss: 3837.436\n",
      " 38%|██████████████████████████████                                                 | 381/1000 [12:05<18:39,  1.81s/it]INFO:root:global_step: 381, logpy: -3658.854, kl: 205.241, loss: 3838.103\n",
      " 38%|██████████████████████████████▏                                                | 382/1000 [12:07<18:39,  1.81s/it]INFO:root:global_step: 382, logpy: -3660.486, kl: 205.193, loss: 3839.947\n",
      " 38%|██████████████████████████████▎                                                | 383/1000 [12:09<18:31,  1.80s/it]INFO:root:global_step: 383, logpy: -3659.241, kl: 204.685, loss: 3838.451\n",
      " 38%|██████████████████████████████▎                                                | 384/1000 [12:11<18:36,  1.81s/it]INFO:root:global_step: 384, logpy: -3660.252, kl: 204.332, loss: 3839.364\n",
      " 38%|██████████████████████████████▍                                                | 385/1000 [12:13<18:34,  1.81s/it]INFO:root:global_step: 385, logpy: -3660.433, kl: 204.209, loss: 3839.675\n",
      " 39%|██████████████████████████████▍                                                | 386/1000 [12:15<18:22,  1.80s/it]INFO:root:global_step: 386, logpy: -3658.416, kl: 203.888, loss: 3837.586\n",
      " 39%|██████████████████████████████▌                                                | 387/1000 [12:16<18:24,  1.80s/it]INFO:root:global_step: 387, logpy: -3658.189, kl: 203.740, loss: 3837.459\n",
      " 39%|██████████████████████████████▋                                                | 388/1000 [12:18<18:26,  1.81s/it]INFO:root:global_step: 388, logpy: -3657.040, kl: 203.583, loss: 3836.397\n",
      " 39%|██████████████████████████████▋                                                | 389/1000 [12:20<18:15,  1.79s/it]INFO:root:global_step: 389, logpy: -3658.776, kl: 203.348, loss: 3838.140\n",
      " 39%|██████████████████████████████▊                                                | 390/1000 [12:22<18:16,  1.80s/it]INFO:root:global_step: 390, logpy: -3659.129, kl: 203.022, loss: 3838.408\n",
      " 39%|██████████████████████████████▉                                                | 391/1000 [12:24<18:19,  1.80s/it]INFO:root:global_step: 391, logpy: -3660.423, kl: 202.951, loss: 3839.868\n",
      " 39%|██████████████████████████████▉                                                | 392/1000 [12:25<18:06,  1.79s/it]INFO:root:global_step: 392, logpy: -3660.628, kl: 202.791, loss: 3840.148\n",
      " 39%|███████████████████████████████                                                | 393/1000 [12:27<18:21,  1.82s/it]INFO:root:global_step: 393, logpy: -3660.868, kl: 202.491, loss: 3840.321\n",
      " 39%|███████████████████████████████▏                                               | 394/1000 [12:29<18:19,  1.81s/it]INFO:root:global_step: 394, logpy: -3660.831, kl: 202.464, loss: 3840.488\n",
      " 40%|███████████████████████████████▏                                               | 395/1000 [12:31<18:20,  1.82s/it]INFO:root:global_step: 395, logpy: -3662.233, kl: 202.441, loss: 3842.094\n",
      " 40%|███████████████████████████████▎                                               | 396/1000 [12:33<18:14,  1.81s/it]INFO:root:global_step: 396, logpy: -3663.583, kl: 202.393, loss: 3843.622\n",
      " 40%|███████████████████████████████▎                                               | 397/1000 [12:34<18:00,  1.79s/it]INFO:root:global_step: 397, logpy: -3662.622, kl: 202.086, loss: 3842.577\n",
      " 40%|███████████████████████████████▍                                               | 398/1000 [12:36<17:56,  1.79s/it]INFO:root:global_step: 398, logpy: -3661.199, kl: 201.887, loss: 3841.177\n",
      " 40%|███████████████████████████████▌                                               | 399/1000 [12:38<17:50,  1.78s/it]INFO:root:global_step: 399, logpy: -3661.227, kl: 201.731, loss: 3841.267\n",
      " 40%|███████████████████████████████▌                                               | 400/1000 [12:40<17:38,  1.76s/it]INFO:root:Saved figure at: ./sim/global_step_400.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 400, logpy: -3659.931, kl: 201.498, loss: 3839.956\n",
      " 40%|███████████████████████████████▋                                               | 401/1000 [12:48<37:15,  3.73s/it]INFO:root:global_step: 401, logpy: -3659.658, kl: 201.263, loss: 3839.662\n",
      " 40%|███████████████████████████████▊                                               | 402/1000 [12:50<31:29,  3.16s/it]INFO:root:global_step: 402, logpy: -3661.610, kl: 201.244, loss: 3841.808\n",
      " 40%|███████████████████████████████▊                                               | 403/1000 [12:52<27:14,  2.74s/it]INFO:root:global_step: 403, logpy: -3660.860, kl: 200.878, loss: 3840.902\n",
      " 40%|███████████████████████████████▉                                               | 404/1000 [12:53<24:31,  2.47s/it]INFO:root:global_step: 404, logpy: -3661.611, kl: 200.852, loss: 3841.836\n",
      " 40%|███████████████████████████████▉                                               | 405/1000 [12:55<22:26,  2.26s/it]INFO:root:global_step: 405, logpy: -3662.924, kl: 200.882, loss: 3843.385\n",
      " 41%|████████████████████████████████                                               | 406/1000 [12:57<20:50,  2.10s/it]INFO:root:global_step: 406, logpy: -3663.628, kl: 200.853, loss: 3844.264\n",
      " 41%|████████████████████████████████▏                                              | 407/1000 [12:59<19:43,  2.00s/it]INFO:root:global_step: 407, logpy: -3662.219, kl: 200.507, loss: 3842.711\n",
      " 41%|████████████████████████████████▏                                              | 408/1000 [13:00<19:11,  1.95s/it]INFO:root:global_step: 408, logpy: -3663.149, kl: 200.333, loss: 3843.668\n",
      " 41%|████████████████████████████████▎                                              | 409/1000 [13:02<19:01,  1.93s/it]INFO:root:global_step: 409, logpy: -3663.309, kl: 199.920, loss: 3843.613\n",
      " 41%|████████████████████████████████▍                                              | 410/1000 [13:04<18:44,  1.91s/it]INFO:root:global_step: 410, logpy: -3663.929, kl: 199.892, loss: 3844.400\n",
      " 41%|████████████████████████████████▍                                              | 411/1000 [13:06<18:17,  1.86s/it]INFO:root:global_step: 411, logpy: -3664.178, kl: 199.801, loss: 3844.754\n",
      " 41%|████████████████████████████████▌                                              | 412/1000 [13:08<18:08,  1.85s/it]INFO:root:global_step: 412, logpy: -3664.878, kl: 199.661, loss: 3845.505\n",
      " 41%|████████████████████████████████▋                                              | 413/1000 [13:10<18:01,  1.84s/it]INFO:root:global_step: 413, logpy: -3664.078, kl: 199.517, loss: 3844.751\n",
      " 41%|████████████████████████████████▋                                              | 414/1000 [13:11<17:49,  1.83s/it]INFO:root:global_step: 414, logpy: -3665.206, kl: 199.301, loss: 3845.852\n",
      " 42%|████████████████████████████████▊                                              | 415/1000 [13:13<17:40,  1.81s/it]INFO:root:global_step: 415, logpy: -3665.328, kl: 199.182, loss: 3846.041\n",
      " 42%|████████████████████████████████▊                                              | 416/1000 [13:15<17:40,  1.82s/it]INFO:root:global_step: 416, logpy: -3666.831, kl: 199.177, loss: 3847.724\n",
      " 42%|████████████████████████████████▉                                              | 417/1000 [13:17<17:35,  1.81s/it]INFO:root:global_step: 417, logpy: -3665.887, kl: 199.147, loss: 3846.933\n",
      " 42%|█████████████████████████████████                                              | 418/1000 [13:19<17:28,  1.80s/it]INFO:root:global_step: 418, logpy: -3665.588, kl: 199.031, loss: 3846.699\n",
      " 42%|█████████████████████████████████                                              | 419/1000 [13:20<17:18,  1.79s/it]INFO:root:global_step: 419, logpy: -3664.638, kl: 198.746, loss: 3845.643\n",
      " 42%|█████████████████████████████████▏                                             | 420/1000 [13:22<17:30,  1.81s/it]INFO:root:global_step: 420, logpy: -3664.547, kl: 198.655, loss: 3845.639\n",
      " 42%|█████████████████████████████████▎                                             | 421/1000 [13:24<17:25,  1.81s/it]INFO:root:global_step: 421, logpy: -3666.051, kl: 198.319, loss: 3846.982\n",
      " 42%|█████████████████████████████████▎                                             | 422/1000 [13:26<17:18,  1.80s/it]INFO:root:global_step: 422, logpy: -3666.059, kl: 198.202, loss: 3847.047\n",
      " 42%|█████████████████████████████████▍                                             | 423/1000 [13:28<17:19,  1.80s/it]INFO:root:global_step: 423, logpy: -3666.070, kl: 198.157, loss: 3847.186\n",
      " 42%|█████████████████████████████████▍                                             | 424/1000 [13:29<17:13,  1.79s/it]INFO:root:global_step: 424, logpy: -3664.686, kl: 198.021, loss: 3845.836\n",
      " 42%|█████████████████████████████████▌                                             | 425/1000 [13:31<17:18,  1.81s/it]INFO:root:global_step: 425, logpy: -3665.153, kl: 197.944, loss: 3846.395\n",
      " 43%|█████████████████████████████████▋                                             | 426/1000 [13:33<17:08,  1.79s/it]INFO:root:global_step: 426, logpy: -3667.044, kl: 198.067, loss: 3848.576\n",
      " 43%|█████████████████████████████████▋                                             | 427/1000 [13:35<17:10,  1.80s/it]INFO:root:global_step: 427, logpy: -3666.805, kl: 197.812, loss: 3848.247\n",
      " 43%|█████████████████████████████████▊                                             | 428/1000 [13:37<17:16,  1.81s/it]INFO:root:global_step: 428, logpy: -3667.846, kl: 197.732, loss: 3849.371\n",
      " 43%|█████████████████████████████████▉                                             | 429/1000 [13:38<17:16,  1.82s/it]INFO:root:global_step: 429, logpy: -3668.142, kl: 197.752, loss: 3849.849\n",
      " 43%|█████████████████████████████████▉                                             | 430/1000 [13:40<17:14,  1.81s/it]INFO:root:global_step: 430, logpy: -3667.023, kl: 197.549, loss: 3848.688\n",
      " 43%|██████████████████████████████████                                             | 431/1000 [13:42<17:15,  1.82s/it]INFO:root:global_step: 431, logpy: -3666.179, kl: 197.482, loss: 3847.937\n",
      " 43%|██████████████████████████████████▏                                            | 432/1000 [13:44<17:00,  1.80s/it]INFO:root:global_step: 432, logpy: -3667.534, kl: 197.325, loss: 3849.291\n",
      " 43%|██████████████████████████████████▏                                            | 433/1000 [13:46<16:52,  1.79s/it]INFO:root:global_step: 433, logpy: -3667.440, kl: 197.210, loss: 3849.238\n",
      " 43%|██████████████████████████████████▎                                            | 434/1000 [13:47<16:44,  1.77s/it]INFO:root:global_step: 434, logpy: -3668.225, kl: 197.129, loss: 3850.096\n",
      " 44%|██████████████████████████████████▎                                            | 435/1000 [13:49<16:45,  1.78s/it]INFO:root:global_step: 435, logpy: -3667.685, kl: 196.987, loss: 3849.566\n",
      " 44%|██████████████████████████████████▍                                            | 436/1000 [13:51<16:59,  1.81s/it]INFO:root:global_step: 436, logpy: -3669.052, kl: 196.940, loss: 3851.038\n",
      " 44%|██████████████████████████████████▌                                            | 437/1000 [13:53<16:49,  1.79s/it]INFO:root:global_step: 437, logpy: -3668.695, kl: 196.854, loss: 3850.744\n",
      " 44%|██████████████████████████████████▌                                            | 438/1000 [13:54<16:41,  1.78s/it]INFO:root:global_step: 438, logpy: -3669.585, kl: 196.805, loss: 3851.734\n",
      " 44%|██████████████████████████████████▋                                            | 439/1000 [13:56<16:45,  1.79s/it]INFO:root:global_step: 439, logpy: -3670.275, kl: 196.707, loss: 3852.472\n",
      " 44%|██████████████████████████████████▊                                            | 440/1000 [13:58<16:39,  1.79s/it]INFO:root:global_step: 440, logpy: -3670.913, kl: 196.607, loss: 3853.154\n",
      " 44%|██████████████████████████████████▊                                            | 441/1000 [14:00<16:35,  1.78s/it]INFO:root:global_step: 441, logpy: -3670.675, kl: 196.365, loss: 3852.818\n",
      " 44%|██████████████████████████████████▉                                            | 442/1000 [14:02<16:46,  1.80s/it]INFO:root:global_step: 442, logpy: -3671.647, kl: 196.271, loss: 3853.839\n",
      " 44%|██████████████████████████████████▉                                            | 443/1000 [14:04<16:48,  1.81s/it]INFO:root:global_step: 443, logpy: -3671.370, kl: 196.379, loss: 3853.811\n",
      " 44%|███████████████████████████████████                                            | 444/1000 [14:05<16:30,  1.78s/it]INFO:root:global_step: 444, logpy: -3670.951, kl: 196.139, loss: 3853.290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|███████████████████████████████████▏                                           | 445/1000 [14:07<16:38,  1.80s/it]INFO:root:global_step: 445, logpy: -3669.834, kl: 195.882, loss: 3852.055\n",
      " 45%|███████████████████████████████████▏                                           | 446/1000 [14:09<16:41,  1.81s/it]INFO:root:global_step: 446, logpy: -3671.421, kl: 195.747, loss: 3853.644\n",
      " 45%|███████████████████████████████████▎                                           | 447/1000 [14:11<16:44,  1.82s/it]INFO:root:global_step: 447, logpy: -3670.960, kl: 195.636, loss: 3853.206\n",
      " 45%|███████████████████████████████████▍                                           | 448/1000 [14:13<16:40,  1.81s/it]INFO:root:global_step: 448, logpy: -3671.060, kl: 195.556, loss: 3853.361\n",
      " 45%|███████████████████████████████████▍                                           | 449/1000 [14:14<16:40,  1.82s/it]INFO:root:global_step: 449, logpy: -3669.848, kl: 195.362, loss: 3852.087\n",
      " 45%|███████████████████████████████████▌                                           | 450/1000 [14:16<16:43,  1.82s/it]INFO:root:Saved figure at: ./sim/global_step_450.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 450, logpy: -3670.721, kl: 195.312, loss: 3853.042\n",
      " 45%|███████████████████████████████████▋                                           | 451/1000 [14:24<34:06,  3.73s/it]INFO:root:global_step: 451, logpy: -3671.128, kl: 195.249, loss: 3853.515\n",
      " 45%|███████████████████████████████████▋                                           | 452/1000 [14:26<28:41,  3.14s/it]INFO:root:global_step: 452, logpy: -3671.024, kl: 195.154, loss: 3853.445\n",
      " 45%|███████████████████████████████████▊                                           | 453/1000 [14:28<24:48,  2.72s/it]INFO:root:global_step: 453, logpy: -3671.555, kl: 195.019, loss: 3853.968\n",
      " 45%|███████████████████████████████████▊                                           | 454/1000 [14:30<22:11,  2.44s/it]INFO:root:global_step: 454, logpy: -3669.886, kl: 194.825, loss: 3852.232\n",
      " 46%|███████████████████████████████████▉                                           | 455/1000 [14:32<20:36,  2.27s/it]INFO:root:global_step: 455, logpy: -3669.862, kl: 194.757, loss: 3852.264\n",
      " 46%|████████████████████████████████████                                           | 456/1000 [14:33<19:19,  2.13s/it]INFO:root:global_step: 456, logpy: -3670.990, kl: 194.842, loss: 3853.601\n",
      " 46%|████████████████████████████████████                                           | 457/1000 [14:35<18:15,  2.02s/it]INFO:root:global_step: 457, logpy: -3673.091, kl: 195.014, loss: 3855.996\n",
      " 46%|████████████████████████████████████▏                                          | 458/1000 [14:37<17:29,  1.94s/it]INFO:root:global_step: 458, logpy: -3674.041, kl: 194.865, loss: 3856.918\n",
      " 46%|████████████████████████████████████▎                                          | 459/1000 [14:39<17:14,  1.91s/it]INFO:root:global_step: 459, logpy: -3673.613, kl: 194.553, loss: 3856.298\n",
      " 46%|████████████████████████████████████▎                                          | 460/1000 [14:41<17:11,  1.91s/it]INFO:root:global_step: 460, logpy: -3673.989, kl: 194.316, loss: 3856.556\n",
      " 46%|████████████████████████████████████▍                                          | 461/1000 [14:42<16:50,  1.87s/it]INFO:root:global_step: 461, logpy: -3676.623, kl: 194.367, loss: 3859.359\n",
      " 46%|████████████████████████████████████▍                                          | 462/1000 [14:44<16:46,  1.87s/it]INFO:root:global_step: 462, logpy: -3676.857, kl: 194.243, loss: 3859.585\n",
      " 46%|████████████████████████████████████▌                                          | 463/1000 [14:46<16:45,  1.87s/it]INFO:root:global_step: 463, logpy: -3676.424, kl: 194.101, loss: 3859.125\n",
      " 46%|████████████████████████████████████▋                                          | 464/1000 [14:48<16:27,  1.84s/it]INFO:root:global_step: 464, logpy: -3676.697, kl: 193.781, loss: 3859.192\n",
      " 46%|████████████████████████████████████▋                                          | 465/1000 [14:50<16:13,  1.82s/it]INFO:root:global_step: 465, logpy: -3674.404, kl: 193.575, loss: 3856.806\n",
      " 47%|████████████████████████████████████▊                                          | 466/1000 [14:52<16:12,  1.82s/it]INFO:root:global_step: 466, logpy: -3672.768, kl: 193.492, loss: 3855.199\n",
      " 47%|████████████████████████████████████▉                                          | 467/1000 [14:53<16:06,  1.81s/it]INFO:root:global_step: 467, logpy: -3672.300, kl: 193.422, loss: 3854.771\n",
      " 47%|████████████████████████████████████▉                                          | 468/1000 [14:55<16:00,  1.81s/it]INFO:root:global_step: 468, logpy: -3672.857, kl: 193.322, loss: 3855.337\n",
      " 47%|█████████████████████████████████████                                          | 469/1000 [14:57<15:57,  1.80s/it]INFO:root:global_step: 469, logpy: -3673.277, kl: 193.249, loss: 3855.793\n",
      " 47%|█████████████████████████████████████▏                                         | 470/1000 [14:59<16:06,  1.82s/it]INFO:root:global_step: 470, logpy: -3672.258, kl: 193.117, loss: 3854.749\n",
      " 47%|█████████████████████████████████████▏                                         | 471/1000 [15:01<15:56,  1.81s/it]INFO:root:global_step: 471, logpy: -3673.464, kl: 193.194, loss: 3856.138\n",
      " 47%|█████████████████████████████████████▎                                         | 472/1000 [15:02<15:49,  1.80s/it]INFO:root:global_step: 472, logpy: -3674.637, kl: 193.159, loss: 3857.382\n",
      " 47%|█████████████████████████████████████▎                                         | 473/1000 [15:04<15:38,  1.78s/it]INFO:root:global_step: 473, logpy: -3675.055, kl: 193.183, loss: 3857.927\n",
      " 47%|█████████████████████████████████████▍                                         | 474/1000 [15:06<15:38,  1.79s/it]INFO:root:global_step: 474, logpy: -3674.787, kl: 193.019, loss: 3857.598\n",
      " 48%|█████████████████████████████████████▌                                         | 475/1000 [15:08<15:42,  1.79s/it]INFO:root:global_step: 475, logpy: -3674.976, kl: 193.072, loss: 3857.943\n",
      " 48%|█████████████████████████████████████▌                                         | 476/1000 [15:09<15:41,  1.80s/it]INFO:root:global_step: 476, logpy: -3674.638, kl: 192.913, loss: 3857.546\n",
      " 48%|█████████████████████████████████████▋                                         | 477/1000 [15:11<15:34,  1.79s/it]INFO:root:global_step: 477, logpy: -3675.811, kl: 192.946, loss: 3858.852\n",
      " 48%|█████████████████████████████████████▊                                         | 478/1000 [15:13<15:46,  1.81s/it]INFO:root:global_step: 478, logpy: -3675.157, kl: 192.683, loss: 3858.035\n",
      " 48%|█████████████████████████████████████▊                                         | 479/1000 [15:15<15:45,  1.82s/it]INFO:root:global_step: 479, logpy: -3675.455, kl: 192.705, loss: 3858.454\n",
      " 48%|█████████████████████████████████████▉                                         | 480/1000 [15:17<15:43,  1.81s/it]INFO:root:global_step: 480, logpy: -3675.182, kl: 192.456, loss: 3858.028\n",
      " 48%|█████████████████████████████████████▉                                         | 481/1000 [15:19<15:39,  1.81s/it]INFO:root:global_step: 481, logpy: -3675.468, kl: 192.588, loss: 3858.542\n",
      " 48%|██████████████████████████████████████                                         | 482/1000 [15:20<15:26,  1.79s/it]INFO:root:global_step: 482, logpy: -3675.500, kl: 192.259, loss: 3858.340\n",
      " 48%|██████████████████████████████████████▏                                        | 483/1000 [15:22<15:37,  1.81s/it]INFO:root:global_step: 483, logpy: -3675.722, kl: 192.144, loss: 3858.542\n",
      " 48%|██████████████████████████████████████▏                                        | 484/1000 [15:24<15:35,  1.81s/it]INFO:root:global_step: 484, logpy: -3675.145, kl: 192.245, loss: 3858.159\n",
      " 48%|██████████████████████████████████████▎                                        | 485/1000 [15:26<15:33,  1.81s/it]INFO:root:global_step: 485, logpy: -3673.986, kl: 192.009, loss: 3856.856\n",
      " 49%|██████████████████████████████████████▍                                        | 486/1000 [15:28<15:40,  1.83s/it]INFO:root:global_step: 486, logpy: -3675.050, kl: 191.967, loss: 3857.969\n",
      " 49%|██████████████████████████████████████▍                                        | 487/1000 [15:29<15:38,  1.83s/it]INFO:root:global_step: 487, logpy: -3675.764, kl: 191.841, loss: 3858.648\n",
      " 49%|██████████████████████████████████████▌                                        | 488/1000 [15:31<15:26,  1.81s/it]INFO:root:global_step: 488, logpy: -3677.424, kl: 191.925, loss: 3860.481\n",
      " 49%|██████████████████████████████████████▋                                        | 489/1000 [15:33<15:11,  1.78s/it]INFO:root:global_step: 489, logpy: -3676.335, kl: 191.736, loss: 3859.293\n",
      " 49%|██████████████████████████████████████▋                                        | 490/1000 [15:35<15:20,  1.81s/it]INFO:root:global_step: 490, logpy: -3676.460, kl: 191.739, loss: 3859.508\n",
      " 49%|██████████████████████████████████████▊                                        | 491/1000 [15:37<15:11,  1.79s/it]INFO:root:global_step: 491, logpy: -3675.215, kl: 191.657, loss: 3858.267\n",
      " 49%|██████████████████████████████████████▊                                        | 492/1000 [15:38<15:11,  1.79s/it]INFO:root:global_step: 492, logpy: -3676.347, kl: 191.544, loss: 3859.373\n",
      " 49%|██████████████████████████████████████▉                                        | 493/1000 [15:40<15:04,  1.78s/it]INFO:root:global_step: 493, logpy: -3676.298, kl: 191.336, loss: 3859.201\n",
      " 49%|███████████████████████████████████████                                        | 494/1000 [15:42<15:21,  1.82s/it]INFO:root:global_step: 494, logpy: -3678.813, kl: 191.321, loss: 3861.786\n",
      " 50%|███████████████████████████████████████                                        | 495/1000 [15:44<15:18,  1.82s/it]INFO:root:global_step: 495, logpy: -3679.263, kl: 191.259, loss: 3862.257\n",
      " 50%|███████████████████████████████████████▏                                       | 496/1000 [15:46<15:21,  1.83s/it]INFO:root:global_step: 496, logpy: -3679.917, kl: 191.383, loss: 3863.118\n",
      " 50%|███████████████████████████████████████▎                                       | 497/1000 [15:47<15:09,  1.81s/it]INFO:root:global_step: 497, logpy: -3680.315, kl: 191.357, loss: 3863.572\n",
      " 50%|███████████████████████████████████████▎                                       | 498/1000 [15:49<15:05,  1.80s/it]INFO:root:global_step: 498, logpy: -3678.883, kl: 191.236, loss: 3862.100\n",
      " 50%|███████████████████████████████████████▍                                       | 499/1000 [15:51<15:02,  1.80s/it]INFO:root:global_step: 499, logpy: -3678.031, kl: 191.064, loss: 3861.156\n",
      " 50%|███████████████████████████████████████▌                                       | 500/1000 [15:53<15:02,  1.81s/it]INFO:root:Saved figure at: ./sim/global_step_500.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 500, logpy: -3677.626, kl: 191.011, loss: 3860.777\n",
      " 50%|███████████████████████████████████████▌                                       | 501/1000 [16:01<31:16,  3.76s/it]INFO:root:global_step: 501, logpy: -3678.107, kl: 190.960, loss: 3861.285\n",
      " 50%|███████████████████████████████████████▋                                       | 502/1000 [16:03<26:23,  3.18s/it]INFO:root:global_step: 502, logpy: -3678.845, kl: 190.892, loss: 3862.033\n",
      " 50%|███████████████████████████████████████▋                                       | 503/1000 [16:05<22:44,  2.75s/it]INFO:root:global_step: 503, logpy: -3678.386, kl: 190.949, loss: 3861.708\n",
      " 50%|███████████████████████████████████████▊                                       | 504/1000 [16:07<20:29,  2.48s/it]INFO:root:global_step: 504, logpy: -3677.963, kl: 190.944, loss: 3861.357\n",
      " 50%|███████████████████████████████████████▉                                       | 505/1000 [16:08<18:38,  2.26s/it]INFO:root:global_step: 505, logpy: -3678.831, kl: 190.855, loss: 3862.211\n",
      " 51%|███████████████████████████████████████▉                                       | 506/1000 [16:10<17:26,  2.12s/it]INFO:root:global_step: 506, logpy: -3678.442, kl: 190.825, loss: 3861.867\n",
      " 51%|████████████████████████████████████████                                       | 507/1000 [16:12<16:44,  2.04s/it]INFO:root:global_step: 507, logpy: -3679.283, kl: 190.826, loss: 3862.783\n",
      " 51%|████████████████████████████████████████▏                                      | 508/1000 [16:14<16:14,  1.98s/it]INFO:root:global_step: 508, logpy: -3681.185, kl: 190.894, loss: 3864.827\n",
      " 51%|████████████████████████████████████████▏                                      | 509/1000 [16:16<15:41,  1.92s/it]INFO:root:global_step: 509, logpy: -3681.118, kl: 190.563, loss: 3864.501\n",
      " 51%|████████████████████████████████████████▎                                      | 510/1000 [16:17<15:23,  1.88s/it]INFO:root:global_step: 510, logpy: -3681.603, kl: 190.475, loss: 3864.970\n",
      " 51%|████████████████████████████████████████▎                                      | 511/1000 [16:19<15:02,  1.85s/it]INFO:root:global_step: 511, logpy: -3680.675, kl: 190.319, loss: 3863.957\n",
      " 51%|████████████████████████████████████████▍                                      | 512/1000 [16:21<14:48,  1.82s/it]INFO:root:global_step: 512, logpy: -3677.605, kl: 190.050, loss: 3860.689\n",
      " 51%|████████████████████████████████████████▌                                      | 513/1000 [16:23<14:39,  1.81s/it]INFO:root:global_step: 513, logpy: -3677.682, kl: 189.919, loss: 3860.703\n",
      " 51%|████████████████████████████████████████▌                                      | 514/1000 [16:25<14:40,  1.81s/it]INFO:root:global_step: 514, logpy: -3676.414, kl: 189.762, loss: 3859.348\n",
      " 52%|████████████████████████████████████████▋                                      | 515/1000 [16:26<14:32,  1.80s/it]INFO:root:global_step: 515, logpy: -3678.657, kl: 189.686, loss: 3861.583\n",
      " 52%|████████████████████████████████████████▊                                      | 516/1000 [16:28<14:25,  1.79s/it]INFO:root:global_step: 516, logpy: -3679.256, kl: 189.652, loss: 3862.216\n",
      " 52%|████████████████████████████████████████▊                                      | 517/1000 [16:30<14:17,  1.77s/it]INFO:root:global_step: 517, logpy: -3677.034, kl: 189.610, loss: 3860.018\n",
      " 52%|████████████████████████████████████████▉                                      | 518/1000 [16:32<14:15,  1.77s/it]INFO:root:global_step: 518, logpy: -3675.875, kl: 189.512, loss: 3858.828\n",
      " 52%|█████████████████████████████████████████                                      | 519/1000 [16:33<14:18,  1.79s/it]INFO:root:global_step: 519, logpy: -3676.116, kl: 189.449, loss: 3859.071\n",
      " 52%|█████████████████████████████████████████                                      | 520/1000 [16:35<14:23,  1.80s/it]INFO:root:global_step: 520, logpy: -3675.638, kl: 189.369, loss: 3858.579\n",
      " 52%|█████████████████████████████████████████▏                                     | 521/1000 [16:37<14:35,  1.83s/it]INFO:root:global_step: 521, logpy: -3675.026, kl: 189.293, loss: 3857.954\n",
      " 52%|█████████████████████████████████████████▏                                     | 522/1000 [16:39<14:35,  1.83s/it]INFO:root:global_step: 522, logpy: -3675.836, kl: 189.293, loss: 3858.829\n",
      " 52%|█████████████████████████████████████████▎                                     | 523/1000 [16:41<14:31,  1.83s/it]INFO:root:global_step: 523, logpy: -3676.469, kl: 189.359, loss: 3859.590\n",
      " 52%|█████████████████████████████████████████▍                                     | 524/1000 [16:43<14:29,  1.83s/it]INFO:root:global_step: 524, logpy: -3675.308, kl: 189.258, loss: 3858.391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████████████████████████████████████████▍                                     | 525/1000 [16:44<14:24,  1.82s/it]INFO:root:global_step: 525, logpy: -3675.232, kl: 189.309, loss: 3858.428\n",
      " 53%|█████████████████████████████████████████▌                                     | 526/1000 [16:46<14:17,  1.81s/it]INFO:root:global_step: 526, logpy: -3673.748, kl: 189.116, loss: 3856.811\n",
      " 53%|█████████████████████████████████████████▋                                     | 527/1000 [16:48<14:25,  1.83s/it]INFO:root:global_step: 527, logpy: -3675.343, kl: 189.216, loss: 3858.567\n",
      " 53%|█████████████████████████████████████████▋                                     | 528/1000 [16:50<14:03,  1.79s/it]INFO:root:global_step: 528, logpy: -3676.194, kl: 189.149, loss: 3859.411\n",
      " 53%|█████████████████████████████████████████▊                                     | 529/1000 [16:52<14:09,  1.80s/it]INFO:root:global_step: 529, logpy: -3677.010, kl: 189.124, loss: 3860.262\n",
      " 53%|█████████████████████████████████████████▊                                     | 530/1000 [16:53<14:11,  1.81s/it]INFO:root:global_step: 530, logpy: -3678.515, kl: 189.167, loss: 3861.868\n",
      " 53%|█████████████████████████████████████████▉                                     | 531/1000 [16:55<14:01,  1.79s/it]INFO:root:global_step: 531, logpy: -3677.280, kl: 189.107, loss: 3860.632\n",
      " 53%|██████████████████████████████████████████                                     | 532/1000 [16:57<14:01,  1.80s/it]INFO:root:global_step: 532, logpy: -3678.084, kl: 189.293, loss: 3861.678\n",
      " 53%|██████████████████████████████████████████                                     | 533/1000 [16:59<13:56,  1.79s/it]INFO:root:global_step: 533, logpy: -3678.637, kl: 189.292, loss: 3862.288\n",
      " 53%|██████████████████████████████████████████▏                                    | 534/1000 [17:00<13:47,  1.78s/it]INFO:root:global_step: 534, logpy: -3678.795, kl: 189.151, loss: 3862.361\n",
      " 54%|██████████████████████████████████████████▎                                    | 535/1000 [17:02<13:43,  1.77s/it]INFO:root:global_step: 535, logpy: -3679.045, kl: 189.008, loss: 3862.523\n",
      " 54%|██████████████████████████████████████████▎                                    | 536/1000 [17:04<13:43,  1.77s/it]INFO:root:global_step: 536, logpy: -3678.295, kl: 188.977, loss: 3861.798\n",
      " 54%|██████████████████████████████████████████▍                                    | 537/1000 [17:06<13:44,  1.78s/it]INFO:root:global_step: 537, logpy: -3678.567, kl: 189.027, loss: 3862.175\n",
      " 54%|██████████████████████████████████████████▌                                    | 538/1000 [17:08<13:48,  1.79s/it]INFO:root:global_step: 538, logpy: -3679.277, kl: 188.879, loss: 3862.790\n",
      " 54%|██████████████████████████████████████████▌                                    | 539/1000 [17:09<13:41,  1.78s/it]INFO:root:global_step: 539, logpy: -3679.075, kl: 188.811, loss: 3862.575\n",
      " 54%|██████████████████████████████████████████▋                                    | 540/1000 [17:11<13:39,  1.78s/it]INFO:root:global_step: 540, logpy: -3678.467, kl: 188.807, loss: 3862.016\n",
      " 54%|██████████████████████████████████████████▋                                    | 541/1000 [17:13<13:42,  1.79s/it]INFO:root:global_step: 541, logpy: -3679.226, kl: 189.091, loss: 3863.111\n",
      " 54%|██████████████████████████████████████████▊                                    | 542/1000 [17:15<13:34,  1.78s/it]INFO:root:global_step: 542, logpy: -3677.199, kl: 188.904, loss: 3860.950\n",
      " 54%|██████████████████████████████████████████▉                                    | 543/1000 [17:17<13:43,  1.80s/it]INFO:root:global_step: 543, logpy: -3675.913, kl: 188.807, loss: 3859.619\n",
      " 54%|██████████████████████████████████████████▉                                    | 544/1000 [17:18<13:41,  1.80s/it]INFO:root:global_step: 544, logpy: -3675.927, kl: 188.610, loss: 3859.487\n",
      " 55%|███████████████████████████████████████████                                    | 545/1000 [17:20<13:39,  1.80s/it]INFO:root:global_step: 545, logpy: -3674.107, kl: 188.426, loss: 3857.532\n",
      " 55%|███████████████████████████████████████████▏                                   | 546/1000 [17:22<13:33,  1.79s/it]INFO:root:global_step: 546, logpy: -3674.432, kl: 188.328, loss: 3857.810\n",
      " 55%|███████████████████████████████████████████▏                                   | 547/1000 [17:24<13:34,  1.80s/it]INFO:root:global_step: 547, logpy: -3674.159, kl: 188.279, loss: 3857.538\n",
      " 55%|███████████████████████████████████████████▎                                   | 548/1000 [17:26<13:35,  1.81s/it]INFO:root:global_step: 548, logpy: -3675.321, kl: 188.341, loss: 3858.810\n",
      " 55%|███████████████████████████████████████████▎                                   | 549/1000 [17:27<13:34,  1.81s/it]INFO:root:global_step: 549, logpy: -3675.727, kl: 188.195, loss: 3859.119\n",
      " 55%|███████████████████████████████████████████▍                                   | 550/1000 [17:29<13:38,  1.82s/it]INFO:root:Saved figure at: ./sim/global_step_550.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 550, logpy: -3675.875, kl: 188.285, loss: 3859.405\n",
      " 55%|███████████████████████████████████████████▌                                   | 551/1000 [17:38<28:09,  3.76s/it]INFO:root:global_step: 551, logpy: -3673.963, kl: 188.097, loss: 3857.352\n",
      " 55%|███████████████████████████████████████████▌                                   | 552/1000 [17:39<23:39,  3.17s/it]INFO:root:global_step: 552, logpy: -3674.513, kl: 188.156, loss: 3858.008\n",
      " 55%|███████████████████████████████████████████▋                                   | 553/1000 [17:41<20:28,  2.75s/it]INFO:root:global_step: 553, logpy: -3676.128, kl: 188.266, loss: 3859.780\n",
      " 55%|███████████████████████████████████████████▊                                   | 554/1000 [17:43<18:20,  2.47s/it]INFO:root:global_step: 554, logpy: -3675.122, kl: 188.084, loss: 3858.638\n",
      " 56%|███████████████████████████████████████████▊                                   | 555/1000 [17:45<16:42,  2.25s/it]INFO:root:global_step: 555, logpy: -3673.301, kl: 187.961, loss: 3856.740\n",
      " 56%|███████████████████████████████████████████▉                                   | 556/1000 [17:46<15:38,  2.11s/it]INFO:root:global_step: 556, logpy: -3673.614, kl: 187.957, loss: 3857.094\n",
      " 56%|████████████████████████████████████████████                                   | 557/1000 [17:48<14:40,  1.99s/it]INFO:root:global_step: 557, logpy: -3672.216, kl: 187.839, loss: 3855.623\n",
      " 56%|████████████████████████████████████████████                                   | 558/1000 [17:50<14:10,  1.92s/it]INFO:root:global_step: 558, logpy: -3672.460, kl: 187.832, loss: 3855.904\n",
      " 56%|████████████████████████████████████████████▏                                  | 559/1000 [17:52<13:38,  1.86s/it]INFO:root:global_step: 559, logpy: -3673.889, kl: 187.754, loss: 3857.300\n",
      " 56%|████████████████████████████████████████████▏                                  | 560/1000 [17:53<13:17,  1.81s/it]INFO:root:global_step: 560, logpy: -3673.558, kl: 187.772, loss: 3857.029\n",
      " 56%|████████████████████████████████████████████▎                                  | 561/1000 [17:55<13:07,  1.79s/it]INFO:root:global_step: 561, logpy: -3674.359, kl: 187.719, loss: 3857.821\n",
      " 56%|████████████████████████████████████████████▍                                  | 562/1000 [17:57<13:11,  1.81s/it]INFO:root:global_step: 562, logpy: -3676.525, kl: 187.963, loss: 3860.272\n",
      " 56%|████████████████████████████████████████████▍                                  | 563/1000 [17:59<12:59,  1.78s/it]INFO:root:global_step: 563, logpy: -3677.273, kl: 187.954, loss: 3861.054\n",
      " 56%|████████████████████████████████████████████▌                                  | 564/1000 [18:00<12:54,  1.78s/it]INFO:root:global_step: 564, logpy: -3676.451, kl: 187.881, loss: 3860.201\n",
      " 56%|████████████████████████████████████████████▋                                  | 565/1000 [18:02<12:43,  1.76s/it]INFO:root:global_step: 565, logpy: -3676.172, kl: 187.756, loss: 3859.838\n",
      " 57%|████████████████████████████████████████████▋                                  | 566/1000 [18:04<12:40,  1.75s/it]INFO:root:global_step: 566, logpy: -3677.811, kl: 187.826, loss: 3861.588\n",
      " 57%|████████████████████████████████████████████▊                                  | 567/1000 [18:06<12:27,  1.73s/it]INFO:root:global_step: 567, logpy: -3677.584, kl: 187.730, loss: 3861.306\n",
      " 57%|████████████████████████████████████████████▊                                  | 568/1000 [18:07<12:30,  1.74s/it]INFO:root:global_step: 568, logpy: -3679.285, kl: 187.751, loss: 3863.067\n",
      " 57%|████████████████████████████████████████████▉                                  | 569/1000 [18:09<12:23,  1.72s/it]INFO:root:global_step: 569, logpy: -3678.014, kl: 187.654, loss: 3861.739\n",
      " 57%|█████████████████████████████████████████████                                  | 570/1000 [18:11<12:35,  1.76s/it]INFO:root:global_step: 570, logpy: -3679.790, kl: 187.781, loss: 3863.681\n",
      " 57%|█████████████████████████████████████████████                                  | 571/1000 [18:13<12:27,  1.74s/it]INFO:root:global_step: 571, logpy: -3679.676, kl: 187.699, loss: 3863.524\n",
      " 57%|█████████████████████████████████████████████▏                                 | 572/1000 [18:14<12:28,  1.75s/it]INFO:root:global_step: 572, logpy: -3679.524, kl: 187.511, loss: 3863.223\n",
      " 57%|█████████████████████████████████████████████▎                                 | 573/1000 [18:16<12:32,  1.76s/it]INFO:root:global_step: 573, logpy: -3681.795, kl: 187.601, loss: 3865.623\n",
      " 57%|█████████████████████████████████████████████▎                                 | 574/1000 [18:18<12:28,  1.76s/it]INFO:root:global_step: 574, logpy: -3680.437, kl: 187.238, loss: 3863.939\n",
      " 57%|█████████████████████████████████████████████▍                                 | 575/1000 [18:20<12:26,  1.76s/it]INFO:root:global_step: 575, logpy: -3680.414, kl: 187.256, loss: 3863.971\n",
      " 58%|█████████████████████████████████████████████▌                                 | 576/1000 [18:21<12:17,  1.74s/it]INFO:root:global_step: 576, logpy: -3681.007, kl: 187.155, loss: 3864.500\n",
      " 58%|█████████████████████████████████████████████▌                                 | 577/1000 [18:23<12:15,  1.74s/it]INFO:root:global_step: 577, logpy: -3681.941, kl: 187.232, loss: 3865.547\n",
      " 58%|█████████████████████████████████████████████▋                                 | 578/1000 [18:25<12:14,  1.74s/it]INFO:root:global_step: 578, logpy: -3680.291, kl: 187.143, loss: 3863.845\n",
      " 58%|█████████████████████████████████████████████▋                                 | 579/1000 [18:27<12:33,  1.79s/it]INFO:root:global_step: 579, logpy: -3677.913, kl: 187.068, loss: 3861.428\n",
      " 58%|█████████████████████████████████████████████▊                                 | 580/1000 [18:28<12:30,  1.79s/it]INFO:root:global_step: 580, logpy: -3676.514, kl: 187.122, loss: 3860.118\n",
      " 58%|█████████████████████████████████████████████▉                                 | 581/1000 [18:30<12:22,  1.77s/it]INFO:root:global_step: 581, logpy: -3675.998, kl: 187.176, loss: 3859.691\n",
      " 58%|█████████████████████████████████████████████▉                                 | 582/1000 [18:32<12:27,  1.79s/it]INFO:root:global_step: 582, logpy: -3676.847, kl: 187.411, loss: 3860.811\n",
      " 58%|██████████████████████████████████████████████                                 | 583/1000 [18:34<12:28,  1.79s/it]INFO:root:global_step: 583, logpy: -3678.036, kl: 187.491, loss: 3862.114\n",
      " 58%|██████████████████████████████████████████████▏                                | 584/1000 [18:36<12:24,  1.79s/it]INFO:root:global_step: 584, logpy: -3676.525, kl: 187.236, loss: 3860.382\n",
      " 58%|██████████████████████████████████████████████▏                                | 585/1000 [18:37<12:27,  1.80s/it]INFO:root:global_step: 585, logpy: -3675.507, kl: 187.151, loss: 3859.312\n",
      " 59%|██████████████████████████████████████████████▎                                | 586/1000 [18:39<12:28,  1.81s/it]INFO:root:global_step: 586, logpy: -3674.300, kl: 186.892, loss: 3857.880\n",
      " 59%|██████████████████████████████████████████████▎                                | 587/1000 [18:41<12:34,  1.83s/it]INFO:root:global_step: 587, logpy: -3672.275, kl: 186.669, loss: 3855.666\n",
      " 59%|██████████████████████████████████████████████▍                                | 588/1000 [18:43<12:27,  1.81s/it]INFO:root:global_step: 588, logpy: -3670.388, kl: 186.523, loss: 3853.665\n",
      " 59%|██████████████████████████████████████████████▌                                | 589/1000 [18:45<12:23,  1.81s/it]INFO:root:global_step: 589, logpy: -3669.242, kl: 186.549, loss: 3852.578\n",
      " 59%|██████████████████████████████████████████████▌                                | 590/1000 [18:46<12:18,  1.80s/it]INFO:root:global_step: 590, logpy: -3669.191, kl: 186.453, loss: 3852.462\n",
      " 59%|██████████████████████████████████████████████▋                                | 591/1000 [18:48<12:23,  1.82s/it]INFO:root:global_step: 591, logpy: -3669.594, kl: 186.356, loss: 3852.801\n",
      " 59%|██████████████████████████████████████████████▊                                | 592/1000 [18:50<12:13,  1.80s/it]INFO:root:global_step: 592, logpy: -3669.190, kl: 186.251, loss: 3852.323\n",
      " 59%|██████████████████████████████████████████████▊                                | 593/1000 [18:52<12:05,  1.78s/it]INFO:root:global_step: 593, logpy: -3666.971, kl: 186.111, loss: 3849.995\n",
      " 59%|██████████████████████████████████████████████▉                                | 594/1000 [18:54<12:02,  1.78s/it]INFO:root:global_step: 594, logpy: -3667.430, kl: 186.098, loss: 3850.473\n",
      " 60%|███████████████████████████████████████████████                                | 595/1000 [18:55<11:55,  1.77s/it]INFO:root:global_step: 595, logpy: -3666.272, kl: 185.970, loss: 3849.218\n",
      " 60%|███████████████████████████████████████████████                                | 596/1000 [18:57<11:56,  1.77s/it]INFO:root:global_step: 596, logpy: -3665.050, kl: 185.756, loss: 3847.811\n",
      " 60%|███████████████████████████████████████████████▏                               | 597/1000 [18:59<11:49,  1.76s/it]INFO:root:global_step: 597, logpy: -3665.071, kl: 185.832, loss: 3847.938\n",
      " 60%|███████████████████████████████████████████████▏                               | 598/1000 [19:01<11:55,  1.78s/it]INFO:root:global_step: 598, logpy: -3666.082, kl: 185.844, loss: 3848.990\n",
      " 60%|███████████████████████████████████████████████▎                               | 599/1000 [19:03<12:00,  1.80s/it]INFO:root:global_step: 599, logpy: -3666.758, kl: 185.838, loss: 3849.689\n",
      " 60%|███████████████████████████████████████████████▍                               | 600/1000 [19:04<12:03,  1.81s/it]INFO:root:Saved figure at: ./sim/global_step_600.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 600, logpy: -3665.811, kl: 185.934, loss: 3848.868\n",
      " 60%|███████████████████████████████████████████████▍                               | 601/1000 [19:13<25:02,  3.77s/it]INFO:root:global_step: 601, logpy: -3666.763, kl: 185.928, loss: 3849.843\n",
      " 60%|███████████████████████████████████████████████▌                               | 602/1000 [19:15<21:06,  3.18s/it]INFO:root:global_step: 602, logpy: -3667.470, kl: 185.910, loss: 3850.560\n",
      " 60%|███████████████████████████████████████████████▋                               | 603/1000 [19:16<18:16,  2.76s/it]INFO:root:global_step: 603, logpy: -3668.896, kl: 185.994, loss: 3852.099\n",
      " 60%|███████████████████████████████████████████████▋                               | 604/1000 [19:18<16:20,  2.48s/it]INFO:root:global_step: 604, logpy: -3668.585, kl: 185.928, loss: 3851.749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████████████████████████▊                               | 605/1000 [19:20<15:04,  2.29s/it]INFO:root:global_step: 605, logpy: -3669.141, kl: 185.784, loss: 3852.189\n",
      " 61%|███████████████████████████████████████████████▊                               | 606/1000 [19:22<14:14,  2.17s/it]INFO:root:global_step: 606, logpy: -3668.896, kl: 185.702, loss: 3851.889\n",
      " 61%|███████████████████████████████████████████████▉                               | 607/1000 [19:24<13:25,  2.05s/it]INFO:root:global_step: 607, logpy: -3667.778, kl: 185.503, loss: 3850.599\n",
      " 61%|████████████████████████████████████████████████                               | 608/1000 [19:25<12:57,  1.98s/it]INFO:root:global_step: 608, logpy: -3668.175, kl: 185.707, loss: 3851.227\n",
      " 61%|████████████████████████████████████████████████                               | 609/1000 [19:27<12:31,  1.92s/it]INFO:root:global_step: 609, logpy: -3668.965, kl: 185.806, loss: 3852.143\n",
      " 61%|████████████████████████████████████████████████▏                              | 610/1000 [19:29<12:30,  1.92s/it]INFO:root:global_step: 610, logpy: -3670.008, kl: 185.870, loss: 3853.276\n",
      " 61%|████████████████████████████████████████████████▎                              | 611/1000 [19:31<12:15,  1.89s/it]INFO:root:global_step: 611, logpy: -3671.352, kl: 185.855, loss: 3854.631\n",
      " 61%|████████████████████████████████████████████████▎                              | 612/1000 [19:33<12:01,  1.86s/it]INFO:root:global_step: 612, logpy: -3672.290, kl: 185.951, loss: 3855.690\n",
      " 61%|████████████████████████████████████████████████▍                              | 613/1000 [19:35<11:53,  1.84s/it]INFO:root:global_step: 613, logpy: -3674.027, kl: 185.976, loss: 3857.478\n",
      " 61%|████████████████████████████████████████████████▌                              | 614/1000 [19:36<11:41,  1.82s/it]INFO:root:global_step: 614, logpy: -3675.012, kl: 185.975, loss: 3858.488\n",
      " 62%|████████████████████████████████████████████████▌                              | 615/1000 [19:38<11:39,  1.82s/it]INFO:root:global_step: 615, logpy: -3673.682, kl: 185.953, loss: 3857.161\n",
      " 62%|████████████████████████████████████████████████▋                              | 616/1000 [19:40<11:34,  1.81s/it]INFO:root:global_step: 616, logpy: -3670.257, kl: 185.688, loss: 3853.495\n",
      " 62%|████████████████████████████████████████████████▋                              | 617/1000 [19:42<11:34,  1.81s/it]INFO:root:global_step: 617, logpy: -3669.205, kl: 185.571, loss: 3852.351\n",
      " 62%|████████████████████████████████████████████████▊                              | 618/1000 [19:44<11:37,  1.83s/it]INFO:root:global_step: 618, logpy: -3669.127, kl: 185.416, loss: 3852.142\n",
      " 62%|████████████████████████████████████████████████▉                              | 619/1000 [19:45<11:28,  1.81s/it]INFO:root:global_step: 619, logpy: -3670.792, kl: 185.451, loss: 3853.866\n",
      " 62%|████████████████████████████████████████████████▉                              | 620/1000 [19:47<11:30,  1.82s/it]INFO:root:global_step: 620, logpy: -3671.336, kl: 185.641, loss: 3854.624\n",
      " 62%|█████████████████████████████████████████████████                              | 621/1000 [19:49<11:29,  1.82s/it]INFO:root:global_step: 621, logpy: -3672.561, kl: 185.632, loss: 3855.864\n",
      " 62%|█████████████████████████████████████████████████▏                             | 622/1000 [19:51<11:26,  1.81s/it]INFO:root:global_step: 622, logpy: -3671.644, kl: 185.563, loss: 3854.901\n",
      " 62%|█████████████████████████████████████████████████▏                             | 623/1000 [19:53<11:20,  1.80s/it]INFO:root:global_step: 623, logpy: -3672.759, kl: 185.684, loss: 3856.161\n",
      " 62%|█████████████████████████████████████████████████▎                             | 624/1000 [19:54<11:16,  1.80s/it]INFO:root:global_step: 624, logpy: -3673.506, kl: 185.781, loss: 3857.027\n",
      " 62%|█████████████████████████████████████████████████▍                             | 625/1000 [19:56<11:08,  1.78s/it]INFO:root:global_step: 625, logpy: -3673.810, kl: 185.812, loss: 3857.385\n",
      " 63%|█████████████████████████████████████████████████▍                             | 626/1000 [19:58<11:04,  1.78s/it]INFO:root:global_step: 626, logpy: -3674.663, kl: 185.884, loss: 3858.332\n",
      " 63%|█████████████████████████████████████████████████▌                             | 627/1000 [20:00<11:18,  1.82s/it]INFO:root:global_step: 627, logpy: -3673.661, kl: 185.699, loss: 3857.167\n",
      " 63%|█████████████████████████████████████████████████▌                             | 628/1000 [20:02<11:16,  1.82s/it]INFO:root:global_step: 628, logpy: -3674.375, kl: 185.743, loss: 3857.947\n",
      " 63%|█████████████████████████████████████████████████▋                             | 629/1000 [20:03<11:15,  1.82s/it]INFO:root:global_step: 629, logpy: -3672.892, kl: 185.650, loss: 3856.392\n",
      " 63%|█████████████████████████████████████████████████▊                             | 630/1000 [20:05<11:11,  1.81s/it]INFO:root:global_step: 630, logpy: -3673.568, kl: 185.727, loss: 3857.167\n",
      " 63%|█████████████████████████████████████████████████▊                             | 631/1000 [20:07<11:02,  1.80s/it]INFO:root:global_step: 631, logpy: -3673.808, kl: 185.749, loss: 3857.450\n",
      " 63%|█████████████████████████████████████████████████▉                             | 632/1000 [20:09<11:09,  1.82s/it]INFO:root:global_step: 632, logpy: -3674.578, kl: 185.729, loss: 3858.220\n",
      " 63%|██████████████████████████████████████████████████                             | 633/1000 [20:11<11:02,  1.81s/it]INFO:root:global_step: 633, logpy: -3673.312, kl: 185.600, loss: 3856.847\n",
      " 63%|██████████████████████████████████████████████████                             | 634/1000 [20:13<11:02,  1.81s/it]INFO:root:global_step: 634, logpy: -3674.614, kl: 185.707, loss: 3858.277\n",
      " 64%|██████████████████████████████████████████████████▏                            | 635/1000 [20:14<11:01,  1.81s/it]INFO:root:global_step: 635, logpy: -3675.159, kl: 185.611, loss: 3858.746\n",
      " 64%|██████████████████████████████████████████████████▏                            | 636/1000 [20:16<11:05,  1.83s/it]INFO:root:global_step: 636, logpy: -3675.632, kl: 185.581, loss: 3859.209\n",
      " 64%|██████████████████████████████████████████████████▎                            | 637/1000 [20:18<10:57,  1.81s/it]INFO:root:global_step: 637, logpy: -3676.266, kl: 185.761, loss: 3860.043\n",
      " 64%|██████████████████████████████████████████████████▍                            | 638/1000 [20:20<10:53,  1.80s/it]INFO:root:global_step: 638, logpy: -3677.292, kl: 185.791, loss: 3861.120\n",
      " 64%|██████████████████████████████████████████████████▍                            | 639/1000 [20:22<10:44,  1.79s/it]INFO:root:global_step: 639, logpy: -3677.913, kl: 185.793, loss: 3861.762\n",
      " 64%|██████████████████████████████████████████████████▌                            | 640/1000 [20:23<10:38,  1.77s/it]INFO:root:global_step: 640, logpy: -3677.687, kl: 185.789, loss: 3861.552\n",
      " 64%|██████████████████████████████████████████████████▋                            | 641/1000 [20:25<10:39,  1.78s/it]INFO:root:global_step: 641, logpy: -3679.301, kl: 185.977, loss: 3863.373\n",
      " 64%|██████████████████████████████████████████████████▋                            | 642/1000 [20:27<10:42,  1.79s/it]INFO:root:global_step: 642, logpy: -3679.591, kl: 186.031, loss: 3863.735\n",
      " 64%|██████████████████████████████████████████████████▊                            | 643/1000 [20:29<10:42,  1.80s/it]INFO:root:global_step: 643, logpy: -3679.734, kl: 185.862, loss: 3863.729\n",
      " 64%|██████████████████████████████████████████████████▉                            | 644/1000 [20:31<10:48,  1.82s/it]INFO:root:global_step: 644, logpy: -3678.538, kl: 185.728, loss: 3862.417\n",
      " 64%|██████████████████████████████████████████████████▉                            | 645/1000 [20:32<10:46,  1.82s/it]INFO:root:global_step: 645, logpy: -3677.542, kl: 185.721, loss: 3861.433\n",
      " 65%|███████████████████████████████████████████████████                            | 646/1000 [20:34<10:33,  1.79s/it]INFO:root:global_step: 646, logpy: -3678.879, kl: 185.841, loss: 3862.908\n",
      " 65%|███████████████████████████████████████████████████                            | 647/1000 [20:36<10:30,  1.79s/it]INFO:root:global_step: 647, logpy: -3678.685, kl: 185.733, loss: 3862.624\n",
      " 65%|███████████████████████████████████████████████████▏                           | 648/1000 [20:38<10:25,  1.78s/it]INFO:root:global_step: 648, logpy: -3677.127, kl: 185.626, loss: 3860.977\n",
      " 65%|███████████████████████████████████████████████████▎                           | 649/1000 [20:39<10:27,  1.79s/it]INFO:root:global_step: 649, logpy: -3677.119, kl: 185.607, loss: 3860.968\n",
      " 65%|███████████████████████████████████████████████████▎                           | 650/1000 [20:41<10:37,  1.82s/it]INFO:root:Saved figure at: ./sim/global_step_650.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 650, logpy: -3678.694, kl: 185.618, loss: 3862.572\n",
      " 65%|███████████████████████████████████████████████████▍                           | 651/1000 [20:50<21:52,  3.76s/it]INFO:root:global_step: 651, logpy: -3678.641, kl: 185.563, loss: 3862.481\n",
      " 65%|███████████████████████████████████████████████████▌                           | 652/1000 [20:52<18:33,  3.20s/it]INFO:root:global_step: 652, logpy: -3680.031, kl: 185.662, loss: 3863.988\n",
      " 65%|███████████████████████████████████████████████████▌                           | 653/1000 [20:53<16:01,  2.77s/it]INFO:root:global_step: 653, logpy: -3679.194, kl: 185.655, loss: 3863.161\n",
      " 65%|███████████████████████████████████████████████████▋                           | 654/1000 [20:55<14:15,  2.47s/it]INFO:root:global_step: 654, logpy: -3679.481, kl: 185.590, loss: 3863.400\n",
      " 66%|███████████████████████████████████████████████████▋                           | 655/1000 [20:57<13:05,  2.28s/it]INFO:root:global_step: 655, logpy: -3680.155, kl: 185.598, loss: 3864.097\n",
      " 66%|███████████████████████████████████████████████████▊                           | 656/1000 [20:59<12:07,  2.11s/it]INFO:root:global_step: 656, logpy: -3679.932, kl: 185.500, loss: 3863.794\n",
      " 66%|███████████████████████████████████████████████████▉                           | 657/1000 [21:01<11:43,  2.05s/it]INFO:root:global_step: 657, logpy: -3679.227, kl: 185.445, loss: 3863.050\n",
      " 66%|███████████████████████████████████████████████████▉                           | 658/1000 [21:02<11:20,  1.99s/it]INFO:root:global_step: 658, logpy: -3677.126, kl: 185.482, loss: 3861.001\n",
      " 66%|████████████████████████████████████████████████████                           | 659/1000 [21:04<10:53,  1.92s/it]INFO:root:global_step: 659, logpy: -3676.919, kl: 185.513, loss: 3860.842\n",
      " 66%|████████████████████████████████████████████████████▏                          | 660/1000 [21:06<10:39,  1.88s/it]INFO:root:global_step: 660, logpy: -3677.059, kl: 185.504, loss: 3860.989\n",
      " 66%|████████████████████████████████████████████████████▏                          | 661/1000 [21:08<10:28,  1.85s/it]INFO:root:global_step: 661, logpy: -3677.479, kl: 185.413, loss: 3861.334\n",
      " 66%|████████████████████████████████████████████████████▎                          | 662/1000 [21:09<10:19,  1.83s/it]INFO:root:global_step: 662, logpy: -3677.432, kl: 185.428, loss: 3861.317\n",
      " 66%|████████████████████████████████████████████████████▍                          | 663/1000 [21:11<10:17,  1.83s/it]INFO:root:global_step: 663, logpy: -3680.734, kl: 185.627, loss: 3864.833\n",
      " 66%|████████████████████████████████████████████████████▍                          | 664/1000 [21:13<10:07,  1.81s/it]INFO:root:global_step: 664, logpy: -3681.449, kl: 185.668, loss: 3865.605\n",
      " 66%|████████████████████████████████████████████████████▌                          | 665/1000 [21:15<10:09,  1.82s/it]INFO:root:global_step: 665, logpy: -3682.579, kl: 185.692, loss: 3866.773\n",
      " 67%|████████████████████████████████████████████████████▌                          | 666/1000 [21:17<10:05,  1.81s/it]INFO:root:global_step: 666, logpy: -3682.905, kl: 185.526, loss: 3866.949\n",
      " 67%|████████████████████████████████████████████████████▋                          | 667/1000 [21:18<09:54,  1.79s/it]INFO:root:global_step: 667, logpy: -3683.156, kl: 185.663, loss: 3867.352\n",
      " 67%|████████████████████████████████████████████████████▊                          | 668/1000 [21:20<09:53,  1.79s/it]INFO:root:global_step: 668, logpy: -3684.983, kl: 185.794, loss: 3869.324\n",
      " 67%|████████████████████████████████████████████████████▊                          | 669/1000 [21:22<10:01,  1.82s/it]INFO:root:global_step: 669, logpy: -3686.815, kl: 185.802, loss: 3871.179\n",
      " 67%|████████████████████████████████████████████████████▉                          | 670/1000 [21:24<09:56,  1.81s/it]INFO:root:global_step: 670, logpy: -3687.538, kl: 185.821, loss: 3871.935\n",
      " 67%|█████████████████████████████████████████████████████                          | 671/1000 [21:26<09:57,  1.82s/it]INFO:root:global_step: 671, logpy: -3688.863, kl: 185.878, loss: 3873.331\n",
      " 67%|█████████████████████████████████████████████████████                          | 672/1000 [21:27<09:50,  1.80s/it]INFO:root:global_step: 672, logpy: -3690.556, kl: 186.122, loss: 3875.283\n",
      " 67%|█████████████████████████████████████████████████████▏                         | 673/1000 [21:29<09:46,  1.79s/it]INFO:root:global_step: 673, logpy: -3690.642, kl: 186.074, loss: 3875.334\n",
      " 67%|█████████████████████████████████████████████████████▏                         | 674/1000 [21:31<09:55,  1.83s/it]INFO:root:global_step: 674, logpy: -3689.147, kl: 185.929, loss: 3873.709\n",
      " 68%|█████████████████████████████████████████████████████▎                         | 675/1000 [21:33<09:51,  1.82s/it]INFO:root:global_step: 675, logpy: -3687.297, kl: 185.931, loss: 3871.874\n",
      " 68%|█████████████████████████████████████████████████████▍                         | 676/1000 [21:35<09:46,  1.81s/it]INFO:root:global_step: 676, logpy: -3688.099, kl: 186.016, loss: 3872.775\n",
      " 68%|█████████████████████████████████████████████████████▍                         | 677/1000 [21:37<09:44,  1.81s/it]INFO:root:global_step: 677, logpy: -3688.142, kl: 186.140, loss: 3872.955\n",
      " 68%|█████████████████████████████████████████████████████▌                         | 678/1000 [21:38<09:40,  1.80s/it]INFO:root:global_step: 678, logpy: -3687.023, kl: 186.149, loss: 3871.858\n",
      " 68%|█████████████████████████████████████████████████████▋                         | 679/1000 [21:40<09:31,  1.78s/it]INFO:root:global_step: 679, logpy: -3688.736, kl: 186.142, loss: 3873.578\n",
      " 68%|█████████████████████████████████████████████████████▋                         | 680/1000 [21:42<09:24,  1.76s/it]INFO:root:global_step: 680, logpy: -3690.758, kl: 186.244, loss: 3875.715\n",
      " 68%|█████████████████████████████████████████████████████▊                         | 681/1000 [21:44<09:24,  1.77s/it]INFO:root:global_step: 681, logpy: -3690.806, kl: 186.296, loss: 3875.827\n",
      " 68%|█████████████████████████████████████████████████████▉                         | 682/1000 [21:45<09:22,  1.77s/it]INFO:root:global_step: 682, logpy: -3690.672, kl: 186.161, loss: 3875.571\n",
      " 68%|█████████████████████████████████████████████████████▉                         | 683/1000 [21:47<09:27,  1.79s/it]INFO:root:global_step: 683, logpy: -3690.055, kl: 186.288, loss: 3875.093\n",
      " 68%|██████████████████████████████████████████████████████                         | 684/1000 [21:49<09:30,  1.80s/it]INFO:root:global_step: 684, logpy: -3689.871, kl: 186.091, loss: 3874.725\n",
      " 68%|██████████████████████████████████████████████████████                         | 685/1000 [21:51<09:34,  1.82s/it]INFO:root:global_step: 685, logpy: -3689.312, kl: 186.014, loss: 3874.102\n",
      " 69%|██████████████████████████████████████████████████████▏                        | 686/1000 [21:53<09:25,  1.80s/it]INFO:root:global_step: 686, logpy: -3690.504, kl: 186.239, loss: 3875.530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████████████████████████████████████████████████████▎                        | 687/1000 [21:54<09:22,  1.80s/it]INFO:root:global_step: 687, logpy: -3692.078, kl: 186.330, loss: 3877.207\n",
      " 69%|██████████████████████████████████████████████████████▎                        | 688/1000 [21:56<09:17,  1.79s/it]INFO:root:global_step: 688, logpy: -3691.353, kl: 186.245, loss: 3876.410\n",
      " 69%|██████████████████████████████████████████████████████▍                        | 689/1000 [21:58<09:14,  1.78s/it]INFO:root:global_step: 689, logpy: -3689.377, kl: 186.059, loss: 3874.259\n",
      " 69%|██████████████████████████████████████████████████████▌                        | 690/1000 [22:00<09:07,  1.76s/it]INFO:root:global_step: 690, logpy: -3689.237, kl: 186.021, loss: 3874.093\n",
      " 69%|██████████████████████████████████████████████████████▌                        | 691/1000 [22:02<09:10,  1.78s/it]INFO:root:global_step: 691, logpy: -3689.460, kl: 185.973, loss: 3874.280\n",
      " 69%|██████████████████████████████████████████████████████▋                        | 692/1000 [22:03<09:12,  1.79s/it]INFO:root:global_step: 692, logpy: -3689.878, kl: 186.144, loss: 3874.881\n",
      " 69%|██████████████████████████████████████████████████████▋                        | 693/1000 [22:05<09:05,  1.78s/it]INFO:root:global_step: 693, logpy: -3688.987, kl: 186.244, loss: 3874.102\n",
      " 69%|██████████████████████████████████████████████████████▊                        | 694/1000 [22:07<09:06,  1.78s/it]INFO:root:global_step: 694, logpy: -3691.264, kl: 186.268, loss: 3876.414\n",
      " 70%|██████████████████████████████████████████████████████▉                        | 695/1000 [22:09<09:10,  1.80s/it]INFO:root:global_step: 695, logpy: -3692.067, kl: 186.243, loss: 3877.203\n",
      " 70%|██████████████████████████████████████████████████████▉                        | 696/1000 [22:11<09:06,  1.80s/it]INFO:root:global_step: 696, logpy: -3693.871, kl: 186.372, loss: 3879.147\n",
      " 70%|███████████████████████████████████████████████████████                        | 697/1000 [22:12<09:05,  1.80s/it]INFO:root:global_step: 697, logpy: -3690.736, kl: 186.382, loss: 3876.033\n",
      " 70%|███████████████████████████████████████████████████████▏                       | 698/1000 [22:14<09:07,  1.81s/it]INFO:root:global_step: 698, logpy: -3691.653, kl: 186.492, loss: 3877.071\n",
      " 70%|███████████████████████████████████████████████████████▏                       | 699/1000 [22:16<08:59,  1.79s/it]INFO:root:global_step: 699, logpy: -3690.102, kl: 186.516, loss: 3875.554\n",
      " 70%|███████████████████████████████████████████████████████▎                       | 700/1000 [22:18<08:55,  1.79s/it]INFO:root:Saved figure at: ./sim/global_step_700.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 700, logpy: -3691.446, kl: 186.602, loss: 3876.995\n",
      " 70%|███████████████████████████████████████████████████████▍                       | 701/1000 [22:26<18:40,  3.75s/it]INFO:root:global_step: 701, logpy: -3691.786, kl: 186.524, loss: 3877.267\n",
      " 70%|███████████████████████████████████████████████████████▍                       | 702/1000 [22:28<15:39,  3.15s/it]INFO:root:global_step: 702, logpy: -3692.402, kl: 186.477, loss: 3877.846\n",
      " 70%|███████████████████████████████████████████████████████▌                       | 703/1000 [22:30<13:35,  2.74s/it]INFO:root:global_step: 703, logpy: -3691.500, kl: 186.404, loss: 3876.882\n",
      " 70%|███████████████████████████████████████████████████████▌                       | 704/1000 [22:31<12:13,  2.48s/it]INFO:root:global_step: 704, logpy: -3692.148, kl: 186.567, loss: 3877.704\n",
      " 70%|███████████████████████████████████████████████████████▋                       | 705/1000 [22:33<11:16,  2.29s/it]INFO:root:global_step: 705, logpy: -3693.718, kl: 186.751, loss: 3879.467\n",
      " 71%|███████████████████████████████████████████████████████▊                       | 706/1000 [22:35<10:27,  2.13s/it]INFO:root:global_step: 706, logpy: -3692.107, kl: 186.596, loss: 3877.712\n",
      " 71%|███████████████████████████████████████████████████████▊                       | 707/1000 [22:37<09:53,  2.03s/it]INFO:root:global_step: 707, logpy: -3693.281, kl: 186.749, loss: 3879.048\n",
      " 71%|███████████████████████████████████████████████████████▉                       | 708/1000 [22:39<09:34,  1.97s/it]INFO:root:global_step: 708, logpy: -3693.647, kl: 186.743, loss: 3879.417\n",
      " 71%|████████████████████████████████████████████████████████                       | 709/1000 [22:40<09:14,  1.90s/it]INFO:root:global_step: 709, logpy: -3692.337, kl: 186.767, loss: 3878.142\n",
      " 71%|████████████████████████████████████████████████████████                       | 710/1000 [22:42<09:03,  1.87s/it]INFO:root:global_step: 710, logpy: -3691.090, kl: 186.642, loss: 3876.780\n",
      " 71%|████████████████████████████████████████████████████████▏                      | 711/1000 [22:44<08:59,  1.87s/it]INFO:root:global_step: 711, logpy: -3691.548, kl: 186.664, loss: 3877.270\n",
      " 71%|████████████████████████████████████████████████████████▏                      | 712/1000 [22:46<08:53,  1.85s/it]INFO:root:global_step: 712, logpy: -3690.865, kl: 186.669, loss: 3876.600\n",
      " 71%|████████████████████████████████████████████████████████▎                      | 713/1000 [22:48<08:53,  1.86s/it]INFO:root:global_step: 713, logpy: -3691.053, kl: 186.595, loss: 3876.724\n",
      " 71%|████████████████████████████████████████████████████████▍                      | 714/1000 [22:50<08:47,  1.84s/it]INFO:root:global_step: 714, logpy: -3687.970, kl: 186.480, loss: 3873.535\n",
      " 72%|████████████████████████████████████████████████████████▍                      | 715/1000 [22:51<08:47,  1.85s/it]INFO:root:global_step: 715, logpy: -3687.660, kl: 186.360, loss: 3873.114\n",
      " 72%|████████████████████████████████████████████████████████▌                      | 716/1000 [22:53<08:39,  1.83s/it]INFO:root:global_step: 716, logpy: -3688.544, kl: 186.490, loss: 3874.137\n",
      " 72%|████████████████████████████████████████████████████████▋                      | 717/1000 [22:55<08:29,  1.80s/it]INFO:root:global_step: 717, logpy: -3689.417, kl: 186.416, loss: 3874.945\n",
      " 72%|████████████████████████████████████████████████████████▋                      | 718/1000 [22:57<08:32,  1.82s/it]INFO:root:global_step: 718, logpy: -3690.598, kl: 186.459, loss: 3876.178\n",
      " 72%|████████████████████████████████████████████████████████▊                      | 719/1000 [22:59<08:33,  1.83s/it]INFO:root:global_step: 719, logpy: -3690.723, kl: 186.420, loss: 3876.273\n",
      " 72%|████████████████████████████████████████████████████████▉                      | 720/1000 [23:00<08:28,  1.82s/it]INFO:root:global_step: 720, logpy: -3690.726, kl: 186.478, loss: 3876.343\n",
      " 72%|████████████████████████████████████████████████████████▉                      | 721/1000 [23:02<08:27,  1.82s/it]INFO:root:global_step: 721, logpy: -3690.494, kl: 186.583, loss: 3876.224\n",
      " 72%|█████████████████████████████████████████████████████████                      | 722/1000 [23:04<08:24,  1.81s/it]INFO:root:global_step: 722, logpy: -3690.740, kl: 186.571, loss: 3876.467\n",
      " 72%|█████████████████████████████████████████████████████████                      | 723/1000 [23:06<08:18,  1.80s/it]INFO:root:global_step: 723, logpy: -3691.236, kl: 186.557, loss: 3876.957\n",
      " 72%|█████████████████████████████████████████████████████████▏                     | 724/1000 [23:08<08:22,  1.82s/it]INFO:root:global_step: 724, logpy: -3691.724, kl: 186.648, loss: 3877.545\n",
      " 72%|█████████████████████████████████████████████████████████▎                     | 725/1000 [23:10<08:20,  1.82s/it]INFO:root:global_step: 725, logpy: -3690.275, kl: 186.470, loss: 3875.926\n",
      " 73%|█████████████████████████████████████████████████████████▎                     | 726/1000 [23:11<08:14,  1.81s/it]INFO:root:global_step: 726, logpy: -3690.193, kl: 186.516, loss: 3875.898\n",
      " 73%|█████████████████████████████████████████████████████████▍                     | 727/1000 [23:13<08:11,  1.80s/it]INFO:root:global_step: 727, logpy: -3690.408, kl: 186.472, loss: 3876.077\n",
      " 73%|█████████████████████████████████████████████████████████▌                     | 728/1000 [23:15<08:09,  1.80s/it]INFO:root:global_step: 728, logpy: -3689.685, kl: 186.300, loss: 3875.191\n",
      " 73%|█████████████████████████████████████████████████████████▌                     | 729/1000 [23:17<08:07,  1.80s/it]INFO:root:global_step: 729, logpy: -3688.873, kl: 186.071, loss: 3874.157\n",
      " 73%|█████████████████████████████████████████████████████████▋                     | 730/1000 [23:18<08:06,  1.80s/it]INFO:root:global_step: 730, logpy: -3688.381, kl: 186.020, loss: 3873.622\n",
      " 73%|█████████████████████████████████████████████████████████▋                     | 731/1000 [23:20<08:01,  1.79s/it]INFO:root:global_step: 731, logpy: -3687.636, kl: 185.874, loss: 3872.739\n",
      " 73%|█████████████████████████████████████████████████████████▊                     | 732/1000 [23:22<07:56,  1.78s/it]INFO:root:global_step: 732, logpy: -3687.294, kl: 185.715, loss: 3872.245\n",
      " 73%|█████████████████████████████████████████████████████████▉                     | 733/1000 [23:24<07:52,  1.77s/it]INFO:root:global_step: 733, logpy: -3690.084, kl: 185.833, loss: 3875.161\n",
      " 73%|█████████████████████████████████████████████████████████▉                     | 734/1000 [23:26<07:54,  1.79s/it]INFO:root:global_step: 734, logpy: -3691.247, kl: 185.904, loss: 3876.403\n",
      " 74%|██████████████████████████████████████████████████████████                     | 735/1000 [23:27<07:55,  1.80s/it]INFO:root:global_step: 735, logpy: -3690.991, kl: 185.733, loss: 3875.983\n",
      " 74%|██████████████████████████████████████████████████████████▏                    | 736/1000 [23:29<07:54,  1.80s/it]INFO:root:global_step: 736, logpy: -3691.342, kl: 185.733, loss: 3876.341\n",
      " 74%|██████████████████████████████████████████████████████████▏                    | 737/1000 [23:31<07:54,  1.80s/it]INFO:root:global_step: 737, logpy: -3690.770, kl: 185.890, loss: 3875.935\n",
      " 74%|██████████████████████████████████████████████████████████▎                    | 738/1000 [23:33<07:50,  1.80s/it]INFO:root:global_step: 738, logpy: -3688.977, kl: 185.931, loss: 3874.190\n",
      " 74%|██████████████████████████████████████████████████████████▍                    | 739/1000 [23:35<07:53,  1.81s/it]INFO:root:global_step: 739, logpy: -3690.485, kl: 185.981, loss: 3875.754\n",
      " 74%|██████████████████████████████████████████████████████████▍                    | 740/1000 [23:36<07:51,  1.81s/it]INFO:root:global_step: 740, logpy: -3690.618, kl: 186.110, loss: 3876.024\n",
      " 74%|██████████████████████████████████████████████████████████▌                    | 741/1000 [23:38<07:54,  1.83s/it]INFO:root:global_step: 741, logpy: -3693.047, kl: 186.189, loss: 3878.538\n",
      " 74%|██████████████████████████████████████████████████████████▌                    | 742/1000 [23:40<07:47,  1.81s/it]INFO:root:global_step: 742, logpy: -3694.130, kl: 186.144, loss: 3879.584\n",
      " 74%|██████████████████████████████████████████████████████████▋                    | 743/1000 [23:42<07:45,  1.81s/it]INFO:root:global_step: 743, logpy: -3693.573, kl: 186.118, loss: 3879.008\n",
      " 74%|██████████████████████████████████████████████████████████▊                    | 744/1000 [23:44<07:43,  1.81s/it]INFO:root:global_step: 744, logpy: -3693.886, kl: 186.026, loss: 3879.235\n",
      " 74%|██████████████████████████████████████████████████████████▊                    | 745/1000 [23:45<07:38,  1.80s/it]INFO:root:global_step: 745, logpy: -3692.216, kl: 186.072, loss: 3877.619\n",
      " 75%|██████████████████████████████████████████████████████████▉                    | 746/1000 [23:47<07:35,  1.79s/it]INFO:root:global_step: 746, logpy: -3691.970, kl: 186.040, loss: 3877.347\n",
      " 75%|███████████████████████████████████████████████████████████                    | 747/1000 [23:49<07:32,  1.79s/it]INFO:root:global_step: 747, logpy: -3692.381, kl: 186.136, loss: 3877.860\n",
      " 75%|███████████████████████████████████████████████████████████                    | 748/1000 [23:51<07:41,  1.83s/it]INFO:root:global_step: 748, logpy: -3692.805, kl: 186.201, loss: 3878.355\n",
      " 75%|███████████████████████████████████████████████████████████▏                   | 749/1000 [23:53<07:36,  1.82s/it]INFO:root:global_step: 749, logpy: -3691.410, kl: 186.165, loss: 3876.931\n",
      " 75%|███████████████████████████████████████████████████████████▎                   | 750/1000 [23:55<07:36,  1.83s/it]INFO:root:Saved figure at: ./sim/global_step_750.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 750, logpy: -3692.370, kl: 186.264, loss: 3877.998\n",
      " 75%|███████████████████████████████████████████████████████████▎                   | 751/1000 [24:03<15:27,  3.73s/it]INFO:root:global_step: 751, logpy: -3693.357, kl: 186.219, loss: 3878.946\n",
      " 75%|███████████████████████████████████████████████████████████▍                   | 752/1000 [24:05<13:05,  3.17s/it]INFO:root:global_step: 752, logpy: -3691.425, kl: 186.150, loss: 3876.950\n",
      " 75%|███████████████████████████████████████████████████████████▍                   | 753/1000 [24:06<11:20,  2.76s/it]INFO:root:global_step: 753, logpy: -3691.075, kl: 185.970, loss: 3876.427\n",
      " 75%|███████████████████████████████████████████████████████████▌                   | 754/1000 [24:08<10:08,  2.47s/it]INFO:root:global_step: 754, logpy: -3693.094, kl: 186.267, loss: 3878.749\n",
      " 76%|███████████████████████████████████████████████████████████▋                   | 755/1000 [24:10<09:16,  2.27s/it]INFO:root:global_step: 755, logpy: -3693.124, kl: 186.360, loss: 3878.878\n",
      " 76%|███████████████████████████████████████████████████████████▋                   | 756/1000 [24:12<08:42,  2.14s/it]INFO:root:global_step: 756, logpy: -3693.453, kl: 186.344, loss: 3879.197\n",
      " 76%|███████████████████████████████████████████████████████████▊                   | 757/1000 [24:14<08:11,  2.02s/it]INFO:root:global_step: 757, logpy: -3695.266, kl: 186.342, loss: 3881.015\n",
      " 76%|███████████████████████████████████████████████████████████▉                   | 758/1000 [24:15<07:49,  1.94s/it]INFO:root:global_step: 758, logpy: -3693.068, kl: 186.138, loss: 3878.617\n",
      " 76%|███████████████████████████████████████████████████████████▉                   | 759/1000 [24:17<07:35,  1.89s/it]INFO:root:global_step: 759, logpy: -3693.211, kl: 186.010, loss: 3878.639\n",
      " 76%|████████████████████████████████████████████████████████████                   | 760/1000 [24:19<07:26,  1.86s/it]INFO:root:global_step: 760, logpy: -3691.628, kl: 185.920, loss: 3876.971\n",
      " 76%|████████████████████████████████████████████████████████████                   | 761/1000 [24:21<07:13,  1.82s/it]INFO:root:global_step: 761, logpy: -3692.401, kl: 185.955, loss: 3877.785\n",
      " 76%|████████████████████████████████████████████████████████████▏                  | 762/1000 [24:22<07:08,  1.80s/it]INFO:root:global_step: 762, logpy: -3695.752, kl: 185.870, loss: 3881.057\n",
      " 76%|████████████████████████████████████████████████████████████▎                  | 763/1000 [24:24<06:59,  1.77s/it]INFO:root:global_step: 763, logpy: -3697.414, kl: 185.926, loss: 3882.781\n",
      " 76%|████████████████████████████████████████████████████████████▎                  | 764/1000 [24:26<06:59,  1.78s/it]INFO:root:global_step: 764, logpy: -3698.766, kl: 185.986, loss: 3884.198\n",
      " 76%|████████████████████████████████████████████████████████████▍                  | 765/1000 [24:28<07:00,  1.79s/it]INFO:root:global_step: 765, logpy: -3698.368, kl: 185.955, loss: 3883.775\n",
      " 77%|████████████████████████████████████████████████████████████▌                  | 766/1000 [24:29<06:54,  1.77s/it]INFO:root:global_step: 766, logpy: -3699.108, kl: 186.049, loss: 3884.615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|████████████████████████████████████████████████████████████▌                  | 767/1000 [24:31<06:48,  1.75s/it]INFO:root:global_step: 767, logpy: -3697.740, kl: 186.183, loss: 3883.386\n",
      " 77%|████████████████████████████████████████████████████████████▋                  | 768/1000 [24:33<06:46,  1.75s/it]INFO:root:global_step: 768, logpy: -3698.040, kl: 186.198, loss: 3883.707\n",
      " 77%|████████████████████████████████████████████████████████████▊                  | 769/1000 [24:35<06:50,  1.78s/it]INFO:root:global_step: 769, logpy: -3699.238, kl: 186.326, loss: 3885.038\n",
      " 77%|████████████████████████████████████████████████████████████▊                  | 770/1000 [24:36<06:45,  1.76s/it]INFO:root:global_step: 770, logpy: -3698.603, kl: 186.401, loss: 3884.482\n",
      " 77%|████████████████████████████████████████████████████████████▉                  | 771/1000 [24:38<06:40,  1.75s/it]INFO:root:global_step: 771, logpy: -3699.544, kl: 186.462, loss: 3885.490\n",
      " 77%|████████████████████████████████████████████████████████████▉                  | 772/1000 [24:40<06:41,  1.76s/it]INFO:root:global_step: 772, logpy: -3698.923, kl: 186.606, loss: 3885.018\n",
      " 77%|█████████████████████████████████████████████████████████████                  | 773/1000 [24:42<06:41,  1.77s/it]INFO:root:global_step: 773, logpy: -3699.643, kl: 186.592, loss: 3885.730\n",
      " 77%|█████████████████████████████████████████████████████████████▏                 | 774/1000 [24:44<06:38,  1.76s/it]INFO:root:global_step: 774, logpy: -3700.045, kl: 186.499, loss: 3886.044\n",
      " 78%|█████████████████████████████████████████████████████████████▏                 | 775/1000 [24:45<06:36,  1.76s/it]INFO:root:global_step: 775, logpy: -3700.296, kl: 186.439, loss: 3886.239\n",
      " 78%|█████████████████████████████████████████████████████████████▎                 | 776/1000 [24:47<06:32,  1.75s/it]INFO:root:global_step: 776, logpy: -3702.412, kl: 186.511, loss: 3888.432\n",
      " 78%|█████████████████████████████████████████████████████████████▍                 | 777/1000 [24:49<06:34,  1.77s/it]INFO:root:global_step: 777, logpy: -3701.676, kl: 186.542, loss: 3887.732\n",
      " 78%|█████████████████████████████████████████████████████████████▍                 | 778/1000 [24:51<06:40,  1.80s/it]INFO:root:global_step: 778, logpy: -3703.572, kl: 186.579, loss: 3889.670\n",
      " 78%|█████████████████████████████████████████████████████████████▌                 | 779/1000 [24:53<06:45,  1.84s/it]INFO:root:global_step: 779, logpy: -3707.186, kl: 186.701, loss: 3893.411\n",
      " 78%|█████████████████████████████████████████████████████████████▌                 | 780/1000 [24:54<06:43,  1.83s/it]INFO:root:global_step: 780, logpy: -3705.829, kl: 186.549, loss: 3891.907\n",
      " 78%|█████████████████████████████████████████████████████████████▋                 | 781/1000 [24:56<06:38,  1.82s/it]INFO:root:global_step: 781, logpy: -3704.968, kl: 186.422, loss: 3890.923\n",
      " 78%|█████████████████████████████████████████████████████████████▊                 | 782/1000 [24:58<06:33,  1.81s/it]INFO:root:global_step: 782, logpy: -3702.944, kl: 186.195, loss: 3888.677\n",
      " 78%|█████████████████████████████████████████████████████████████▊                 | 783/1000 [25:00<06:31,  1.80s/it]INFO:root:global_step: 783, logpy: -3703.355, kl: 186.205, loss: 3889.103\n",
      " 78%|█████████████████████████████████████████████████████████████▉                 | 784/1000 [25:02<06:31,  1.81s/it]INFO:root:global_step: 784, logpy: -3703.744, kl: 186.213, loss: 3889.505\n",
      " 78%|██████████████████████████████████████████████████████████████                 | 785/1000 [25:03<06:26,  1.80s/it]INFO:root:global_step: 785, logpy: -3702.731, kl: 186.196, loss: 3888.479\n",
      " 79%|██████████████████████████████████████████████████████████████                 | 786/1000 [25:05<06:24,  1.80s/it]INFO:root:global_step: 786, logpy: -3700.344, kl: 186.081, loss: 3885.981\n",
      " 79%|██████████████████████████████████████████████████████████████▏                | 787/1000 [25:07<06:32,  1.84s/it]INFO:root:global_step: 787, logpy: -3700.750, kl: 186.081, loss: 3886.392\n",
      " 79%|██████████████████████████████████████████████████████████████▎                | 788/1000 [25:09<06:27,  1.83s/it]INFO:root:global_step: 788, logpy: -3701.630, kl: 186.060, loss: 3887.254\n",
      " 79%|██████████████████████████████████████████████████████████████▎                | 789/1000 [25:11<06:22,  1.81s/it]INFO:root:global_step: 789, logpy: -3701.838, kl: 186.087, loss: 3887.494\n",
      " 79%|██████████████████████████████████████████████████████████████▍                | 790/1000 [25:12<06:18,  1.80s/it]INFO:root:global_step: 790, logpy: -3701.366, kl: 186.198, loss: 3887.137\n",
      " 79%|██████████████████████████████████████████████████████████████▍                | 791/1000 [25:14<06:12,  1.78s/it]INFO:root:global_step: 791, logpy: -3701.936, kl: 186.310, loss: 3887.825\n",
      " 79%|██████████████████████████████████████████████████████████████▌                | 792/1000 [25:16<06:13,  1.80s/it]INFO:root:global_step: 792, logpy: -3701.471, kl: 186.297, loss: 3887.350\n",
      " 79%|██████████████████████████████████████████████████████████████▋                | 793/1000 [25:18<06:07,  1.78s/it]INFO:root:global_step: 793, logpy: -3699.771, kl: 186.177, loss: 3885.534\n",
      " 79%|██████████████████████████████████████████████████████████████▋                | 794/1000 [25:20<06:09,  1.79s/it]INFO:root:global_step: 794, logpy: -3700.835, kl: 186.209, loss: 3886.635\n",
      " 80%|██████████████████████████████████████████████████████████████▊                | 795/1000 [25:21<06:06,  1.79s/it]INFO:root:global_step: 795, logpy: -3700.309, kl: 186.303, loss: 3886.206\n",
      " 80%|██████████████████████████████████████████████████████████████▉                | 796/1000 [25:23<06:01,  1.77s/it]INFO:root:global_step: 796, logpy: -3700.906, kl: 186.427, loss: 3886.932\n",
      " 80%|██████████████████████████████████████████████████████████████▉                | 797/1000 [25:25<06:06,  1.80s/it]INFO:root:global_step: 797, logpy: -3700.843, kl: 186.441, loss: 3886.887\n",
      " 80%|███████████████████████████████████████████████████████████████                | 798/1000 [25:27<06:01,  1.79s/it]INFO:root:global_step: 798, logpy: -3701.144, kl: 186.413, loss: 3887.164\n",
      " 80%|███████████████████████████████████████████████████████████████                | 799/1000 [25:29<06:00,  1.79s/it]INFO:root:global_step: 799, logpy: -3699.966, kl: 186.363, loss: 3885.940\n",
      " 80%|███████████████████████████████████████████████████████████████▏               | 800/1000 [25:30<06:00,  1.80s/it]INFO:root:Saved figure at: ./sim/global_step_800.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 800, logpy: -3700.057, kl: 186.512, loss: 3886.184\n",
      " 80%|███████████████████████████████████████████████████████████████▎               | 801/1000 [25:39<12:25,  3.74s/it]INFO:root:global_step: 801, logpy: -3698.924, kl: 186.377, loss: 3884.919\n",
      " 80%|███████████████████████████████████████████████████████████████▎               | 802/1000 [25:40<10:25,  3.16s/it]INFO:root:global_step: 802, logpy: -3700.898, kl: 186.467, loss: 3886.987\n",
      " 80%|███████████████████████████████████████████████████████████████▍               | 803/1000 [25:42<09:02,  2.75s/it]INFO:root:global_step: 803, logpy: -3699.460, kl: 186.513, loss: 3885.599\n",
      " 80%|███████████████████████████████████████████████████████████████▌               | 804/1000 [25:44<08:02,  2.46s/it]INFO:root:global_step: 804, logpy: -3701.027, kl: 186.710, loss: 3887.366\n",
      " 80%|███████████████████████████████████████████████████████████████▌               | 805/1000 [25:46<07:18,  2.25s/it]INFO:root:global_step: 805, logpy: -3700.105, kl: 186.598, loss: 3886.337\n",
      " 81%|███████████████████████████████████████████████████████████████▋               | 806/1000 [25:48<06:52,  2.12s/it]INFO:root:global_step: 806, logpy: -3700.284, kl: 186.634, loss: 3886.555\n",
      " 81%|███████████████████████████████████████████████████████████████▊               | 807/1000 [25:49<06:27,  2.01s/it]INFO:root:global_step: 807, logpy: -3701.996, kl: 186.727, loss: 3888.364\n",
      " 81%|███████████████████████████████████████████████████████████████▊               | 808/1000 [25:51<06:09,  1.92s/it]INFO:root:global_step: 808, logpy: -3701.600, kl: 186.665, loss: 3887.910\n",
      " 81%|███████████████████████████████████████████████████████████████▉               | 809/1000 [25:53<06:02,  1.90s/it]INFO:root:global_step: 809, logpy: -3701.064, kl: 186.553, loss: 3887.265\n",
      " 81%|███████████████████████████████████████████████████████████████▉               | 810/1000 [25:55<05:53,  1.86s/it]INFO:root:global_step: 810, logpy: -3701.452, kl: 186.441, loss: 3887.544\n",
      " 81%|████████████████████████████████████████████████████████████████               | 811/1000 [25:56<05:46,  1.84s/it]INFO:root:global_step: 811, logpy: -3703.476, kl: 186.382, loss: 3889.513\n",
      " 81%|████████████████████████████████████████████████████████████████▏              | 812/1000 [25:58<05:45,  1.84s/it]INFO:root:global_step: 812, logpy: -3703.956, kl: 186.590, loss: 3890.204\n",
      " 81%|████████████████████████████████████████████████████████████████▏              | 813/1000 [26:00<05:37,  1.81s/it]INFO:root:global_step: 813, logpy: -3703.954, kl: 186.668, loss: 3890.283\n",
      " 81%|████████████████████████████████████████████████████████████████▎              | 814/1000 [26:02<05:34,  1.80s/it]INFO:root:global_step: 814, logpy: -3702.748, kl: 186.662, loss: 3889.075\n",
      " 82%|████████████████████████████████████████████████████████████████▍              | 815/1000 [26:04<05:30,  1.79s/it]INFO:root:global_step: 815, logpy: -3702.803, kl: 186.643, loss: 3889.115\n",
      " 82%|████████████████████████████████████████████████████████████████▍              | 816/1000 [26:05<05:28,  1.79s/it]INFO:root:global_step: 816, logpy: -3703.304, kl: 186.708, loss: 3889.684\n",
      " 82%|████████████████████████████████████████████████████████████████▌              | 817/1000 [26:07<05:25,  1.78s/it]INFO:root:global_step: 817, logpy: -3703.772, kl: 186.656, loss: 3890.103\n",
      " 82%|████████████████████████████████████████████████████████████████▌              | 818/1000 [26:09<05:24,  1.78s/it]INFO:root:global_step: 818, logpy: -3701.985, kl: 186.549, loss: 3888.212\n",
      " 82%|████████████████████████████████████████████████████████████████▋              | 819/1000 [26:11<05:26,  1.80s/it]INFO:root:global_step: 819, logpy: -3700.701, kl: 186.469, loss: 3886.852\n",
      " 82%|████████████████████████████████████████████████████████████████▊              | 820/1000 [26:13<05:23,  1.80s/it]INFO:root:global_step: 820, logpy: -3699.763, kl: 186.362, loss: 3885.810\n",
      " 82%|████████████████████████████████████████████████████████████████▊              | 821/1000 [26:14<05:21,  1.80s/it]INFO:root:global_step: 821, logpy: -3699.024, kl: 186.426, loss: 3885.138\n",
      " 82%|████████████████████████████████████████████████████████████████▉              | 822/1000 [26:16<05:16,  1.78s/it]INFO:root:global_step: 822, logpy: -3697.895, kl: 186.448, loss: 3884.034\n",
      " 82%|█████████████████████████████████████████████████████████████████              | 823/1000 [26:18<05:13,  1.77s/it]INFO:root:global_step: 823, logpy: -3699.873, kl: 186.453, loss: 3886.020\n",
      " 82%|█████████████████████████████████████████████████████████████████              | 824/1000 [26:20<05:13,  1.78s/it]INFO:root:global_step: 824, logpy: -3700.384, kl: 186.532, loss: 3886.613\n",
      " 82%|█████████████████████████████████████████████████████████████████▏             | 825/1000 [26:21<05:14,  1.79s/it]INFO:root:global_step: 825, logpy: -3699.373, kl: 186.677, loss: 3885.750\n",
      " 83%|█████████████████████████████████████████████████████████████████▎             | 826/1000 [26:23<05:15,  1.81s/it]INFO:root:global_step: 826, logpy: -3698.104, kl: 186.362, loss: 3884.169\n",
      " 83%|█████████████████████████████████████████████████████████████████▎             | 827/1000 [26:25<05:18,  1.84s/it]INFO:root:global_step: 827, logpy: -3699.906, kl: 186.376, loss: 3885.988\n",
      " 83%|█████████████████████████████████████████████████████████████████▍             | 828/1000 [26:27<05:16,  1.84s/it]INFO:root:global_step: 828, logpy: -3699.606, kl: 186.376, loss: 3885.691\n",
      " 83%|█████████████████████████████████████████████████████████████████▍             | 829/1000 [26:29<05:14,  1.84s/it]INFO:root:global_step: 829, logpy: -3698.824, kl: 186.327, loss: 3884.863\n",
      " 83%|█████████████████████████████████████████████████████████████████▌             | 830/1000 [26:31<05:13,  1.84s/it]INFO:root:global_step: 830, logpy: -3699.385, kl: 186.422, loss: 3885.522\n",
      " 83%|█████████████████████████████████████████████████████████████████▋             | 831/1000 [26:33<05:06,  1.82s/it]INFO:root:global_step: 831, logpy: -3699.367, kl: 186.469, loss: 3885.554\n",
      " 83%|█████████████████████████████████████████████████████████████████▋             | 832/1000 [26:34<05:01,  1.80s/it]INFO:root:global_step: 832, logpy: -3697.603, kl: 186.230, loss: 3883.553\n",
      " 83%|█████████████████████████████████████████████████████████████████▊             | 833/1000 [26:36<05:00,  1.80s/it]INFO:root:global_step: 833, logpy: -3697.775, kl: 186.228, loss: 3883.727\n",
      " 83%|█████████████████████████████████████████████████████████████████▉             | 834/1000 [26:38<04:57,  1.79s/it]INFO:root:global_step: 834, logpy: -3700.098, kl: 186.333, loss: 3886.158\n",
      " 84%|█████████████████████████████████████████████████████████████████▉             | 835/1000 [26:40<04:54,  1.78s/it]INFO:root:global_step: 835, logpy: -3701.038, kl: 186.551, loss: 3887.318\n",
      " 84%|██████████████████████████████████████████████████████████████████             | 836/1000 [26:41<04:54,  1.79s/it]INFO:root:global_step: 836, logpy: -3701.881, kl: 186.504, loss: 3888.117\n",
      " 84%|██████████████████████████████████████████████████████████████████             | 837/1000 [26:43<04:52,  1.79s/it]INFO:root:global_step: 837, logpy: -3700.955, kl: 186.363, loss: 3887.052\n",
      " 84%|██████████████████████████████████████████████████████████████████▏            | 838/1000 [26:45<04:49,  1.79s/it]INFO:root:global_step: 838, logpy: -3703.616, kl: 186.562, loss: 3889.915\n",
      " 84%|██████████████████████████████████████████████████████████████████▎            | 839/1000 [26:47<04:51,  1.81s/it]INFO:root:global_step: 839, logpy: -3703.674, kl: 186.574, loss: 3889.988\n",
      " 84%|██████████████████████████████████████████████████████████████████▎            | 840/1000 [26:49<04:53,  1.84s/it]INFO:root:global_step: 840, logpy: -3703.274, kl: 186.536, loss: 3889.553\n",
      " 84%|██████████████████████████████████████████████████████████████████▍            | 841/1000 [26:51<04:50,  1.82s/it]INFO:root:global_step: 841, logpy: -3702.475, kl: 186.556, loss: 3888.776\n",
      " 84%|██████████████████████████████████████████████████████████████████▌            | 842/1000 [26:52<04:47,  1.82s/it]INFO:root:global_step: 842, logpy: -3702.977, kl: 186.493, loss: 3889.217\n",
      " 84%|██████████████████████████████████████████████████████████████████▌            | 843/1000 [26:54<04:44,  1.81s/it]INFO:root:global_step: 843, logpy: -3702.342, kl: 186.500, loss: 3888.591\n",
      " 84%|██████████████████████████████████████████████████████████████████▋            | 844/1000 [26:56<04:41,  1.80s/it]INFO:root:global_step: 844, logpy: -3704.216, kl: 186.666, loss: 3890.634\n",
      " 84%|██████████████████████████████████████████████████████████████████▊            | 845/1000 [26:58<04:44,  1.84s/it]INFO:root:global_step: 845, logpy: -3704.380, kl: 186.656, loss: 3890.791\n",
      " 85%|██████████████████████████████████████████████████████████████████▊            | 846/1000 [27:00<04:38,  1.81s/it]INFO:root:global_step: 846, logpy: -3705.284, kl: 186.520, loss: 3891.562\n",
      " 85%|██████████████████████████████████████████████████████████████████▉            | 847/1000 [27:01<04:34,  1.79s/it]INFO:root:global_step: 847, logpy: -3706.565, kl: 186.782, loss: 3893.106\n",
      " 85%|██████████████████████████████████████████████████████████████████▉            | 848/1000 [27:03<04:32,  1.79s/it]INFO:root:global_step: 848, logpy: -3706.222, kl: 186.683, loss: 3892.667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|███████████████████████████████████████████████████████████████████            | 849/1000 [27:05<04:30,  1.79s/it]INFO:root:global_step: 849, logpy: -3705.119, kl: 186.615, loss: 3891.499\n",
      " 85%|███████████████████████████████████████████████████████████████████▏           | 850/1000 [27:07<04:28,  1.79s/it]INFO:root:Saved figure at: ./sim/global_step_850.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 850, logpy: -3704.726, kl: 186.389, loss: 3890.883\n",
      " 85%|███████████████████████████████████████████████████████████████████▏           | 851/1000 [27:15<09:20,  3.76s/it]INFO:root:global_step: 851, logpy: -3705.600, kl: 186.440, loss: 3891.809\n",
      " 85%|███████████████████████████████████████████████████████████████████▎           | 852/1000 [27:17<07:51,  3.18s/it]INFO:root:global_step: 852, logpy: -3705.250, kl: 186.438, loss: 3891.459\n",
      " 85%|███████████████████████████████████████████████████████████████████▍           | 853/1000 [27:19<06:45,  2.76s/it]INFO:root:global_step: 853, logpy: -3706.103, kl: 186.639, loss: 3892.517\n",
      " 85%|███████████████████████████████████████████████████████████████████▍           | 854/1000 [27:21<06:02,  2.48s/it]INFO:root:global_step: 854, logpy: -3705.378, kl: 186.526, loss: 3891.680\n",
      " 86%|███████████████████████████████████████████████████████████████████▌           | 855/1000 [27:22<05:31,  2.28s/it]INFO:root:global_step: 855, logpy: -3705.215, kl: 186.431, loss: 3891.424\n",
      " 86%|███████████████████████████████████████████████████████████████████▌           | 856/1000 [27:24<05:07,  2.14s/it]INFO:root:global_step: 856, logpy: -3704.860, kl: 186.306, loss: 3890.947\n",
      " 86%|███████████████████████████████████████████████████████████████████▋           | 857/1000 [27:26<04:54,  2.06s/it]INFO:root:global_step: 857, logpy: -3704.323, kl: 186.206, loss: 3890.311\n",
      " 86%|███████████████████████████████████████████████████████████████████▊           | 858/1000 [27:28<04:41,  1.98s/it]INFO:root:global_step: 858, logpy: -3703.536, kl: 186.158, loss: 3889.479\n",
      " 86%|███████████████████████████████████████████████████████████████████▊           | 859/1000 [27:30<04:33,  1.94s/it]INFO:root:global_step: 859, logpy: -3703.322, kl: 186.140, loss: 3889.249\n",
      " 86%|███████████████████████████████████████████████████████████████████▉           | 860/1000 [27:31<04:25,  1.89s/it]INFO:root:global_step: 860, logpy: -3703.257, kl: 186.121, loss: 3889.167\n",
      " 86%|████████████████████████████████████████████████████████████████████           | 861/1000 [27:33<04:19,  1.87s/it]INFO:root:global_step: 861, logpy: -3702.075, kl: 185.959, loss: 3887.826\n",
      " 86%|████████████████████████████████████████████████████████████████████           | 862/1000 [27:35<04:14,  1.85s/it]INFO:root:global_step: 862, logpy: -3700.294, kl: 185.861, loss: 3885.948\n",
      " 86%|████████████████████████████████████████████████████████████████████▏          | 863/1000 [27:37<04:09,  1.82s/it]INFO:root:global_step: 863, logpy: -3700.613, kl: 185.761, loss: 3886.169\n",
      " 86%|████████████████████████████████████████████████████████████████████▎          | 864/1000 [27:39<04:05,  1.81s/it]INFO:root:global_step: 864, logpy: -3701.657, kl: 186.002, loss: 3887.456\n",
      " 86%|████████████████████████████████████████████████████████████████████▎          | 865/1000 [27:40<04:01,  1.79s/it]INFO:root:global_step: 865, logpy: -3701.937, kl: 186.059, loss: 3887.796\n",
      " 87%|████████████████████████████████████████████████████████████████████▍          | 866/1000 [27:42<03:58,  1.78s/it]INFO:root:global_step: 866, logpy: -3701.452, kl: 186.054, loss: 3887.306\n",
      " 87%|████████████████████████████████████████████████████████████████████▍          | 867/1000 [27:44<03:55,  1.77s/it]INFO:root:global_step: 867, logpy: -3703.240, kl: 186.089, loss: 3889.132\n",
      " 87%|████████████████████████████████████████████████████████████████████▌          | 868/1000 [27:46<03:53,  1.77s/it]INFO:root:global_step: 868, logpy: -3703.978, kl: 186.088, loss: 3889.872\n",
      " 87%|████████████████████████████████████████████████████████████████████▋          | 869/1000 [27:47<03:54,  1.79s/it]INFO:root:global_step: 869, logpy: -3704.358, kl: 186.090, loss: 3890.256\n",
      " 87%|████████████████████████████████████████████████████████████████████▋          | 870/1000 [27:49<03:52,  1.79s/it]INFO:root:global_step: 870, logpy: -3704.890, kl: 186.080, loss: 3890.779\n",
      " 87%|████████████████████████████████████████████████████████████████████▊          | 871/1000 [27:51<03:51,  1.79s/it]INFO:root:global_step: 871, logpy: -3706.163, kl: 186.266, loss: 3892.240\n",
      " 87%|████████████████████████████████████████████████████████████████████▉          | 872/1000 [27:53<03:46,  1.77s/it]INFO:root:global_step: 872, logpy: -3705.230, kl: 186.094, loss: 3891.137\n",
      " 87%|████████████████████████████████████████████████████████████████████▉          | 873/1000 [27:55<03:45,  1.77s/it]INFO:root:global_step: 873, logpy: -3706.856, kl: 186.261, loss: 3892.932\n",
      " 87%|█████████████████████████████████████████████████████████████████████          | 874/1000 [27:56<03:44,  1.78s/it]INFO:root:global_step: 874, logpy: -3706.639, kl: 186.145, loss: 3892.601\n",
      " 88%|█████████████████████████████████████████████████████████████████████▏         | 875/1000 [27:58<03:44,  1.80s/it]INFO:root:global_step: 875, logpy: -3706.389, kl: 186.047, loss: 3892.255\n",
      " 88%|█████████████████████████████████████████████████████████████████████▏         | 876/1000 [28:00<03:43,  1.81s/it]INFO:root:global_step: 876, logpy: -3706.171, kl: 186.000, loss: 3891.991\n",
      " 88%|█████████████████████████████████████████████████████████████████████▎         | 877/1000 [28:02<03:42,  1.81s/it]INFO:root:global_step: 877, logpy: -3707.779, kl: 186.069, loss: 3893.671\n",
      " 88%|█████████████████████████████████████████████████████████████████████▎         | 878/1000 [28:04<03:39,  1.80s/it]INFO:root:global_step: 878, logpy: -3708.153, kl: 185.866, loss: 3893.843\n",
      " 88%|█████████████████████████████████████████████████████████████████████▍         | 879/1000 [28:05<03:37,  1.79s/it]INFO:root:global_step: 879, logpy: -3707.371, kl: 185.905, loss: 3893.102\n",
      " 88%|█████████████████████████████████████████████████████████████████████▌         | 880/1000 [28:07<03:37,  1.81s/it]INFO:root:global_step: 880, logpy: -3706.036, kl: 185.849, loss: 3891.713\n",
      " 88%|█████████████████████████████████████████████████████████████████████▌         | 881/1000 [28:09<03:36,  1.82s/it]INFO:root:global_step: 881, logpy: -3707.973, kl: 186.001, loss: 3893.803\n",
      " 88%|█████████████████████████████████████████████████████████████████████▋         | 882/1000 [28:11<03:33,  1.81s/it]INFO:root:global_step: 882, logpy: -3708.236, kl: 186.076, loss: 3894.144\n",
      " 88%|█████████████████████████████████████████████████████████████████████▊         | 883/1000 [28:13<03:28,  1.79s/it]INFO:root:global_step: 883, logpy: -3708.377, kl: 185.985, loss: 3894.194\n",
      " 88%|█████████████████████████████████████████████████████████████████████▊         | 884/1000 [28:14<03:26,  1.78s/it]INFO:root:global_step: 884, logpy: -3708.593, kl: 185.866, loss: 3894.294\n",
      " 88%|█████████████████████████████████████████████████████████████████████▉         | 885/1000 [28:16<03:26,  1.79s/it]INFO:root:global_step: 885, logpy: -3706.714, kl: 185.915, loss: 3892.466\n",
      " 89%|█████████████████████████████████████████████████████████████████████▉         | 886/1000 [28:18<03:25,  1.80s/it]INFO:root:global_step: 886, logpy: -3706.976, kl: 185.912, loss: 3892.726\n",
      " 89%|██████████████████████████████████████████████████████████████████████         | 887/1000 [28:20<03:25,  1.82s/it]INFO:root:global_step: 887, logpy: -3705.638, kl: 185.848, loss: 3891.325\n",
      " 89%|██████████████████████████████████████████████████████████████████████▏        | 888/1000 [28:22<03:22,  1.81s/it]INFO:root:global_step: 888, logpy: -3705.305, kl: 185.798, loss: 3890.944\n",
      " 89%|██████████████████████████████████████████████████████████████████████▏        | 889/1000 [28:23<03:20,  1.80s/it]INFO:root:global_step: 889, logpy: -3703.417, kl: 185.600, loss: 3888.859\n",
      " 89%|██████████████████████████████████████████████████████████████████████▎        | 890/1000 [28:25<03:17,  1.80s/it]INFO:root:global_step: 890, logpy: -3703.676, kl: 185.661, loss: 3889.181\n",
      " 89%|██████████████████████████████████████████████████████████████████████▍        | 891/1000 [28:27<03:15,  1.80s/it]INFO:root:global_step: 891, logpy: -3703.523, kl: 185.718, loss: 3889.087\n",
      " 89%|██████████████████████████████████████████████████████████████████████▍        | 892/1000 [28:29<03:13,  1.79s/it]INFO:root:global_step: 892, logpy: -3701.135, kl: 185.643, loss: 3886.625\n",
      " 89%|██████████████████████████████████████████████████████████████████████▌        | 893/1000 [28:31<03:13,  1.81s/it]INFO:root:global_step: 893, logpy: -3701.819, kl: 185.615, loss: 3887.283\n",
      " 89%|██████████████████████████████████████████████████████████████████████▋        | 894/1000 [28:32<03:12,  1.82s/it]INFO:root:global_step: 894, logpy: -3700.971, kl: 185.573, loss: 3886.394\n",
      " 90%|██████████████████████████████████████████████████████████████████████▋        | 895/1000 [28:34<03:11,  1.82s/it]INFO:root:global_step: 895, logpy: -3699.046, kl: 185.574, loss: 3884.472\n",
      " 90%|██████████████████████████████████████████████████████████████████████▊        | 896/1000 [28:36<03:07,  1.81s/it]INFO:root:global_step: 896, logpy: -3698.519, kl: 185.547, loss: 3883.919\n",
      " 90%|██████████████████████████████████████████████████████████████████████▊        | 897/1000 [28:38<03:05,  1.81s/it]INFO:root:global_step: 897, logpy: -3699.948, kl: 185.635, loss: 3885.438\n",
      " 90%|██████████████████████████████████████████████████████████████████████▉        | 898/1000 [28:40<03:03,  1.80s/it]INFO:root:global_step: 898, logpy: -3699.624, kl: 185.587, loss: 3885.067\n",
      " 90%|███████████████████████████████████████████████████████████████████████        | 899/1000 [28:41<03:02,  1.80s/it]INFO:root:global_step: 899, logpy: -3699.863, kl: 185.446, loss: 3885.167\n",
      " 90%|███████████████████████████████████████████████████████████████████████        | 900/1000 [28:43<02:59,  1.79s/it]INFO:root:Saved figure at: ./sim/global_step_900.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 900, logpy: -3700.457, kl: 185.402, loss: 3885.718\n",
      " 90%|███████████████████████████████████████████████████████████████████████▏       | 901/1000 [28:52<06:10,  3.75s/it]INFO:root:global_step: 901, logpy: -3698.388, kl: 185.065, loss: 3883.313\n",
      " 90%|███████████████████████████████████████████████████████████████████████▎       | 902/1000 [28:53<05:08,  3.15s/it]INFO:root:global_step: 902, logpy: -3699.237, kl: 185.061, loss: 3884.160\n",
      " 90%|███████████████████████████████████████████████████████████████████████▎       | 903/1000 [28:55<04:24,  2.73s/it]INFO:root:global_step: 903, logpy: -3700.082, kl: 185.040, loss: 3884.985\n",
      " 90%|███████████████████████████████████████████████████████████████████████▍       | 904/1000 [28:57<03:56,  2.46s/it]INFO:root:global_step: 904, logpy: -3700.798, kl: 185.020, loss: 3885.683\n",
      " 90%|███████████████████████████████████████████████████████████████████████▍       | 905/1000 [28:59<03:35,  2.27s/it]INFO:root:global_step: 905, logpy: -3699.347, kl: 184.904, loss: 3884.117\n",
      " 91%|███████████████████████████████████████████████████████████████████████▌       | 906/1000 [29:01<03:23,  2.16s/it]INFO:root:global_step: 906, logpy: -3698.522, kl: 185.005, loss: 3883.395\n",
      " 91%|███████████████████████████████████████████████████████████████████████▋       | 907/1000 [29:02<03:08,  2.03s/it]INFO:root:global_step: 907, logpy: -3699.837, kl: 185.007, loss: 3884.713\n",
      " 91%|███████████████████████████████████████████████████████████████████████▋       | 908/1000 [29:04<03:00,  1.96s/it]INFO:root:global_step: 908, logpy: -3698.948, kl: 185.052, loss: 3883.870\n",
      " 91%|███████████████████████████████████████████████████████████████████████▊       | 909/1000 [29:06<02:54,  1.92s/it]INFO:root:global_step: 909, logpy: -3700.952, kl: 184.934, loss: 3885.758\n",
      " 91%|███████████████████████████████████████████████████████████████████████▉       | 910/1000 [29:08<02:47,  1.86s/it]INFO:root:global_step: 910, logpy: -3699.902, kl: 184.858, loss: 3884.632\n",
      " 91%|███████████████████████████████████████████████████████████████████████▉       | 911/1000 [29:10<02:45,  1.86s/it]INFO:root:global_step: 911, logpy: -3702.363, kl: 185.002, loss: 3887.239\n",
      " 91%|████████████████████████████████████████████████████████████████████████       | 912/1000 [29:11<02:40,  1.82s/it]INFO:root:global_step: 912, logpy: -3703.191, kl: 184.941, loss: 3888.007\n",
      " 91%|████████████████████████████████████████████████████████████████████████▏      | 913/1000 [29:13<02:39,  1.83s/it]INFO:root:global_step: 913, logpy: -3703.453, kl: 185.116, loss: 3888.445\n",
      " 91%|████████████████████████████████████████████████████████████████████████▏      | 914/1000 [29:15<02:35,  1.81s/it]INFO:root:global_step: 914, logpy: -3704.316, kl: 185.269, loss: 3889.462\n",
      " 92%|████████████████████████████████████████████████████████████████████████▎      | 915/1000 [29:17<02:34,  1.81s/it]INFO:root:global_step: 915, logpy: -3703.865, kl: 185.385, loss: 3889.128\n",
      " 92%|████████████████████████████████████████████████████████████████████████▎      | 916/1000 [29:18<02:30,  1.79s/it]INFO:root:global_step: 916, logpy: -3703.157, kl: 185.495, loss: 3888.532\n",
      " 92%|████████████████████████████████████████████████████████████████████████▍      | 917/1000 [29:20<02:28,  1.79s/it]INFO:root:global_step: 917, logpy: -3702.125, kl: 185.637, loss: 3887.644\n",
      " 92%|████████████████████████████████████████████████████████████████████████▌      | 918/1000 [29:22<02:27,  1.80s/it]INFO:root:global_step: 918, logpy: -3702.652, kl: 185.733, loss: 3888.267\n",
      " 92%|████████████████████████████████████████████████████████████████████████▌      | 919/1000 [29:24<02:26,  1.81s/it]INFO:root:global_step: 919, logpy: -3703.460, kl: 185.963, loss: 3889.306\n",
      " 92%|████████████████████████████████████████████████████████████████████████▋      | 920/1000 [29:26<02:23,  1.80s/it]INFO:root:global_step: 920, logpy: -3702.994, kl: 186.073, loss: 3888.952\n",
      " 92%|████████████████████████████████████████████████████████████████████████▊      | 921/1000 [29:27<02:20,  1.78s/it]INFO:root:global_step: 921, logpy: -3702.272, kl: 185.973, loss: 3888.130\n",
      " 92%|████████████████████████████████████████████████████████████████████████▊      | 922/1000 [29:29<02:18,  1.78s/it]INFO:root:global_step: 922, logpy: -3701.186, kl: 185.829, loss: 3886.902\n",
      " 92%|████████████████████████████████████████████████████████████████████████▉      | 923/1000 [29:31<02:17,  1.78s/it]INFO:root:global_step: 923, logpy: -3700.866, kl: 185.768, loss: 3886.522\n",
      " 92%|████████████████████████████████████████████████████████████████████████▉      | 924/1000 [29:33<02:15,  1.78s/it]INFO:root:global_step: 924, logpy: -3700.945, kl: 185.699, loss: 3886.534\n",
      " 92%|█████████████████████████████████████████████████████████████████████████      | 925/1000 [29:35<02:15,  1.81s/it]INFO:root:global_step: 925, logpy: -3699.685, kl: 185.539, loss: 3885.115\n",
      " 93%|█████████████████████████████████████████████████████████████████████████▏     | 926/1000 [29:36<02:13,  1.81s/it]INFO:root:global_step: 926, logpy: -3698.831, kl: 185.640, loss: 3884.362\n",
      " 93%|█████████████████████████████████████████████████████████████████████████▏     | 927/1000 [29:38<02:13,  1.82s/it]INFO:root:global_step: 927, logpy: -3697.443, kl: 185.721, loss: 3883.057\n",
      " 93%|█████████████████████████████████████████████████████████████████████████▎     | 928/1000 [29:40<02:09,  1.80s/it]INFO:root:global_step: 928, logpy: -3698.881, kl: 185.835, loss: 3884.609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████████████████████████████████████████████████████████████████████▍     | 929/1000 [29:42<02:09,  1.82s/it]INFO:root:global_step: 929, logpy: -3699.945, kl: 185.767, loss: 3885.607\n",
      " 93%|█████████████████████████████████████████████████████████████████████████▍     | 930/1000 [29:44<02:07,  1.82s/it]INFO:root:global_step: 930, logpy: -3703.438, kl: 185.758, loss: 3889.091\n",
      " 93%|█████████████████████████████████████████████████████████████████████████▌     | 931/1000 [29:46<02:06,  1.83s/it]INFO:root:global_step: 931, logpy: -3703.799, kl: 185.591, loss: 3889.287\n",
      " 93%|█████████████████████████████████████████████████████████████████████████▋     | 932/1000 [29:47<02:03,  1.82s/it]INFO:root:global_step: 932, logpy: -3702.323, kl: 185.537, loss: 3887.758\n",
      " 93%|█████████████████████████████████████████████████████████████████████████▋     | 933/1000 [29:49<01:59,  1.78s/it]INFO:root:global_step: 933, logpy: -3702.981, kl: 185.538, loss: 3888.418\n",
      " 93%|█████████████████████████████████████████████████████████████████████████▊     | 934/1000 [29:51<01:57,  1.77s/it]INFO:root:global_step: 934, logpy: -3702.209, kl: 185.383, loss: 3887.492\n",
      " 94%|█████████████████████████████████████████████████████████████████████████▊     | 935/1000 [29:53<01:55,  1.78s/it]INFO:root:global_step: 935, logpy: -3701.968, kl: 185.206, loss: 3887.075\n",
      " 94%|█████████████████████████████████████████████████████████████████████████▉     | 936/1000 [29:55<01:56,  1.81s/it]INFO:root:global_step: 936, logpy: -3702.559, kl: 185.302, loss: 3887.763\n",
      " 94%|██████████████████████████████████████████████████████████████████████████     | 937/1000 [29:56<01:52,  1.79s/it]INFO:root:global_step: 937, logpy: -3703.009, kl: 185.305, loss: 3888.217\n",
      " 94%|██████████████████████████████████████████████████████████████████████████     | 938/1000 [29:58<01:49,  1.77s/it]INFO:root:global_step: 938, logpy: -3704.804, kl: 185.543, loss: 3890.251\n",
      " 94%|██████████████████████████████████████████████████████████████████████████▏    | 939/1000 [30:00<01:48,  1.77s/it]INFO:root:global_step: 939, logpy: -3703.814, kl: 185.510, loss: 3889.228\n",
      " 94%|██████████████████████████████████████████████████████████████████████████▎    | 940/1000 [30:02<01:46,  1.77s/it]INFO:root:global_step: 940, logpy: -3702.556, kl: 185.488, loss: 3887.950\n",
      " 94%|██████████████████████████████████████████████████████████████████████████▎    | 941/1000 [30:03<01:44,  1.78s/it]INFO:root:global_step: 941, logpy: -3700.582, kl: 185.374, loss: 3885.863\n",
      " 94%|██████████████████████████████████████████████████████████████████████████▍    | 942/1000 [30:05<01:43,  1.79s/it]INFO:root:global_step: 942, logpy: -3701.704, kl: 185.647, loss: 3887.259\n",
      " 94%|██████████████████████████████████████████████████████████████████████████▍    | 943/1000 [30:07<01:41,  1.77s/it]INFO:root:global_step: 943, logpy: -3701.680, kl: 185.503, loss: 3887.091\n",
      " 94%|██████████████████████████████████████████████████████████████████████████▌    | 944/1000 [30:09<01:39,  1.77s/it]INFO:root:global_step: 944, logpy: -3702.366, kl: 185.571, loss: 3887.847\n",
      " 94%|██████████████████████████████████████████████████████████████████████████▋    | 945/1000 [30:10<01:38,  1.79s/it]INFO:root:global_step: 945, logpy: -3701.925, kl: 185.596, loss: 3887.431\n",
      " 95%|██████████████████████████████████████████████████████████████████████████▋    | 946/1000 [30:12<01:37,  1.80s/it]INFO:root:global_step: 946, logpy: -3701.954, kl: 185.551, loss: 3887.415\n",
      " 95%|██████████████████████████████████████████████████████████████████████████▊    | 947/1000 [30:14<01:34,  1.78s/it]INFO:root:global_step: 947, logpy: -3701.266, kl: 185.500, loss: 3886.678\n",
      " 95%|██████████████████████████████████████████████████████████████████████████▉    | 948/1000 [30:16<01:34,  1.82s/it]INFO:root:global_step: 948, logpy: -3700.195, kl: 185.479, loss: 3885.587\n",
      " 95%|██████████████████████████████████████████████████████████████████████████▉    | 949/1000 [30:18<01:32,  1.82s/it]INFO:root:global_step: 949, logpy: -3699.197, kl: 185.492, loss: 3884.602\n",
      " 95%|███████████████████████████████████████████████████████████████████████████    | 950/1000 [30:20<01:30,  1.80s/it]INFO:root:Saved figure at: ./sim/global_step_950.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 950, logpy: -3698.445, kl: 185.715, loss: 3884.074\n",
      " 95%|███████████████████████████████████████████████████████████████████████████▏   | 951/1000 [30:28<03:06,  3.80s/it]INFO:root:global_step: 951, logpy: -3700.075, kl: 185.762, loss: 3885.753\n",
      " 95%|███████████████████████████████████████████████████████████████████████████▏   | 952/1000 [30:30<02:33,  3.19s/it]INFO:root:global_step: 952, logpy: -3698.030, kl: 185.691, loss: 3883.638\n",
      " 95%|███████████████████████████████████████████████████████████████████████████▎   | 953/1000 [30:32<02:11,  2.80s/it]INFO:root:global_step: 953, logpy: -3699.388, kl: 185.683, loss: 3884.988\n",
      " 95%|███████████████████████████████████████████████████████████████████████████▎   | 954/1000 [30:33<01:55,  2.50s/it]INFO:root:global_step: 954, logpy: -3698.319, kl: 185.741, loss: 3883.978\n",
      " 96%|███████████████████████████████████████████████████████████████████████████▍   | 955/1000 [30:35<01:43,  2.31s/it]INFO:root:global_step: 955, logpy: -3698.461, kl: 185.758, loss: 3884.137\n",
      " 96%|███████████████████████████████████████████████████████████████████████████▌   | 956/1000 [30:37<01:34,  2.14s/it]INFO:root:global_step: 956, logpy: -3698.378, kl: 185.807, loss: 3884.105\n",
      " 96%|███████████████████████████████████████████████████████████████████████████▌   | 957/1000 [30:39<01:28,  2.05s/it]INFO:root:global_step: 957, logpy: -3699.505, kl: 185.879, loss: 3885.304\n",
      " 96%|███████████████████████████████████████████████████████████████████████████▋   | 958/1000 [30:41<01:23,  1.99s/it]INFO:root:global_step: 958, logpy: -3699.376, kl: 185.864, loss: 3885.161\n",
      " 96%|███████████████████████████████████████████████████████████████████████████▊   | 959/1000 [30:43<01:19,  1.95s/it]INFO:root:global_step: 959, logpy: -3697.235, kl: 185.756, loss: 3882.913\n",
      " 96%|███████████████████████████████████████████████████████████████████████████▊   | 960/1000 [30:44<01:15,  1.89s/it]INFO:root:global_step: 960, logpy: -3699.173, kl: 185.893, loss: 3884.990\n",
      " 96%|███████████████████████████████████████████████████████████████████████████▉   | 961/1000 [30:46<01:11,  1.84s/it]INFO:root:global_step: 961, logpy: -3697.183, kl: 185.715, loss: 3882.821\n",
      " 96%|███████████████████████████████████████████████████████████████████████████▉   | 962/1000 [30:48<01:09,  1.84s/it]INFO:root:global_step: 962, logpy: -3697.507, kl: 185.666, loss: 3883.097\n",
      " 96%|████████████████████████████████████████████████████████████████████████████   | 963/1000 [30:50<01:07,  1.82s/it]INFO:root:global_step: 963, logpy: -3696.747, kl: 185.487, loss: 3882.160\n",
      " 96%|████████████████████████████████████████████████████████████████████████████▏  | 964/1000 [30:51<01:04,  1.80s/it]INFO:root:global_step: 964, logpy: -3697.488, kl: 185.462, loss: 3882.876\n",
      " 96%|████████████████████████████████████████████████████████████████████████████▏  | 965/1000 [30:53<01:02,  1.78s/it]INFO:root:global_step: 965, logpy: -3695.948, kl: 185.448, loss: 3881.322\n",
      " 97%|████████████████████████████████████████████████████████████████████████████▎  | 966/1000 [30:55<01:00,  1.77s/it]INFO:root:global_step: 966, logpy: -3695.812, kl: 185.455, loss: 3881.195\n",
      " 97%|████████████████████████████████████████████████████████████████████████████▍  | 967/1000 [30:57<00:58,  1.77s/it]INFO:root:global_step: 967, logpy: -3697.803, kl: 185.548, loss: 3883.279\n",
      " 97%|████████████████████████████████████████████████████████████████████████████▍  | 968/1000 [30:59<00:57,  1.79s/it]INFO:root:global_step: 968, logpy: -3697.801, kl: 185.554, loss: 3883.284\n",
      " 97%|████████████████████████████████████████████████████████████████████████████▌  | 969/1000 [31:00<00:55,  1.79s/it]INFO:root:global_step: 969, logpy: -3698.030, kl: 185.722, loss: 3883.682\n",
      " 97%|████████████████████████████████████████████████████████████████████████████▋  | 970/1000 [31:02<00:53,  1.79s/it]INFO:root:global_step: 970, logpy: -3698.434, kl: 185.753, loss: 3884.117\n",
      " 97%|████████████████████████████████████████████████████████████████████████████▋  | 971/1000 [31:04<00:51,  1.77s/it]INFO:root:global_step: 971, logpy: -3697.599, kl: 185.834, loss: 3883.364\n",
      " 97%|████████████████████████████████████████████████████████████████████████████▊  | 972/1000 [31:06<00:50,  1.80s/it]INFO:root:global_step: 972, logpy: -3696.450, kl: 185.704, loss: 3882.086\n",
      " 97%|████████████████████████████████████████████████████████████████████████████▊  | 973/1000 [31:07<00:48,  1.80s/it]INFO:root:global_step: 973, logpy: -3696.576, kl: 185.676, loss: 3882.184\n",
      " 97%|████████████████████████████████████████████████████████████████████████████▉  | 974/1000 [31:09<00:47,  1.82s/it]INFO:root:global_step: 974, logpy: -3697.628, kl: 185.779, loss: 3883.340\n",
      " 98%|█████████████████████████████████████████████████████████████████████████████  | 975/1000 [31:11<00:45,  1.80s/it]INFO:root:global_step: 975, logpy: -3695.456, kl: 185.558, loss: 3880.947\n",
      " 98%|█████████████████████████████████████████████████████████████████████████████  | 976/1000 [31:13<00:42,  1.79s/it]INFO:root:global_step: 976, logpy: -3695.555, kl: 185.571, loss: 3881.060\n",
      " 98%|█████████████████████████████████████████████████████████████████████████████▏ | 977/1000 [31:15<00:41,  1.80s/it]INFO:root:global_step: 977, logpy: -3694.602, kl: 185.485, loss: 3880.022\n",
      " 98%|█████████████████████████████████████████████████████████████████████████████▎ | 978/1000 [31:17<00:39,  1.81s/it]INFO:root:global_step: 978, logpy: -3695.273, kl: 185.683, loss: 3880.892\n",
      " 98%|█████████████████████████████████████████████████████████████████████████████▎ | 979/1000 [31:18<00:38,  1.82s/it]INFO:root:global_step: 979, logpy: -3693.143, kl: 185.694, loss: 3878.773\n",
      " 98%|█████████████████████████████████████████████████████████████████████████████▍ | 980/1000 [31:20<00:35,  1.79s/it]INFO:root:global_step: 980, logpy: -3693.842, kl: 185.781, loss: 3879.560\n",
      " 98%|█████████████████████████████████████████████████████████████████████████████▍ | 981/1000 [31:22<00:34,  1.79s/it]INFO:root:global_step: 981, logpy: -3694.314, kl: 185.712, loss: 3879.963\n",
      " 98%|█████████████████████████████████████████████████████████████████████████████▌ | 982/1000 [31:24<00:32,  1.78s/it]INFO:root:global_step: 982, logpy: -3694.313, kl: 185.763, loss: 3880.014\n",
      " 98%|█████████████████████████████████████████████████████████████████████████████▋ | 983/1000 [31:25<00:30,  1.78s/it]INFO:root:global_step: 983, logpy: -3696.250, kl: 185.811, loss: 3882.000\n",
      " 98%|█████████████████████████████████████████████████████████████████████████████▋ | 984/1000 [31:27<00:28,  1.79s/it]INFO:root:global_step: 984, logpy: -3695.785, kl: 185.813, loss: 3881.537\n",
      " 98%|█████████████████████████████████████████████████████████████████████████████▊ | 985/1000 [31:29<00:26,  1.77s/it]INFO:root:global_step: 985, logpy: -3695.573, kl: 185.524, loss: 3881.037\n",
      " 99%|█████████████████████████████████████████████████████████████████████████████▉ | 986/1000 [31:31<00:25,  1.81s/it]INFO:root:global_step: 986, logpy: -3696.641, kl: 185.578, loss: 3882.160\n",
      " 99%|█████████████████████████████████████████████████████████████████████████████▉ | 987/1000 [31:33<00:23,  1.82s/it]INFO:root:global_step: 987, logpy: -3696.436, kl: 185.460, loss: 3881.837\n",
      " 99%|██████████████████████████████████████████████████████████████████████████████ | 988/1000 [31:34<00:21,  1.81s/it]INFO:root:global_step: 988, logpy: -3696.742, kl: 185.476, loss: 3882.160\n",
      " 99%|██████████████████████████████████████████████████████████████████████████████▏| 989/1000 [31:36<00:19,  1.81s/it]INFO:root:global_step: 989, logpy: -3695.670, kl: 185.511, loss: 3881.123\n",
      " 99%|██████████████████████████████████████████████████████████████████████████████▏| 990/1000 [31:38<00:17,  1.80s/it]INFO:root:global_step: 990, logpy: -3694.330, kl: 185.437, loss: 3879.710\n",
      " 99%|██████████████████████████████████████████████████████████████████████████████▎| 991/1000 [31:40<00:16,  1.80s/it]INFO:root:global_step: 991, logpy: -3695.496, kl: 185.501, loss: 3880.940\n",
      " 99%|██████████████████████████████████████████████████████████████████████████████▎| 992/1000 [31:42<00:14,  1.80s/it]INFO:root:global_step: 992, logpy: -3696.303, kl: 185.584, loss: 3881.831\n",
      " 99%|██████████████████████████████████████████████████████████████████████████████▍| 993/1000 [31:43<00:12,  1.79s/it]INFO:root:global_step: 993, logpy: -3696.816, kl: 185.457, loss: 3882.218\n",
      " 99%|██████████████████████████████████████████████████████████████████████████████▌| 994/1000 [31:45<00:10,  1.80s/it]INFO:root:global_step: 994, logpy: -3697.317, kl: 185.374, loss: 3882.636\n",
      "100%|██████████████████████████████████████████████████████████████████████████████▌| 995/1000 [31:47<00:08,  1.79s/it]INFO:root:global_step: 995, logpy: -3697.630, kl: 185.400, loss: 3882.976\n",
      "100%|██████████████████████████████████████████████████████████████████████████████▋| 996/1000 [31:49<00:07,  1.78s/it]INFO:root:global_step: 996, logpy: -3698.174, kl: 185.460, loss: 3883.580\n",
      "100%|██████████████████████████████████████████████████████████████████████████████▊| 997/1000 [31:51<00:05,  1.79s/it]INFO:root:global_step: 997, logpy: -3700.063, kl: 185.429, loss: 3885.439\n",
      "100%|██████████████████████████████████████████████████████████████████████████████▊| 998/1000 [31:52<00:03,  1.80s/it]INFO:root:global_step: 998, logpy: -3699.864, kl: 185.377, loss: 3885.188\n",
      "100%|██████████████████████████████████████████████████████████████████████████████▉| 999/1000 [31:54<00:01,  1.78s/it]INFO:root:global_step: 999, logpy: -3697.764, kl: 185.296, loss: 3883.007\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [31:56<00:00,  1.92s/it]\n"
     ]
    }
   ],
   "source": [
    "manual_seed(args['seed'])\n",
    "\n",
    "if args['debug']:\n",
    "    logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "ckpt_dir = os.path.join('./sim/', 'ckpts')\n",
    "os.makedirs(ckpt_dir, exist_ok=True)\n",
    "\n",
    "sdeint_fn = torchsde.sdeint_adjoint if args['adjoint'] else torchsde.sdeint\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c356ad31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7712260f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
