{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4dd7b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from collections import namedtuple\n",
    "from typing import Optional, Union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import tqdm\n",
    "from torch import distributions, nn, optim\n",
    "\n",
    "import torchsde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0aeebbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the gpu is available or not, if yes, use gpu\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2902c1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the tuple for data, \n",
    "Data = namedtuple('Data', ['ts_', 'ts_ext_', 'ts_vis_', 'ts', 'ts_ext', 'ts_vis', 'ys', 'ys_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9198a09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"train_iters\": 1000,\n",
    "    \"pause_iters\": 50,\n",
    "    \"hide_ticks\": False,\n",
    "    \"save_ckpt\":True,\n",
    "    \"likelihood\":\"laplace\",\n",
    "    \"scale\": 0.001,\n",
    "    \"adjoint\": True,\n",
    "    \"debug\": True,\n",
    "    \"seed\": 42,\n",
    "    'data':'segmented_cosine',\n",
    "    \"dt\": 1e-2,\n",
    "    \"batch_size\": 256,\n",
    "    \"method\": 'euler',\n",
    "    \"adaptive\": 'False',\n",
    "    \"rtol\": 1e-3,\n",
    "    \"atol\": 1e-3\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40420fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output values from 0 to maxval with iters steps\n",
    "class LinearScheduler(object):\n",
    "    def __init__(self, iters, maxval=1.0):\n",
    "        self._iters = max(1,iters)\n",
    "        self._val = maxval/self._iters\n",
    "        self._maxval = maxval\n",
    "    \n",
    "    def step(self):\n",
    "        self._val = min(self._maxval, self._val+self._maxval/self._iters)\n",
    "        \n",
    "    @property\n",
    "    def val(self):\n",
    "        return self._val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93c09c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EMAMetric(object):\n",
    "    def __init__(self, gamma: Optional[float]=0.99):\n",
    "        super(EMAMetric, self).__init__()\n",
    "        self._val=0\n",
    "        self._gamma = gamma\n",
    "    def step(self, x:Union[torch.Tensor, np.ndarray]):\n",
    "        x = x.detach().cpu().numpy() if torch.is_tensor(x) else x\n",
    "        self._val = self._gamma * self._val + (1-self._gamma)*x\n",
    "        return self._val\n",
    "    \n",
    "    @property\n",
    "    def val(self):\n",
    "        return self._val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a4ec86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the seed\n",
    "def manual_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98a2f4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure that the dvision is stable\n",
    "def _stable_division(a,b,epsilon=1e-7):\n",
    "    b = torch.where(b.abs().detach() > epsilon, b, torch.full_like(b, fill_value=epsilon)*b.sign())\n",
    "    return a/b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "522d3e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LatentSDE(torchsde.SDEIto): # sde with ito calculus\n",
    "    def __init__(self, theta=1.0, mu=0.0, sigma=0.01):\n",
    "        super(LatentSDE, self).__init__(noise_type=\"diagonal\")\n",
    "        logvar = math.log(sigma ** 2/(2.*theta))\n",
    "        \n",
    "        # prior drift\n",
    "        self.register_buffer(\"theta\",torch.tensor([[theta]])) # prior parameters, register 成buffer, 参数不会进行更新\n",
    "        self.register_buffer(\"mu\", torch.tensor([[mu]]))\n",
    "        self.register_buffer(\"sigma\",torch.tensor([[sigma]]))\n",
    "        \n",
    "        # p(y0)\n",
    "        self.register_buffer(\"py0_mean\", torch.tensor([[mu]]))\n",
    "        self.register_buffer(\"py0_logvar\", torch.tensor([[logvar]]))\n",
    "        \n",
    "        # approximate posterior drift: Takes in 2 positional encodings and the state\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(3,200),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(200,200),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(200,1)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        # Initialization the parameters\n",
    "        self.net[-1].weight.data.fill_(0.) # 初始化最后一层的参数\n",
    "        self.net[-1].bias.data.fill_(0.)\n",
    "            \n",
    "        # q(y0)\n",
    "        self.qy0_mean = nn.Parameter(torch.tensor([[mu]]), requires_grad=True) # 创建parameters\n",
    "        self.qy0_logvar = nn.Parameter(torch.tensor([[logvar]]), requires_grad=True) # 创建parameters\n",
    "        #self.theta = nn.Parameter(torch.tensor([[theta]]),requires_grad=True)\n",
    "        #self.sigma = nn.Parameter(torch.tensor([[sigma]]),requires_grad=True)\n",
    "        \n",
    "        #self.theta = nn.Parameter(torch.tensor([[theta]]),requires_grad=True)\n",
    "            \n",
    "    def f(self, t, y):  # Approximate posterior drift.\n",
    "        if t.dim() == 0:\n",
    "            t = torch.full_like(y, fill_value=t) # create a tensor of t\n",
    "        # Positional encoding in transformers for time-inhomogeneous posterior.\n",
    "        return self.net(torch.cat((torch.sin(t), torch.cos(t), y), dim=-1))\n",
    "\n",
    "    def g(self, t, y):  # Shared diffusion.\n",
    "        return self.sigma.repeat(y.size(0), 1) # 重复复制, 创建一个size为[y.size[0],1]\n",
    "\n",
    "    def h(self, t, y):  # Prior drift.\n",
    "        return self.theta * (self.mu - y)\n",
    "\n",
    "    def f_aug(self, t, y):  # Drift for augmented dynamics with logqp term.\n",
    "        y = y[:, 0:1] # 提取第一列，保持列的形态\n",
    "        f, g, h = self.f(t, y), self.g(t, y), self.h(t, y)\n",
    "        u = _stable_division(f - h, g) # 计算u(z,t)\n",
    "        f_logqp = .5 * (u ** 2).sum(dim=1, keepdim=True) # 计算integral\n",
    "        return torch.cat([f, f_logqp], dim=1)\n",
    "\n",
    "    def g_aug(self, t, y):  # Diffusion for augmented dynamics with logqp term.\n",
    "        y = y[:, 0:1]\n",
    "        g = self.g(t, y)\n",
    "        g_logqp = torch.zeros_like(y)\n",
    "        return torch.cat([g, g_logqp], dim=1)\n",
    "\n",
    "    def forward(self, ts, batch_size, eps=None):\n",
    "        eps = torch.randn(batch_size, 1).to(self.qy0_std) if eps is None else eps\n",
    "        y0 = self.qy0_mean + eps * self.qy0_std # the latent variable\n",
    "        qy0 = distributions.Normal(loc=self.qy0_mean, scale=self.qy0_std) # approximate posterior distribution\n",
    "        py0 = distributions.Normal(loc=self.py0_mean, scale=self.py0_std) # prior distribution\n",
    "        logqp0 = distributions.kl_divergence(qy0, py0).sum(dim=1)  # KL(t=0). calculate the kl divergence\n",
    "        #print(y0.size()) # (256, 1)\n",
    "        aug_y0 = torch.cat([y0, torch.zeros(batch_size, 1).to(y0)], dim=1) # create the augmented initial value\n",
    "        #print(aug_y0.size()) # [256, 2]\n",
    "        aug_ys = sdeint_fn(\n",
    "            sde=self,\n",
    "            y0=aug_y0,\n",
    "            ts=ts,\n",
    "            method=args['method'],\n",
    "            dt=args['dt'],\n",
    "            adaptive=args['adaptive'],\n",
    "            rtol=args['rtol'],\n",
    "            atol=args['atol'],\n",
    "            names={'drift': 'f_aug', 'diffusion': 'g_aug'}\n",
    "        ) # call the sde solver to \n",
    "        # print(aug_ys.size()) # [22, 256, 2]\n",
    "        ys, logqp_path = aug_ys[:, :, 0:1], aug_ys[-1, :, 1] # get the integral of the u(z,t) at the last time\n",
    "        \n",
    "        logqp = (logqp0 + logqp_path).mean(dim=0)  # KL(t=0) + KL(path).\n",
    "        return ys, logqp\n",
    "\n",
    "    def sample_p(self, ts, batch_size, eps=None, bm=None):\n",
    "        eps = torch.randn(batch_size, 1).to(self.py0_mean) if eps is None else eps\n",
    "        y0 = self.py0_mean + eps * self.py0_std\n",
    "        return sdeint_fn(self, y0, ts, bm=bm, method=args['method'], dt=args['dt'], names={'drift': 'h'}) # prior sde\n",
    "\n",
    "    def sample_q(self, ts, batch_size, eps=None, bm=None):\n",
    "        eps = torch.randn(batch_size, 1).to(self.qy0_mean) if eps is None else eps\n",
    "        y0 = self.qy0_mean + eps * self.qy0_std\n",
    "        return sdeint_fn(self, y0, ts, bm=bm, method=args['method'], dt=args['dt']) # posterior sde\n",
    "\n",
    "    @property\n",
    "    def py0_std(self):\n",
    "        return torch.exp(.5 * self.py0_logvar)\n",
    "\n",
    "    @property\n",
    "    def qy0_std(self):\n",
    "        return torch.exp(.5 * self.qy0_logvar)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80736fff",
   "metadata": {},
   "source": [
    "## 5. Simulation of time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd15aaa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "T = 120\n",
    "#beta = 0.1694\n",
    "beta=1\n",
    "phi = 0.9\n",
    "sigma_v = 0.003342\n",
    "u_over_v = 1\n",
    "rho = -0.856\n",
    "mu = 0\n",
    "def make_time_series():\n",
    "    \n",
    "    \n",
    "    noise_mu = [0, 0]\n",
    "    sigma_u = u_over_v * sigma_v\n",
    "    cov_uv = rho*sigma_u*sigma_v\n",
    "    cov = [[sigma_u**2, cov_uv], [cov_uv, sigma_v**2]]\n",
    "    \n",
    "    shocks = np.random.multivariate_normal(noise_mu, cov, T) # 1st column is u; 2nd columne is v\n",
    "    z0 = np.random.normal(mu, sigma_u ** 2/(1-phi**2), 1)\n",
    "    r0 = shocks[0][0]\n",
    "\n",
    "    z = np.zeros(T)\n",
    "    r = np.zeros(T)\n",
    "    z[0] = z0\n",
    "    r[0] = r0\n",
    "\n",
    "    for idx_t in range(T-1):\n",
    "        z[idx_t+1] = phi*(z[idx_t]-mu) + shocks[idx_t+1][1] + mu\n",
    "        r[idx_t+1] = beta*z[idx_t] + shocks[idx_t+1][0]\n",
    "    return r, z\n",
    "r,z = make_time_series()\n",
    "plt.figure(figsize=(15,5))\n",
    "xvalues = np.array(range(T))\n",
    "plt.plot(xvalues, r, linestyle='-', color='g', label=\"observed $r_t$\")\n",
    "plt.plot(xvalues, z, linestyle=\"--\", color=\"r\", label=r\"hidden variable $\\beta * z_t$\", linewidth=3.0)\n",
    "\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('%')\n",
    "plt.grid(True)\n",
    "plt.title(r\"Simulated $r_t$ and hidden $\\beta * z_t$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0cf9fca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data():\n",
    "    ts_ = np.linspace(0.1,3.0,120)\n",
    "    ts_ext_ = np.array([0.] + list(ts_) + [3.1])\n",
    "    ts_vis_ = np.linspace(0.1, 3.1, 121)\n",
    "    ys_ = r[:,None]\n",
    "    ts = torch.tensor(ts_).float()\n",
    "    ts_ext = torch.tensor(ts_ext_).float()\n",
    "    ts_vis = torch.tensor(ts_vis_).float()\n",
    "    ys = torch.tensor(ys_).float().to(device)\n",
    "    return Data(ts_, ts_ext_, ts_vis_, ts, ts_ext, ts_vis, ys, ys_)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99a1fc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Dataset\n",
    "    ts_, ts_ext_, ts_vis_, ts, ts_ext, ts_vis, ys, ys_ = make_data()\n",
    "    mu = torch.mean(ys)\n",
    "    sigma = torch.std(ys)\n",
    "    # plotting parameters\n",
    "    vis_batch_size = 1024\n",
    "    ylims = (-0.03, 0.03)\n",
    "    alphas = [0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.55]\n",
    "    percentiles = [0.999, 0.99, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1]\n",
    "    vis_idx = np.random.permutation(vis_batch_size)\n",
    "    sample_colors = ('#8c96c6', '#8c6bb1', '#810f7c')\n",
    "    fill_color = '#9ebcda'\n",
    "    mean_color = '#4d004b'\n",
    "    num_samples = len(sample_colors)\n",
    "    \n",
    "    eps = torch.randn(vis_batch_size, 1).to(device)\n",
    "    bm = torchsde.BrownianInterval(\n",
    "        t0=ts_vis[0],\n",
    "        t1=ts_vis[-1],\n",
    "        size=(vis_batch_size,1),\n",
    "        device=device,\n",
    "        levy_area_approximation=\"space-time\")\n",
    "    \n",
    "    # Model\n",
    "    model = LatentSDE(mu=mu,sigma=sigma).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\n",
    "    kl_scheduler = LinearScheduler(iters=500)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    logpy_metric = EMAMetric()\n",
    "    kl_metric = EMAMetric()\n",
    "    loss_metric = EMAMetric()\n",
    "    \n",
    "    \n",
    "    # show prior\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        zs = model.sample_p(ts=ts_vis, batch_size = vis_batch_size, eps = eps, bm=bm).squeeze()\n",
    "       \n",
    "        ts_vis_, zs_ = ts_vis.cpu().numpy(), zs.cpu().numpy()\n",
    "        #plt.scatter(ts_vis_, ys_, color='r', label=\"prior\")\n",
    "        zs_ = np.sort(zs_,axis=1)\n",
    "        img_dir = os.path.join('./img_generation/','prior.png')\n",
    "        plt.subplot(frameon=False)\n",
    "        for alpha, percentile in zip(alphas, percentiles):\n",
    "            idx = int((1 - percentile) / 2. * vis_batch_size)\n",
    "            zs_bot_ = zs_[:, idx]\n",
    "            zs_top_ = zs_[:, -idx]\n",
    "            plt.fill_between(ts_vis_, zs_bot_, zs_top_, alpha=alpha, color=fill_color)\n",
    "\n",
    "        # `zorder` determines who's on top; the larger the more at the top.\n",
    "        \n",
    "        plt.scatter(ts_, ys_, marker='x', zorder=3, color='k', s=35)  # Data.\n",
    "        plt.plot(ts_, ys_, marker='x', zorder=3, color='k',label=\"observed $r_t$\")\n",
    "        plt.plot(ts_, z[:,None], color='g', linewidth=3.0, label=r\"hidden variable $z_t$\")\n",
    "        plt.ylim(ylims)\n",
    "        plt.xlabel('$t$')\n",
    "        plt.ylabel('$Y_t$')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.legend()\n",
    "        plt.savefig(img_dir, dpi=300)\n",
    "        plt.close()\n",
    "        logging.info(f'Saved prior figure at: {img_dir}')\n",
    "    \n",
    "    \n",
    "    for global_step in tqdm.tqdm(range(args['train_iters'])):\n",
    "        \n",
    "        # Plot and save.\n",
    "        if global_step % args['pause_iters'] == 0:\n",
    "            img_path = os.path.join(\"./img_generation/\", f'global_step_{global_step}.png')\n",
    "\n",
    "            with torch.no_grad():\n",
    "                zs = model.sample_q(ts=ts_vis, batch_size=vis_batch_size, eps=eps, bm=bm).squeeze()\n",
    "                samples = zs[:, vis_idx]\n",
    "                ts_vis_, zs_, samples_ = ts_vis.cpu().numpy(), zs.cpu().numpy(), samples.cpu().numpy()\n",
    "                zs_ = np.sort(zs_, axis=1)\n",
    "                plt.subplot(frameon=False)\n",
    "\n",
    "                if True: # args.show_percentiles:\n",
    "                    for alpha, percentile in zip(alphas, percentiles):\n",
    "                        idx = int((1 - percentile) / 2. * vis_batch_size)\n",
    "                        zs_bot_, zs_top_ = zs_[:, idx], zs_[:, -idx]\n",
    "                        plt.fill_between(ts_vis_, zs_bot_, zs_top_, alpha=alpha, color=fill_color)\n",
    "\n",
    "                if False: #args.show_mean:\n",
    "                    plt.plot(ts_vis_, zs_.mean(axis=1), color=mean_color)\n",
    "\n",
    "                if True: #args.show_samples:\n",
    "                    #for j in range(num_samples):\n",
    "                    #    plt.plot(ts_vis_, samples_[:, j], color=sample_colors[j], linewidth=1.0)\n",
    "                    # plt.plot(ts_, z[:,None], color='g', linewidth=3.0, label=r\"hidden variable $z_t$\")\n",
    "                    plt.plot(ts_vis_, samples_.mean(axis=1), marker='o', color='r',label=r'mean of latent variables')\n",
    "\n",
    "                if True: #args.show_arrows:\n",
    "                    num, dt = 3, 0.12\n",
    "                    t, y = torch.meshgrid(\n",
    "                        [torch.linspace(0, 3, num).to(device), torch.linspace(-0.3, 0.3, num).to(device)]\n",
    "                    )\n",
    "                    t, y = t.reshape(-1, 1), y.reshape(-1, 1)\n",
    "                    fty = model.f(t=t, y=y).reshape(num, num)\n",
    "                    dt = torch.zeros(num, num).fill_(dt).to(device)\n",
    "                    dy = fty * dt\n",
    "                    dt_, dy_, t_, y_ = dt.cpu().numpy(), dy.cpu().numpy(), t.cpu().numpy(), y.cpu().numpy()\n",
    "                    plt.quiver(t_, y_, dt_, dy_, alpha=0.3, edgecolors='k', width=0.0035, scale=50)\n",
    "\n",
    "                if False: #args.hide_ticks:\n",
    "                    plt.xticks([], [])\n",
    "                    plt.yticks([], [])\n",
    "\n",
    "                #plt.scatter(ts_, ys_, marker='x', zorder=3, color='k', s=35)  # Data.\n",
    "                plt.plot(ts_, ys_, linestyle=\"-\",color='g', zorder=3, label=\"observed $r_t$ \") # new added\n",
    "                \n",
    "                for j in range(num_samples):\n",
    "                    zs = samples[:,j:j+1]\n",
    "                    likelihood_constructor = {\"laplace\": distributions.Laplace, \"normal\": distributions.Normal}[args['likelihood']]\n",
    "                    likelihood = likelihood_constructor(loc=zs, scale=args['scale'])\n",
    "                    reconstruct = likelihood.sample()\n",
    "                    print(reconstruct.size())\n",
    "                    plt.plot(ts_vis_, reconstruct, color=sample_colors[j], linewidth=1.0,label=r'estimated observations')\n",
    "                \n",
    "\n",
    "                \n",
    "                plt.ylim(ylims)\n",
    "                plt.xlabel('$t$')\n",
    "                plt.ylabel('$Y_t$')\n",
    "                plt.tight_layout()\n",
    "                plt.legend()\n",
    "                plt.savefig(img_path, dpi=300)\n",
    "                plt.close()\n",
    "                logging.info(f'Saved figure at: {img_path}')\n",
    "\n",
    "                \n",
    "        \n",
    "        # Train.\n",
    "        optimizer.zero_grad() # zero the gradient\n",
    "        zs, kl = model(ts=ts_ext, batch_size=args['batch_size']) # pass through the model, ys, logqp\n",
    "        zs = zs.squeeze() # remove the dimensions of input of size 1\n",
    "        zs = zs[1:-1]  # Drop first and last which are only used to penalize out-of-data region and spread uncertainty.\n",
    "        likelihood_constructor = {\"laplace\": distributions.Laplace, \"normal\": distributions.Normal}[args['likelihood']]\n",
    "        likelihood = likelihood_constructor(loc=zs, scale=args['scale']) # create the laplace distribution\n",
    "        logpy = likelihood.log_prob(ys).sum(dim=0).mean(dim=0)\n",
    "        loss = -logpy + kl * kl_scheduler.val\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        kl_scheduler.step()\n",
    "\n",
    "        logpy_metric.step(logpy)\n",
    "        kl_metric.step(kl)\n",
    "        loss_metric.step(loss)\n",
    "\n",
    "        logging.info(\n",
    "            f'global_step: {global_step}, '\n",
    "            f'logpy: {logpy_metric.val:.3f}, '\n",
    "            f'kl: {kl_metric.val:.3f}, '\n",
    "            f'loss: {loss_metric.val:.3f}'\n",
    "        )\n",
    "    torch.save(\n",
    "        {'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'scheduler': scheduler.state_dict(),\n",
    "            'kl_scheduler': kl_scheduler},\n",
    "        os.path.join('./sim/', f'global_step_{global_step}.ckpt')\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "74b55c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saved prior figure at: ./img_generation/prior.png\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([121, 1])\n",
      "torch.Size([121, 1])\n",
      "torch.Size([121, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saved figure at: ./img_generation/global_step_0.png\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_core/sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 0, logpy: -18.315, kl: 0.030, loss: 18.315\n",
      "  0%|          | 1/1000 [00:02<47:56,  2.88s/it]INFO:root:global_step: 1, logpy: -585.703, kl: 22.858, loss: 585.795\n",
      "  0%|          | 2/1000 [00:04<40:47,  2.45s/it]INFO:root:global_step: 2, logpy: -1171.891, kl: 50.262, loss: 1172.147\n",
      "  0%|          | 3/1000 [00:05<35:54,  2.16s/it]INFO:root:global_step: 3, logpy: -1357.197, kl: 52.687, loss: 1357.474\n",
      "  0%|          | 4/1000 [00:07<32:24,  1.95s/it]INFO:root:global_step: 4, logpy: -1396.050, kl: 52.503, loss: 1396.328\n",
      "  0%|          | 5/1000 [00:08<30:34,  1.84s/it]INFO:root:global_step: 5, logpy: -1679.736, kl: 59.525, loss: 1680.102\n",
      "  1%|          | 6/1000 [00:10<29:10,  1.76s/it]INFO:root:global_step: 6, logpy: -1693.857, kl: 59.009, loss: 1694.220\n",
      "  1%|          | 7/1000 [00:11<27:59,  1.69s/it]INFO:root:global_step: 7, logpy: -1700.471, kl: 58.572, loss: 1700.833\n",
      "  1%|          | 8/1000 [00:13<26:52,  1.63s/it]INFO:root:global_step: 8, logpy: -1741.059, kl: 58.223, loss: 1741.421\n",
      "  1%|          | 9/1000 [00:14<26:17,  1.59s/it]INFO:root:global_step: 9, logpy: -1753.613, kl: 57.740, loss: 1753.974\n",
      "  1%|          | 10/1000 [00:16<25:10,  1.53s/it]INFO:root:global_step: 10, logpy: -1760.657, kl: 57.291, loss: 1761.017\n",
      "  1%|          | 11/1000 [00:17<24:32,  1.49s/it]INFO:root:global_step: 11, logpy: -1752.690, kl: 56.778, loss: 1753.048\n",
      "  1%|          | 12/1000 [00:19<23:47,  1.44s/it]INFO:root:global_step: 12, logpy: -1759.942, kl: 56.339, loss: 1760.300\n",
      "  1%|▏         | 13/1000 [00:20<23:32,  1.43s/it]INFO:root:global_step: 13, logpy: -1759.934, kl: 55.859, loss: 1760.290\n",
      "  1%|▏         | 14/1000 [00:21<23:50,  1.45s/it]INFO:root:global_step: 14, logpy: -1760.473, kl: 55.381, loss: 1760.829\n",
      "  2%|▏         | 15/1000 [00:23<24:09,  1.47s/it]INFO:root:global_step: 15, logpy: -1754.727, kl: 54.907, loss: 1755.081\n",
      "  2%|▏         | 16/1000 [00:24<24:11,  1.47s/it]INFO:root:global_step: 16, logpy: -1743.816, kl: 54.425, loss: 1744.169\n",
      "  2%|▏         | 17/1000 [00:26<24:13,  1.48s/it]INFO:root:global_step: 17, logpy: -1742.164, kl: 53.995, loss: 1742.518\n",
      "  2%|▏         | 18/1000 [00:27<24:18,  1.49s/it]INFO:root:global_step: 18, logpy: -1731.306, kl: 53.521, loss: 1731.659\n",
      "  2%|▏         | 19/1000 [00:29<24:25,  1.49s/it]INFO:root:global_step: 19, logpy: -1729.755, kl: 53.064, loss: 1730.107\n",
      "  2%|▏         | 20/1000 [00:31<25:03,  1.53s/it]INFO:root:global_step: 20, logpy: -1725.127, kl: 52.600, loss: 1725.478\n",
      "  2%|▏         | 21/1000 [00:32<26:29,  1.62s/it]INFO:root:global_step: 21, logpy: -1720.357, kl: 52.111, loss: 1720.707\n",
      "  2%|▏         | 22/1000 [00:34<26:47,  1.64s/it]INFO:root:global_step: 22, logpy: -1709.881, kl: 51.624, loss: 1710.228\n",
      "  2%|▏         | 23/1000 [00:36<26:54,  1.65s/it]INFO:root:global_step: 23, logpy: -1705.763, kl: 51.184, loss: 1706.111\n",
      "  2%|▏         | 24/1000 [00:37<26:35,  1.64s/it]INFO:root:global_step: 24, logpy: -1699.013, kl: 50.764, loss: 1699.362\n",
      "  2%|▎         | 25/1000 [00:39<26:07,  1.61s/it]INFO:root:global_step: 25, logpy: -1692.735, kl: 50.350, loss: 1693.085\n",
      "  3%|▎         | 26/1000 [00:41<26:20,  1.62s/it]INFO:root:global_step: 26, logpy: -1686.478, kl: 49.911, loss: 1686.828\n",
      "  3%|▎         | 27/1000 [00:42<26:52,  1.66s/it]INFO:root:global_step: 27, logpy: -1674.131, kl: 49.450, loss: 1674.480\n",
      "  3%|▎         | 28/1000 [00:44<27:23,  1.69s/it]INFO:root:global_step: 28, logpy: -1666.859, kl: 49.009, loss: 1667.208\n",
      "  3%|▎         | 29/1000 [00:46<27:48,  1.72s/it]INFO:root:global_step: 29, logpy: -1652.438, kl: 48.561, loss: 1652.786\n",
      "  3%|▎         | 30/1000 [00:48<27:50,  1.72s/it]INFO:root:global_step: 30, logpy: -1644.560, kl: 48.148, loss: 1644.908\n",
      "  3%|▎         | 31/1000 [00:49<27:53,  1.73s/it]INFO:root:global_step: 31, logpy: -1634.108, kl: 47.749, loss: 1634.458\n",
      "  3%|▎         | 32/1000 [00:51<27:50,  1.73s/it]INFO:root:global_step: 32, logpy: -1623.257, kl: 47.338, loss: 1623.609\n",
      "  3%|▎         | 33/1000 [00:53<27:39,  1.72s/it]INFO:root:global_step: 33, logpy: -1611.988, kl: 46.915, loss: 1612.339\n",
      "  3%|▎         | 34/1000 [00:55<27:58,  1.74s/it]INFO:root:global_step: 34, logpy: -1600.586, kl: 46.489, loss: 1600.937\n",
      "  4%|▎         | 35/1000 [00:56<28:26,  1.77s/it]INFO:root:global_step: 35, logpy: -1589.443, kl: 46.071, loss: 1589.794\n",
      "  4%|▎         | 36/1000 [00:58<28:43,  1.79s/it]INFO:root:global_step: 36, logpy: -1576.756, kl: 45.669, loss: 1577.107\n",
      "  4%|▎         | 37/1000 [01:00<28:55,  1.80s/it]INFO:root:global_step: 37, logpy: -1565.161, kl: 45.284, loss: 1565.515\n",
      "  4%|▍         | 38/1000 [01:02<28:42,  1.79s/it]INFO:root:global_step: 38, logpy: -1552.537, kl: 44.908, loss: 1552.893\n",
      "  4%|▍         | 39/1000 [01:04<28:33,  1.78s/it]INFO:root:global_step: 39, logpy: -1540.233, kl: 44.526, loss: 1540.590\n",
      "  4%|▍         | 40/1000 [01:06<29:21,  1.84s/it]INFO:root:global_step: 40, logpy: -1527.575, kl: 44.137, loss: 1527.934\n",
      "  4%|▍         | 41/1000 [01:07<29:35,  1.85s/it]INFO:root:global_step: 41, logpy: -1515.446, kl: 43.753, loss: 1515.806\n",
      "  4%|▍         | 42/1000 [01:09<29:54,  1.87s/it]INFO:root:global_step: 42, logpy: -1501.808, kl: 43.376, loss: 1502.170\n",
      "  4%|▍         | 43/1000 [01:11<29:51,  1.87s/it]INFO:root:global_step: 43, logpy: -1489.420, kl: 43.014, loss: 1489.784\n",
      "  4%|▍         | 44/1000 [01:13<29:25,  1.85s/it]INFO:root:global_step: 44, logpy: -1476.109, kl: 42.654, loss: 1476.476\n",
      "  4%|▍         | 45/1000 [01:15<29:23,  1.85s/it]INFO:root:global_step: 45, logpy: -1463.395, kl: 42.288, loss: 1463.764\n",
      "  5%|▍         | 46/1000 [01:17<29:28,  1.85s/it]INFO:root:global_step: 46, logpy: -1450.003, kl: 41.921, loss: 1450.374\n",
      "  5%|▍         | 47/1000 [01:19<29:39,  1.87s/it]INFO:root:global_step: 47, logpy: -1437.437, kl: 41.556, loss: 1437.808\n",
      "  5%|▍         | 48/1000 [01:21<29:52,  1.88s/it]INFO:root:global_step: 48, logpy: -1424.192, kl: 41.199, loss: 1424.566\n",
      "  5%|▍         | 49/1000 [01:22<29:54,  1.89s/it]INFO:root:global_step: 49, logpy: -1411.649, kl: 40.852, loss: 1412.026\n",
      "  5%|▌         | 50/1000 [01:24<29:51,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([121, 1])\n",
      "torch.Size([121, 1])\n",
      "torch.Size([121, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saved figure at: ./img_generation/global_step_50.png\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_core/sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 50, logpy: -1398.633, kl: 40.509, loss: 1399.013\n",
      "  5%|▌         | 51/1000 [01:27<35:37,  2.25s/it]INFO:root:global_step: 51, logpy: -1385.997, kl: 40.168, loss: 1386.380\n",
      "  5%|▌         | 52/1000 [01:29<34:03,  2.16s/it]INFO:root:global_step: 52, logpy: -1373.271, kl: 39.826, loss: 1373.656\n",
      "  5%|▌         | 53/1000 [01:31<33:47,  2.14s/it]INFO:root:global_step: 53, logpy: -1360.767, kl: 39.487, loss: 1361.155\n",
      "  5%|▌         | 54/1000 [01:34<33:24,  2.12s/it]INFO:root:global_step: 54, logpy: -1348.292, kl: 39.155, loss: 1348.682\n",
      "  6%|▌         | 55/1000 [01:36<32:38,  2.07s/it]INFO:root:global_step: 55, logpy: -1335.994, kl: 38.835, loss: 1336.388\n",
      "  6%|▌         | 56/1000 [01:37<31:41,  2.01s/it]INFO:root:global_step: 56, logpy: -1323.813, kl: 38.515, loss: 1324.211\n",
      "  6%|▌         | 57/1000 [01:39<31:23,  2.00s/it]INFO:root:global_step: 57, logpy: -1311.634, kl: 38.196, loss: 1312.036\n",
      "  6%|▌         | 58/1000 [01:41<31:08,  1.98s/it]INFO:root:global_step: 58, logpy: -1299.597, kl: 37.874, loss: 1300.002\n",
      "  6%|▌         | 59/1000 [01:43<31:46,  2.03s/it]INFO:root:global_step: 59, logpy: -1287.423, kl: 37.555, loss: 1287.832\n",
      "  6%|▌         | 60/1000 [01:46<32:21,  2.07s/it]INFO:root:global_step: 60, logpy: -1275.611, kl: 37.245, loss: 1276.023\n",
      "  6%|▌         | 61/1000 [01:48<32:16,  2.06s/it]INFO:root:global_step: 61, logpy: -1263.805, kl: 36.941, loss: 1264.221\n",
      "  6%|▌         | 62/1000 [01:50<31:35,  2.02s/it]INFO:root:global_step: 62, logpy: -1252.358, kl: 36.639, loss: 1252.779\n",
      "  6%|▋         | 63/1000 [01:52<31:25,  2.01s/it]INFO:root:global_step: 63, logpy: -1240.625, kl: 36.335, loss: 1241.049\n",
      "  6%|▋         | 64/1000 [01:54<31:40,  2.03s/it]INFO:root:global_step: 64, logpy: -1229.287, kl: 36.030, loss: 1229.715\n",
      "  6%|▋         | 65/1000 [01:56<31:39,  2.03s/it]INFO:root:global_step: 65, logpy: -1217.863, kl: 35.731, loss: 1218.295\n",
      "  7%|▋         | 66/1000 [01:58<31:48,  2.04s/it]INFO:root:global_step: 66, logpy: -1206.610, kl: 35.441, loss: 1207.047\n",
      "  7%|▋         | 67/1000 [02:00<31:37,  2.03s/it]INFO:root:global_step: 67, logpy: -1195.301, kl: 35.151, loss: 1195.742\n",
      "  7%|▋         | 68/1000 [02:02<31:26,  2.02s/it]INFO:root:global_step: 68, logpy: -1184.207, kl: 34.866, loss: 1184.653\n",
      "  7%|▋         | 69/1000 [02:04<31:24,  2.02s/it]INFO:root:global_step: 69, logpy: -1173.210, kl: 34.581, loss: 1173.660\n",
      "  7%|▋         | 70/1000 [02:06<32:03,  2.07s/it]INFO:root:global_step: 70, logpy: -1162.381, kl: 34.301, loss: 1162.836\n",
      "  7%|▋         | 71/1000 [02:08<32:14,  2.08s/it]INFO:root:global_step: 71, logpy: -1151.840, kl: 34.023, loss: 1152.300\n",
      "  7%|▋         | 72/1000 [02:10<32:22,  2.09s/it]INFO:root:global_step: 72, logpy: -1140.953, kl: 33.750, loss: 1141.418\n",
      "  7%|▋         | 73/1000 [02:12<32:08,  2.08s/it]INFO:root:global_step: 73, logpy: -1130.571, kl: 33.482, loss: 1131.041\n",
      "  7%|▋         | 74/1000 [02:14<32:08,  2.08s/it]INFO:root:global_step: 74, logpy: -1119.831, kl: 33.213, loss: 1120.307\n",
      "  8%|▊         | 75/1000 [02:16<32:05,  2.08s/it]INFO:root:global_step: 75, logpy: -1109.355, kl: 32.943, loss: 1109.836\n",
      "  8%|▊         | 76/1000 [02:18<31:44,  2.06s/it]INFO:root:global_step: 76, logpy: -1098.892, kl: 32.679, loss: 1099.378\n",
      "  8%|▊         | 77/1000 [02:20<31:42,  2.06s/it]INFO:root:global_step: 77, logpy: -1088.659, kl: 32.419, loss: 1089.150\n",
      "  8%|▊         | 78/1000 [02:23<31:35,  2.06s/it]INFO:root:global_step: 78, logpy: -1078.491, kl: 32.164, loss: 1078.988\n",
      "  8%|▊         | 79/1000 [02:25<31:19,  2.04s/it]INFO:root:global_step: 79, logpy: -1068.310, kl: 31.912, loss: 1068.813\n",
      "  8%|▊         | 80/1000 [02:27<31:20,  2.04s/it]INFO:root:global_step: 80, logpy: -1058.213, kl: 31.655, loss: 1058.722\n",
      "  8%|▊         | 81/1000 [02:29<31:22,  2.05s/it]INFO:root:global_step: 81, logpy: -1048.140, kl: 31.403, loss: 1048.654\n",
      "  8%|▊         | 82/1000 [02:31<31:17,  2.04s/it]INFO:root:global_step: 82, logpy: -1038.365, kl: 31.157, loss: 1038.885\n",
      "  8%|▊         | 83/1000 [02:33<31:21,  2.05s/it]INFO:root:global_step: 83, logpy: -1028.455, kl: 30.913, loss: 1028.982\n",
      "  8%|▊         | 84/1000 [02:35<31:12,  2.04s/it]INFO:root:global_step: 84, logpy: -1018.753, kl: 30.674, loss: 1019.286\n",
      "  8%|▊         | 85/1000 [02:37<31:28,  2.06s/it]INFO:root:global_step: 85, logpy: -1008.935, kl: 30.432, loss: 1009.474\n",
      "  9%|▊         | 86/1000 [02:39<31:25,  2.06s/it]INFO:root:global_step: 86, logpy: -999.411, kl: 30.195, loss: 999.956\n",
      "  9%|▊         | 87/1000 [02:41<31:26,  2.07s/it]INFO:root:global_step: 87, logpy: -989.863, kl: 29.960, loss: 990.414\n",
      "  9%|▉         | 88/1000 [02:43<31:20,  2.06s/it]INFO:root:global_step: 88, logpy: -980.405, kl: 29.731, loss: 980.964\n",
      "  9%|▉         | 89/1000 [02:45<31:03,  2.05s/it]INFO:root:global_step: 89, logpy: -971.044, kl: 29.503, loss: 971.609\n",
      "  9%|▉         | 90/1000 [02:47<30:59,  2.04s/it]INFO:root:global_step: 90, logpy: -961.650, kl: 29.278, loss: 962.222\n",
      "  9%|▉         | 91/1000 [02:49<31:03,  2.05s/it]INFO:root:global_step: 91, logpy: -952.422, kl: 29.051, loss: 953.001\n",
      "  9%|▉         | 92/1000 [02:51<31:07,  2.06s/it]INFO:root:global_step: 92, logpy: -943.251, kl: 28.829, loss: 943.837\n",
      "  9%|▉         | 93/1000 [02:53<31:08,  2.06s/it]INFO:root:global_step: 93, logpy: -934.159, kl: 28.608, loss: 934.751\n",
      "  9%|▉         | 94/1000 [02:55<31:18,  2.07s/it]INFO:root:global_step: 94, logpy: -925.044, kl: 28.389, loss: 925.643\n",
      " 10%|▉         | 95/1000 [02:58<31:22,  2.08s/it]INFO:root:global_step: 95, logpy: -916.096, kl: 28.171, loss: 916.702\n",
      " 10%|▉         | 96/1000 [03:00<31:23,  2.08s/it]INFO:root:global_step: 96, logpy: -907.286, kl: 27.954, loss: 907.898\n",
      " 10%|▉         | 97/1000 [03:02<31:33,  2.10s/it]INFO:root:global_step: 97, logpy: -898.433, kl: 27.743, loss: 899.053\n",
      " 10%|▉         | 98/1000 [03:04<31:36,  2.10s/it]INFO:root:global_step: 98, logpy: -889.655, kl: 27.536, loss: 890.283\n",
      " 10%|▉         | 99/1000 [03:06<31:47,  2.12s/it]INFO:root:global_step: 99, logpy: -880.992, kl: 27.333, loss: 881.628\n",
      " 10%|█         | 100/1000 [03:08<31:44,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([121, 1])\n",
      "torch.Size([121, 1])\n",
      "torch.Size([121, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saved figure at: ./img_generation/global_step_100.png\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_core/sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 100, logpy: -872.371, kl: 27.126, loss: 873.014\n",
      " 10%|█         | 101/1000 [03:11<37:21,  2.49s/it]INFO:root:global_step: 101, logpy: -863.803, kl: 26.919, loss: 864.452\n",
      " 10%|█         | 102/1000 [03:14<35:51,  2.40s/it]INFO:root:global_step: 102, logpy: -855.393, kl: 26.720, loss: 856.050\n",
      " 10%|█         | 103/1000 [03:16<34:43,  2.32s/it]INFO:root:global_step: 103, logpy: -847.124, kl: 26.523, loss: 847.790\n",
      " 10%|█         | 104/1000 [03:18<33:54,  2.27s/it]INFO:root:global_step: 104, logpy: -838.889, kl: 26.327, loss: 839.563\n",
      " 10%|█         | 105/1000 [03:20<33:17,  2.23s/it]INFO:root:global_step: 105, logpy: -830.771, kl: 26.133, loss: 831.452\n",
      " 11%|█         | 106/1000 [03:22<32:47,  2.20s/it]INFO:root:global_step: 106, logpy: -822.571, kl: 25.937, loss: 823.259\n",
      " 11%|█         | 107/1000 [03:24<32:32,  2.19s/it]INFO:root:global_step: 107, logpy: -814.546, kl: 25.745, loss: 815.242\n",
      " 11%|█         | 108/1000 [03:27<32:25,  2.18s/it]INFO:root:global_step: 108, logpy: -806.623, kl: 25.558, loss: 807.327\n",
      " 11%|█         | 109/1000 [03:29<32:23,  2.18s/it]INFO:root:global_step: 109, logpy: -798.766, kl: 25.369, loss: 799.478\n",
      " 11%|█         | 110/1000 [03:31<32:21,  2.18s/it]INFO:root:global_step: 110, logpy: -790.913, kl: 25.180, loss: 791.633\n",
      " 11%|█         | 111/1000 [03:33<32:53,  2.22s/it]INFO:root:global_step: 111, logpy: -783.207, kl: 24.994, loss: 783.934\n",
      " 11%|█         | 112/1000 [03:35<32:49,  2.22s/it]INFO:root:global_step: 112, logpy: -775.486, kl: 24.814, loss: 776.222\n",
      " 11%|█▏        | 113/1000 [03:38<32:38,  2.21s/it]INFO:root:global_step: 113, logpy: -767.872, kl: 24.638, loss: 768.617\n",
      " 11%|█▏        | 114/1000 [03:40<32:31,  2.20s/it]INFO:root:global_step: 114, logpy: -760.272, kl: 24.460, loss: 761.025\n",
      " 12%|█▏        | 115/1000 [03:42<32:51,  2.23s/it]INFO:root:global_step: 115, logpy: -752.864, kl: 24.281, loss: 753.624\n",
      " 12%|█▏        | 116/1000 [03:44<32:57,  2.24s/it]INFO:root:global_step: 116, logpy: -745.432, kl: 24.105, loss: 746.201\n",
      " 12%|█▏        | 117/1000 [03:47<32:52,  2.23s/it]INFO:root:global_step: 117, logpy: -738.036, kl: 23.934, loss: 738.813\n",
      " 12%|█▏        | 118/1000 [03:49<32:44,  2.23s/it]INFO:root:global_step: 118, logpy: -730.777, kl: 23.769, loss: 731.565\n",
      " 12%|█▏        | 119/1000 [03:51<32:32,  2.22s/it]INFO:root:global_step: 119, logpy: -723.477, kl: 23.603, loss: 724.273\n",
      " 12%|█▏        | 120/1000 [03:53<32:35,  2.22s/it]INFO:root:global_step: 120, logpy: -716.234, kl: 23.437, loss: 717.040\n",
      " 12%|█▏        | 121/1000 [03:56<32:54,  2.25s/it]INFO:root:global_step: 121, logpy: -709.067, kl: 23.272, loss: 709.881\n",
      " 12%|█▏        | 122/1000 [03:58<33:22,  2.28s/it]INFO:root:global_step: 122, logpy: -701.968, kl: 23.114, loss: 702.792\n",
      " 12%|█▏        | 123/1000 [04:00<33:24,  2.29s/it]INFO:root:global_step: 123, logpy: -695.028, kl: 22.956, loss: 695.863\n",
      " 12%|█▏        | 124/1000 [04:02<33:26,  2.29s/it]INFO:root:global_step: 124, logpy: -687.988, kl: 22.796, loss: 688.832\n",
      " 12%|█▎        | 125/1000 [04:05<33:17,  2.28s/it]INFO:root:global_step: 125, logpy: -681.081, kl: 22.637, loss: 681.933\n",
      " 13%|█▎        | 126/1000 [04:07<33:09,  2.28s/it]INFO:root:global_step: 126, logpy: -674.234, kl: 22.479, loss: 675.096\n",
      " 13%|█▎        | 127/1000 [04:09<33:03,  2.27s/it]INFO:root:global_step: 127, logpy: -667.437, kl: 22.325, loss: 668.308\n",
      " 13%|█▎        | 128/1000 [04:12<33:12,  2.29s/it]INFO:root:global_step: 128, logpy: -660.721, kl: 22.172, loss: 661.602\n",
      " 13%|█▎        | 129/1000 [04:14<33:15,  2.29s/it]INFO:root:global_step: 129, logpy: -654.007, kl: 22.020, loss: 654.897\n",
      " 13%|█▎        | 130/1000 [04:16<33:28,  2.31s/it]INFO:root:global_step: 130, logpy: -647.335, kl: 21.868, loss: 648.234\n",
      " 13%|█▎        | 131/1000 [04:19<33:35,  2.32s/it]INFO:root:global_step: 131, logpy: -640.736, kl: 21.717, loss: 641.644\n",
      " 13%|█▎        | 132/1000 [04:21<33:26,  2.31s/it]INFO:root:global_step: 132, logpy: -634.214, kl: 21.569, loss: 635.131\n",
      " 13%|█▎        | 133/1000 [04:23<33:21,  2.31s/it]INFO:root:global_step: 133, logpy: -627.828, kl: 21.424, loss: 628.755\n",
      " 13%|█▎        | 134/1000 [04:25<33:08,  2.30s/it]INFO:root:global_step: 134, logpy: -621.400, kl: 21.277, loss: 622.336\n",
      " 14%|█▎        | 135/1000 [04:28<33:16,  2.31s/it]INFO:root:global_step: 135, logpy: -614.967, kl: 21.136, loss: 615.913\n",
      " 14%|█▎        | 136/1000 [04:30<33:32,  2.33s/it]INFO:root:global_step: 136, logpy: -608.669, kl: 20.997, loss: 609.625\n",
      " 14%|█▎        | 137/1000 [04:32<33:19,  2.32s/it]INFO:root:global_step: 137, logpy: -602.398, kl: 20.857, loss: 603.364\n",
      " 14%|█▍        | 138/1000 [04:35<33:19,  2.32s/it]INFO:root:global_step: 138, logpy: -596.236, kl: 20.723, loss: 597.213\n",
      " 14%|█▍        | 139/1000 [04:37<33:19,  2.32s/it]INFO:root:global_step: 139, logpy: -590.075, kl: 20.587, loss: 591.062\n",
      " 14%|█▍        | 140/1000 [04:39<33:28,  2.34s/it]INFO:root:global_step: 140, logpy: -584.072, kl: 20.452, loss: 585.070\n",
      " 14%|█▍        | 141/1000 [04:42<33:26,  2.34s/it]INFO:root:global_step: 141, logpy: -577.958, kl: 20.317, loss: 578.965\n",
      " 14%|█▍        | 142/1000 [04:44<33:22,  2.33s/it]INFO:root:global_step: 142, logpy: -571.985, kl: 20.187, loss: 573.003\n",
      " 14%|█▍        | 143/1000 [04:46<33:15,  2.33s/it]INFO:root:global_step: 143, logpy: -566.048, kl: 20.057, loss: 567.077\n",
      " 14%|█▍        | 144/1000 [04:49<33:17,  2.33s/it]INFO:root:global_step: 144, logpy: -560.116, kl: 19.928, loss: 561.155\n",
      " 14%|█▍        | 145/1000 [04:51<33:25,  2.35s/it]INFO:root:global_step: 145, logpy: -554.309, kl: 19.800, loss: 555.358\n",
      " 15%|█▍        | 146/1000 [04:54<33:27,  2.35s/it]INFO:root:global_step: 146, logpy: -548.498, kl: 19.673, loss: 549.558\n",
      " 15%|█▍        | 147/1000 [04:56<34:00,  2.39s/it]INFO:root:global_step: 147, logpy: -542.813, kl: 19.549, loss: 543.883\n",
      " 15%|█▍        | 148/1000 [04:58<33:43,  2.38s/it]INFO:root:global_step: 148, logpy: -537.159, kl: 19.425, loss: 538.240\n",
      " 15%|█▍        | 149/1000 [05:01<33:32,  2.37s/it]INFO:root:global_step: 149, logpy: -531.509, kl: 19.303, loss: 532.601\n",
      " 15%|█▌        | 150/1000 [05:03<33:31,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([121, 1])\n",
      "torch.Size([121, 1])\n",
      "torch.Size([121, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saved figure at: ./img_generation/global_step_150.png\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_core/sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 150, logpy: -525.957, kl: 19.181, loss: 527.060\n",
      " 15%|█▌        | 151/1000 [05:07<38:48,  2.74s/it]INFO:root:global_step: 151, logpy: -520.451, kl: 19.064, loss: 521.566\n",
      " 15%|█▌        | 152/1000 [05:09<37:40,  2.67s/it]INFO:root:global_step: 152, logpy: -514.930, kl: 18.947, loss: 516.056\n",
      " 15%|█▌        | 153/1000 [05:12<36:27,  2.58s/it]INFO:root:global_step: 153, logpy: -509.459, kl: 18.831, loss: 510.596\n",
      " 15%|█▌        | 154/1000 [05:14<35:30,  2.52s/it]INFO:root:global_step: 154, logpy: -504.124, kl: 18.718, loss: 505.273\n",
      " 16%|█▌        | 155/1000 [05:16<35:09,  2.50s/it]INFO:root:global_step: 155, logpy: -498.752, kl: 18.604, loss: 499.912\n",
      " 16%|█▌        | 156/1000 [05:19<35:11,  2.50s/it]INFO:root:global_step: 156, logpy: -493.482, kl: 18.491, loss: 494.654\n",
      " 16%|█▌        | 157/1000 [05:22<35:41,  2.54s/it]INFO:root:global_step: 157, logpy: -488.183, kl: 18.379, loss: 489.365\n",
      " 16%|█▌        | 158/1000 [05:24<35:15,  2.51s/it]INFO:root:global_step: 158, logpy: -483.014, kl: 18.271, loss: 484.209\n",
      " 16%|█▌        | 159/1000 [05:26<34:38,  2.47s/it]INFO:root:global_step: 159, logpy: -477.830, kl: 18.161, loss: 479.036\n",
      " 16%|█▌        | 160/1000 [05:29<34:15,  2.45s/it]INFO:root:global_step: 160, logpy: -472.732, kl: 18.051, loss: 473.950\n",
      " 16%|█▌        | 161/1000 [05:31<34:17,  2.45s/it]INFO:root:global_step: 161, logpy: -467.684, kl: 17.941, loss: 468.913\n",
      " 16%|█▌        | 162/1000 [05:34<34:09,  2.45s/it]INFO:root:global_step: 162, logpy: -462.698, kl: 17.836, loss: 463.938\n",
      " 16%|█▋        | 163/1000 [05:36<34:32,  2.48s/it]INFO:root:global_step: 163, logpy: -457.772, kl: 17.735, loss: 459.025\n",
      " 16%|█▋        | 164/1000 [05:39<34:07,  2.45s/it]INFO:root:global_step: 164, logpy: -452.872, kl: 17.634, loss: 454.138\n",
      " 16%|█▋        | 165/1000 [05:41<33:54,  2.44s/it]INFO:root:global_step: 165, logpy: -448.005, kl: 17.533, loss: 449.283\n",
      " 17%|█▋        | 166/1000 [05:44<34:28,  2.48s/it]INFO:root:global_step: 166, logpy: -443.214, kl: 17.435, loss: 444.505\n",
      " 17%|█▋        | 167/1000 [05:46<35:02,  2.52s/it]INFO:root:global_step: 167, logpy: -438.372, kl: 17.336, loss: 439.676\n",
      " 17%|█▋        | 168/1000 [05:49<35:26,  2.56s/it]INFO:root:global_step: 168, logpy: -433.645, kl: 17.239, loss: 434.961\n",
      " 17%|█▋        | 169/1000 [05:51<34:47,  2.51s/it]INFO:root:global_step: 169, logpy: -428.972, kl: 17.144, loss: 430.302\n",
      " 17%|█▋        | 170/1000 [05:54<34:23,  2.49s/it]INFO:root:global_step: 170, logpy: -424.360, kl: 17.046, loss: 425.701\n",
      " 17%|█▋        | 171/1000 [05:56<34:10,  2.47s/it]INFO:root:global_step: 171, logpy: -419.648, kl: 16.950, loss: 421.002\n",
      " 17%|█▋        | 172/1000 [05:59<34:21,  2.49s/it]INFO:root:global_step: 172, logpy: -415.020, kl: 16.856, loss: 416.386\n",
      " 17%|█▋        | 173/1000 [06:01<34:07,  2.48s/it]INFO:root:global_step: 173, logpy: -410.520, kl: 16.766, loss: 411.899\n",
      " 17%|█▋        | 174/1000 [06:03<33:48,  2.46s/it]INFO:root:global_step: 174, logpy: -405.936, kl: 16.673, loss: 407.328\n",
      " 18%|█▊        | 175/1000 [06:06<33:49,  2.46s/it]INFO:root:global_step: 175, logpy: -401.477, kl: 16.580, loss: 402.882\n",
      " 18%|█▊        | 176/1000 [06:08<33:55,  2.47s/it]INFO:root:global_step: 176, logpy: -397.045, kl: 16.488, loss: 398.462\n",
      " 18%|█▊        | 177/1000 [06:11<33:58,  2.48s/it]INFO:root:global_step: 177, logpy: -392.635, kl: 16.400, loss: 394.064\n",
      " 18%|█▊        | 178/1000 [06:13<33:52,  2.47s/it]INFO:root:global_step: 178, logpy: -388.254, kl: 16.314, loss: 389.697\n",
      " 18%|█▊        | 179/1000 [06:16<34:12,  2.50s/it]INFO:root:global_step: 179, logpy: -383.922, kl: 16.229, loss: 385.378\n",
      " 18%|█▊        | 180/1000 [06:18<33:59,  2.49s/it]INFO:root:global_step: 180, logpy: -379.629, kl: 16.144, loss: 381.099\n",
      " 18%|█▊        | 181/1000 [06:21<33:50,  2.48s/it]INFO:root:global_step: 181, logpy: -375.422, kl: 16.060, loss: 376.906\n",
      " 18%|█▊        | 182/1000 [06:23<33:55,  2.49s/it]INFO:root:global_step: 182, logpy: -371.188, kl: 15.977, loss: 372.685\n",
      " 18%|█▊        | 183/1000 [06:26<33:48,  2.48s/it]INFO:root:global_step: 183, logpy: -367.003, kl: 15.895, loss: 368.514\n",
      " 18%|█▊        | 184/1000 [06:28<33:41,  2.48s/it]INFO:root:global_step: 184, logpy: -362.920, kl: 15.815, loss: 364.445\n",
      " 18%|█▊        | 185/1000 [06:31<33:34,  2.47s/it]INFO:root:global_step: 185, logpy: -358.851, kl: 15.736, loss: 360.390\n",
      " 19%|█▊        | 186/1000 [06:33<33:37,  2.48s/it]INFO:root:global_step: 186, logpy: -354.773, kl: 15.658, loss: 356.327\n",
      " 19%|█▊        | 187/1000 [06:36<33:35,  2.48s/it]INFO:root:global_step: 187, logpy: -350.804, kl: 15.581, loss: 352.372\n",
      " 19%|█▉        | 188/1000 [06:38<33:30,  2.48s/it]INFO:root:global_step: 188, logpy: -346.774, kl: 15.504, loss: 348.356\n",
      " 19%|█▉        | 189/1000 [06:41<33:32,  2.48s/it]INFO:root:global_step: 189, logpy: -342.822, kl: 15.429, loss: 344.419\n",
      " 19%|█▉        | 190/1000 [06:43<33:50,  2.51s/it]INFO:root:global_step: 190, logpy: -338.956, kl: 15.355, loss: 340.568\n",
      " 19%|█▉        | 191/1000 [06:46<33:51,  2.51s/it]INFO:root:global_step: 191, logpy: -334.960, kl: 15.282, loss: 336.586\n",
      " 19%|█▉        | 192/1000 [06:48<33:47,  2.51s/it]INFO:root:global_step: 192, logpy: -331.051, kl: 15.210, loss: 332.692\n",
      " 19%|█▉        | 193/1000 [06:51<33:43,  2.51s/it]INFO:root:global_step: 193, logpy: -327.227, kl: 15.137, loss: 328.883\n",
      " 19%|█▉        | 194/1000 [06:53<33:46,  2.51s/it]INFO:root:global_step: 194, logpy: -323.404, kl: 15.065, loss: 325.074\n",
      " 20%|█▉        | 195/1000 [06:56<33:45,  2.52s/it]INFO:root:global_step: 195, logpy: -319.658, kl: 14.994, loss: 321.343\n",
      " 20%|█▉        | 196/1000 [06:58<33:37,  2.51s/it]INFO:root:global_step: 196, logpy: -315.981, kl: 14.928, loss: 317.682\n",
      " 20%|█▉        | 197/1000 [07:01<33:42,  2.52s/it]INFO:root:global_step: 197, logpy: -312.213, kl: 14.861, loss: 313.930\n",
      " 20%|█▉        | 198/1000 [07:03<33:32,  2.51s/it]INFO:root:global_step: 198, logpy: -308.558, kl: 14.794, loss: 310.290\n",
      " 20%|█▉        | 199/1000 [07:06<33:58,  2.54s/it]INFO:root:global_step: 199, logpy: -305.012, kl: 14.727, loss: 306.758\n",
      " 20%|██        | 200/1000 [07:09<33:52,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([121, 1])\n",
      "torch.Size([121, 1])\n",
      "torch.Size([121, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saved figure at: ./img_generation/global_step_200.png\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_core/sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 200, logpy: -301.454, kl: 14.662, loss: 303.217\n",
      " 20%|██        | 201/1000 [07:12<39:23,  2.96s/it]INFO:root:global_step: 201, logpy: -297.845, kl: 14.597, loss: 299.623\n",
      " 20%|██        | 202/1000 [07:15<37:45,  2.84s/it]INFO:root:global_step: 202, logpy: -294.333, kl: 14.533, loss: 296.126\n",
      " 20%|██        | 203/1000 [07:18<36:32,  2.75s/it]INFO:root:global_step: 203, logpy: -290.791, kl: 14.469, loss: 292.599\n",
      " 20%|██        | 204/1000 [07:20<35:48,  2.70s/it]INFO:root:global_step: 204, logpy: -287.305, kl: 14.407, loss: 289.130\n",
      " 20%|██        | 205/1000 [07:23<34:58,  2.64s/it]INFO:root:global_step: 205, logpy: -283.846, kl: 14.347, loss: 285.686\n",
      " 21%|██        | 206/1000 [07:25<34:34,  2.61s/it]INFO:root:global_step: 206, logpy: -280.428, kl: 14.285, loss: 282.284\n",
      " 21%|██        | 207/1000 [07:28<34:28,  2.61s/it]INFO:root:global_step: 207, logpy: -277.036, kl: 14.225, loss: 278.908\n",
      " 21%|██        | 208/1000 [07:30<34:31,  2.62s/it]INFO:root:global_step: 208, logpy: -273.730, kl: 14.166, loss: 275.617\n",
      " 21%|██        | 209/1000 [07:33<34:43,  2.63s/it]INFO:root:global_step: 209, logpy: -270.367, kl: 14.106, loss: 272.270\n",
      " 21%|██        | 210/1000 [07:36<34:30,  2.62s/it]INFO:root:global_step: 210, logpy: -267.054, kl: 14.050, loss: 268.974\n",
      " 21%|██        | 211/1000 [07:38<34:29,  2.62s/it]INFO:root:global_step: 211, logpy: -263.718, kl: 13.996, loss: 265.655\n",
      " 21%|██        | 212/1000 [07:41<34:08,  2.60s/it]INFO:root:global_step: 212, logpy: -260.475, kl: 13.939, loss: 262.429\n",
      " 21%|██▏       | 213/1000 [07:43<34:11,  2.61s/it]INFO:root:global_step: 213, logpy: -257.258, kl: 13.886, loss: 259.229\n",
      " 21%|██▏       | 214/1000 [07:46<34:01,  2.60s/it]INFO:root:global_step: 214, logpy: -254.030, kl: 13.835, loss: 256.019\n",
      " 22%|██▏       | 215/1000 [07:49<34:00,  2.60s/it]INFO:root:global_step: 215, logpy: -250.866, kl: 13.783, loss: 252.872\n",
      " 22%|██▏       | 216/1000 [07:51<34:07,  2.61s/it]INFO:root:global_step: 216, logpy: -247.731, kl: 13.731, loss: 249.754\n",
      " 22%|██▏       | 217/1000 [07:54<33:57,  2.60s/it]INFO:root:global_step: 217, logpy: -244.689, kl: 13.681, loss: 246.731\n",
      " 22%|██▏       | 218/1000 [07:56<33:52,  2.60s/it]INFO:root:global_step: 218, logpy: -241.609, kl: 13.630, loss: 243.667\n",
      " 22%|██▏       | 219/1000 [07:59<33:42,  2.59s/it]INFO:root:global_step: 219, logpy: -238.633, kl: 13.584, loss: 240.710\n",
      " 22%|██▏       | 220/1000 [08:02<33:29,  2.58s/it]INFO:root:global_step: 220, logpy: -235.611, kl: 13.537, loss: 237.707\n",
      " 22%|██▏       | 221/1000 [08:04<33:18,  2.57s/it]INFO:root:global_step: 221, logpy: -232.613, kl: 13.489, loss: 234.727\n",
      " 22%|██▏       | 222/1000 [08:07<33:47,  2.61s/it]INFO:root:global_step: 222, logpy: -229.652, kl: 13.440, loss: 231.783\n",
      " 22%|██▏       | 223/1000 [08:10<33:59,  2.63s/it]INFO:root:global_step: 223, logpy: -226.668, kl: 13.392, loss: 228.817\n",
      " 22%|██▏       | 224/1000 [08:12<33:51,  2.62s/it]INFO:root:global_step: 224, logpy: -223.796, kl: 13.349, loss: 225.964\n",
      " 22%|██▎       | 225/1000 [08:15<33:47,  2.62s/it]INFO:root:global_step: 225, logpy: -220.878, kl: 13.304, loss: 223.064\n",
      " 23%|██▎       | 226/1000 [08:17<33:39,  2.61s/it]INFO:root:global_step: 226, logpy: -218.004, kl: 13.260, loss: 220.209\n",
      " 23%|██▎       | 227/1000 [08:20<33:35,  2.61s/it]INFO:root:global_step: 227, logpy: -215.167, kl: 13.217, loss: 217.391\n",
      " 23%|██▎       | 228/1000 [08:23<33:33,  2.61s/it]INFO:root:global_step: 228, logpy: -212.366, kl: 13.175, loss: 214.609\n",
      " 23%|██▎       | 229/1000 [08:25<33:23,  2.60s/it]INFO:root:global_step: 229, logpy: -209.569, kl: 13.133, loss: 211.830\n",
      " 23%|██▎       | 230/1000 [08:28<33:16,  2.59s/it]INFO:root:global_step: 230, logpy: -206.794, kl: 13.090, loss: 209.074\n",
      " 23%|██▎       | 231/1000 [08:30<33:14,  2.59s/it]INFO:root:global_step: 231, logpy: -204.002, kl: 13.048, loss: 206.300\n",
      " 23%|██▎       | 232/1000 [08:33<33:25,  2.61s/it]INFO:root:global_step: 232, logpy: -201.302, kl: 13.009, loss: 203.620\n",
      " 23%|██▎       | 233/1000 [08:36<33:37,  2.63s/it]INFO:root:global_step: 233, logpy: -198.685, kl: 12.970, loss: 201.023\n",
      " 23%|██▎       | 234/1000 [08:38<33:31,  2.63s/it]INFO:root:global_step: 234, logpy: -195.989, kl: 12.934, loss: 198.348\n",
      " 24%|██▎       | 235/1000 [08:41<33:30,  2.63s/it]INFO:root:global_step: 235, logpy: -193.298, kl: 12.894, loss: 195.674\n",
      " 24%|██▎       | 236/1000 [08:43<33:10,  2.61s/it]INFO:root:global_step: 236, logpy: -190.683, kl: 12.856, loss: 193.079\n",
      " 24%|██▎       | 237/1000 [08:46<33:07,  2.60s/it]INFO:root:global_step: 237, logpy: -188.004, kl: 12.821, loss: 190.421\n",
      " 24%|██▍       | 238/1000 [08:49<32:57,  2.60s/it]INFO:root:global_step: 238, logpy: -185.460, kl: 12.789, loss: 187.899\n",
      " 24%|██▍       | 239/1000 [08:51<32:47,  2.58s/it]INFO:root:global_step: 239, logpy: -182.853, kl: 12.752, loss: 185.310\n",
      " 24%|██▍       | 240/1000 [08:54<32:42,  2.58s/it]INFO:root:global_step: 240, logpy: -180.287, kl: 12.716, loss: 182.764\n",
      " 24%|██▍       | 241/1000 [08:56<32:46,  2.59s/it]INFO:root:global_step: 241, logpy: -177.812, kl: 12.683, loss: 180.310\n",
      " 24%|██▍       | 242/1000 [08:59<32:47,  2.60s/it]INFO:root:global_step: 242, logpy: -175.277, kl: 12.651, loss: 177.796\n",
      " 24%|██▍       | 243/1000 [09:02<32:48,  2.60s/it]INFO:root:global_step: 243, logpy: -172.825, kl: 12.618, loss: 175.365\n",
      " 24%|██▍       | 244/1000 [09:04<33:02,  2.62s/it]INFO:root:global_step: 244, logpy: -170.345, kl: 12.584, loss: 172.904\n",
      " 24%|██▍       | 245/1000 [09:07<33:11,  2.64s/it]INFO:root:global_step: 245, logpy: -167.861, kl: 12.551, loss: 170.441\n",
      " 25%|██▍       | 246/1000 [09:10<33:08,  2.64s/it]INFO:root:global_step: 246, logpy: -165.522, kl: 12.519, loss: 168.121\n",
      " 25%|██▍       | 247/1000 [09:12<33:13,  2.65s/it]INFO:root:global_step: 247, logpy: -163.195, kl: 12.489, loss: 165.816\n",
      " 25%|██▍       | 248/1000 [09:15<33:13,  2.65s/it]INFO:root:global_step: 248, logpy: -160.808, kl: 12.458, loss: 163.450\n",
      " 25%|██▍       | 249/1000 [09:17<33:09,  2.65s/it]INFO:root:global_step: 249, logpy: -158.551, kl: 12.429, loss: 161.214\n",
      " 25%|██▌       | 250/1000 [09:20<33:20,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([121, 1])\n",
      "torch.Size([121, 1])\n",
      "torch.Size([121, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saved figure at: ./img_generation/global_step_250.png\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_core/sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 250, logpy: -156.313, kl: 12.401, loss: 158.998\n",
      " 25%|██▌       | 251/1000 [09:24<37:48,  3.03s/it]INFO:root:global_step: 251, logpy: -153.947, kl: 12.372, loss: 156.653\n",
      " 25%|██▌       | 252/1000 [09:27<36:41,  2.94s/it]INFO:root:global_step: 252, logpy: -151.788, kl: 12.345, loss: 154.515\n",
      " 25%|██▌       | 253/1000 [09:30<35:40,  2.87s/it]INFO:root:global_step: 253, logpy: -149.580, kl: 12.317, loss: 152.329\n",
      " 25%|██▌       | 254/1000 [09:32<35:45,  2.88s/it]INFO:root:global_step: 254, logpy: -147.270, kl: 12.290, loss: 150.040\n",
      " 26%|██▌       | 255/1000 [09:35<35:18,  2.84s/it]INFO:root:global_step: 255, logpy: -145.143, kl: 12.263, loss: 147.935\n",
      " 26%|██▌       | 256/1000 [09:38<34:38,  2.79s/it]INFO:root:global_step: 256, logpy: -142.955, kl: 12.237, loss: 145.768\n",
      " 26%|██▌       | 257/1000 [09:41<34:16,  2.77s/it]INFO:root:global_step: 257, logpy: -140.729, kl: 12.210, loss: 143.564\n",
      " 26%|██▌       | 258/1000 [09:43<34:23,  2.78s/it]INFO:root:global_step: 258, logpy: -138.533, kl: 12.188, loss: 141.391\n",
      " 26%|██▌       | 259/1000 [09:46<34:30,  2.79s/it]INFO:root:global_step: 259, logpy: -136.359, kl: 12.164, loss: 139.240\n",
      " 26%|██▌       | 260/1000 [09:49<34:06,  2.77s/it]INFO:root:global_step: 260, logpy: -134.176, kl: 12.135, loss: 137.076\n",
      " 26%|██▌       | 261/1000 [09:52<33:46,  2.74s/it]INFO:root:global_step: 261, logpy: -132.041, kl: 12.111, loss: 134.963\n",
      " 26%|██▌       | 262/1000 [09:54<33:33,  2.73s/it]INFO:root:global_step: 262, logpy: -129.944, kl: 12.090, loss: 132.889\n",
      " 26%|██▋       | 263/1000 [09:57<33:18,  2.71s/it]INFO:root:global_step: 263, logpy: -127.831, kl: 12.065, loss: 130.798\n",
      " 26%|██▋       | 264/1000 [10:00<33:17,  2.71s/it]INFO:root:global_step: 264, logpy: -125.767, kl: 12.044, loss: 128.756\n",
      " 26%|██▋       | 265/1000 [10:03<33:41,  2.75s/it]INFO:root:global_step: 265, logpy: -123.692, kl: 12.022, loss: 126.704\n",
      " 27%|██▋       | 266/1000 [10:05<34:03,  2.78s/it]INFO:root:global_step: 266, logpy: -121.582, kl: 12.001, loss: 124.617\n",
      " 27%|██▋       | 267/1000 [10:08<33:56,  2.78s/it]INFO:root:global_step: 267, logpy: -119.528, kl: 11.981, loss: 122.586\n",
      " 27%|██▋       | 268/1000 [10:11<33:40,  2.76s/it]INFO:root:global_step: 268, logpy: -117.547, kl: 11.962, loss: 120.629\n",
      " 27%|██▋       | 269/1000 [10:14<33:26,  2.74s/it]INFO:root:global_step: 269, logpy: -115.576, kl: 11.946, loss: 118.683\n",
      " 27%|██▋       | 270/1000 [10:16<33:07,  2.72s/it]INFO:root:global_step: 270, logpy: -113.553, kl: 11.925, loss: 116.682\n",
      " 27%|██▋       | 271/1000 [10:19<33:10,  2.73s/it]INFO:root:global_step: 271, logpy: -111.580, kl: 11.906, loss: 114.733\n",
      " 27%|██▋       | 272/1000 [10:22<33:06,  2.73s/it]INFO:root:global_step: 272, logpy: -109.648, kl: 11.888, loss: 112.825\n",
      " 27%|██▋       | 273/1000 [10:24<32:55,  2.72s/it]INFO:root:global_step: 273, logpy: -107.687, kl: 11.874, loss: 110.889\n",
      " 27%|██▋       | 274/1000 [10:27<32:47,  2.71s/it]INFO:root:global_step: 274, logpy: -105.772, kl: 11.856, loss: 108.997\n",
      " 28%|██▊       | 275/1000 [10:30<32:44,  2.71s/it]INFO:root:global_step: 275, logpy: -103.881, kl: 11.838, loss: 107.129\n",
      " 28%|██▊       | 276/1000 [10:33<33:02,  2.74s/it]INFO:root:global_step: 276, logpy: -102.005, kl: 11.820, loss: 105.277\n",
      " 28%|██▊       | 277/1000 [10:35<32:44,  2.72s/it]INFO:root:global_step: 277, logpy: -100.160, kl: 11.808, loss: 103.458\n",
      " 28%|██▊       | 278/1000 [10:38<32:42,  2.72s/it]INFO:root:global_step: 278, logpy: -98.364, kl: 11.792, loss: 101.686\n",
      " 28%|██▊       | 279/1000 [10:41<32:34,  2.71s/it]INFO:root:global_step: 279, logpy: -96.480, kl: 11.778, loss: 99.827\n",
      " 28%|██▊       | 280/1000 [10:43<32:33,  2.71s/it]INFO:root:global_step: 280, logpy: -94.657, kl: 11.766, loss: 98.030\n",
      " 28%|██▊       | 281/1000 [10:46<32:40,  2.73s/it]INFO:root:global_step: 281, logpy: -92.876, kl: 11.751, loss: 96.274\n",
      " 28%|██▊       | 282/1000 [10:49<32:26,  2.71s/it]INFO:root:global_step: 282, logpy: -91.115, kl: 11.741, loss: 94.539\n",
      " 28%|██▊       | 283/1000 [10:52<32:21,  2.71s/it]INFO:root:global_step: 283, logpy: -89.340, kl: 11.728, loss: 92.789\n",
      " 28%|██▊       | 284/1000 [10:54<32:29,  2.72s/it]INFO:root:global_step: 284, logpy: -87.596, kl: 11.715, loss: 91.070\n",
      " 28%|██▊       | 285/1000 [10:57<32:25,  2.72s/it]INFO:root:global_step: 285, logpy: -85.814, kl: 11.703, loss: 89.314\n",
      " 29%|██▊       | 286/1000 [11:00<32:26,  2.73s/it]INFO:root:global_step: 286, logpy: -84.135, kl: 11.690, loss: 87.659\n",
      " 29%|██▊       | 287/1000 [11:03<32:39,  2.75s/it]INFO:root:global_step: 287, logpy: -82.465, kl: 11.679, loss: 86.015\n",
      " 29%|██▉       | 288/1000 [11:05<32:30,  2.74s/it]INFO:root:global_step: 288, logpy: -80.738, kl: 11.667, loss: 84.313\n",
      " 29%|██▉       | 289/1000 [11:08<32:25,  2.74s/it]INFO:root:global_step: 289, logpy: -79.107, kl: 11.656, loss: 82.707\n",
      " 29%|██▉       | 290/1000 [11:11<32:25,  2.74s/it]INFO:root:global_step: 290, logpy: -77.473, kl: 11.642, loss: 81.098\n",
      " 29%|██▉       | 291/1000 [11:14<32:26,  2.75s/it]INFO:root:global_step: 291, logpy: -75.796, kl: 11.633, loss: 79.447\n",
      " 29%|██▉       | 292/1000 [11:16<32:20,  2.74s/it]INFO:root:global_step: 292, logpy: -74.221, kl: 11.623, loss: 77.898\n",
      " 29%|██▉       | 293/1000 [11:19<32:14,  2.74s/it]INFO:root:global_step: 293, logpy: -72.592, kl: 11.612, loss: 76.294\n",
      " 29%|██▉       | 294/1000 [11:22<32:11,  2.74s/it]INFO:root:global_step: 294, logpy: -71.009, kl: 11.605, loss: 74.738\n",
      " 30%|██▉       | 295/1000 [11:24<32:08,  2.74s/it]INFO:root:global_step: 295, logpy: -69.563, kl: 11.602, loss: 73.321\n",
      " 30%|██▉       | 296/1000 [11:27<32:01,  2.73s/it]INFO:root:global_step: 296, logpy: -68.007, kl: 11.595, loss: 71.793\n",
      " 30%|██▉       | 297/1000 [11:30<32:13,  2.75s/it]INFO:root:global_step: 297, logpy: -66.409, kl: 11.586, loss: 70.221\n",
      " 30%|██▉       | 298/1000 [11:33<32:21,  2.77s/it]INFO:root:global_step: 298, logpy: -64.916, kl: 11.584, loss: 68.757\n",
      " 30%|██▉       | 299/1000 [11:36<32:15,  2.76s/it]INFO:root:global_step: 299, logpy: -63.432, kl: 11.577, loss: 67.300\n",
      " 30%|███       | 300/1000 [11:38<32:10,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([121, 1])\n",
      "torch.Size([121, 1])\n",
      "torch.Size([121, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saved figure at: ./img_generation/global_step_300.png\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_core/sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 300, logpy: -61.894, kl: 11.571, loss: 65.790\n",
      " 30%|███       | 301/1000 [11:42<36:52,  3.16s/it]INFO:root:global_step: 301, logpy: -60.500, kl: 11.568, loss: 64.425\n",
      " 30%|███       | 302/1000 [11:45<35:23,  3.04s/it]INFO:root:global_step: 302, logpy: -58.991, kl: 11.563, loss: 62.944\n",
      " 30%|███       | 303/1000 [11:48<35:03,  3.02s/it]INFO:root:global_step: 303, logpy: -57.553, kl: 11.557, loss: 61.533\n",
      " 30%|███       | 304/1000 [11:51<34:39,  2.99s/it]INFO:root:global_step: 304, logpy: -56.113, kl: 11.554, loss: 60.122\n",
      " 30%|███       | 305/1000 [11:54<33:44,  2.91s/it]INFO:root:global_step: 305, logpy: -54.621, kl: 11.549, loss: 58.657\n",
      " 31%|███       | 306/1000 [11:57<33:12,  2.87s/it]INFO:root:global_step: 306, logpy: -53.175, kl: 11.543, loss: 57.239\n",
      " 31%|███       | 307/1000 [11:59<32:52,  2.85s/it]INFO:root:global_step: 307, logpy: -51.742, kl: 11.544, loss: 55.836\n",
      " 31%|███       | 308/1000 [12:02<32:23,  2.81s/it]INFO:root:global_step: 308, logpy: -50.285, kl: 11.539, loss: 54.407\n",
      " 31%|███       | 309/1000 [12:05<32:24,  2.81s/it]INFO:root:global_step: 309, logpy: -48.871, kl: 11.535, loss: 53.021\n",
      " 31%|███       | 310/1000 [12:08<32:19,  2.81s/it]INFO:root:global_step: 310, logpy: -47.426, kl: 11.534, loss: 51.605\n",
      " 31%|███       | 311/1000 [12:10<32:23,  2.82s/it]INFO:root:global_step: 311, logpy: -46.107, kl: 11.535, loss: 50.317\n",
      " 31%|███       | 312/1000 [12:13<32:44,  2.86s/it]INFO:root:global_step: 312, logpy: -44.845, kl: 11.536, loss: 49.085\n",
      " 31%|███▏      | 313/1000 [12:16<32:47,  2.86s/it]INFO:root:global_step: 313, logpy: -43.447, kl: 11.533, loss: 47.716\n",
      " 31%|███▏      | 314/1000 [12:19<32:42,  2.86s/it]INFO:root:global_step: 314, logpy: -42.139, kl: 11.532, loss: 46.437\n",
      " 32%|███▏      | 315/1000 [12:22<32:28,  2.84s/it]INFO:root:global_step: 315, logpy: -40.842, kl: 11.530, loss: 45.169\n",
      " 32%|███▏      | 316/1000 [12:25<32:08,  2.82s/it]INFO:root:global_step: 316, logpy: -39.501, kl: 11.532, loss: 43.859\n",
      " 32%|███▏      | 317/1000 [12:27<31:48,  2.79s/it]INFO:root:global_step: 317, logpy: -38.202, kl: 11.535, loss: 42.591\n",
      " 32%|███▏      | 318/1000 [12:30<31:55,  2.81s/it]INFO:root:global_step: 318, logpy: -36.909, kl: 11.535, loss: 41.328\n",
      " 32%|███▏      | 319/1000 [12:33<32:10,  2.84s/it]INFO:root:global_step: 319, logpy: -35.600, kl: 11.536, loss: 40.049\n",
      " 32%|███▏      | 320/1000 [12:36<32:14,  2.84s/it]INFO:root:global_step: 320, logpy: -34.298, kl: 11.534, loss: 38.776\n",
      " 32%|███▏      | 321/1000 [12:39<32:12,  2.85s/it]INFO:root:global_step: 321, logpy: -32.998, kl: 11.533, loss: 37.505\n",
      " 32%|███▏      | 322/1000 [12:42<31:51,  2.82s/it]INFO:root:global_step: 322, logpy: -31.679, kl: 11.537, loss: 36.218\n",
      " 32%|███▏      | 323/1000 [12:44<31:30,  2.79s/it]INFO:root:global_step: 323, logpy: -30.431, kl: 11.536, loss: 34.999\n",
      " 32%|███▏      | 324/1000 [12:47<31:30,  2.80s/it]INFO:root:global_step: 324, logpy: -29.179, kl: 11.536, loss: 33.776\n",
      " 32%|███▎      | 325/1000 [12:50<31:24,  2.79s/it]INFO:root:global_step: 325, logpy: -27.983, kl: 11.540, loss: 32.611\n",
      " 33%|███▎      | 326/1000 [12:53<31:13,  2.78s/it]INFO:root:global_step: 326, logpy: -26.769, kl: 11.539, loss: 31.426\n",
      " 33%|███▎      | 327/1000 [12:56<31:16,  2.79s/it]INFO:root:global_step: 327, logpy: -25.529, kl: 11.540, loss: 30.216\n",
      " 33%|███▎      | 328/1000 [12:58<31:08,  2.78s/it]INFO:root:global_step: 328, logpy: -24.352, kl: 11.542, loss: 29.069\n",
      " 33%|███▎      | 329/1000 [13:01<31:13,  2.79s/it]INFO:root:global_step: 329, logpy: -23.199, kl: 11.547, loss: 27.949\n",
      " 33%|███▎      | 330/1000 [13:04<31:04,  2.78s/it]INFO:root:global_step: 330, logpy: -22.033, kl: 11.548, loss: 26.812\n",
      " 33%|███▎      | 331/1000 [13:07<31:09,  2.79s/it]INFO:root:global_step: 331, logpy: -20.832, kl: 11.554, loss: 25.644\n",
      " 33%|███▎      | 332/1000 [13:10<31:15,  2.81s/it]INFO:root:global_step: 332, logpy: -19.646, kl: 11.556, loss: 24.488\n",
      " 33%|███▎      | 333/1000 [13:12<31:22,  2.82s/it]INFO:root:global_step: 333, logpy: -18.456, kl: 11.556, loss: 23.327\n",
      " 33%|███▎      | 334/1000 [13:15<31:12,  2.81s/it]INFO:root:global_step: 334, logpy: -17.322, kl: 11.563, loss: 22.226\n",
      " 34%|███▎      | 335/1000 [13:18<31:09,  2.81s/it]INFO:root:global_step: 335, logpy: -16.125, kl: 11.567, loss: 21.060\n",
      " 34%|███▎      | 336/1000 [13:21<31:03,  2.81s/it]INFO:root:global_step: 336, logpy: -14.933, kl: 11.569, loss: 19.899\n",
      " 34%|███▎      | 337/1000 [13:24<31:01,  2.81s/it]INFO:root:global_step: 337, logpy: -13.763, kl: 11.573, loss: 18.760\n",
      " 34%|███▍      | 338/1000 [13:26<31:08,  2.82s/it]INFO:root:global_step: 338, logpy: -12.637, kl: 11.579, loss: 17.666\n",
      " 34%|███▍      | 339/1000 [13:29<30:58,  2.81s/it]INFO:root:global_step: 339, logpy: -11.550, kl: 11.584, loss: 16.611\n",
      " 34%|███▍      | 340/1000 [13:32<30:55,  2.81s/it]INFO:root:global_step: 340, logpy: -10.401, kl: 11.588, loss: 15.494\n",
      " 34%|███▍      | 341/1000 [13:35<30:57,  2.82s/it]INFO:root:global_step: 341, logpy: -9.300, kl: 11.592, loss: 14.423\n",
      " 34%|███▍      | 342/1000 [13:38<30:45,  2.80s/it]INFO:root:global_step: 342, logpy: -8.230, kl: 11.599, loss: 13.387\n",
      " 34%|███▍      | 343/1000 [13:41<31:09,  2.85s/it]INFO:root:global_step: 343, logpy: -7.141, kl: 11.607, loss: 12.332\n",
      " 34%|███▍      | 344/1000 [13:44<31:24,  2.87s/it]INFO:root:global_step: 344, logpy: -6.056, kl: 11.610, loss: 11.276\n",
      " 34%|███▍      | 345/1000 [13:47<31:48,  2.91s/it]INFO:root:global_step: 345, logpy: -4.978, kl: 11.618, loss: 10.233\n",
      " 35%|███▍      | 346/1000 [13:49<31:46,  2.92s/it]INFO:root:global_step: 346, logpy: -3.922, kl: 11.627, loss: 9.211\n",
      " 35%|███▍      | 347/1000 [13:52<31:19,  2.88s/it]INFO:root:global_step: 347, logpy: -2.852, kl: 11.633, loss: 8.173\n",
      " 35%|███▍      | 348/1000 [13:55<31:14,  2.87s/it]INFO:root:global_step: 348, logpy: -1.804, kl: 11.638, loss: 7.157\n",
      " 35%|███▍      | 349/1000 [13:58<31:12,  2.88s/it]INFO:root:global_step: 349, logpy: -0.771, kl: 11.645, loss: 6.157\n",
      " 35%|███▌      | 350/1000 [14:01<31:06,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([121, 1])\n",
      "torch.Size([121, 1])\n",
      "torch.Size([121, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saved figure at: ./img_generation/global_step_350.png\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_core/sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 350, logpy: 0.267, kl: 11.652, loss: 5.151\n",
      " 35%|███▌      | 351/1000 [14:05<35:14,  3.26s/it]INFO:root:global_step: 351, logpy: 1.297, kl: 11.657, loss: 4.153\n",
      " 35%|███▌      | 352/1000 [14:08<34:17,  3.18s/it]INFO:root:global_step: 352, logpy: 2.296, kl: 11.662, loss: 3.185\n",
      " 35%|███▌      | 353/1000 [14:11<33:43,  3.13s/it]INFO:root:global_step: 353, logpy: 3.272, kl: 11.669, loss: 2.241\n",
      " 35%|███▌      | 354/1000 [14:14<32:51,  3.05s/it]INFO:root:global_step: 354, logpy: 4.193, kl: 11.677, loss: 1.354\n",
      " 36%|███▌      | 355/1000 [14:17<32:18,  3.01s/it]INFO:root:global_step: 355, logpy: 5.124, kl: 11.687, loss: 0.457\n",
      " 36%|███▌      | 356/1000 [14:20<32:08,  2.99s/it]INFO:root:global_step: 356, logpy: 6.062, kl: 11.696, loss: -0.446\n",
      " 36%|███▌      | 357/1000 [14:23<31:39,  2.95s/it]INFO:root:global_step: 357, logpy: 6.950, kl: 11.707, loss: -1.299\n",
      " 36%|███▌      | 358/1000 [14:26<31:24,  2.93s/it]INFO:root:global_step: 358, logpy: 7.901, kl: 11.714, loss: -2.217\n",
      " 36%|███▌      | 359/1000 [14:28<31:16,  2.93s/it]INFO:root:global_step: 359, logpy: 8.827, kl: 11.721, loss: -3.111\n",
      " 36%|███▌      | 360/1000 [14:31<31:05,  2.92s/it]INFO:root:global_step: 360, logpy: 9.713, kl: 11.732, loss: -3.962\n",
      " 36%|███▌      | 361/1000 [14:34<30:54,  2.90s/it]INFO:root:global_step: 361, logpy: 10.641, kl: 11.741, loss: -4.856\n",
      " 36%|███▌      | 362/1000 [14:37<30:44,  2.89s/it]INFO:root:global_step: 362, logpy: 11.548, kl: 11.750, loss: -5.729\n",
      " 36%|███▋      | 363/1000 [14:40<30:54,  2.91s/it]INFO:root:global_step: 363, logpy: 12.409, kl: 11.759, loss: -6.556\n",
      " 36%|███▋      | 364/1000 [14:43<30:39,  2.89s/it]INFO:root:global_step: 364, logpy: 13.331, kl: 11.769, loss: -7.443\n",
      " 36%|███▋      | 365/1000 [14:46<30:28,  2.88s/it]INFO:root:global_step: 365, logpy: 14.226, kl: 11.779, loss: -8.304\n",
      " 37%|███▋      | 366/1000 [14:49<30:11,  2.86s/it]INFO:root:global_step: 366, logpy: 15.136, kl: 11.791, loss: -9.178\n",
      " 37%|███▋      | 367/1000 [14:51<30:12,  2.86s/it]INFO:root:global_step: 367, logpy: 16.049, kl: 11.801, loss: -10.056\n",
      " 37%|███▋      | 368/1000 [14:54<30:15,  2.87s/it]INFO:root:global_step: 368, logpy: 16.921, kl: 11.815, loss: -10.890\n",
      " 37%|███▋      | 369/1000 [14:57<30:16,  2.88s/it]INFO:root:global_step: 369, logpy: 17.829, kl: 11.824, loss: -11.765\n",
      " 37%|███▋      | 370/1000 [15:00<30:22,  2.89s/it]INFO:root:global_step: 370, logpy: 18.738, kl: 11.837, loss: -12.636\n",
      " 37%|███▋      | 371/1000 [15:03<30:19,  2.89s/it]INFO:root:global_step: 371, logpy: 19.595, kl: 11.849, loss: -13.457\n",
      " 37%|███▋      | 372/1000 [15:06<30:11,  2.88s/it]INFO:root:global_step: 372, logpy: 20.487, kl: 11.862, loss: -14.313\n",
      " 37%|███▋      | 373/1000 [15:09<30:05,  2.88s/it]INFO:root:global_step: 373, logpy: 21.296, kl: 11.876, loss: -15.085\n",
      " 37%|███▋      | 374/1000 [15:12<30:25,  2.92s/it]INFO:root:global_step: 374, logpy: 22.164, kl: 11.887, loss: -15.917\n",
      " 38%|███▊      | 375/1000 [15:15<30:14,  2.90s/it]INFO:root:global_step: 375, logpy: 23.044, kl: 11.901, loss: -16.760\n",
      " 38%|███▊      | 376/1000 [15:17<30:07,  2.90s/it]INFO:root:global_step: 376, logpy: 23.791, kl: 11.913, loss: -17.471\n",
      " 38%|███▊      | 377/1000 [15:20<30:04,  2.90s/it]INFO:root:global_step: 377, logpy: 24.609, kl: 11.926, loss: -18.253\n",
      " 38%|███▊      | 378/1000 [15:23<30:03,  2.90s/it]INFO:root:global_step: 378, logpy: 25.404, kl: 11.937, loss: -19.012\n",
      " 38%|███▊      | 379/1000 [15:26<30:03,  2.90s/it]INFO:root:global_step: 379, logpy: 26.173, kl: 11.948, loss: -19.746\n",
      " 38%|███▊      | 380/1000 [15:29<29:58,  2.90s/it]INFO:root:global_step: 380, logpy: 27.066, kl: 11.958, loss: -20.605\n",
      " 38%|███▊      | 381/1000 [15:32<29:55,  2.90s/it]INFO:root:global_step: 381, logpy: 27.859, kl: 11.969, loss: -21.362\n",
      " 38%|███▊      | 382/1000 [15:35<29:47,  2.89s/it]INFO:root:global_step: 382, logpy: 28.659, kl: 11.980, loss: -22.127\n",
      " 38%|███▊      | 383/1000 [15:38<29:37,  2.88s/it]INFO:root:global_step: 383, logpy: 29.480, kl: 11.990, loss: -22.913\n",
      " 38%|███▊      | 384/1000 [15:41<29:39,  2.89s/it]INFO:root:global_step: 384, logpy: 30.296, kl: 12.004, loss: -23.693\n",
      " 38%|███▊      | 385/1000 [15:44<30:14,  2.95s/it]INFO:root:global_step: 385, logpy: 31.105, kl: 12.018, loss: -24.464\n",
      " 39%|███▊      | 386/1000 [15:47<30:18,  2.96s/it]INFO:root:global_step: 386, logpy: 31.875, kl: 12.032, loss: -25.197\n",
      " 39%|███▊      | 387/1000 [15:50<30:31,  2.99s/it]INFO:root:global_step: 387, logpy: 32.638, kl: 12.048, loss: -25.921\n",
      " 39%|███▉      | 388/1000 [15:53<30:12,  2.96s/it]INFO:root:global_step: 388, logpy: 33.397, kl: 12.063, loss: -26.641\n",
      " 39%|███▉      | 389/1000 [15:56<30:34,  3.00s/it]INFO:root:global_step: 389, logpy: 34.166, kl: 12.074, loss: -27.376\n",
      " 39%|███▉      | 390/1000 [15:59<30:43,  3.02s/it]INFO:root:global_step: 390, logpy: 34.936, kl: 12.087, loss: -28.108\n",
      " 39%|███▉      | 391/1000 [16:02<30:32,  3.01s/it]INFO:root:global_step: 391, logpy: 35.706, kl: 12.098, loss: -28.843\n",
      " 39%|███▉      | 392/1000 [16:05<31:24,  3.10s/it]INFO:root:global_step: 392, logpy: 36.443, kl: 12.110, loss: -29.544\n",
      " 39%|███▉      | 393/1000 [16:08<30:50,  3.05s/it]INFO:root:global_step: 393, logpy: 37.217, kl: 12.124, loss: -30.282\n",
      " 39%|███▉      | 394/1000 [16:11<30:53,  3.06s/it]INFO:root:global_step: 394, logpy: 37.977, kl: 12.134, loss: -31.007\n",
      " 40%|███▉      | 395/1000 [16:14<30:52,  3.06s/it]INFO:root:global_step: 395, logpy: 38.717, kl: 12.150, loss: -31.708\n",
      " 40%|███▉      | 396/1000 [16:17<30:43,  3.05s/it]INFO:root:global_step: 396, logpy: 39.449, kl: 12.158, loss: -32.407\n",
      " 40%|███▉      | 397/1000 [16:20<30:19,  3.02s/it]INFO:root:global_step: 397, logpy: 40.182, kl: 12.174, loss: -33.101\n",
      " 40%|███▉      | 398/1000 [16:23<30:04,  3.00s/it]INFO:root:global_step: 398, logpy: 40.898, kl: 12.190, loss: -33.778\n",
      " 40%|███▉      | 399/1000 [16:26<29:55,  2.99s/it]INFO:root:global_step: 399, logpy: 41.597, kl: 12.204, loss: -34.439\n",
      " 40%|████      | 400/1000 [16:29<29:42,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([121, 1])\n",
      "torch.Size([121, 1])\n",
      "torch.Size([121, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saved figure at: ./img_generation/global_step_400.png\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_core/sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 400, logpy: 42.362, kl: 12.215, loss: -35.169\n",
      " 40%|████      | 401/1000 [16:33<33:13,  3.33s/it]INFO:root:global_step: 401, logpy: 43.057, kl: 12.230, loss: -35.825\n",
      " 40%|████      | 402/1000 [16:36<32:30,  3.26s/it]INFO:root:global_step: 402, logpy: 43.758, kl: 12.244, loss: -36.489\n",
      " 40%|████      | 403/1000 [16:39<31:43,  3.19s/it]INFO:root:global_step: 403, logpy: 44.469, kl: 12.257, loss: -37.164\n",
      " 40%|████      | 404/1000 [16:42<30:51,  3.11s/it]INFO:root:global_step: 404, logpy: 45.227, kl: 12.270, loss: -37.884\n",
      " 40%|████      | 405/1000 [16:45<30:08,  3.04s/it]INFO:root:global_step: 405, logpy: 45.890, kl: 12.285, loss: -38.510\n",
      " 41%|████      | 406/1000 [16:48<30:07,  3.04s/it]INFO:root:global_step: 406, logpy: 46.595, kl: 12.296, loss: -39.179\n",
      " 41%|████      | 407/1000 [16:51<29:50,  3.02s/it]INFO:root:global_step: 407, logpy: 47.213, kl: 12.311, loss: -39.759\n",
      " 41%|████      | 408/1000 [16:54<29:35,  3.00s/it]INFO:root:global_step: 408, logpy: 47.863, kl: 12.327, loss: -40.369\n",
      " 41%|████      | 409/1000 [16:57<29:17,  2.97s/it]INFO:root:global_step: 409, logpy: 48.494, kl: 12.347, loss: -40.958\n",
      " 41%|████      | 410/1000 [17:00<29:03,  2.95s/it]INFO:root:global_step: 410, logpy: 49.159, kl: 12.362, loss: -41.585\n",
      " 41%|████      | 411/1000 [17:03<28:55,  2.95s/it]INFO:root:global_step: 411, logpy: 49.765, kl: 12.375, loss: -42.153\n",
      " 41%|████      | 412/1000 [17:06<29:01,  2.96s/it]INFO:root:global_step: 412, logpy: 50.381, kl: 12.391, loss: -42.730\n",
      " 41%|████▏     | 413/1000 [17:09<28:54,  2.95s/it]INFO:root:global_step: 413, logpy: 51.006, kl: 12.404, loss: -43.319\n",
      " 41%|████▏     | 414/1000 [17:12<29:00,  2.97s/it]INFO:root:global_step: 414, logpy: 51.670, kl: 12.419, loss: -43.944\n",
      " 42%|████▏     | 415/1000 [17:15<28:52,  2.96s/it]INFO:root:global_step: 415, logpy: 52.305, kl: 12.436, loss: -44.539\n",
      " 42%|████▏     | 416/1000 [17:18<28:42,  2.95s/it]INFO:root:global_step: 416, logpy: 52.958, kl: 12.452, loss: -45.152\n",
      " 42%|████▏     | 417/1000 [17:21<28:56,  2.98s/it]INFO:root:global_step: 417, logpy: 53.626, kl: 12.466, loss: -45.783\n",
      " 42%|████▏     | 418/1000 [17:24<28:39,  2.95s/it]INFO:root:global_step: 418, logpy: 54.225, kl: 12.481, loss: -46.343\n",
      " 42%|████▏     | 419/1000 [17:27<28:35,  2.95s/it]INFO:root:global_step: 419, logpy: 54.872, kl: 12.498, loss: -46.950\n",
      " 42%|████▏     | 420/1000 [17:29<28:31,  2.95s/it]INFO:root:global_step: 420, logpy: 55.479, kl: 12.510, loss: -47.520\n",
      " 42%|████▏     | 421/1000 [17:33<28:49,  2.99s/it]INFO:root:global_step: 421, logpy: 56.078, kl: 12.527, loss: -48.079\n",
      " 42%|████▏     | 422/1000 [17:36<28:43,  2.98s/it]INFO:root:global_step: 422, logpy: 56.619, kl: 12.545, loss: -48.580\n",
      " 42%|████▏     | 423/1000 [17:38<28:32,  2.97s/it]INFO:root:global_step: 423, logpy: 57.222, kl: 12.559, loss: -49.144\n",
      " 42%|████▏     | 424/1000 [17:41<28:34,  2.98s/it]INFO:root:global_step: 424, logpy: 57.853, kl: 12.571, loss: -49.740\n",
      " 42%|████▎     | 425/1000 [17:45<28:51,  3.01s/it]INFO:root:global_step: 425, logpy: 58.465, kl: 12.583, loss: -50.315\n",
      " 43%|████▎     | 426/1000 [17:48<28:45,  3.01s/it]INFO:root:global_step: 426, logpy: 59.095, kl: 12.597, loss: -50.908\n",
      " 43%|████▎     | 427/1000 [17:50<28:27,  2.98s/it]INFO:root:global_step: 427, logpy: 59.669, kl: 12.612, loss: -51.442\n",
      " 43%|████▎     | 428/1000 [17:53<28:34,  3.00s/it]INFO:root:global_step: 428, logpy: 60.267, kl: 12.626, loss: -52.002\n",
      " 43%|████▎     | 429/1000 [17:56<28:25,  2.99s/it]INFO:root:global_step: 429, logpy: 60.846, kl: 12.646, loss: -52.538\n",
      " 43%|████▎     | 430/1000 [17:59<28:10,  2.97s/it]INFO:root:global_step: 430, logpy: 61.426, kl: 12.662, loss: -53.079\n",
      " 43%|████▎     | 431/1000 [18:02<28:02,  2.96s/it]INFO:root:global_step: 431, logpy: 62.000, kl: 12.677, loss: -53.614\n",
      " 43%|████▎     | 432/1000 [18:05<28:03,  2.96s/it]INFO:root:global_step: 432, logpy: 62.536, kl: 12.694, loss: -54.109\n",
      " 43%|████▎     | 433/1000 [18:08<28:01,  2.97s/it]INFO:root:global_step: 433, logpy: 63.101, kl: 12.712, loss: -54.632\n",
      " 43%|████▎     | 434/1000 [18:11<28:01,  2.97s/it]INFO:root:global_step: 434, logpy: 63.636, kl: 12.729, loss: -55.126\n",
      " 44%|████▎     | 435/1000 [18:14<27:48,  2.95s/it]INFO:root:global_step: 435, logpy: 64.172, kl: 12.748, loss: -55.620\n",
      " 44%|████▎     | 436/1000 [18:17<27:46,  2.95s/it]INFO:root:global_step: 436, logpy: 64.678, kl: 12.768, loss: -56.083\n",
      " 44%|████▎     | 437/1000 [18:20<27:43,  2.95s/it]INFO:root:global_step: 437, logpy: 65.161, kl: 12.785, loss: -56.525\n",
      " 44%|████▍     | 438/1000 [18:23<27:44,  2.96s/it]INFO:root:global_step: 438, logpy: 65.715, kl: 12.802, loss: -57.038\n",
      " 44%|████▍     | 439/1000 [18:26<27:55,  2.99s/it]INFO:root:global_step: 439, logpy: 66.207, kl: 12.816, loss: -57.492\n",
      " 44%|████▍     | 440/1000 [18:29<27:45,  2.97s/it]INFO:root:global_step: 440, logpy: 66.712, kl: 12.832, loss: -57.958\n",
      " 44%|████▍     | 441/1000 [18:32<28:42,  3.08s/it]INFO:root:global_step: 441, logpy: 67.215, kl: 12.847, loss: -58.421\n",
      " 44%|████▍     | 442/1000 [18:35<28:49,  3.10s/it]INFO:root:global_step: 442, logpy: 67.751, kl: 12.862, loss: -58.918\n",
      " 44%|████▍     | 443/1000 [18:39<28:39,  3.09s/it]INFO:root:global_step: 443, logpy: 68.272, kl: 12.877, loss: -59.399\n",
      " 44%|████▍     | 444/1000 [18:42<28:22,  3.06s/it]INFO:root:global_step: 444, logpy: 68.812, kl: 12.893, loss: -59.900\n",
      " 44%|████▍     | 445/1000 [18:45<28:12,  3.05s/it]INFO:root:global_step: 445, logpy: 69.334, kl: 12.910, loss: -60.380\n",
      " 45%|████▍     | 446/1000 [18:48<27:57,  3.03s/it]INFO:root:global_step: 446, logpy: 69.865, kl: 12.928, loss: -60.870\n",
      " 45%|████▍     | 447/1000 [18:51<27:44,  3.01s/it]INFO:root:global_step: 447, logpy: 70.376, kl: 12.947, loss: -61.337\n",
      " 45%|████▍     | 448/1000 [18:54<27:37,  3.00s/it]INFO:root:global_step: 448, logpy: 70.860, kl: 12.967, loss: -61.778\n",
      " 45%|████▍     | 449/1000 [18:56<27:27,  2.99s/it]INFO:root:global_step: 449, logpy: 71.338, kl: 12.983, loss: -62.216\n",
      " 45%|████▌     | 450/1000 [19:00<27:45,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([121, 1])\n",
      "torch.Size([121, 1])\n",
      "torch.Size([121, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saved figure at: ./img_generation/global_step_450.png\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_core/sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 450, logpy: 71.799, kl: 13.000, loss: -62.635\n",
      " 45%|████▌     | 451/1000 [19:04<31:03,  3.39s/it]INFO:root:global_step: 451, logpy: 72.196, kl: 13.017, loss: -62.991\n",
      " 45%|████▌     | 452/1000 [19:07<30:08,  3.30s/it]INFO:root:global_step: 452, logpy: 72.672, kl: 13.034, loss: -63.426\n",
      " 45%|████▌     | 453/1000 [19:10<29:51,  3.27s/it]INFO:root:global_step: 453, logpy: 73.166, kl: 13.050, loss: -63.879\n",
      " 45%|████▌     | 454/1000 [19:13<29:13,  3.21s/it]INFO:root:global_step: 454, logpy: 73.632, kl: 13.064, loss: -64.306\n",
      " 46%|████▌     | 455/1000 [19:16<28:35,  3.15s/it]INFO:root:global_step: 455, logpy: 74.096, kl: 13.080, loss: -64.730\n",
      " 46%|████▌     | 456/1000 [19:19<28:02,  3.09s/it]INFO:root:global_step: 456, logpy: 74.544, kl: 13.100, loss: -65.134\n",
      " 46%|████▌     | 457/1000 [19:22<27:43,  3.06s/it]INFO:root:global_step: 457, logpy: 75.039, kl: 13.115, loss: -65.589\n",
      " 46%|████▌     | 458/1000 [19:25<27:28,  3.04s/it]INFO:root:global_step: 458, logpy: 75.444, kl: 13.135, loss: -65.950\n",
      " 46%|████▌     | 459/1000 [19:28<27:22,  3.04s/it]INFO:root:global_step: 459, logpy: 75.816, kl: 13.150, loss: -66.283\n",
      " 46%|████▌     | 460/1000 [19:31<27:30,  3.06s/it]INFO:root:global_step: 460, logpy: 76.233, kl: 13.169, loss: -66.656\n",
      " 46%|████▌     | 461/1000 [19:34<27:11,  3.03s/it]INFO:root:global_step: 461, logpy: 76.658, kl: 13.187, loss: -67.039\n",
      " 46%|████▌     | 462/1000 [19:37<27:02,  3.02s/it]INFO:root:global_step: 462, logpy: 77.060, kl: 13.206, loss: -67.397\n",
      " 46%|████▋     | 463/1000 [19:40<26:56,  3.01s/it]INFO:root:global_step: 463, logpy: 77.492, kl: 13.227, loss: -67.783\n",
      " 46%|████▋     | 464/1000 [19:43<27:03,  3.03s/it]INFO:root:global_step: 464, logpy: 77.972, kl: 13.243, loss: -68.223\n",
      " 46%|████▋     | 465/1000 [19:46<27:23,  3.07s/it]INFO:root:global_step: 465, logpy: 78.435, kl: 13.258, loss: -68.646\n",
      " 47%|████▋     | 466/1000 [19:50<27:22,  3.08s/it]INFO:root:global_step: 466, logpy: 78.898, kl: 13.273, loss: -69.069\n",
      " 47%|████▋     | 467/1000 [19:53<27:08,  3.06s/it]INFO:root:global_step: 467, logpy: 79.322, kl: 13.289, loss: -69.452\n",
      " 47%|████▋     | 468/1000 [19:56<27:28,  3.10s/it]INFO:root:global_step: 468, logpy: 79.760, kl: 13.307, loss: -69.847\n",
      " 47%|████▋     | 469/1000 [19:59<27:46,  3.14s/it]INFO:root:global_step: 469, logpy: 80.165, kl: 13.322, loss: -70.213\n",
      " 47%|████▋     | 470/1000 [20:02<28:14,  3.20s/it]INFO:root:global_step: 470, logpy: 80.596, kl: 13.338, loss: -70.601\n",
      " 47%|████▋     | 471/1000 [20:05<28:03,  3.18s/it]INFO:root:global_step: 471, logpy: 81.007, kl: 13.353, loss: -70.973\n",
      " 47%|████▋     | 472/1000 [20:09<29:49,  3.39s/it]INFO:root:global_step: 472, logpy: 81.469, kl: 13.370, loss: -71.392\n",
      " 47%|████▋     | 473/1000 [20:13<29:27,  3.35s/it]INFO:root:global_step: 473, logpy: 81.864, kl: 13.388, loss: -71.745\n",
      " 47%|████▋     | 474/1000 [20:16<28:37,  3.26s/it]INFO:root:global_step: 474, logpy: 82.243, kl: 13.411, loss: -72.076\n",
      " 48%|████▊     | 475/1000 [20:19<28:24,  3.25s/it]INFO:root:global_step: 475, logpy: 82.654, kl: 13.432, loss: -72.441\n",
      " 48%|████▊     | 476/1000 [20:22<28:40,  3.28s/it]INFO:root:global_step: 476, logpy: 83.076, kl: 13.447, loss: -72.822\n",
      " 48%|████▊     | 477/1000 [20:26<28:45,  3.30s/it]INFO:root:global_step: 477, logpy: 83.488, kl: 13.467, loss: -73.189\n",
      " 48%|████▊     | 478/1000 [20:29<28:50,  3.32s/it]INFO:root:global_step: 478, logpy: 83.863, kl: 13.486, loss: -73.519\n",
      " 48%|████▊     | 479/1000 [20:32<28:18,  3.26s/it]INFO:root:global_step: 479, logpy: 84.291, kl: 13.508, loss: -73.900\n",
      " 48%|████▊     | 480/1000 [20:35<28:13,  3.26s/it]INFO:root:global_step: 480, logpy: 84.697, kl: 13.527, loss: -74.263\n",
      " 48%|████▊     | 481/1000 [20:38<27:54,  3.23s/it]INFO:root:global_step: 481, logpy: 85.113, kl: 13.545, loss: -74.635\n",
      " 48%|████▊     | 482/1000 [20:42<28:15,  3.27s/it]INFO:root:global_step: 482, logpy: 85.512, kl: 13.563, loss: -74.991\n",
      " 48%|████▊     | 483/1000 [20:45<28:14,  3.28s/it]INFO:root:global_step: 483, logpy: 85.931, kl: 13.584, loss: -75.363\n",
      " 48%|████▊     | 484/1000 [20:48<27:40,  3.22s/it]INFO:root:global_step: 484, logpy: 86.282, kl: 13.603, loss: -75.670\n",
      " 48%|████▊     | 485/1000 [20:51<27:23,  3.19s/it]INFO:root:global_step: 485, logpy: 86.629, kl: 13.620, loss: -75.975\n",
      " 49%|████▊     | 486/1000 [20:54<26:57,  3.15s/it]INFO:root:global_step: 486, logpy: 87.018, kl: 13.637, loss: -76.321\n",
      " 49%|████▊     | 487/1000 [20:57<26:36,  3.11s/it]INFO:root:global_step: 487, logpy: 87.361, kl: 13.658, loss: -76.617\n",
      " 49%|████▉     | 488/1000 [21:00<26:13,  3.07s/it]INFO:root:global_step: 488, logpy: 87.747, kl: 13.684, loss: -76.952\n",
      " 49%|████▉     | 489/1000 [21:03<25:52,  3.04s/it]INFO:root:global_step: 489, logpy: 88.112, kl: 13.701, loss: -77.274\n",
      " 49%|████▉     | 490/1000 [21:06<25:47,  3.03s/it]INFO:root:global_step: 490, logpy: 88.489, kl: 13.713, loss: -77.612\n",
      " 49%|████▉     | 491/1000 [21:09<25:51,  3.05s/it]INFO:root:global_step: 491, logpy: 88.830, kl: 13.732, loss: -77.908\n",
      " 49%|████▉     | 492/1000 [21:12<25:42,  3.04s/it]INFO:root:global_step: 492, logpy: 89.220, kl: 13.750, loss: -78.254\n",
      " 49%|████▉     | 493/1000 [21:16<25:50,  3.06s/it]INFO:root:global_step: 493, logpy: 89.561, kl: 13.769, loss: -78.551\n",
      " 49%|████▉     | 494/1000 [21:19<25:38,  3.04s/it]INFO:root:global_step: 494, logpy: 89.910, kl: 13.785, loss: -78.858\n",
      " 50%|████▉     | 495/1000 [21:22<25:43,  3.06s/it]INFO:root:global_step: 495, logpy: 90.255, kl: 13.807, loss: -79.155\n",
      " 50%|████▉     | 496/1000 [21:25<25:39,  3.05s/it]INFO:root:global_step: 496, logpy: 90.549, kl: 13.828, loss: -79.402\n",
      " 50%|████▉     | 497/1000 [21:28<25:40,  3.06s/it]INFO:root:global_step: 497, logpy: 90.903, kl: 13.849, loss: -79.708\n",
      " 50%|████▉     | 498/1000 [21:31<26:10,  3.13s/it]INFO:root:global_step: 498, logpy: 91.185, kl: 13.866, loss: -79.948\n",
      " 50%|████▉     | 499/1000 [21:34<26:03,  3.12s/it]INFO:root:global_step: 499, logpy: 91.518, kl: 13.885, loss: -80.236\n",
      " 50%|█████     | 500/1000 [21:38<26:35,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([121, 1])\n",
      "torch.Size([121, 1])\n",
      "torch.Size([121, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saved figure at: ./img_generation/global_step_500.png\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_core/sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 500, logpy: 91.844, kl: 13.905, loss: -80.515\n",
      " 50%|█████     | 501/1000 [21:42<30:22,  3.65s/it]INFO:root:global_step: 501, logpy: 92.173, kl: 13.924, loss: -80.799\n",
      " 50%|█████     | 502/1000 [21:46<29:16,  3.53s/it]INFO:root:global_step: 502, logpy: 92.537, kl: 13.943, loss: -81.119\n",
      " 50%|█████     | 503/1000 [21:49<28:29,  3.44s/it]INFO:root:global_step: 503, logpy: 92.824, kl: 13.963, loss: -81.360\n",
      " 50%|█████     | 504/1000 [21:52<27:56,  3.38s/it]INFO:root:global_step: 504, logpy: 93.162, kl: 13.979, loss: -81.658\n",
      " 50%|█████     | 505/1000 [21:55<27:19,  3.31s/it]INFO:root:global_step: 505, logpy: 93.508, kl: 13.997, loss: -81.961\n",
      " 51%|█████     | 506/1000 [21:58<26:39,  3.24s/it]INFO:root:global_step: 506, logpy: 93.831, kl: 14.011, loss: -82.244\n",
      " 51%|█████     | 507/1000 [22:01<26:06,  3.18s/it]INFO:root:global_step: 507, logpy: 94.161, kl: 14.028, loss: -82.533\n",
      " 51%|█████     | 508/1000 [22:04<25:52,  3.16s/it]INFO:root:global_step: 508, logpy: 94.469, kl: 14.049, loss: -82.796\n",
      " 51%|█████     | 509/1000 [22:07<25:31,  3.12s/it]INFO:root:global_step: 509, logpy: 94.777, kl: 14.063, loss: -83.068\n",
      " 51%|█████     | 510/1000 [22:11<26:08,  3.20s/it]INFO:root:global_step: 510, logpy: 95.110, kl: 14.081, loss: -83.358\n",
      " 51%|█████     | 511/1000 [22:14<26:12,  3.22s/it]INFO:root:global_step: 511, logpy: 95.433, kl: 14.100, loss: -83.639\n",
      " 51%|█████     | 512/1000 [22:17<26:04,  3.21s/it]INFO:root:global_step: 512, logpy: 95.785, kl: 14.119, loss: -83.950\n",
      " 51%|█████▏    | 513/1000 [22:21<26:29,  3.26s/it]INFO:root:global_step: 513, logpy: 96.109, kl: 14.134, loss: -84.235\n",
      " 51%|█████▏    | 514/1000 [22:24<27:07,  3.35s/it]INFO:root:global_step: 514, logpy: 96.397, kl: 14.154, loss: -84.480\n",
      " 52%|█████▏    | 515/1000 [22:28<27:10,  3.36s/it]INFO:root:global_step: 515, logpy: 96.730, kl: 14.172, loss: -84.773\n",
      " 52%|█████▏    | 516/1000 [22:31<27:00,  3.35s/it]INFO:root:global_step: 516, logpy: 97.059, kl: 14.185, loss: -85.067\n",
      " 52%|█████▏    | 517/1000 [22:34<26:25,  3.28s/it]INFO:root:global_step: 517, logpy: 97.374, kl: 14.207, loss: -85.339\n",
      " 52%|█████▏    | 518/1000 [22:37<25:45,  3.21s/it]INFO:root:global_step: 518, logpy: 97.664, kl: 14.224, loss: -85.590\n",
      " 52%|█████▏    | 519/1000 [22:40<25:20,  3.16s/it]INFO:root:global_step: 519, logpy: 98.015, kl: 14.245, loss: -85.898\n",
      " 52%|█████▏    | 520/1000 [22:43<25:03,  3.13s/it]INFO:root:global_step: 520, logpy: 98.304, kl: 14.263, loss: -86.148\n",
      " 52%|█████▏    | 521/1000 [22:46<24:53,  3.12s/it]INFO:root:global_step: 521, logpy: 98.613, kl: 14.280, loss: -86.419\n",
      " 52%|█████▏    | 522/1000 [22:49<24:58,  3.13s/it]INFO:root:global_step: 522, logpy: 98.960, kl: 14.302, loss: -86.723\n",
      " 52%|█████▏    | 523/1000 [22:53<24:50,  3.12s/it]INFO:root:global_step: 523, logpy: 99.225, kl: 14.320, loss: -86.949\n",
      " 52%|█████▏    | 524/1000 [22:56<24:46,  3.12s/it]INFO:root:global_step: 524, logpy: 99.506, kl: 14.337, loss: -87.193\n",
      " 52%|█████▎    | 525/1000 [22:59<24:55,  3.15s/it]INFO:root:global_step: 525, logpy: 99.781, kl: 14.354, loss: -87.431\n",
      " 53%|█████▎    | 526/1000 [23:02<24:50,  3.15s/it]INFO:root:global_step: 526, logpy: 100.069, kl: 14.373, loss: -87.680\n",
      " 53%|█████▎    | 527/1000 [23:05<24:32,  3.11s/it]INFO:root:global_step: 527, logpy: 100.347, kl: 14.390, loss: -87.921\n",
      " 53%|█████▎    | 528/1000 [23:08<24:21,  3.10s/it]INFO:root:global_step: 528, logpy: 100.629, kl: 14.407, loss: -88.166\n",
      " 53%|█████▎    | 529/1000 [23:11<24:27,  3.11s/it]INFO:root:global_step: 529, logpy: 100.956, kl: 14.427, loss: -88.454\n",
      " 53%|█████▎    | 530/1000 [23:14<24:15,  3.10s/it]INFO:root:global_step: 530, logpy: 101.226, kl: 14.445, loss: -88.686\n",
      " 53%|█████▎    | 531/1000 [23:17<24:13,  3.10s/it]INFO:root:global_step: 531, logpy: 101.542, kl: 14.462, loss: -88.966\n",
      " 53%|█████▎    | 532/1000 [23:20<24:02,  3.08s/it]INFO:root:global_step: 532, logpy: 101.847, kl: 14.480, loss: -89.235\n",
      " 53%|█████▎    | 533/1000 [23:23<23:55,  3.07s/it]INFO:root:global_step: 533, logpy: 102.108, kl: 14.496, loss: -89.461\n",
      " 53%|█████▎    | 534/1000 [23:27<23:56,  3.08s/it]INFO:root:global_step: 534, logpy: 102.381, kl: 14.517, loss: -89.694\n",
      " 54%|█████▎    | 535/1000 [23:30<23:43,  3.06s/it]INFO:root:global_step: 535, logpy: 102.615, kl: 14.534, loss: -89.893\n",
      " 54%|█████▎    | 536/1000 [23:33<23:41,  3.06s/it]INFO:root:global_step: 536, logpy: 102.891, kl: 14.552, loss: -90.133\n",
      " 54%|█████▎    | 537/1000 [23:36<23:55,  3.10s/it]INFO:root:global_step: 537, logpy: 103.207, kl: 14.566, loss: -90.417\n",
      " 54%|█████▍    | 538/1000 [23:39<23:49,  3.09s/it]INFO:root:global_step: 538, logpy: 103.421, kl: 14.588, loss: -90.591\n",
      " 54%|█████▍    | 539/1000 [23:42<23:55,  3.11s/it]INFO:root:global_step: 539, logpy: 103.700, kl: 14.607, loss: -90.834\n",
      " 54%|█████▍    | 540/1000 [23:45<24:14,  3.16s/it]INFO:root:global_step: 540, logpy: 103.955, kl: 14.626, loss: -91.053\n",
      " 54%|█████▍    | 541/1000 [23:48<24:03,  3.15s/it]INFO:root:global_step: 541, logpy: 104.229, kl: 14.644, loss: -91.290\n",
      " 54%|█████▍    | 542/1000 [23:52<23:46,  3.11s/it]INFO:root:global_step: 542, logpy: 104.514, kl: 14.658, loss: -91.546\n",
      " 54%|█████▍    | 543/1000 [23:55<23:39,  3.11s/it]INFO:root:global_step: 543, logpy: 104.757, kl: 14.676, loss: -91.754\n",
      " 54%|█████▍    | 544/1000 [23:58<23:38,  3.11s/it]INFO:root:global_step: 544, logpy: 105.027, kl: 14.694, loss: -91.988\n",
      " 55%|█████▍    | 545/1000 [24:01<23:26,  3.09s/it]INFO:root:global_step: 545, logpy: 105.261, kl: 14.714, loss: -92.186\n",
      " 55%|█████▍    | 546/1000 [24:04<23:16,  3.08s/it]INFO:root:global_step: 546, logpy: 105.499, kl: 14.732, loss: -92.390\n",
      " 55%|█████▍    | 547/1000 [24:07<23:15,  3.08s/it]INFO:root:global_step: 547, logpy: 105.765, kl: 14.751, loss: -92.620\n",
      " 55%|█████▍    | 548/1000 [24:10<23:30,  3.12s/it]INFO:root:global_step: 548, logpy: 105.987, kl: 14.770, loss: -92.807\n",
      " 55%|█████▍    | 549/1000 [24:13<23:31,  3.13s/it]INFO:root:global_step: 549, logpy: 106.189, kl: 14.786, loss: -92.977\n",
      " 55%|█████▌    | 550/1000 [24:16<23:21,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([121, 1])\n",
      "torch.Size([121, 1])\n",
      "torch.Size([121, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saved figure at: ./img_generation/global_step_550.png\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_core/sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 550, logpy: 106.421, kl: 14.802, loss: -93.178\n",
      " 55%|█████▌    | 551/1000 [24:21<26:22,  3.52s/it]INFO:root:global_step: 551, logpy: 106.690, kl: 14.819, loss: -93.414\n",
      " 55%|█████▌    | 552/1000 [24:24<25:23,  3.40s/it]INFO:root:global_step: 552, logpy: 106.937, kl: 14.835, loss: -93.629\n",
      " 55%|█████▌    | 553/1000 [24:27<25:05,  3.37s/it]INFO:root:global_step: 553, logpy: 107.179, kl: 14.853, loss: -93.838\n",
      " 55%|█████▌    | 554/1000 [24:30<24:34,  3.31s/it]INFO:root:global_step: 554, logpy: 107.439, kl: 14.871, loss: -94.065\n",
      " 56%|█████▌    | 555/1000 [24:33<24:01,  3.24s/it]INFO:root:global_step: 555, logpy: 107.681, kl: 14.891, loss: -94.272\n",
      " 56%|█████▌    | 556/1000 [24:37<23:31,  3.18s/it]INFO:root:global_step: 556, logpy: 107.901, kl: 14.909, loss: -94.459\n",
      " 56%|█████▌    | 557/1000 [24:40<23:14,  3.15s/it]INFO:root:global_step: 557, logpy: 108.147, kl: 14.928, loss: -94.671\n",
      " 56%|█████▌    | 558/1000 [24:43<23:13,  3.15s/it]INFO:root:global_step: 558, logpy: 108.384, kl: 14.946, loss: -94.875\n",
      " 56%|█████▌    | 559/1000 [24:46<22:56,  3.12s/it]INFO:root:global_step: 559, logpy: 108.593, kl: 14.968, loss: -95.049\n",
      " 56%|█████▌    | 560/1000 [24:49<22:46,  3.11s/it]INFO:root:global_step: 560, logpy: 108.822, kl: 14.986, loss: -95.245\n",
      " 56%|█████▌    | 561/1000 [24:52<22:41,  3.10s/it]INFO:root:global_step: 561, logpy: 109.095, kl: 15.005, loss: -95.485\n",
      " 56%|█████▌    | 562/1000 [24:55<22:44,  3.12s/it]INFO:root:global_step: 562, logpy: 109.335, kl: 15.027, loss: -95.689\n",
      " 56%|█████▋    | 563/1000 [24:58<22:38,  3.11s/it]INFO:root:global_step: 563, logpy: 109.561, kl: 15.045, loss: -95.883\n",
      " 56%|█████▋    | 564/1000 [25:01<22:41,  3.12s/it]INFO:root:global_step: 564, logpy: 109.795, kl: 15.057, loss: -96.092\n",
      " 56%|█████▋    | 565/1000 [25:05<22:42,  3.13s/it]INFO:root:global_step: 565, logpy: 109.989, kl: 15.080, loss: -96.249\n",
      " 57%|█████▋    | 566/1000 [25:08<22:40,  3.14s/it]INFO:root:global_step: 566, logpy: 110.210, kl: 15.099, loss: -96.438\n",
      " 57%|█████▋    | 567/1000 [25:11<22:46,  3.15s/it]INFO:root:global_step: 567, logpy: 110.447, kl: 15.116, loss: -96.645\n",
      " 57%|█████▋    | 568/1000 [25:14<22:48,  3.17s/it]INFO:root:global_step: 568, logpy: 110.653, kl: 15.135, loss: -96.819\n",
      " 57%|█████▋    | 569/1000 [25:17<22:46,  3.17s/it]INFO:root:global_step: 569, logpy: 110.886, kl: 15.151, loss: -97.023\n",
      " 57%|█████▋    | 570/1000 [25:20<22:52,  3.19s/it]INFO:root:global_step: 570, logpy: 111.079, kl: 15.168, loss: -97.185\n",
      " 57%|█████▋    | 571/1000 [25:24<22:34,  3.16s/it]INFO:root:global_step: 571, logpy: 111.272, kl: 15.190, loss: -97.343\n",
      " 57%|█████▋    | 572/1000 [25:27<22:24,  3.14s/it]INFO:root:global_step: 572, logpy: 111.461, kl: 15.210, loss: -97.500\n",
      " 57%|█████▋    | 573/1000 [25:30<22:16,  3.13s/it]INFO:root:global_step: 573, logpy: 111.674, kl: 15.230, loss: -97.681\n",
      " 57%|█████▋    | 574/1000 [25:33<22:08,  3.12s/it]INFO:root:global_step: 574, logpy: 111.874, kl: 15.250, loss: -97.848\n",
      " 57%|█████▊    | 575/1000 [25:36<22:03,  3.11s/it]INFO:root:global_step: 575, logpy: 112.095, kl: 15.268, loss: -98.039\n",
      " 58%|█████▊    | 576/1000 [25:39<21:52,  3.09s/it]INFO:root:global_step: 576, logpy: 112.259, kl: 15.287, loss: -98.173\n",
      " 58%|█████▊    | 577/1000 [25:42<22:00,  3.12s/it]INFO:root:global_step: 577, logpy: 112.440, kl: 15.305, loss: -98.324\n",
      " 58%|█████▊    | 578/1000 [25:45<22:12,  3.16s/it]INFO:root:global_step: 578, logpy: 112.606, kl: 15.324, loss: -98.458\n",
      " 58%|█████▊    | 579/1000 [25:49<22:11,  3.16s/it]INFO:root:global_step: 579, logpy: 112.790, kl: 15.346, loss: -98.608\n",
      " 58%|█████▊    | 580/1000 [25:52<21:56,  3.13s/it]INFO:root:global_step: 580, logpy: 112.991, kl: 15.366, loss: -98.777\n",
      " 58%|█████▊    | 581/1000 [25:55<21:40,  3.10s/it]INFO:root:global_step: 581, logpy: 113.168, kl: 15.388, loss: -98.922\n",
      " 58%|█████▊    | 582/1000 [25:58<21:49,  3.13s/it]INFO:root:global_step: 582, logpy: 113.357, kl: 15.403, loss: -99.084\n",
      " 58%|█████▊    | 583/1000 [26:01<21:49,  3.14s/it]INFO:root:global_step: 583, logpy: 113.516, kl: 15.424, loss: -99.210\n",
      " 58%|█████▊    | 584/1000 [26:04<21:42,  3.13s/it]INFO:root:global_step: 584, logpy: 113.703, kl: 15.443, loss: -99.366\n",
      " 58%|█████▊    | 585/1000 [26:07<21:31,  3.11s/it]INFO:root:global_step: 585, logpy: 113.917, kl: 15.462, loss: -99.550\n",
      " 59%|█████▊    | 586/1000 [26:10<21:30,  3.12s/it]INFO:root:global_step: 586, logpy: 114.079, kl: 15.484, loss: -99.679\n",
      " 59%|█████▊    | 587/1000 [26:13<21:22,  3.11s/it]INFO:root:global_step: 587, logpy: 114.254, kl: 15.505, loss: -99.823\n",
      " 59%|█████▉    | 588/1000 [26:17<21:16,  3.10s/it]INFO:root:global_step: 588, logpy: 114.416, kl: 15.526, loss: -99.954\n",
      " 59%|█████▉    | 589/1000 [26:20<21:08,  3.09s/it]INFO:root:global_step: 589, logpy: 114.621, kl: 15.543, loss: -100.131\n",
      " 59%|█████▉    | 590/1000 [26:23<21:12,  3.10s/it]INFO:root:global_step: 590, logpy: 114.788, kl: 15.560, loss: -100.271\n",
      " 59%|█████▉    | 591/1000 [26:26<21:13,  3.11s/it]INFO:root:global_step: 591, logpy: 114.994, kl: 15.580, loss: -100.446\n",
      " 59%|█████▉    | 592/1000 [26:29<21:01,  3.09s/it]INFO:root:global_step: 592, logpy: 115.152, kl: 15.598, loss: -100.576\n",
      " 59%|█████▉    | 593/1000 [26:32<21:01,  3.10s/it]INFO:root:global_step: 593, logpy: 115.332, kl: 15.612, loss: -100.731\n",
      " 59%|█████▉    | 594/1000 [26:35<21:15,  3.14s/it]INFO:root:global_step: 594, logpy: 115.534, kl: 15.627, loss: -100.908\n",
      " 60%|█████▉    | 595/1000 [26:38<21:14,  3.15s/it]INFO:root:global_step: 595, logpy: 115.765, kl: 15.646, loss: -101.110\n",
      " 60%|█████▉    | 596/1000 [26:42<21:07,  3.14s/it]INFO:root:global_step: 596, logpy: 116.008, kl: 15.664, loss: -101.325\n",
      " 60%|█████▉    | 597/1000 [26:45<20:57,  3.12s/it]INFO:root:global_step: 597, logpy: 116.210, kl: 15.688, loss: -101.494\n",
      " 60%|█████▉    | 598/1000 [26:48<20:56,  3.12s/it]INFO:root:global_step: 598, logpy: 116.392, kl: 15.709, loss: -101.645\n",
      " 60%|█████▉    | 599/1000 [26:51<20:51,  3.12s/it]INFO:root:global_step: 599, logpy: 116.601, kl: 15.723, loss: -101.830\n",
      " 60%|██████    | 600/1000 [26:54<20:57,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([121, 1])\n",
      "torch.Size([121, 1])\n",
      "torch.Size([121, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saved figure at: ./img_generation/global_step_600.png\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_core/sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 600, logpy: 116.753, kl: 15.743, loss: -101.953\n",
      " 60%|██████    | 601/1000 [26:58<23:17,  3.50s/it]INFO:root:global_step: 601, logpy: 116.934, kl: 15.763, loss: -102.104\n",
      " 60%|██████    | 602/1000 [27:02<22:36,  3.41s/it]INFO:root:global_step: 602, logpy: 117.116, kl: 15.781, loss: -102.260\n",
      " 60%|██████    | 603/1000 [27:05<22:13,  3.36s/it]INFO:root:global_step: 603, logpy: 117.293, kl: 15.797, loss: -102.411\n",
      " 60%|██████    | 604/1000 [27:08<21:44,  3.30s/it]INFO:root:global_step: 604, logpy: 117.462, kl: 15.813, loss: -102.555\n",
      " 60%|██████    | 605/1000 [27:11<21:39,  3.29s/it]INFO:root:global_step: 605, logpy: 117.614, kl: 15.832, loss: -102.679\n",
      " 61%|██████    | 606/1000 [27:14<21:21,  3.25s/it]INFO:root:global_step: 606, logpy: 117.831, kl: 15.849, loss: -102.870\n",
      " 61%|██████    | 607/1000 [27:18<21:03,  3.21s/it]INFO:root:global_step: 607, logpy: 118.006, kl: 15.868, loss: -103.017\n",
      " 61%|██████    | 608/1000 [27:21<20:51,  3.19s/it]INFO:root:global_step: 608, logpy: 118.202, kl: 15.885, loss: -103.187\n",
      " 61%|██████    | 609/1000 [27:24<20:38,  3.17s/it]INFO:root:global_step: 609, logpy: 118.366, kl: 15.903, loss: -103.324\n",
      " 61%|██████    | 610/1000 [27:27<20:26,  3.14s/it]INFO:root:global_step: 610, logpy: 118.547, kl: 15.919, loss: -103.481\n",
      " 61%|██████    | 611/1000 [27:30<20:23,  3.15s/it]INFO:root:global_step: 611, logpy: 118.717, kl: 15.937, loss: -103.625\n",
      " 61%|██████    | 612/1000 [27:33<20:19,  3.14s/it]INFO:root:global_step: 612, logpy: 118.867, kl: 15.953, loss: -103.750\n",
      " 61%|██████▏   | 613/1000 [27:36<20:08,  3.12s/it]INFO:root:global_step: 613, logpy: 119.048, kl: 15.972, loss: -103.904\n",
      " 61%|██████▏   | 614/1000 [27:39<19:56,  3.10s/it]INFO:root:global_step: 614, logpy: 119.212, kl: 15.991, loss: -104.041\n",
      " 62%|██████▏   | 615/1000 [27:43<20:09,  3.14s/it]INFO:root:global_step: 615, logpy: 119.387, kl: 16.012, loss: -104.186\n",
      " 62%|██████▏   | 616/1000 [27:46<20:13,  3.16s/it]INFO:root:global_step: 616, logpy: 119.529, kl: 16.030, loss: -104.302\n",
      " 62%|██████▏   | 617/1000 [27:49<20:08,  3.16s/it]INFO:root:global_step: 617, logpy: 119.699, kl: 16.049, loss: -104.444\n",
      " 62%|██████▏   | 618/1000 [27:52<20:12,  3.17s/it]INFO:root:global_step: 618, logpy: 119.860, kl: 16.067, loss: -104.580\n",
      " 62%|██████▏   | 619/1000 [27:55<20:02,  3.16s/it]INFO:root:global_step: 619, logpy: 120.000, kl: 16.089, loss: -104.690\n",
      " 62%|██████▏   | 620/1000 [27:58<19:53,  3.14s/it]INFO:root:global_step: 620, logpy: 120.153, kl: 16.110, loss: -104.814\n",
      " 62%|██████▏   | 621/1000 [28:01<19:52,  3.15s/it]INFO:root:global_step: 621, logpy: 120.314, kl: 16.129, loss: -104.948\n",
      " 62%|██████▏   | 622/1000 [28:05<19:45,  3.14s/it]INFO:root:global_step: 622, logpy: 120.468, kl: 16.148, loss: -105.076\n",
      " 62%|██████▏   | 623/1000 [28:08<19:47,  3.15s/it]INFO:root:global_step: 623, logpy: 120.634, kl: 16.167, loss: -105.216\n",
      " 62%|██████▏   | 624/1000 [28:11<19:46,  3.16s/it]INFO:root:global_step: 624, logpy: 120.788, kl: 16.183, loss: -105.346\n",
      " 62%|██████▎   | 625/1000 [28:14<19:44,  3.16s/it]INFO:root:global_step: 625, logpy: 120.945, kl: 16.202, loss: -105.477\n",
      " 63%|██████▎   | 626/1000 [28:17<19:32,  3.14s/it]INFO:root:global_step: 626, logpy: 121.109, kl: 16.218, loss: -105.617\n",
      " 63%|██████▎   | 627/1000 [28:20<19:37,  3.16s/it]INFO:root:global_step: 627, logpy: 121.258, kl: 16.239, loss: -105.738\n",
      " 63%|██████▎   | 628/1000 [28:23<19:25,  3.13s/it]INFO:root:global_step: 628, logpy: 121.418, kl: 16.255, loss: -105.875\n",
      " 63%|██████▎   | 629/1000 [28:27<19:29,  3.15s/it]INFO:root:global_step: 629, logpy: 121.594, kl: 16.277, loss: -106.022\n",
      " 63%|██████▎   | 630/1000 [28:30<19:35,  3.18s/it]INFO:root:global_step: 630, logpy: 121.753, kl: 16.297, loss: -106.154\n",
      " 63%|██████▎   | 631/1000 [28:33<19:22,  3.15s/it]INFO:root:global_step: 631, logpy: 121.912, kl: 16.313, loss: -106.289\n",
      " 63%|██████▎   | 632/1000 [28:36<19:14,  3.14s/it]INFO:root:global_step: 632, logpy: 122.087, kl: 16.333, loss: -106.438\n",
      " 63%|██████▎   | 633/1000 [28:39<19:12,  3.14s/it]INFO:root:global_step: 633, logpy: 122.251, kl: 16.349, loss: -106.579\n",
      " 63%|██████▎   | 634/1000 [28:42<19:05,  3.13s/it]INFO:root:global_step: 634, logpy: 122.385, kl: 16.366, loss: -106.689\n",
      " 64%|██████▎   | 635/1000 [28:45<18:59,  3.12s/it]INFO:root:global_step: 635, logpy: 122.520, kl: 16.384, loss: -106.798\n",
      " 64%|██████▎   | 636/1000 [28:49<18:58,  3.13s/it]INFO:root:global_step: 636, logpy: 122.638, kl: 16.407, loss: -106.887\n",
      " 64%|██████▎   | 637/1000 [28:52<18:52,  3.12s/it]INFO:root:global_step: 637, logpy: 122.751, kl: 16.426, loss: -106.975\n",
      " 64%|██████▍   | 638/1000 [28:55<18:51,  3.12s/it]INFO:root:global_step: 638, logpy: 122.928, kl: 16.446, loss: -107.126\n",
      " 64%|██████▍   | 639/1000 [28:58<18:45,  3.12s/it]INFO:root:global_step: 639, logpy: 123.083, kl: 16.458, loss: -107.262\n",
      " 64%|██████▍   | 640/1000 [29:01<18:47,  3.13s/it]INFO:root:global_step: 640, logpy: 123.233, kl: 16.476, loss: -107.388\n",
      " 64%|██████▍   | 641/1000 [29:04<18:51,  3.15s/it]INFO:root:global_step: 641, logpy: 123.399, kl: 16.493, loss: -107.531\n",
      " 64%|██████▍   | 642/1000 [29:08<18:55,  3.17s/it]INFO:root:global_step: 642, logpy: 123.572, kl: 16.509, loss: -107.681\n",
      " 64%|██████▍   | 643/1000 [29:11<18:58,  3.19s/it]INFO:root:global_step: 643, logpy: 123.718, kl: 16.525, loss: -107.805\n",
      " 64%|██████▍   | 644/1000 [29:14<18:49,  3.17s/it]INFO:root:global_step: 644, logpy: 123.850, kl: 16.547, loss: -107.909\n",
      " 64%|██████▍   | 645/1000 [29:17<18:43,  3.17s/it]INFO:root:global_step: 645, logpy: 124.035, kl: 16.564, loss: -108.071\n",
      " 65%|██████▍   | 646/1000 [29:20<18:45,  3.18s/it]INFO:root:global_step: 646, logpy: 124.175, kl: 16.584, loss: -108.185\n",
      " 65%|██████▍   | 647/1000 [29:23<18:36,  3.16s/it]INFO:root:global_step: 647, logpy: 124.315, kl: 16.598, loss: -108.304\n",
      " 65%|██████▍   | 648/1000 [29:27<18:29,  3.15s/it]INFO:root:global_step: 648, logpy: 124.458, kl: 16.616, loss: -108.424\n",
      " 65%|██████▍   | 649/1000 [29:30<18:32,  3.17s/it]INFO:root:global_step: 649, logpy: 124.608, kl: 16.634, loss: -108.550\n",
      " 65%|██████▌   | 650/1000 [29:33<18:24,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([121, 1])\n",
      "torch.Size([121, 1])\n",
      "torch.Size([121, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saved figure at: ./img_generation/global_step_650.png\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_core/sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 650, logpy: 124.724, kl: 16.655, loss: -108.640\n",
      " 65%|██████▌   | 651/1000 [29:37<20:36,  3.54s/it]INFO:root:global_step: 651, logpy: 124.848, kl: 16.672, loss: -108.741\n",
      " 65%|██████▌   | 652/1000 [29:41<20:15,  3.49s/it]INFO:root:global_step: 652, logpy: 125.003, kl: 16.684, loss: -108.878\n",
      " 65%|██████▌   | 653/1000 [29:44<19:56,  3.45s/it]INFO:root:global_step: 653, logpy: 125.120, kl: 16.706, loss: -108.967\n",
      " 65%|██████▌   | 654/1000 [29:47<19:29,  3.38s/it]INFO:root:global_step: 654, logpy: 125.255, kl: 16.723, loss: -109.080\n",
      " 66%|██████▌   | 655/1000 [29:50<19:01,  3.31s/it]INFO:root:global_step: 655, logpy: 125.417, kl: 16.736, loss: -109.224\n",
      " 66%|██████▌   | 656/1000 [29:54<18:42,  3.26s/it]INFO:root:global_step: 656, logpy: 125.559, kl: 16.760, loss: -109.335\n",
      " 66%|██████▌   | 657/1000 [29:57<18:28,  3.23s/it]INFO:root:global_step: 657, logpy: 125.694, kl: 16.780, loss: -109.446\n",
      " 66%|██████▌   | 658/1000 [30:00<18:17,  3.21s/it]INFO:root:global_step: 658, logpy: 125.814, kl: 16.793, loss: -109.547\n",
      " 66%|██████▌   | 659/1000 [30:03<18:06,  3.19s/it]INFO:root:global_step: 659, logpy: 125.921, kl: 16.808, loss: -109.634\n",
      " 66%|██████▌   | 660/1000 [30:06<18:05,  3.19s/it]INFO:root:global_step: 660, logpy: 126.045, kl: 16.831, loss: -109.730\n",
      " 66%|██████▌   | 661/1000 [30:09<17:59,  3.18s/it]INFO:root:global_step: 661, logpy: 126.148, kl: 16.850, loss: -109.809\n",
      " 66%|██████▌   | 662/1000 [30:13<17:53,  3.18s/it]INFO:root:global_step: 662, logpy: 126.309, kl: 16.867, loss: -109.948\n",
      " 66%|██████▋   | 663/1000 [30:16<17:48,  3.17s/it]INFO:root:global_step: 663, logpy: 126.449, kl: 16.885, loss: -110.064\n",
      " 66%|██████▋   | 664/1000 [30:19<17:41,  3.16s/it]INFO:root:global_step: 664, logpy: 126.609, kl: 16.901, loss: -110.204\n",
      " 66%|██████▋   | 665/1000 [30:22<17:49,  3.19s/it]INFO:root:global_step: 665, logpy: 126.727, kl: 16.918, loss: -110.300\n",
      " 67%|██████▋   | 666/1000 [30:25<17:44,  3.19s/it]INFO:root:global_step: 666, logpy: 126.880, kl: 16.938, loss: -110.428\n",
      " 67%|██████▋   | 667/1000 [30:28<17:35,  3.17s/it]INFO:root:global_step: 667, logpy: 127.014, kl: 16.954, loss: -110.541\n",
      " 67%|██████▋   | 668/1000 [30:32<17:39,  3.19s/it]INFO:root:global_step: 668, logpy: 127.152, kl: 16.970, loss: -110.658\n",
      " 67%|██████▋   | 669/1000 [30:35<17:28,  3.17s/it]INFO:root:global_step: 669, logpy: 127.290, kl: 16.990, loss: -110.772\n",
      " 67%|██████▋   | 670/1000 [30:38<17:26,  3.17s/it]INFO:root:global_step: 670, logpy: 127.411, kl: 17.007, loss: -110.871\n",
      " 67%|██████▋   | 671/1000 [30:41<17:53,  3.26s/it]INFO:root:global_step: 671, logpy: 127.549, kl: 17.024, loss: -110.987\n",
      " 67%|██████▋   | 672/1000 [30:45<18:11,  3.33s/it]INFO:root:global_step: 672, logpy: 127.677, kl: 17.042, loss: -111.093\n",
      " 67%|██████▋   | 673/1000 [30:49<18:47,  3.45s/it]INFO:root:global_step: 673, logpy: 127.830, kl: 17.056, loss: -111.227\n",
      " 67%|██████▋   | 674/1000 [30:52<18:46,  3.46s/it]INFO:root:global_step: 674, logpy: 127.928, kl: 17.075, loss: -111.301\n",
      " 68%|██████▊   | 675/1000 [30:56<18:43,  3.46s/it]INFO:root:global_step: 675, logpy: 128.040, kl: 17.095, loss: -111.388\n",
      " 68%|██████▊   | 676/1000 [30:59<18:19,  3.39s/it]INFO:root:global_step: 676, logpy: 128.141, kl: 17.113, loss: -111.467\n",
      " 68%|██████▊   | 677/1000 [31:02<18:14,  3.39s/it]INFO:root:global_step: 677, logpy: 128.271, kl: 17.129, loss: -111.578\n",
      " 68%|██████▊   | 678/1000 [31:05<17:56,  3.34s/it]INFO:root:global_step: 678, logpy: 128.395, kl: 17.144, loss: -111.681\n",
      " 68%|██████▊   | 679/1000 [31:09<17:43,  3.31s/it]INFO:root:global_step: 679, logpy: 128.506, kl: 17.165, loss: -111.767\n",
      " 68%|██████▊   | 680/1000 [31:12<17:40,  3.32s/it]INFO:root:global_step: 680, logpy: 128.617, kl: 17.182, loss: -111.857\n",
      " 68%|██████▊   | 681/1000 [31:15<17:38,  3.32s/it]INFO:root:global_step: 681, logpy: 128.711, kl: 17.202, loss: -111.927\n",
      " 68%|██████▊   | 682/1000 [31:19<17:31,  3.31s/it]INFO:root:global_step: 682, logpy: 128.829, kl: 17.224, loss: -112.019\n",
      " 68%|██████▊   | 683/1000 [31:22<17:30,  3.31s/it]INFO:root:global_step: 683, logpy: 128.941, kl: 17.243, loss: -112.107\n",
      " 68%|██████▊   | 684/1000 [31:25<17:30,  3.32s/it]INFO:root:global_step: 684, logpy: 129.079, kl: 17.261, loss: -112.223\n",
      " 68%|██████▊   | 685/1000 [31:28<17:12,  3.28s/it]INFO:root:global_step: 685, logpy: 129.182, kl: 17.281, loss: -112.302\n",
      " 69%|██████▊   | 686/1000 [31:32<17:03,  3.26s/it]INFO:root:global_step: 686, logpy: 129.311, kl: 17.301, loss: -112.407\n",
      " 69%|██████▊   | 687/1000 [31:35<16:51,  3.23s/it]INFO:root:global_step: 687, logpy: 129.445, kl: 17.321, loss: -112.518\n",
      " 69%|██████▉   | 688/1000 [31:38<16:43,  3.22s/it]INFO:root:global_step: 688, logpy: 129.541, kl: 17.340, loss: -112.590\n",
      " 69%|██████▉   | 689/1000 [31:41<16:43,  3.23s/it]INFO:root:global_step: 689, logpy: 129.673, kl: 17.358, loss: -112.701\n",
      " 69%|██████▉   | 690/1000 [31:44<16:40,  3.23s/it]INFO:root:global_step: 690, logpy: 129.783, kl: 17.381, loss: -112.783\n",
      " 69%|██████▉   | 691/1000 [31:48<16:44,  3.25s/it]INFO:root:global_step: 691, logpy: 129.900, kl: 17.398, loss: -112.880\n",
      " 69%|██████▉   | 692/1000 [31:51<16:36,  3.24s/it]INFO:root:global_step: 692, logpy: 130.010, kl: 17.410, loss: -112.974\n",
      " 69%|██████▉   | 693/1000 [31:54<16:26,  3.21s/it]INFO:root:global_step: 693, logpy: 130.109, kl: 17.425, loss: -113.054\n",
      " 69%|██████▉   | 694/1000 [31:57<16:20,  3.21s/it]INFO:root:global_step: 694, logpy: 130.238, kl: 17.444, loss: -113.161\n",
      " 70%|██████▉   | 695/1000 [32:00<16:11,  3.19s/it]INFO:root:global_step: 695, logpy: 130.367, kl: 17.463, loss: -113.267\n",
      " 70%|██████▉   | 696/1000 [32:04<16:03,  3.17s/it]INFO:root:global_step: 696, logpy: 130.475, kl: 17.481, loss: -113.353\n",
      " 70%|██████▉   | 697/1000 [32:07<15:59,  3.17s/it]INFO:root:global_step: 697, logpy: 130.621, kl: 17.499, loss: -113.478\n",
      " 70%|██████▉   | 698/1000 [32:10<15:58,  3.17s/it]INFO:root:global_step: 698, logpy: 130.713, kl: 17.519, loss: -113.546\n",
      " 70%|██████▉   | 699/1000 [32:13<15:56,  3.18s/it]INFO:root:global_step: 699, logpy: 130.818, kl: 17.539, loss: -113.627\n",
      " 70%|███████   | 700/1000 [32:16<15:53,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([121, 1])\n",
      "torch.Size([121, 1])\n",
      "torch.Size([121, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saved figure at: ./img_generation/global_step_700.png\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_core/sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 700, logpy: 130.921, kl: 17.560, loss: -113.706\n",
      " 70%|███████   | 701/1000 [32:21<17:46,  3.57s/it]INFO:root:global_step: 701, logpy: 131.025, kl: 17.580, loss: -113.787\n",
      " 70%|███████   | 702/1000 [32:24<17:08,  3.45s/it]INFO:root:global_step: 702, logpy: 131.144, kl: 17.596, loss: -113.886\n",
      " 70%|███████   | 703/1000 [32:27<16:53,  3.41s/it]INFO:root:global_step: 703, logpy: 131.246, kl: 17.613, loss: -113.968\n",
      " 70%|███████   | 704/1000 [32:31<16:38,  3.37s/it]INFO:root:global_step: 704, logpy: 131.334, kl: 17.633, loss: -114.033\n",
      " 70%|███████   | 705/1000 [32:34<16:25,  3.34s/it]INFO:root:global_step: 705, logpy: 131.466, kl: 17.647, loss: -114.147\n",
      " 71%|███████   | 706/1000 [32:37<16:15,  3.32s/it]INFO:root:global_step: 706, logpy: 131.579, kl: 17.671, loss: -114.233\n",
      " 71%|███████   | 707/1000 [32:40<15:56,  3.26s/it]INFO:root:global_step: 707, logpy: 131.710, kl: 17.685, loss: -114.347\n",
      " 71%|███████   | 708/1000 [32:44<15:56,  3.28s/it]INFO:root:global_step: 708, logpy: 131.833, kl: 17.700, loss: -114.451\n",
      " 71%|███████   | 709/1000 [32:47<15:44,  3.25s/it]INFO:root:global_step: 709, logpy: 131.963, kl: 17.720, loss: -114.558\n",
      " 71%|███████   | 710/1000 [32:50<15:31,  3.21s/it]INFO:root:global_step: 710, logpy: 132.077, kl: 17.740, loss: -114.649\n",
      " 71%|███████   | 711/1000 [32:53<15:23,  3.20s/it]INFO:root:global_step: 711, logpy: 132.159, kl: 17.760, loss: -114.708\n",
      " 71%|███████   | 712/1000 [32:56<15:15,  3.18s/it]INFO:root:global_step: 712, logpy: 132.267, kl: 17.780, loss: -114.793\n",
      " 71%|███████▏  | 713/1000 [32:59<15:24,  3.22s/it]INFO:root:global_step: 713, logpy: 132.350, kl: 17.796, loss: -114.857\n",
      " 71%|███████▏  | 714/1000 [33:03<15:22,  3.22s/it]INFO:root:global_step: 714, logpy: 132.474, kl: 17.815, loss: -114.958\n",
      " 72%|███████▏  | 715/1000 [33:06<15:14,  3.21s/it]INFO:root:global_step: 715, logpy: 132.581, kl: 17.829, loss: -115.048\n",
      " 72%|███████▏  | 716/1000 [33:09<15:21,  3.25s/it]INFO:root:global_step: 716, logpy: 132.694, kl: 17.851, loss: -115.136\n",
      " 72%|███████▏  | 717/1000 [33:13<15:55,  3.38s/it]INFO:root:global_step: 717, logpy: 132.805, kl: 17.865, loss: -115.231\n",
      " 72%|███████▏  | 718/1000 [33:16<15:43,  3.35s/it]INFO:root:global_step: 718, logpy: 132.913, kl: 17.885, loss: -115.316\n",
      " 72%|███████▏  | 719/1000 [33:19<15:33,  3.32s/it]INFO:root:global_step: 719, logpy: 133.027, kl: 17.903, loss: -115.409\n",
      " 72%|███████▏  | 720/1000 [33:23<15:30,  3.32s/it]INFO:root:global_step: 720, logpy: 133.091, kl: 17.921, loss: -115.452\n",
      " 72%|███████▏  | 721/1000 [33:26<15:21,  3.30s/it]INFO:root:global_step: 721, logpy: 133.206, kl: 17.937, loss: -115.549\n",
      " 72%|███████▏  | 722/1000 [33:29<15:05,  3.26s/it]INFO:root:global_step: 722, logpy: 133.305, kl: 17.955, loss: -115.627\n",
      " 72%|███████▏  | 723/1000 [33:32<14:56,  3.24s/it]INFO:root:global_step: 723, logpy: 133.389, kl: 17.972, loss: -115.691\n",
      " 72%|███████▏  | 724/1000 [33:36<14:49,  3.22s/it]INFO:root:global_step: 724, logpy: 133.467, kl: 17.988, loss: -115.750\n",
      " 72%|███████▎  | 725/1000 [33:39<14:45,  3.22s/it]INFO:root:global_step: 725, logpy: 133.540, kl: 18.011, loss: -115.797\n",
      " 73%|███████▎  | 726/1000 [33:42<14:41,  3.22s/it]INFO:root:global_step: 726, logpy: 133.654, kl: 18.026, loss: -115.894\n",
      " 73%|███████▎  | 727/1000 [33:45<14:59,  3.30s/it]INFO:root:global_step: 727, logpy: 133.755, kl: 18.048, loss: -115.970\n",
      " 73%|███████▎  | 728/1000 [33:49<14:51,  3.28s/it]INFO:root:global_step: 728, logpy: 133.835, kl: 18.066, loss: -116.030\n",
      " 73%|███████▎  | 729/1000 [33:52<14:50,  3.28s/it]INFO:root:global_step: 729, logpy: 133.966, kl: 18.083, loss: -116.141\n",
      " 73%|███████▎  | 730/1000 [33:56<16:01,  3.56s/it]INFO:root:global_step: 730, logpy: 134.079, kl: 18.096, loss: -116.238\n",
      " 73%|███████▎  | 731/1000 [34:00<16:08,  3.60s/it]INFO:root:global_step: 731, logpy: 134.147, kl: 18.110, loss: -116.289\n",
      " 73%|███████▎  | 732/1000 [34:04<16:12,  3.63s/it]INFO:root:global_step: 732, logpy: 134.207, kl: 18.130, loss: -116.328\n",
      " 73%|███████▎  | 733/1000 [34:07<15:54,  3.57s/it]INFO:root:global_step: 733, logpy: 134.285, kl: 18.149, loss: -116.383\n",
      " 73%|███████▎  | 734/1000 [34:10<15:41,  3.54s/it]INFO:root:global_step: 734, logpy: 134.365, kl: 18.168, loss: -116.442\n",
      " 74%|███████▎  | 735/1000 [34:14<15:43,  3.56s/it]INFO:root:global_step: 735, logpy: 134.444, kl: 18.189, loss: -116.498\n",
      " 74%|███████▎  | 736/1000 [34:18<15:48,  3.59s/it]INFO:root:global_step: 736, logpy: 134.556, kl: 18.206, loss: -116.591\n",
      " 74%|███████▎  | 737/1000 [34:22<16:10,  3.69s/it]INFO:root:global_step: 737, logpy: 134.654, kl: 18.221, loss: -116.670\n",
      " 74%|███████▍  | 738/1000 [34:25<16:07,  3.69s/it]INFO:root:global_step: 738, logpy: 134.732, kl: 18.239, loss: -116.728\n",
      " 74%|███████▍  | 739/1000 [34:29<15:49,  3.64s/it]INFO:root:global_step: 739, logpy: 134.851, kl: 18.260, loss: -116.825\n",
      " 74%|███████▍  | 740/1000 [34:32<15:27,  3.57s/it]INFO:root:global_step: 740, logpy: 134.940, kl: 18.281, loss: -116.890\n",
      " 74%|███████▍  | 741/1000 [34:36<15:13,  3.53s/it]INFO:root:global_step: 741, logpy: 135.023, kl: 18.299, loss: -116.953\n",
      " 74%|███████▍  | 742/1000 [34:39<14:59,  3.48s/it]INFO:root:global_step: 742, logpy: 135.124, kl: 18.316, loss: -117.034\n",
      " 74%|███████▍  | 743/1000 [34:42<14:37,  3.41s/it]INFO:root:global_step: 743, logpy: 135.239, kl: 18.332, loss: -117.132\n",
      " 74%|███████▍  | 744/1000 [34:46<14:21,  3.36s/it]INFO:root:global_step: 744, logpy: 135.313, kl: 18.347, loss: -117.188\n",
      " 74%|███████▍  | 745/1000 [34:49<14:12,  3.34s/it]INFO:root:global_step: 745, logpy: 135.369, kl: 18.365, loss: -117.224\n",
      " 75%|███████▍  | 746/1000 [34:52<13:59,  3.31s/it]INFO:root:global_step: 746, logpy: 135.454, kl: 18.382, loss: -117.290\n",
      " 75%|███████▍  | 747/1000 [34:56<14:08,  3.35s/it]INFO:root:global_step: 747, logpy: 135.535, kl: 18.396, loss: -117.354\n",
      " 75%|███████▍  | 748/1000 [34:59<14:21,  3.42s/it]INFO:root:global_step: 748, logpy: 135.615, kl: 18.410, loss: -117.418\n",
      " 75%|███████▍  | 749/1000 [35:02<14:15,  3.41s/it]INFO:root:global_step: 749, logpy: 135.693, kl: 18.426, loss: -117.477\n",
      " 75%|███████▌  | 750/1000 [35:06<14:14,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([121, 1])\n",
      "torch.Size([121, 1])\n",
      "torch.Size([121, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saved figure at: ./img_generation/global_step_750.png\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_core/sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 750, logpy: 135.799, kl: 18.442, loss: -117.566\n",
      " 75%|███████▌  | 751/1000 [35:11<16:16,  3.92s/it]INFO:root:global_step: 751, logpy: 135.864, kl: 18.462, loss: -117.610\n",
      " 75%|███████▌  | 752/1000 [35:15<15:45,  3.81s/it]INFO:root:global_step: 752, logpy: 135.953, kl: 18.477, loss: -117.681\n",
      " 75%|███████▌  | 753/1000 [35:18<15:31,  3.77s/it]INFO:root:global_step: 753, logpy: 136.019, kl: 18.492, loss: -117.729\n",
      " 75%|███████▌  | 754/1000 [35:22<15:02,  3.67s/it]INFO:root:global_step: 754, logpy: 136.139, kl: 18.509, loss: -117.830\n",
      " 76%|███████▌  | 755/1000 [35:25<14:34,  3.57s/it]INFO:root:global_step: 755, logpy: 136.217, kl: 18.526, loss: -117.890\n",
      " 76%|███████▌  | 756/1000 [35:28<14:05,  3.47s/it]INFO:root:global_step: 756, logpy: 136.328, kl: 18.540, loss: -117.984\n",
      " 76%|███████▌  | 757/1000 [35:32<14:04,  3.47s/it]INFO:root:global_step: 757, logpy: 136.409, kl: 18.560, loss: -118.044\n",
      " 76%|███████▌  | 758/1000 [35:35<14:07,  3.50s/it]INFO:root:global_step: 758, logpy: 136.522, kl: 18.579, loss: -118.135\n",
      " 76%|███████▌  | 759/1000 [35:39<13:54,  3.46s/it]INFO:root:global_step: 759, logpy: 136.596, kl: 18.599, loss: -118.188\n",
      " 76%|███████▌  | 760/1000 [35:42<13:41,  3.42s/it]INFO:root:global_step: 760, logpy: 136.711, kl: 18.611, loss: -118.289\n",
      " 76%|███████▌  | 761/1000 [35:46<13:52,  3.48s/it]INFO:root:global_step: 761, logpy: 136.784, kl: 18.628, loss: -118.343\n",
      " 76%|███████▌  | 762/1000 [35:49<14:01,  3.54s/it]INFO:root:global_step: 762, logpy: 136.893, kl: 18.646, loss: -118.432\n",
      " 76%|███████▋  | 763/1000 [35:53<13:39,  3.46s/it]INFO:root:global_step: 763, logpy: 137.008, kl: 18.663, loss: -118.528\n",
      " 76%|███████▋  | 764/1000 [35:56<13:20,  3.39s/it]INFO:root:global_step: 764, logpy: 137.085, kl: 18.680, loss: -118.586\n",
      " 76%|███████▋  | 765/1000 [35:59<13:11,  3.37s/it]INFO:root:global_step: 765, logpy: 137.124, kl: 18.703, loss: -118.601\n",
      " 77%|███████▋  | 766/1000 [36:02<13:04,  3.35s/it]INFO:root:global_step: 766, logpy: 137.192, kl: 18.716, loss: -118.654\n",
      " 77%|███████▋  | 767/1000 [36:06<12:54,  3.32s/it]INFO:root:global_step: 767, logpy: 137.279, kl: 18.729, loss: -118.726\n",
      " 77%|███████▋  | 768/1000 [36:09<12:57,  3.35s/it]INFO:root:global_step: 768, logpy: 137.361, kl: 18.747, loss: -118.788\n",
      " 77%|███████▋  | 769/1000 [36:12<12:47,  3.32s/it]INFO:root:global_step: 769, logpy: 137.432, kl: 18.764, loss: -118.841\n",
      " 77%|███████▋  | 770/1000 [36:16<12:37,  3.30s/it]INFO:root:global_step: 770, logpy: 137.545, kl: 18.777, loss: -118.939\n",
      " 77%|███████▋  | 771/1000 [36:19<12:29,  3.27s/it]INFO:root:global_step: 771, logpy: 137.602, kl: 18.793, loss: -118.979\n",
      " 77%|███████▋  | 772/1000 [36:22<12:23,  3.26s/it]INFO:root:global_step: 772, logpy: 137.700, kl: 18.807, loss: -119.060\n",
      " 77%|███████▋  | 773/1000 [36:25<12:22,  3.27s/it]INFO:root:global_step: 773, logpy: 137.796, kl: 18.823, loss: -119.139\n",
      " 77%|███████▋  | 774/1000 [36:29<12:15,  3.26s/it]INFO:root:global_step: 774, logpy: 137.865, kl: 18.839, loss: -119.190\n",
      " 78%|███████▊  | 775/1000 [36:32<12:15,  3.27s/it]INFO:root:global_step: 775, logpy: 137.962, kl: 18.855, loss: -119.269\n",
      " 78%|███████▊  | 776/1000 [36:35<12:20,  3.30s/it]INFO:root:global_step: 776, logpy: 138.068, kl: 18.869, loss: -119.360\n",
      " 78%|███████▊  | 777/1000 [36:39<12:37,  3.40s/it]INFO:root:global_step: 777, logpy: 138.125, kl: 18.885, loss: -119.399\n",
      " 78%|███████▊  | 778/1000 [36:42<12:42,  3.43s/it]INFO:root:global_step: 778, logpy: 138.168, kl: 18.901, loss: -119.424\n",
      " 78%|███████▊  | 779/1000 [36:46<12:32,  3.40s/it]INFO:root:global_step: 779, logpy: 138.261, kl: 18.919, loss: -119.498\n",
      " 78%|███████▊  | 780/1000 [36:49<12:26,  3.40s/it]INFO:root:global_step: 780, logpy: 138.364, kl: 18.935, loss: -119.583\n",
      " 78%|███████▊  | 781/1000 [36:52<12:11,  3.34s/it]INFO:root:global_step: 781, logpy: 138.441, kl: 18.956, loss: -119.638\n",
      " 78%|███████▊  | 782/1000 [36:55<11:56,  3.29s/it]INFO:root:global_step: 782, logpy: 138.513, kl: 18.967, loss: -119.697\n",
      " 78%|███████▊  | 783/1000 [36:59<11:50,  3.28s/it]INFO:root:global_step: 783, logpy: 138.622, kl: 18.983, loss: -119.790\n",
      " 78%|███████▊  | 784/1000 [37:02<11:43,  3.26s/it]INFO:root:global_step: 784, logpy: 138.734, kl: 18.996, loss: -119.887\n",
      " 78%|███████▊  | 785/1000 [37:05<11:38,  3.25s/it]INFO:root:global_step: 785, logpy: 138.851, kl: 19.010, loss: -119.987\n",
      " 79%|███████▊  | 786/1000 [37:08<11:35,  3.25s/it]INFO:root:global_step: 786, logpy: 138.945, kl: 19.024, loss: -120.066\n",
      " 79%|███████▊  | 787/1000 [37:12<11:34,  3.26s/it]INFO:root:global_step: 787, logpy: 139.030, kl: 19.044, loss: -120.130\n",
      " 79%|███████▉  | 788/1000 [37:15<11:28,  3.25s/it]INFO:root:global_step: 788, logpy: 139.122, kl: 19.062, loss: -120.203\n",
      " 79%|███████▉  | 789/1000 [37:18<11:22,  3.24s/it]INFO:root:global_step: 789, logpy: 139.218, kl: 19.078, loss: -120.281\n",
      " 79%|███████▉  | 790/1000 [37:21<11:20,  3.24s/it]INFO:root:global_step: 790, logpy: 139.293, kl: 19.098, loss: -120.335\n",
      " 79%|███████▉  | 791/1000 [37:25<11:13,  3.22s/it]INFO:root:global_step: 791, logpy: 139.357, kl: 19.117, loss: -120.378\n",
      " 79%|███████▉  | 792/1000 [37:28<11:10,  3.22s/it]INFO:root:global_step: 792, logpy: 139.422, kl: 19.132, loss: -120.427\n",
      " 79%|███████▉  | 793/1000 [37:31<11:14,  3.26s/it]INFO:root:global_step: 793, logpy: 139.495, kl: 19.142, loss: -120.488\n",
      " 79%|███████▉  | 794/1000 [37:34<11:11,  3.26s/it]INFO:root:global_step: 794, logpy: 139.566, kl: 19.159, loss: -120.541\n",
      " 80%|███████▉  | 795/1000 [37:38<11:06,  3.25s/it]INFO:root:global_step: 795, logpy: 139.669, kl: 19.175, loss: -120.627\n",
      " 80%|███████▉  | 796/1000 [37:41<11:02,  3.25s/it]INFO:root:global_step: 796, logpy: 139.743, kl: 19.193, loss: -120.681\n",
      " 80%|███████▉  | 797/1000 [37:44<11:02,  3.26s/it]INFO:root:global_step: 797, logpy: 139.864, kl: 19.212, loss: -120.782\n",
      " 80%|███████▉  | 798/1000 [37:48<11:06,  3.30s/it]INFO:root:global_step: 798, logpy: 139.968, kl: 19.225, loss: -120.872\n",
      " 80%|███████▉  | 799/1000 [37:51<11:00,  3.29s/it]INFO:root:global_step: 799, logpy: 140.014, kl: 19.242, loss: -120.899\n",
      " 80%|████████  | 800/1000 [37:54<10:56,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([121, 1])\n",
      "torch.Size([121, 1])\n",
      "torch.Size([121, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saved figure at: ./img_generation/global_step_800.png\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_core/sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 800, logpy: 140.078, kl: 19.259, loss: -120.946\n",
      " 80%|████████  | 801/1000 [37:59<12:12,  3.68s/it]INFO:root:global_step: 801, logpy: 140.109, kl: 19.279, loss: -120.955\n",
      " 80%|████████  | 802/1000 [38:02<11:46,  3.57s/it]INFO:root:global_step: 802, logpy: 140.140, kl: 19.298, loss: -120.966\n",
      " 80%|████████  | 803/1000 [38:05<11:33,  3.52s/it]INFO:root:global_step: 803, logpy: 140.210, kl: 19.314, loss: -121.019\n",
      " 80%|████████  | 804/1000 [38:09<11:18,  3.46s/it]INFO:root:global_step: 804, logpy: 140.297, kl: 19.326, loss: -121.092\n",
      " 80%|████████  | 805/1000 [38:12<11:03,  3.40s/it]INFO:root:global_step: 805, logpy: 140.376, kl: 19.345, loss: -121.152\n",
      " 81%|████████  | 806/1000 [38:15<10:56,  3.38s/it]INFO:root:global_step: 806, logpy: 140.462, kl: 19.362, loss: -121.219\n",
      " 81%|████████  | 807/1000 [38:19<10:43,  3.33s/it]INFO:root:global_step: 807, logpy: 140.511, kl: 19.380, loss: -121.248\n",
      " 81%|████████  | 808/1000 [38:22<10:33,  3.30s/it]INFO:root:global_step: 808, logpy: 140.568, kl: 19.395, loss: -121.289\n",
      " 81%|████████  | 809/1000 [38:25<10:23,  3.27s/it]INFO:root:global_step: 809, logpy: 140.607, kl: 19.412, loss: -121.310\n",
      " 81%|████████  | 810/1000 [38:28<10:18,  3.25s/it]INFO:root:global_step: 810, logpy: 140.667, kl: 19.430, loss: -121.351\n",
      " 81%|████████  | 811/1000 [38:31<10:14,  3.25s/it]INFO:root:global_step: 811, logpy: 140.709, kl: 19.447, loss: -121.375\n",
      " 81%|████████  | 812/1000 [38:35<10:17,  3.29s/it]INFO:root:global_step: 812, logpy: 140.762, kl: 19.462, loss: -121.412\n",
      " 81%|████████▏ | 813/1000 [38:38<10:10,  3.26s/it]INFO:root:global_step: 813, logpy: 140.838, kl: 19.476, loss: -121.473\n",
      " 81%|████████▏ | 814/1000 [38:41<10:07,  3.27s/it]INFO:root:global_step: 814, logpy: 140.918, kl: 19.495, loss: -121.533\n",
      " 82%|████████▏ | 815/1000 [38:44<09:57,  3.23s/it]INFO:root:global_step: 815, logpy: 140.987, kl: 19.513, loss: -121.582\n",
      " 82%|████████▏ | 816/1000 [38:48<09:54,  3.23s/it]INFO:root:global_step: 816, logpy: 141.056, kl: 19.532, loss: -121.632\n",
      " 82%|████████▏ | 817/1000 [38:51<09:51,  3.23s/it]INFO:root:global_step: 817, logpy: 141.107, kl: 19.547, loss: -121.667\n",
      " 82%|████████▏ | 818/1000 [38:54<09:50,  3.25s/it]INFO:root:global_step: 818, logpy: 141.191, kl: 19.561, loss: -121.736\n",
      " 82%|████████▏ | 819/1000 [38:57<09:47,  3.24s/it]INFO:root:global_step: 819, logpy: 141.241, kl: 19.577, loss: -121.768\n",
      " 82%|████████▏ | 820/1000 [39:01<09:49,  3.27s/it]INFO:root:global_step: 820, logpy: 141.285, kl: 19.596, loss: -121.792\n",
      " 82%|████████▏ | 821/1000 [39:04<09:44,  3.26s/it]INFO:root:global_step: 821, logpy: 141.358, kl: 19.615, loss: -121.846\n",
      " 82%|████████▏ | 822/1000 [39:07<09:38,  3.25s/it]INFO:root:global_step: 822, logpy: 141.431, kl: 19.631, loss: -121.901\n",
      " 82%|████████▏ | 823/1000 [39:11<09:40,  3.28s/it]INFO:root:global_step: 823, logpy: 141.517, kl: 19.644, loss: -121.973\n",
      " 82%|████████▏ | 824/1000 [39:14<09:34,  3.27s/it]INFO:root:global_step: 824, logpy: 141.591, kl: 19.655, loss: -122.036\n",
      " 82%|████████▎ | 825/1000 [39:17<09:32,  3.27s/it]INFO:root:global_step: 825, logpy: 141.646, kl: 19.671, loss: -122.074\n",
      " 83%|████████▎ | 826/1000 [39:20<09:30,  3.28s/it]INFO:root:global_step: 826, logpy: 141.719, kl: 19.688, loss: -122.129\n",
      " 83%|████████▎ | 827/1000 [39:24<09:28,  3.29s/it]INFO:root:global_step: 827, logpy: 141.792, kl: 19.702, loss: -122.187\n",
      " 83%|████████▎ | 828/1000 [39:27<09:26,  3.29s/it]INFO:root:global_step: 828, logpy: 141.875, kl: 19.713, loss: -122.258\n",
      " 83%|████████▎ | 829/1000 [39:30<09:21,  3.29s/it]INFO:root:global_step: 829, logpy: 141.927, kl: 19.732, loss: -122.289\n",
      " 83%|████████▎ | 830/1000 [39:34<09:18,  3.29s/it]INFO:root:global_step: 830, logpy: 142.006, kl: 19.750, loss: -122.349\n",
      " 83%|████████▎ | 831/1000 [39:37<09:15,  3.29s/it]INFO:root:global_step: 831, logpy: 142.071, kl: 19.764, loss: -122.400\n",
      " 83%|████████▎ | 832/1000 [39:40<09:11,  3.28s/it]INFO:root:global_step: 832, logpy: 142.109, kl: 19.780, loss: -122.421\n",
      " 83%|████████▎ | 833/1000 [39:43<09:10,  3.30s/it]INFO:root:global_step: 833, logpy: 142.187, kl: 19.798, loss: -122.480\n",
      " 83%|████████▎ | 834/1000 [39:47<09:16,  3.35s/it]INFO:root:global_step: 834, logpy: 142.277, kl: 19.811, loss: -122.556\n",
      " 84%|████████▎ | 835/1000 [39:50<09:12,  3.35s/it]INFO:root:global_step: 835, logpy: 142.338, kl: 19.830, loss: -122.597\n",
      " 84%|████████▎ | 836/1000 [39:54<09:07,  3.34s/it]INFO:root:global_step: 836, logpy: 142.395, kl: 19.844, loss: -122.639\n",
      " 84%|████████▎ | 837/1000 [39:57<09:02,  3.33s/it]INFO:root:global_step: 837, logpy: 142.463, kl: 19.862, loss: -122.689\n",
      " 84%|████████▍ | 838/1000 [40:00<08:54,  3.30s/it]INFO:root:global_step: 838, logpy: 142.537, kl: 19.877, loss: -122.746\n",
      " 84%|████████▍ | 839/1000 [40:03<08:51,  3.30s/it]INFO:root:global_step: 839, logpy: 142.607, kl: 19.892, loss: -122.801\n",
      " 84%|████████▍ | 840/1000 [40:07<08:45,  3.28s/it]INFO:root:global_step: 840, logpy: 142.656, kl: 19.904, loss: -122.836\n",
      " 84%|████████▍ | 841/1000 [40:10<08:43,  3.29s/it]INFO:root:global_step: 841, logpy: 142.721, kl: 19.920, loss: -122.885\n",
      " 84%|████████▍ | 842/1000 [40:13<08:40,  3.29s/it]INFO:root:global_step: 842, logpy: 142.791, kl: 19.933, loss: -122.941\n",
      " 84%|████████▍ | 843/1000 [40:17<08:35,  3.28s/it]INFO:root:global_step: 843, logpy: 142.835, kl: 19.951, loss: -122.966\n",
      " 84%|████████▍ | 844/1000 [40:20<08:31,  3.28s/it]INFO:root:global_step: 844, logpy: 142.909, kl: 19.968, loss: -123.022\n",
      " 84%|████████▍ | 845/1000 [40:23<08:26,  3.27s/it]INFO:root:global_step: 845, logpy: 142.977, kl: 19.980, loss: -123.078\n",
      " 85%|████████▍ | 846/1000 [40:26<08:24,  3.28s/it]INFO:root:global_step: 846, logpy: 143.075, kl: 20.002, loss: -123.153\n",
      " 85%|████████▍ | 847/1000 [40:30<08:26,  3.31s/it]INFO:root:global_step: 847, logpy: 143.123, kl: 20.020, loss: -123.183\n",
      " 85%|████████▍ | 848/1000 [40:33<08:19,  3.29s/it]INFO:root:global_step: 848, logpy: 143.173, kl: 20.043, loss: -123.208\n",
      " 85%|████████▍ | 849/1000 [40:36<08:15,  3.28s/it]INFO:root:global_step: 849, logpy: 143.232, kl: 20.058, loss: -123.251\n",
      " 85%|████████▌ | 850/1000 [40:39<08:10,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([121, 1])\n",
      "torch.Size([121, 1])\n",
      "torch.Size([121, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saved figure at: ./img_generation/global_step_850.png\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_core/sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 850, logpy: 143.310, kl: 20.073, loss: -123.313\n",
      " 85%|████████▌ | 851/1000 [40:44<09:01,  3.63s/it]INFO:root:global_step: 851, logpy: 143.381, kl: 20.086, loss: -123.370\n",
      " 85%|████████▌ | 852/1000 [40:47<08:48,  3.57s/it]INFO:root:global_step: 852, logpy: 143.439, kl: 20.105, loss: -123.409\n",
      " 85%|████████▌ | 853/1000 [40:51<08:33,  3.49s/it]INFO:root:global_step: 853, logpy: 143.512, kl: 20.122, loss: -123.464\n",
      " 85%|████████▌ | 854/1000 [40:54<08:18,  3.42s/it]INFO:root:global_step: 854, logpy: 143.573, kl: 20.136, loss: -123.510\n",
      " 86%|████████▌ | 855/1000 [40:57<08:12,  3.39s/it]INFO:root:global_step: 855, logpy: 143.629, kl: 20.147, loss: -123.554\n",
      " 86%|████████▌ | 856/1000 [41:01<08:10,  3.40s/it]INFO:root:global_step: 856, logpy: 143.709, kl: 20.159, loss: -123.622\n",
      " 86%|████████▌ | 857/1000 [41:04<07:58,  3.35s/it]INFO:root:global_step: 857, logpy: 143.798, kl: 20.173, loss: -123.696\n",
      " 86%|████████▌ | 858/1000 [41:07<07:50,  3.32s/it]INFO:root:global_step: 858, logpy: 143.870, kl: 20.186, loss: -123.755\n",
      " 86%|████████▌ | 859/1000 [41:11<07:55,  3.37s/it]INFO:root:global_step: 859, logpy: 143.916, kl: 20.202, loss: -123.783\n",
      " 86%|████████▌ | 860/1000 [41:14<07:50,  3.36s/it]INFO:root:global_step: 860, logpy: 143.993, kl: 20.221, loss: -123.841\n",
      " 86%|████████▌ | 861/1000 [41:17<07:42,  3.32s/it]INFO:root:global_step: 861, logpy: 144.035, kl: 20.240, loss: -123.863\n",
      " 86%|████████▌ | 862/1000 [41:21<07:40,  3.33s/it]INFO:root:global_step: 862, logpy: 144.113, kl: 20.252, loss: -123.929\n",
      " 86%|████████▋ | 863/1000 [41:24<07:40,  3.36s/it]INFO:root:global_step: 863, logpy: 144.152, kl: 20.270, loss: -123.950\n",
      " 86%|████████▋ | 864/1000 [41:27<07:33,  3.33s/it]INFO:root:global_step: 864, logpy: 144.208, kl: 20.285, loss: -123.990\n",
      " 86%|████████▋ | 865/1000 [41:31<07:27,  3.31s/it]INFO:root:global_step: 865, logpy: 144.279, kl: 20.297, loss: -124.048\n",
      " 87%|████████▋ | 866/1000 [41:34<07:21,  3.30s/it]INFO:root:global_step: 866, logpy: 144.323, kl: 20.312, loss: -124.076\n",
      " 87%|████████▋ | 867/1000 [41:37<07:19,  3.30s/it]INFO:root:global_step: 867, logpy: 144.381, kl: 20.329, loss: -124.117\n",
      " 87%|████████▋ | 868/1000 [41:40<07:17,  3.31s/it]INFO:root:global_step: 868, logpy: 144.416, kl: 20.344, loss: -124.135\n",
      " 87%|████████▋ | 869/1000 [41:44<07:18,  3.35s/it]INFO:root:global_step: 869, logpy: 144.490, kl: 20.358, loss: -124.195\n",
      " 87%|████████▋ | 870/1000 [41:47<07:19,  3.38s/it]INFO:root:global_step: 870, logpy: 144.537, kl: 20.371, loss: -124.229\n",
      " 87%|████████▋ | 871/1000 [41:51<07:21,  3.42s/it]INFO:root:global_step: 871, logpy: 144.590, kl: 20.386, loss: -124.266\n",
      " 87%|████████▋ | 872/1000 [41:54<07:17,  3.42s/it]INFO:root:global_step: 872, logpy: 144.655, kl: 20.400, loss: -124.316\n",
      " 87%|████████▋ | 873/1000 [41:58<07:16,  3.44s/it]INFO:root:global_step: 873, logpy: 144.712, kl: 20.417, loss: -124.356\n",
      " 87%|████████▋ | 874/1000 [42:01<07:14,  3.45s/it]INFO:root:global_step: 874, logpy: 144.751, kl: 20.432, loss: -124.379\n",
      " 88%|████████▊ | 875/1000 [42:04<07:02,  3.38s/it]INFO:root:global_step: 875, logpy: 144.828, kl: 20.450, loss: -124.437\n",
      " 88%|████████▊ | 876/1000 [42:08<06:54,  3.35s/it]INFO:root:global_step: 876, logpy: 144.873, kl: 20.466, loss: -124.465\n",
      " 88%|████████▊ | 877/1000 [42:11<06:52,  3.36s/it]INFO:root:global_step: 877, logpy: 144.950, kl: 20.481, loss: -124.527\n",
      " 88%|████████▊ | 878/1000 [42:14<06:47,  3.34s/it]INFO:root:global_step: 878, logpy: 144.990, kl: 20.500, loss: -124.548\n",
      " 88%|████████▊ | 879/1000 [42:18<06:41,  3.32s/it]INFO:root:global_step: 879, logpy: 145.068, kl: 20.513, loss: -124.612\n",
      " 88%|████████▊ | 880/1000 [42:21<06:36,  3.30s/it]INFO:root:global_step: 880, logpy: 145.147, kl: 20.530, loss: -124.673\n",
      " 88%|████████▊ | 881/1000 [42:24<06:32,  3.29s/it]INFO:root:global_step: 881, logpy: 145.223, kl: 20.546, loss: -124.733\n",
      " 88%|████████▊ | 882/1000 [42:28<06:30,  3.31s/it]INFO:root:global_step: 882, logpy: 145.303, kl: 20.565, loss: -124.793\n",
      " 88%|████████▊ | 883/1000 [42:31<06:25,  3.30s/it]INFO:root:global_step: 883, logpy: 145.340, kl: 20.579, loss: -124.816\n",
      " 88%|████████▊ | 884/1000 [42:34<06:21,  3.29s/it]INFO:root:global_step: 884, logpy: 145.419, kl: 20.590, loss: -124.884\n",
      " 88%|████████▊ | 885/1000 [42:37<06:18,  3.29s/it]INFO:root:global_step: 885, logpy: 145.473, kl: 20.605, loss: -124.922\n",
      " 89%|████████▊ | 886/1000 [42:41<06:14,  3.28s/it]INFO:root:global_step: 886, logpy: 145.546, kl: 20.614, loss: -124.985\n",
      " 89%|████████▊ | 887/1000 [42:44<06:15,  3.32s/it]INFO:root:global_step: 887, logpy: 145.610, kl: 20.629, loss: -125.033\n",
      " 89%|████████▉ | 888/1000 [42:47<06:10,  3.31s/it]INFO:root:global_step: 888, logpy: 145.680, kl: 20.646, loss: -125.086\n",
      " 89%|████████▉ | 889/1000 [42:51<06:05,  3.29s/it]INFO:root:global_step: 889, logpy: 145.715, kl: 20.664, loss: -125.102\n",
      " 89%|████████▉ | 890/1000 [42:54<06:01,  3.29s/it]INFO:root:global_step: 890, logpy: 145.786, kl: 20.677, loss: -125.160\n",
      " 89%|████████▉ | 891/1000 [42:57<05:59,  3.29s/it]INFO:root:global_step: 891, logpy: 145.866, kl: 20.696, loss: -125.221\n",
      " 89%|████████▉ | 892/1000 [43:00<05:53,  3.27s/it]INFO:root:global_step: 892, logpy: 145.957, kl: 20.712, loss: -125.294\n",
      " 89%|████████▉ | 893/1000 [43:04<05:52,  3.30s/it]INFO:root:global_step: 893, logpy: 146.007, kl: 20.724, loss: -125.332\n",
      " 89%|████████▉ | 894/1000 [43:07<05:54,  3.35s/it]INFO:root:global_step: 894, logpy: 146.077, kl: 20.739, loss: -125.388\n",
      " 90%|████████▉ | 895/1000 [43:11<06:04,  3.47s/it]INFO:root:global_step: 895, logpy: 146.124, kl: 20.754, loss: -125.419\n",
      " 90%|████████▉ | 896/1000 [43:14<05:59,  3.46s/it]INFO:root:global_step: 896, logpy: 146.181, kl: 20.768, loss: -125.461\n",
      " 90%|████████▉ | 897/1000 [43:18<05:54,  3.44s/it]INFO:root:global_step: 897, logpy: 146.225, kl: 20.788, loss: -125.485\n",
      " 90%|████████▉ | 898/1000 [43:21<05:46,  3.39s/it]INFO:root:global_step: 898, logpy: 146.290, kl: 20.801, loss: -125.536\n",
      " 90%|████████▉ | 899/1000 [43:24<05:40,  3.37s/it]INFO:root:global_step: 899, logpy: 146.307, kl: 20.820, loss: -125.533\n",
      " 90%|█████████ | 900/1000 [43:28<05:34,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([121, 1])\n",
      "torch.Size([121, 1])\n",
      "torch.Size([121, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saved figure at: ./img_generation/global_step_900.png\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_core/sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 900, logpy: 146.348, kl: 20.834, loss: -125.561\n",
      " 90%|█████████ | 901/1000 [43:33<06:18,  3.82s/it]INFO:root:global_step: 901, logpy: 146.375, kl: 20.854, loss: -125.567\n",
      " 90%|█████████ | 902/1000 [43:36<06:05,  3.73s/it]INFO:root:global_step: 902, logpy: 146.418, kl: 20.867, loss: -125.596\n",
      " 90%|█████████ | 903/1000 [43:40<05:53,  3.65s/it]INFO:root:global_step: 903, logpy: 146.467, kl: 20.886, loss: -125.625\n",
      " 90%|█████████ | 904/1000 [43:43<05:45,  3.60s/it]INFO:root:global_step: 904, logpy: 146.539, kl: 20.904, loss: -125.680\n",
      " 90%|█████████ | 905/1000 [43:47<05:37,  3.55s/it]INFO:root:global_step: 905, logpy: 146.605, kl: 20.917, loss: -125.733\n",
      " 91%|█████████ | 906/1000 [43:50<05:26,  3.47s/it]INFO:root:global_step: 906, logpy: 146.645, kl: 20.930, loss: -125.759\n",
      " 91%|█████████ | 907/1000 [43:53<05:17,  3.41s/it]INFO:root:global_step: 907, logpy: 146.717, kl: 20.945, loss: -125.815\n",
      " 91%|█████████ | 908/1000 [43:56<05:14,  3.41s/it]INFO:root:global_step: 908, logpy: 146.792, kl: 20.962, loss: -125.872\n",
      " 91%|█████████ | 909/1000 [44:00<05:07,  3.38s/it]INFO:root:global_step: 909, logpy: 146.840, kl: 20.978, loss: -125.904\n",
      " 91%|█████████ | 910/1000 [44:03<05:02,  3.36s/it]INFO:root:global_step: 910, logpy: 146.879, kl: 20.998, loss: -125.922\n",
      " 91%|█████████ | 911/1000 [44:06<04:57,  3.34s/it]INFO:root:global_step: 911, logpy: 146.922, kl: 21.008, loss: -125.955\n",
      " 91%|█████████ | 912/1000 [44:10<04:58,  3.39s/it]INFO:root:global_step: 912, logpy: 146.947, kl: 21.026, loss: -125.962\n",
      " 91%|█████████▏| 913/1000 [44:13<04:52,  3.36s/it]INFO:root:global_step: 913, logpy: 146.995, kl: 21.046, loss: -125.990\n",
      " 91%|█████████▏| 914/1000 [44:17<04:51,  3.39s/it]INFO:root:global_step: 914, logpy: 147.056, kl: 21.061, loss: -126.035\n",
      " 92%|█████████▏| 915/1000 [44:20<04:49,  3.41s/it]INFO:root:global_step: 915, logpy: 147.070, kl: 21.083, loss: -126.027\n",
      " 92%|█████████▏| 916/1000 [44:24<04:47,  3.42s/it]INFO:root:global_step: 916, logpy: 147.131, kl: 21.098, loss: -126.073\n",
      " 92%|█████████▏| 917/1000 [44:27<04:42,  3.40s/it]INFO:root:global_step: 917, logpy: 147.220, kl: 21.111, loss: -126.148\n",
      " 92%|█████████▏| 918/1000 [44:30<04:37,  3.39s/it]INFO:root:global_step: 918, logpy: 147.263, kl: 21.124, loss: -126.178\n",
      " 92%|█████████▏| 919/1000 [44:34<04:33,  3.38s/it]INFO:root:global_step: 919, logpy: 147.328, kl: 21.137, loss: -126.229\n",
      " 92%|█████████▏| 920/1000 [44:37<04:29,  3.37s/it]INFO:root:global_step: 920, logpy: 147.426, kl: 21.153, loss: -126.311\n",
      " 92%|█████████▏| 921/1000 [44:40<04:26,  3.37s/it]INFO:root:global_step: 921, logpy: 147.487, kl: 21.170, loss: -126.355\n",
      " 92%|█████████▏| 922/1000 [44:44<04:21,  3.36s/it]INFO:root:global_step: 922, logpy: 147.528, kl: 21.184, loss: -126.381\n",
      " 92%|█████████▏| 923/1000 [44:47<04:18,  3.36s/it]INFO:root:global_step: 923, logpy: 147.566, kl: 21.196, loss: -126.407\n",
      " 92%|█████████▏| 924/1000 [44:50<04:14,  3.35s/it]INFO:root:global_step: 924, logpy: 147.594, kl: 21.212, loss: -126.419\n",
      " 92%|█████████▎| 925/1000 [44:54<04:13,  3.38s/it]INFO:root:global_step: 925, logpy: 147.657, kl: 21.227, loss: -126.465\n",
      " 93%|█████████▎| 926/1000 [44:57<04:09,  3.37s/it]INFO:root:global_step: 926, logpy: 147.707, kl: 21.242, loss: -126.501\n",
      " 93%|█████████▎| 927/1000 [45:01<04:05,  3.36s/it]INFO:root:global_step: 927, logpy: 147.775, kl: 21.255, loss: -126.555\n",
      " 93%|█████████▎| 928/1000 [45:04<04:03,  3.38s/it]INFO:root:global_step: 928, logpy: 147.854, kl: 21.269, loss: -126.620\n",
      " 93%|█████████▎| 929/1000 [45:07<03:59,  3.38s/it]INFO:root:global_step: 929, logpy: 147.912, kl: 21.285, loss: -126.661\n",
      " 93%|█████████▎| 930/1000 [45:11<03:57,  3.39s/it]INFO:root:global_step: 930, logpy: 147.979, kl: 21.302, loss: -126.711\n",
      " 93%|█████████▎| 931/1000 [45:14<03:54,  3.40s/it]INFO:root:global_step: 931, logpy: 148.037, kl: 21.317, loss: -126.754\n",
      " 93%|█████████▎| 932/1000 [45:18<03:50,  3.39s/it]INFO:root:global_step: 932, logpy: 148.082, kl: 21.330, loss: -126.786\n",
      " 93%|█████████▎| 933/1000 [45:21<03:45,  3.37s/it]INFO:root:global_step: 933, logpy: 148.117, kl: 21.344, loss: -126.807\n",
      " 93%|█████████▎| 934/1000 [45:24<03:42,  3.37s/it]INFO:root:global_step: 934, logpy: 148.183, kl: 21.359, loss: -126.857\n",
      " 94%|█████████▎| 935/1000 [45:28<03:39,  3.38s/it]INFO:root:global_step: 935, logpy: 148.203, kl: 21.379, loss: -126.856\n",
      " 94%|█████████▎| 936/1000 [45:31<03:34,  3.36s/it]INFO:root:global_step: 936, logpy: 148.223, kl: 21.394, loss: -126.861\n",
      " 94%|█████████▎| 937/1000 [45:34<03:31,  3.35s/it]INFO:root:global_step: 937, logpy: 148.257, kl: 21.413, loss: -126.875\n",
      " 94%|█████████▍| 938/1000 [45:38<03:27,  3.35s/it]INFO:root:global_step: 938, logpy: 148.281, kl: 21.430, loss: -126.883\n",
      " 94%|█████████▍| 939/1000 [45:41<03:27,  3.39s/it]INFO:root:global_step: 939, logpy: 148.328, kl: 21.452, loss: -126.907\n",
      " 94%|█████████▍| 940/1000 [45:45<03:24,  3.41s/it]INFO:root:global_step: 940, logpy: 148.390, kl: 21.462, loss: -126.959\n",
      " 94%|█████████▍| 941/1000 [45:48<03:22,  3.43s/it]INFO:root:global_step: 941, logpy: 148.426, kl: 21.474, loss: -126.982\n",
      " 94%|█████████▍| 942/1000 [45:51<03:17,  3.40s/it]INFO:root:global_step: 942, logpy: 148.464, kl: 21.487, loss: -127.008\n",
      " 94%|█████████▍| 943/1000 [45:55<03:12,  3.37s/it]INFO:root:global_step: 943, logpy: 148.486, kl: 21.499, loss: -127.017\n",
      " 94%|█████████▍| 944/1000 [45:58<03:08,  3.37s/it]INFO:root:global_step: 944, logpy: 148.522, kl: 21.512, loss: -127.040\n",
      " 94%|█████████▍| 945/1000 [46:01<03:06,  3.38s/it]INFO:root:global_step: 945, logpy: 148.563, kl: 21.528, loss: -127.065\n",
      " 95%|█████████▍| 946/1000 [46:05<03:01,  3.37s/it]INFO:root:global_step: 946, logpy: 148.621, kl: 21.545, loss: -127.105\n",
      " 95%|█████████▍| 947/1000 [46:08<02:58,  3.36s/it]INFO:root:global_step: 947, logpy: 148.694, kl: 21.556, loss: -127.168\n",
      " 95%|█████████▍| 948/1000 [46:12<02:55,  3.37s/it]INFO:root:global_step: 948, logpy: 148.737, kl: 21.574, loss: -127.192\n",
      " 95%|█████████▍| 949/1000 [46:15<02:51,  3.36s/it]INFO:root:global_step: 949, logpy: 148.788, kl: 21.588, loss: -127.229\n",
      " 95%|█████████▌| 950/1000 [46:18<02:47,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([121, 1])\n",
      "torch.Size([121, 1])\n",
      "torch.Size([121, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saved figure at: ./img_generation/global_step_950.png\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchsde/_core/sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 950, logpy: 148.844, kl: 21.606, loss: -127.265\n",
      " 95%|█████████▌| 951/1000 [46:23<03:03,  3.74s/it]INFO:root:global_step: 951, logpy: 148.900, kl: 21.619, loss: -127.309\n",
      " 95%|█████████▌| 952/1000 [46:27<02:58,  3.73s/it]INFO:root:global_step: 952, logpy: 148.957, kl: 21.636, loss: -127.348\n",
      " 95%|█████████▌| 953/1000 [46:30<02:50,  3.63s/it]INFO:root:global_step: 953, logpy: 149.010, kl: 21.647, loss: -127.390\n",
      " 95%|█████████▌| 954/1000 [46:33<02:43,  3.56s/it]INFO:root:global_step: 954, logpy: 149.085, kl: 21.660, loss: -127.453\n",
      " 96%|█████████▌| 955/1000 [46:37<02:37,  3.49s/it]INFO:root:global_step: 955, logpy: 149.124, kl: 21.676, loss: -127.475\n",
      " 96%|█████████▌| 956/1000 [46:40<02:31,  3.44s/it]INFO:root:global_step: 956, logpy: 149.171, kl: 21.690, loss: -127.507\n",
      " 96%|█████████▌| 957/1000 [46:43<02:26,  3.41s/it]INFO:root:global_step: 957, logpy: 149.208, kl: 21.701, loss: -127.534\n",
      " 96%|█████████▌| 958/1000 [46:47<02:22,  3.40s/it]INFO:root:global_step: 958, logpy: 149.265, kl: 21.714, loss: -127.576\n",
      " 96%|█████████▌| 959/1000 [46:50<02:18,  3.39s/it]INFO:root:global_step: 959, logpy: 149.318, kl: 21.729, loss: -127.614\n",
      " 96%|█████████▌| 960/1000 [46:53<02:14,  3.37s/it]INFO:root:global_step: 960, logpy: 149.378, kl: 21.744, loss: -127.659\n",
      " 96%|█████████▌| 961/1000 [46:57<02:11,  3.36s/it]INFO:root:global_step: 961, logpy: 149.424, kl: 21.756, loss: -127.692\n",
      " 96%|█████████▌| 962/1000 [47:00<02:07,  3.36s/it]INFO:root:global_step: 962, logpy: 149.451, kl: 21.767, loss: -127.709\n",
      " 96%|█████████▋| 963/1000 [47:03<02:04,  3.36s/it]INFO:root:global_step: 963, logpy: 149.516, kl: 21.782, loss: -127.759\n",
      " 96%|█████████▋| 964/1000 [47:07<02:00,  3.36s/it]INFO:root:global_step: 964, logpy: 149.555, kl: 21.798, loss: -127.781\n",
      " 96%|█████████▋| 965/1000 [47:10<01:59,  3.41s/it]INFO:root:global_step: 965, logpy: 149.613, kl: 21.811, loss: -127.826\n",
      " 97%|█████████▋| 966/1000 [47:14<01:55,  3.40s/it]INFO:root:global_step: 966, logpy: 149.664, kl: 21.826, loss: -127.862\n",
      " 97%|█████████▋| 967/1000 [47:17<01:52,  3.41s/it]INFO:root:global_step: 967, logpy: 149.732, kl: 21.837, loss: -127.918\n",
      " 97%|█████████▋| 968/1000 [47:21<01:48,  3.40s/it]INFO:root:global_step: 968, logpy: 149.776, kl: 21.852, loss: -127.947\n",
      " 97%|█████████▋| 969/1000 [47:24<01:44,  3.38s/it]INFO:root:global_step: 969, logpy: 149.811, kl: 21.868, loss: -127.966\n",
      " 97%|█████████▋| 970/1000 [47:27<01:42,  3.41s/it]INFO:root:global_step: 970, logpy: 149.867, kl: 21.886, loss: -128.004\n",
      " 97%|█████████▋| 971/1000 [47:31<01:38,  3.38s/it]INFO:root:global_step: 971, logpy: 149.915, kl: 21.900, loss: -128.037\n",
      " 97%|█████████▋| 972/1000 [47:34<01:34,  3.38s/it]INFO:root:global_step: 972, logpy: 149.965, kl: 21.910, loss: -128.078\n",
      " 97%|█████████▋| 973/1000 [47:37<01:31,  3.38s/it]INFO:root:global_step: 973, logpy: 149.998, kl: 21.924, loss: -128.096\n",
      " 97%|█████████▋| 974/1000 [47:41<01:28,  3.40s/it]INFO:root:global_step: 974, logpy: 150.025, kl: 21.939, loss: -128.107\n",
      " 98%|█████████▊| 975/1000 [47:44<01:26,  3.45s/it]INFO:root:global_step: 975, logpy: 150.090, kl: 21.957, loss: -128.155\n",
      " 98%|█████████▊| 976/1000 [47:48<01:22,  3.43s/it]INFO:root:global_step: 976, logpy: 150.116, kl: 21.973, loss: -128.165\n",
      " 98%|█████████▊| 977/1000 [47:51<01:18,  3.41s/it]INFO:root:global_step: 977, logpy: 150.164, kl: 21.981, loss: -128.204\n",
      " 98%|█████████▊| 978/1000 [47:55<01:15,  3.43s/it]INFO:root:global_step: 978, logpy: 150.230, kl: 21.993, loss: -128.258\n",
      " 98%|█████████▊| 979/1000 [47:58<01:11,  3.41s/it]INFO:root:global_step: 979, logpy: 150.253, kl: 22.006, loss: -128.268\n",
      " 98%|█████████▊| 980/1000 [48:01<01:08,  3.40s/it]INFO:root:global_step: 980, logpy: 150.318, kl: 22.022, loss: -128.317\n",
      " 98%|█████████▊| 981/1000 [48:05<01:04,  3.39s/it]INFO:root:global_step: 981, logpy: 150.361, kl: 22.034, loss: -128.347\n",
      " 98%|█████████▊| 982/1000 [48:08<01:01,  3.39s/it]INFO:root:global_step: 982, logpy: 150.396, kl: 22.045, loss: -128.371\n",
      " 98%|█████████▊| 983/1000 [48:12<00:57,  3.40s/it]INFO:root:global_step: 983, logpy: 150.419, kl: 22.057, loss: -128.382\n",
      " 98%|█████████▊| 984/1000 [48:15<00:54,  3.38s/it]INFO:root:global_step: 984, logpy: 150.481, kl: 22.071, loss: -128.430\n",
      " 98%|█████████▊| 985/1000 [48:18<00:50,  3.37s/it]INFO:root:global_step: 985, logpy: 150.550, kl: 22.082, loss: -128.487\n",
      " 99%|█████████▊| 986/1000 [48:22<00:46,  3.35s/it]INFO:root:global_step: 986, logpy: 150.574, kl: 22.102, loss: -128.492\n",
      " 99%|█████████▊| 987/1000 [48:25<00:43,  3.34s/it]INFO:root:global_step: 987, logpy: 150.605, kl: 22.110, loss: -128.514\n",
      " 99%|█████████▉| 988/1000 [48:28<00:40,  3.35s/it]INFO:root:global_step: 988, logpy: 150.639, kl: 22.124, loss: -128.534\n",
      " 99%|█████████▉| 989/1000 [48:32<00:36,  3.36s/it]INFO:root:global_step: 989, logpy: 150.685, kl: 22.134, loss: -128.570\n",
      " 99%|█████████▉| 990/1000 [48:35<00:33,  3.35s/it]INFO:root:global_step: 990, logpy: 150.745, kl: 22.145, loss: -128.619\n",
      " 99%|█████████▉| 991/1000 [48:38<00:30,  3.35s/it]INFO:root:global_step: 991, logpy: 150.787, kl: 22.159, loss: -128.646\n",
      " 99%|█████████▉| 992/1000 [48:42<00:26,  3.36s/it]INFO:root:global_step: 992, logpy: 150.829, kl: 22.172, loss: -128.675\n",
      " 99%|█████████▉| 993/1000 [48:45<00:23,  3.40s/it]INFO:root:global_step: 993, logpy: 150.889, kl: 22.185, loss: -128.722\n",
      " 99%|█████████▉| 994/1000 [48:49<00:20,  3.39s/it]INFO:root:global_step: 994, logpy: 150.939, kl: 22.200, loss: -128.757\n",
      "100%|█████████▉| 995/1000 [48:52<00:16,  3.39s/it]INFO:root:global_step: 995, logpy: 151.012, kl: 22.216, loss: -128.814\n",
      "100%|█████████▉| 996/1000 [48:55<00:13,  3.40s/it]INFO:root:global_step: 996, logpy: 151.066, kl: 22.230, loss: -128.854\n",
      "100%|█████████▉| 997/1000 [48:59<00:10,  3.41s/it]INFO:root:global_step: 997, logpy: 151.105, kl: 22.243, loss: -128.879\n",
      "100%|█████████▉| 998/1000 [49:02<00:06,  3.39s/it]INFO:root:global_step: 998, logpy: 151.119, kl: 22.260, loss: -128.876\n",
      "100%|█████████▉| 999/1000 [49:06<00:03,  3.40s/it]INFO:root:global_step: 999, logpy: 151.145, kl: 22.275, loss: -128.887\n",
      "100%|██████████| 1000/1000 [49:09<00:00,  2.95s/it]\n"
     ]
    }
   ],
   "source": [
    "manual_seed(args['seed'])\n",
    "\n",
    "if args['debug']:\n",
    "    logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "ckpt_dir = os.path.join('./sim/', 'ckpts')\n",
    "os.makedirs(ckpt_dir, exist_ok=True)\n",
    "\n",
    "sdeint_fn = torchsde.sdeint_adjoint if args['adjoint'] else torchsde.sdeint\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c356ad31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
