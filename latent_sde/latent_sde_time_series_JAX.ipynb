{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4dd7b82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'jaxlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10988/2254085835.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mjaxsde\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjaxsde\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msdeint\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msdeint_ito_fixed_grid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\time_series\\latent_sde\\jaxsde\\jaxsde\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbrownian\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmake_brownian_motion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0msdeint\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mito_integrate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstratonovich_integrate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msdeint_ito\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msdeint_strat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0msde_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime_reflect_ito\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_reflect_stratonovich\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmake_gdg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mito_to_stratonovich\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstratonovich_to_ito\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0msde_vjp\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mvjp_ito_integrate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmake_explicit_sigma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\time_series\\latent_sde\\jaxsde\\jaxsde\\brownian.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mfunctools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpartial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mjax\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mjax\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlax\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscan\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjax\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\jax\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# flake8: noqa: F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m from .api import (\n\u001b[0m\u001b[0;32m     23\u001b[0m   \u001b[0mad\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# TODO(phawkins): update users to avoid this.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m   \u001b[0margnums_partial\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# TODO(phawkins): update Haiku to not use this.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\jax\\api.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcontextlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcontextmanager\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExitStack\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlinear_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mlu\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\jax\\core.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlinear_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mlu\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\jax\\dtypes.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mxla_client\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0mFLAGS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\jax\\lib\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m ]\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mjaxlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m# Must be kept in sync with the jaxlib version in build/test-requirements.txt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'jaxlib'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from collections import namedtuple\n",
    "from typing import Optional, Union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import tqdm\n",
    "from torch import distributions, nn, optim\n",
    "\n",
    "from jaxsde.jaxsde.sdeint import sdeint_ito_fixed_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0aeebbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the gpu is available or not, if yes, use gpu\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2902c1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the tuple for data, \n",
    "Data = namedtuple('Data', ['ts_', 'ts_ext_', 'ts_vis_', 'ts', 'ts_ext', 'ts_vis', 'ys', 'ys_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9198a09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"train_iters\": 500,\n",
    "    \"pause_iters\": 50,\n",
    "    \"hide_ticks\": False,\n",
    "    \"save_ckpt\":True,\n",
    "    \"likelihood\":\"laplace\",\n",
    "    \"scale\": 0.0001,\n",
    "    \"adjoint\": False,\n",
    "    \"debug\": True,\n",
    "    \"seed\": 42,\n",
    "    'data':'segmented_cosine',\n",
    "    \"dt\": 1e-2,\n",
    "    \"batch_size\": 256,\n",
    "    \"method\": 'euler',\n",
    "    \"adaptive\": 'False',\n",
    "    \"rtol\": 1e-3,\n",
    "    \"atol\": 1e-3\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40420fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output values from 0 to maxval with iters steps\n",
    "class LinearScheduler(object):\n",
    "    def __init__(self, iters, maxval=1.0):\n",
    "        self._iters = max(1,iters)\n",
    "        self._val = maxval/self._iters\n",
    "        self._maxval = maxval\n",
    "    \n",
    "    def step(self):\n",
    "        self._val = min(self._maxval, self._val+self._maxval/self._iters)\n",
    "        \n",
    "    @property\n",
    "    def val(self):\n",
    "        return self._val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93c09c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EMAMetric(object):\n",
    "    def __init__(self, gamma: Optional[float]=0.99):\n",
    "        super(EMAMetric, self).__init__()\n",
    "        self._val=0\n",
    "        self._gamma = gamma\n",
    "    def step(self, x:Union[torch.Tensor, np.ndarray]):\n",
    "        x = x.detach().cpu().numpy() if torch.is_tensor(x) else x\n",
    "        self._val = self._gamma * self._val + (1-self._gamma)*x\n",
    "        return self._val\n",
    "    \n",
    "    @property\n",
    "    def val(self):\n",
    "        return self._val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a4ec86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the seed\n",
    "def manual_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98a2f4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure that the dvision is stable\n",
    "def _stable_division(a,b,epsilon=1e-7):\n",
    "    b = torch.where(b.abs().detach() > epsilon, b, torch.full_like(b, fill_value=epsilon)*b.sign())\n",
    "    return a/b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "522d3e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LatentSDE(torchsde.SDEIto): # sde with ito calculus\n",
    "    def __init__(self, theta=1.0, mu=0.0, sigma=1):\n",
    "        super(LatentSDE, self).__init__(noise_type=\"diagonal\")\n",
    "        logvar = math.log(sigma ** 2/(2.*theta))\n",
    "        \n",
    "        # prior drift\n",
    "        self.register_buffer(\"theta\",torch.tensor([[theta]])) # prior parameters, register 成buffer, 参数不会进行更新\n",
    "        self.register_buffer(\"mu\", torch.tensor([[mu]]))\n",
    "        self.register_buffer(\"sigma\",torch.tensor([[sigma]]))\n",
    "        \n",
    "        # p(y0)\n",
    "        self.register_buffer(\"py0_mean\", torch.tensor([[mu]]))\n",
    "        self.register_buffer(\"py0_logvar\", torch.tensor([[logvar]]))\n",
    "        \n",
    "        # approximate posterior drift: Takes in 2 positional encodings and the state\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(3,200),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(200,200),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(200,1)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Initialization the parameters\n",
    "        self.net[-1].weight.data.fill_(0.) # 初始化最后一层的参数\n",
    "        self.net[-1].bias.data.fill_(0.)\n",
    "            \n",
    "        # q(y0)\n",
    "        self.qy0_mean = nn.Parameter(torch.tensor([[mu]]), requires_grad=True) # 创建parameters\n",
    "        self.qy0_logvar = nn.Parameter(torch.tensor([[logvar]]), requires_grad=True) # 创建parameters\n",
    "        #self.theta = nn.Parameter(torch.tensor([[theta]]),requires_grad=True)\n",
    "        #self.theta = nn.Parameter(torch.tensor([[theta]]),requires_grad=True)\n",
    "            \n",
    "    def f(self, t, y):  # Approximate posterior drift.\n",
    "        if t.dim() == 0:\n",
    "            t = torch.full_like(y, fill_value=t) # create a tensor of t\n",
    "        # Positional encoding in transformers for time-inhomogeneous posterior.\n",
    "        return self.net(torch.cat((torch.sin(t), torch.cos(t), y), dim=-1))\n",
    "\n",
    "    def g(self, t, y):  # Shared diffusion.\n",
    "        return self.sigma.repeat(y.size(0), 1) # 重复复制, 创建一个size为[y.size[0],1]\n",
    "\n",
    "    def h(self, t, y):  # Prior drift.\n",
    "        return self.theta * (self.mu - y)\n",
    "\n",
    "    def f_aug(self, t, y):  # Drift for augmented dynamics with logqp term.\n",
    "        y = y[:, 0:1] # 提取第一列，保持列的形态\n",
    "        f, g, h = self.f(t, y), self.g(t, y), self.h(t, y)\n",
    "        u = _stable_division(f - h, g) # 计算u(z,t)\n",
    "        f_logqp = .5 * (u ** 2).sum(dim=1, keepdim=True) # 计算integral\n",
    "        return torch.cat([f, f_logqp], dim=1)\n",
    "\n",
    "    def g_aug(self, t, y):  # Diffusion for augmented dynamics with logqp term.\n",
    "        y = y[:, 0:1]\n",
    "        g = self.g(t, y)\n",
    "        g_logqp = torch.zeros_like(y)\n",
    "        return torch.cat([g, g_logqp], dim=1)\n",
    "\n",
    "    def forward(self, ts, batch_size, eps=None):\n",
    "        eps = torch.randn(batch_size, 1).to(self.qy0_std) if eps is None else eps\n",
    "        y0 = self.qy0_mean + eps * self.qy0_std # the latent variable\n",
    "        qy0 = distributions.Normal(loc=self.qy0_mean, scale=self.qy0_std) # approximate posterior distribution\n",
    "        py0 = distributions.Normal(loc=self.py0_mean, scale=self.py0_std) # prior distribution\n",
    "        logqp0 = distributions.kl_divergence(qy0, py0).sum(dim=1)  # KL(t=0). calculate the kl divergence\n",
    "        #print(y0.size()) # (256, 1)\n",
    "        aug_y0 = torch.cat([y0, torch.zeros(batch_size, 1).to(y0)], dim=1) # create the augmented initial value\n",
    "        #print(aug_y0.size()) # [256, 2]\n",
    "        aug_ys = sdeint_fn(\n",
    "            sde=self,\n",
    "            y0=aug_y0,\n",
    "            ts=ts,\n",
    "            method=args['method'],\n",
    "            dt=args['dt'],\n",
    "            adaptive=args['adaptive'],\n",
    "            rtol=args['rtol'],\n",
    "            atol=args['atol'],\n",
    "            names={'drift': 'f_aug', 'diffusion': 'g_aug'}\n",
    "        ) # call the sde solver to \n",
    "        # print(aug_ys.size()) # [22, 256, 2]\n",
    "        ys, logqp_path = aug_ys[:, :, 0:1], aug_ys[-1, :, 1] # get the integral of the u(z,t) at the last time\n",
    "        \n",
    "        logqp = (logqp0 + logqp_path).mean(dim=0)  # KL(t=0) + KL(path).\n",
    "        return ys, logqp\n",
    "\n",
    "    def sample_p(self, ts, batch_size, eps=None, bm=None):\n",
    "        eps = torch.randn(batch_size, 1).to(self.py0_mean) if eps is None else eps\n",
    "        y0 = self.py0_mean + eps * self.py0_std\n",
    "        return sdeint_fn(self, y0, ts, bm=bm, method=args['method'], dt=args['dt'], names={'drift': 'h'}) # prior sde\n",
    "\n",
    "    def sample_q(self, ts, batch_size, eps=None, bm=None):\n",
    "        eps = torch.randn(batch_size, 1).to(self.qy0_mean) if eps is None else eps\n",
    "        y0 = self.qy0_mean + eps * self.qy0_std\n",
    "        return sdeint_fn(self, y0, ts, bm=bm, method=args['method'], dt=args['dt']) # posterior sde\n",
    "\n",
    "    @property\n",
    "    def py0_std(self):\n",
    "        return torch.exp(.5 * self.py0_logvar)\n",
    "\n",
    "    @property\n",
    "    def qy0_std(self):\n",
    "        return torch.exp(.5 * self.qy0_logvar)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80736fff",
   "metadata": {},
   "source": [
    "## 5. Simulation of time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd15aaa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "T = 30\n",
    "#beta = 0.1694\n",
    "beta=1\n",
    "def make_time_series():\n",
    "    \n",
    "    \n",
    "    phi = 0.99\n",
    "    sigma_v = 0.003342\n",
    "    sigma_u = 0.00328\n",
    "    rho = -0.856\n",
    "    cov_uv = rho * sigma_u * sigma_v\n",
    "\n",
    "    # generating shocks\n",
    "    mu = [0,0]\n",
    "    cov = [[sigma_u**2, cov_uv], [cov_uv, sigma_v**2]]\n",
    "    shocks = np.random.multivariate_normal(mu, cov, T)\n",
    "\n",
    "    z0 = np.random.normal(0, sigma_u**2/(1-phi**2),1)\n",
    "    r0 = shocks[0][0]\n",
    "\n",
    "    z = np.zeros(T)\n",
    "    r = np.zeros(T)\n",
    "    z[0] = z0\n",
    "    r[0] = r0\n",
    "\n",
    "    for idx_t in range(T-1):\n",
    "        z[idx_t+1] = phi*z[idx_t] + shocks[idx_t+1][1]\n",
    "        r[idx_t+1] = beta*z[idx_t+1] + shocks[idx_t+1][0]\n",
    "    return z, r\n",
    "z, r = make_time_series()\n",
    "plt.figure(figsize=(15,5))\n",
    "xvalues = np.array(range(T))\n",
    "plt.plot(xvalues, r, linestyle='-', color='g', label=\"observed $r_t$\")\n",
    "plt.plot(xvalues, z, linestyle=\"--\", color=\"r\", label=r\"hidden variable $\\beta * z_t$\", linewidth=3.0)\n",
    "\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('%')\n",
    "plt.grid(True)\n",
    "plt.title(r\"Simulated $r_t$ and hidden $\\beta * z_t$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cf9fca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data():\n",
    "    ts_ = np.linspace(0.1,30.0,30)\n",
    "    ts_ext_ = np.array([0.] + list(ts_) + [30.1])\n",
    "    ts_vis_ = np.linspace(0.1, 30.1, 31)\n",
    "    ys_ = r[:,None]\n",
    "    ts = torch.tensor(ts_).float()\n",
    "    ts_ext = torch.tensor(ts_ext_).float()\n",
    "    ts_vis = torch.tensor(ts_vis_).float()\n",
    "    ys = torch.tensor(ys_).float().to(device)\n",
    "    return Data(ts_, ts_ext_, ts_vis_, ts, ts_ext, ts_vis, ys, ys_)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99a1fc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Dataset\n",
    "    ts_, ts_ext_, ts_vis_, ts, ts_ext, ts_vis, ys, ys_ = make_data()\n",
    "    #mu = torch.mean(ys)\n",
    "    sigma = torch.std(ys)\n",
    "    \n",
    "    # plotting parameters\n",
    "    vis_batch_size = 1024\n",
    "    ylims = (-0.03, 0.03)\n",
    "    alphas = [0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.55]\n",
    "    percentiles = [0.999, 0.99, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1]\n",
    "    vis_idx = np.random.permutation(vis_batch_size)\n",
    "    sample_colors = ('#8c96c6', '#8c6bb1', '#810f7c')\n",
    "    fill_color = '#9ebcda'\n",
    "    mean_color = '#4d004b'\n",
    "    num_samples = len(sample_colors)\n",
    "    \n",
    "    eps = torch.randn(vis_batch_size, 1).to(device)\n",
    "    bm = torchsde.BrownianInterval(\n",
    "        t0=ts_vis[0],\n",
    "        t1=ts_vis[-1],\n",
    "        size=(vis_batch_size,1),\n",
    "        device=device,\n",
    "        levy_area_approximation=\"space-time\")\n",
    "    \n",
    "    # Model\n",
    "    model = LatentSDE(theta=1.0,mu=0.0,sigma=sigma).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "    kl_scheduler = LinearScheduler(iters=100)\n",
    "    criterion = nn.BCELoss(reduction='sum')\n",
    "    \n",
    "    logpy_metric = EMAMetric()\n",
    "    kl_metric = EMAMetric()\n",
    "    loss_metric = EMAMetric()\n",
    "    \n",
    "    \n",
    "    # show prior\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        zs = model.sample_p(ts=ts_vis, batch_size = vis_batch_size, eps = eps, bm=bm).squeeze()\n",
    "       \n",
    "        ts_vis_, zs_ = ts_vis.cpu().numpy(), zs.cpu().numpy()\n",
    "        #plt.scatter(ts_vis_, ys_, color='r', label=\"prior\")\n",
    "        zs_ = np.sort(zs_,axis=1)\n",
    "        img_dir = os.path.join('./sim/','prior.png')\n",
    "        plt.subplot(frameon=False)\n",
    "        for alpha, percentile in zip(alphas, percentiles):\n",
    "            idx = int((1 - percentile) / 2. * vis_batch_size)\n",
    "            zs_bot_ = zs_[:, idx]\n",
    "            zs_top_ = zs_[:, -idx]\n",
    "            plt.fill_between(ts_vis_, zs_bot_, zs_top_, alpha=alpha, color=fill_color)\n",
    "\n",
    "        # `zorder` determines who's on top; the larger the more at the top.\n",
    "        \n",
    "        plt.scatter(ts_, ys_, marker='x', zorder=3, color='k', s=35)  # Data.\n",
    "        plt.plot(ts_, ys_, marker='x', zorder=3, color='k',label=\"observed $r_t$\")\n",
    "        plt.plot(ts_, z[:,None], color='g', linewidth=3.0, label=r\"hidden variable $z_t$\")\n",
    "        plt.ylim(ylims)\n",
    "        plt.xlabel('$t$')\n",
    "        plt.ylabel('$Y_t$')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.legend()\n",
    "        plt.savefig(img_dir, dpi=300)\n",
    "        plt.close()\n",
    "        logging.info(f'Saved prior figure at: {img_dir}')\n",
    "    \n",
    "    \n",
    "    for global_step in tqdm.tqdm(range(args['train_iters'])):\n",
    "        \n",
    "        # Plot and save.\n",
    "        if global_step % args['pause_iters'] == 0:\n",
    "            img_path = os.path.join(\"./sim/\", f'global_step_{global_step}.png')\n",
    "\n",
    "            with torch.no_grad():\n",
    "                zs = model.sample_q(ts=ts_vis, batch_size=vis_batch_size, eps=eps, bm=bm).squeeze()\n",
    "                samples = zs[:, vis_idx]\n",
    "                ts_vis_, zs_, samples_ = ts_vis.cpu().numpy(), zs.cpu().numpy(), samples.cpu().numpy()\n",
    "                zs_ = np.sort(zs_, axis=1)\n",
    "                plt.subplot(frameon=False)\n",
    "\n",
    "                if True: # args.show_percentiles:\n",
    "                    for alpha, percentile in zip(alphas, percentiles):\n",
    "                        idx = int((1 - percentile) / 2. * vis_batch_size)\n",
    "                        zs_bot_, zs_top_ = zs_[:, idx], zs_[:, -idx]\n",
    "                        plt.fill_between(ts_vis_, zs_bot_, zs_top_, alpha=alpha, color=fill_color)\n",
    "\n",
    "                if True: #args.show_mean:\n",
    "                    plt.plot(ts_vis_, zs_.mean(axis=1), color=mean_color)\n",
    "\n",
    "                if True: #args.show_samples:\n",
    "                    #for j in range(num_samples):\n",
    "                    #    plt.plot(ts_vis_, samples_[:, j], color=sample_colors[j], linewidth=1.0)\n",
    "                    plt.plot(ts_, z[:,None], color='g', linewidth=3.0, label=r\"hidden variable $z_t$\")\n",
    "                    plt.plot(ts_vis_, samples_.mean(axis=1), color='r',label=r'mean of latent variables')\n",
    "\n",
    "                if True: #args.show_arrows:\n",
    "                    num, dt = 3, 0.12\n",
    "                    t, y = torch.meshgrid(\n",
    "                        [torch.linspace(0, 3, num).to(device), torch.linspace(-0.3, 0.3, num).to(device)]\n",
    "                    )\n",
    "                    t, y = t.reshape(-1, 1), y.reshape(-1, 1)\n",
    "                    fty = model.f(t=t, y=y).reshape(num, num)\n",
    "                    dt = torch.zeros(num, num).fill_(dt).to(device)\n",
    "                    dy = fty * dt\n",
    "                    dt_, dy_, t_, y_ = dt.cpu().numpy(), dy.cpu().numpy(), t.cpu().numpy(), y.cpu().numpy()\n",
    "                    plt.quiver(t_, y_, dt_, dy_, alpha=0.3, edgecolors='k', width=0.0035, scale=50)\n",
    "\n",
    "                if False: #args.hide_ticks:\n",
    "                    plt.xticks([], [])\n",
    "                    plt.yticks([], [])\n",
    "\n",
    "                #plt.scatter(ts_, ys_, marker='x', zorder=3, color='k', s=35)  # Data.\n",
    "                plt.plot(ts_, ys_, marker='x', zorder=3, color='k', label=\"observed $r_t$ \") # new added\n",
    "            \n",
    "\n",
    "                \n",
    "                plt.ylim(ylims)\n",
    "                plt.xlabel('$t$')\n",
    "                plt.ylabel('$Y_t$')\n",
    "                plt.tight_layout()\n",
    "                plt.legend()\n",
    "                plt.savefig(img_path, dpi=300)\n",
    "                plt.close()\n",
    "                logging.info(f'Saved figure at: {img_path}')\n",
    "\n",
    "                \n",
    "        \n",
    "        # Train.\n",
    "        optimizer.zero_grad() # zero the gradient\n",
    "        zs, kl = model(ts=ts_ext, batch_size=args['batch_size']) # pass through the model, ys, logqp\n",
    "        zs = zs.squeeze() # remove the dimensions of input of size 1\n",
    "        zs = zs[1:-1]  # Drop first and last which are only used to penalize out-of-data region and spread uncertainty.\n",
    "\n",
    "        likelihood_constructor = {\"laplace\": distributions.Laplace, \"normal\": distributions.Normal}[args['likelihood']]\n",
    "        likelihood = likelihood_constructor(loc=zs, scale=args['scale']) # create the laplace distribution\n",
    "        logpy = likelihood.log_prob(ys).sum(dim=0).mean(dim=0) # got the log likelihood\n",
    "\n",
    "        loss = -logpy + kl * kl_scheduler.val\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        kl_scheduler.step()\n",
    "\n",
    "        logpy_metric.step(logpy)\n",
    "        kl_metric.step(kl)\n",
    "        loss_metric.step(loss)\n",
    "\n",
    "        logging.info(\n",
    "            f'global_step: {global_step}, '\n",
    "            f'logpy: {logpy_metric.val:.3f}, '\n",
    "            f'kl: {kl_metric.val:.3f}, '\n",
    "            f'loss: {loss_metric.val:.3f}'\n",
    "        )\n",
    "    torch.save(\n",
    "        {'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'scheduler': scheduler.state_dict(),\n",
    "            'kl_scheduler': kl_scheduler},\n",
    "        os.path.join('./sim/', f'global_step_{global_step}.ckpt')\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "74b55c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saved prior figure at: ./sim/prior.png\n",
      "  0%|                                                                                         | 0/1000 [00:00<?, ?it/s]INFO:root:Saved figure at: ./sim/global_step_0.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 0, logpy: -57.971, kl: 2.447, loss: 57.995\n",
      "  0%|                                                                               | 1/1000 [00:08<2:14:48,  8.10s/it]INFO:root:global_step: 1, logpy: -1140.805, kl: 848.256, loss: 1157.746\n",
      "  0%|▏                                                                              | 2/1000 [00:08<1:03:31,  3.82s/it]INFO:root:global_step: 2, logpy: -1578.056, kl: 997.561, loss: 1599.561\n",
      "  0%|▏                                                                                | 3/1000 [00:09<42:04,  2.53s/it]INFO:root:global_step: 3, logpy: -1659.156, kl: 991.488, loss: 1680.602\n",
      "  0%|▎                                                                                | 4/1000 [00:11<36:48,  2.22s/it]INFO:root:global_step: 4, logpy: -1813.230, kl: 995.423, loss: 1835.154\n",
      "  0%|▍                                                                                | 5/1000 [00:13<32:20,  1.95s/it]INFO:root:global_step: 5, logpy: -1861.411, kl: 987.349, loss: 1883.229\n",
      "  1%|▍                                                                                | 6/1000 [00:14<31:14,  1.89s/it]INFO:root:global_step: 6, logpy: -1939.093, kl: 989.836, loss: 1961.558\n",
      "  1%|▌                                                                                | 7/1000 [00:16<28:51,  1.74s/it]INFO:root:global_step: 7, logpy: -2065.277, kl: 1002.555, loss: 2089.327\n",
      "  1%|▋                                                                                | 8/1000 [00:17<26:41,  1.61s/it]INFO:root:global_step: 8, logpy: -2160.211, kl: 1008.489, loss: 2185.457\n",
      "  1%|▋                                                                                | 9/1000 [00:19<25:57,  1.57s/it]INFO:root:global_step: 9, logpy: -2195.208, kl: 1004.029, loss: 2220.763\n",
      "  1%|▊                                                                               | 10/1000 [00:20<26:32,  1.61s/it]INFO:root:global_step: 10, logpy: -2219.914, kl: 995.220, loss: 2245.349\n",
      "  1%|▉                                                                               | 11/1000 [00:22<27:15,  1.65s/it]INFO:root:global_step: 11, logpy: -2272.399, kl: 987.313, loss: 2297.825\n",
      "  1%|▉                                                                               | 12/1000 [00:24<27:30,  1.67s/it]INFO:root:global_step: 12, logpy: -2328.126, kl: 979.679, loss: 2353.589\n",
      "  1%|█                                                                               | 13/1000 [00:26<27:39,  1.68s/it]INFO:root:global_step: 13, logpy: -2369.965, kl: 971.546, loss: 2395.406\n",
      "  1%|█                                                                               | 14/1000 [00:27<28:05,  1.71s/it]INFO:root:global_step: 14, logpy: -2392.284, kl: 963.074, loss: 2417.658\n",
      "  2%|█▏                                                                              | 15/1000 [00:29<28:26,  1.73s/it]INFO:root:global_step: 15, logpy: -2404.577, kl: 955.250, loss: 2429.986\n",
      "  2%|█▎                                                                              | 16/1000 [00:31<28:48,  1.76s/it]INFO:root:global_step: 16, logpy: -2421.357, kl: 948.906, loss: 2447.057\n",
      "  2%|█▎                                                                              | 17/1000 [00:33<28:45,  1.76s/it]INFO:root:global_step: 17, logpy: -2450.673, kl: 944.595, loss: 2477.049\n",
      "  2%|█▍                                                                              | 18/1000 [00:34<28:18,  1.73s/it]INFO:root:global_step: 18, logpy: -2481.687, kl: 940.657, loss: 2508.845\n",
      "  2%|█▌                                                                              | 19/1000 [00:36<28:13,  1.73s/it]INFO:root:global_step: 19, logpy: -2505.503, kl: 935.625, loss: 2533.264\n",
      "  2%|█▌                                                                              | 20/1000 [00:38<28:18,  1.73s/it]INFO:root:global_step: 20, logpy: -2525.190, kl: 929.999, loss: 2553.457\n",
      "  2%|█▋                                                                              | 21/1000 [00:39<28:06,  1.72s/it]INFO:root:global_step: 21, logpy: -2537.772, kl: 923.290, loss: 2566.326\n",
      "  2%|█▊                                                                              | 22/1000 [00:41<28:10,  1.73s/it]INFO:root:global_step: 22, logpy: -2551.402, kl: 916.447, loss: 2580.221\n",
      "  2%|█▊                                                                              | 23/1000 [00:43<28:40,  1.76s/it]INFO:root:global_step: 23, logpy: -2566.035, kl: 908.908, loss: 2594.956\n",
      "  2%|█▉                                                                              | 24/1000 [00:45<29:09,  1.79s/it]INFO:root:global_step: 24, logpy: -2581.057, kl: 901.197, loss: 2610.033\n",
      "  2%|██                                                                              | 25/1000 [00:47<28:58,  1.78s/it]INFO:root:global_step: 25, logpy: -2595.120, kl: 893.334, loss: 2624.105\n",
      "  3%|██                                                                              | 26/1000 [00:48<29:02,  1.79s/it]INFO:root:global_step: 26, logpy: -2611.666, kl: 885.714, loss: 2640.715\n",
      "  3%|██▏                                                                             | 27/1000 [00:50<29:14,  1.80s/it]INFO:root:global_step: 27, logpy: -2629.030, kl: 878.211, loss: 2658.169\n",
      "  3%|██▏                                                                             | 28/1000 [00:52<29:14,  1.81s/it]INFO:root:global_step: 28, logpy: -2642.077, kl: 870.660, loss: 2671.281\n",
      "  3%|██▎                                                                             | 29/1000 [00:54<29:18,  1.81s/it]INFO:root:global_step: 29, logpy: -2655.054, kl: 863.183, loss: 2684.335\n",
      "  3%|██▍                                                                             | 30/1000 [00:56<29:10,  1.80s/it]INFO:root:global_step: 30, logpy: -2667.776, kl: 856.007, loss: 2697.215\n",
      "  3%|██▍                                                                             | 31/1000 [00:58<29:13,  1.81s/it]INFO:root:global_step: 31, logpy: -2681.018, kl: 849.063, loss: 2710.680\n",
      "  3%|██▌                                                                             | 32/1000 [00:59<29:05,  1.80s/it]INFO:root:global_step: 32, logpy: -2692.186, kl: 842.214, loss: 2722.093\n",
      "  3%|██▋                                                                             | 33/1000 [01:01<28:55,  1.79s/it]INFO:root:global_step: 33, logpy: -2702.969, kl: 835.539, loss: 2733.171\n",
      "  3%|██▋                                                                             | 34/1000 [01:03<28:34,  1.77s/it]INFO:root:global_step: 34, logpy: -2712.407, kl: 828.967, loss: 2742.931\n",
      "  4%|██▊                                                                             | 35/1000 [01:05<28:38,  1.78s/it]INFO:root:global_step: 35, logpy: -2723.766, kl: 822.550, loss: 2754.659\n",
      "  4%|██▉                                                                             | 36/1000 [01:06<28:46,  1.79s/it]INFO:root:global_step: 36, logpy: -2734.080, kl: 816.278, loss: 2765.387\n",
      "  4%|██▉                                                                             | 37/1000 [01:08<28:21,  1.77s/it]INFO:root:global_step: 37, logpy: -2744.179, kl: 810.330, loss: 2776.015\n",
      "  4%|███                                                                             | 38/1000 [01:10<28:49,  1.80s/it]INFO:root:global_step: 38, logpy: -2753.880, kl: 804.485, loss: 2786.278\n",
      "  4%|███                                                                             | 39/1000 [01:12<28:36,  1.79s/it]INFO:root:global_step: 39, logpy: -2765.418, kl: 798.510, loss: 2798.320\n",
      "  4%|███▏                                                                            | 40/1000 [01:14<28:19,  1.77s/it]INFO:root:global_step: 40, logpy: -2778.253, kl: 792.953, loss: 2811.821\n",
      "  4%|███▎                                                                            | 41/1000 [01:15<28:24,  1.78s/it]INFO:root:global_step: 41, logpy: -2789.421, kl: 787.320, loss: 2823.618\n",
      "  4%|███▎                                                                            | 42/1000 [01:17<28:09,  1.76s/it]INFO:root:global_step: 42, logpy: -2797.884, kl: 781.488, loss: 2832.617\n",
      "  4%|███▍                                                                            | 43/1000 [01:19<28:15,  1.77s/it]INFO:root:global_step: 43, logpy: -2805.973, kl: 775.766, loss: 2841.279\n",
      "  4%|███▌                                                                            | 44/1000 [01:21<28:18,  1.78s/it]INFO:root:global_step: 44, logpy: -2813.922, kl: 770.069, loss: 2849.803\n",
      "  4%|███▌                                                                            | 45/1000 [01:22<28:10,  1.77s/it]INFO:root:global_step: 45, logpy: -2823.154, kl: 764.566, loss: 2859.688\n",
      "  5%|███▋                                                                            | 46/1000 [01:24<28:13,  1.77s/it]INFO:root:global_step: 46, logpy: -2831.861, kl: 758.958, loss: 2868.986\n",
      "  5%|███▊                                                                            | 47/1000 [01:26<28:04,  1.77s/it]INFO:root:global_step: 47, logpy: -2844.182, kl: 753.631, loss: 2882.022\n",
      "  5%|███▊                                                                            | 48/1000 [01:28<27:59,  1.76s/it]INFO:root:global_step: 48, logpy: -2852.321, kl: 748.104, loss: 2890.767\n",
      "  5%|███▉                                                                            | 49/1000 [01:29<28:02,  1.77s/it]INFO:root:global_step: 49, logpy: -2860.427, kl: 742.535, loss: 2899.444\n",
      "  5%|████                                                                            | 50/1000 [01:31<27:39,  1.75s/it]INFO:root:Saved figure at: ./sim/global_step_50.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 50, logpy: -2867.892, kl: 736.966, loss: 2907.467\n",
      "  5%|████                                                                            | 51/1000 [01:39<58:18,  3.69s/it]INFO:root:global_step: 51, logpy: -2876.504, kl: 731.803, loss: 2916.830\n",
      "  5%|████▏                                                                           | 52/1000 [01:41<49:17,  3.12s/it]INFO:root:global_step: 52, logpy: -2883.961, kl: 726.342, loss: 2924.869\n",
      "  5%|████▏                                                                           | 53/1000 [01:43<43:02,  2.73s/it]INFO:root:global_step: 53, logpy: -2890.421, kl: 721.065, loss: 2931.991\n",
      "  5%|████▎                                                                           | 54/1000 [01:45<38:30,  2.44s/it]INFO:root:global_step: 54, logpy: -2897.978, kl: 715.721, loss: 2940.160\n",
      "  6%|████▍                                                                           | 55/1000 [01:46<35:04,  2.23s/it]INFO:root:global_step: 55, logpy: -2905.231, kl: 710.665, loss: 2948.167\n",
      "  6%|████▍                                                                           | 56/1000 [01:48<33:07,  2.11s/it]INFO:root:global_step: 56, logpy: -2912.816, kl: 705.517, loss: 2956.440\n",
      "  6%|████▌                                                                           | 57/1000 [01:50<31:37,  2.01s/it]INFO:root:global_step: 57, logpy: -2919.663, kl: 700.303, loss: 2963.919\n",
      "  6%|████▋                                                                           | 58/1000 [01:52<30:35,  1.95s/it]INFO:root:global_step: 58, logpy: -2929.468, kl: 695.197, loss: 2974.400\n",
      "  6%|████▋                                                                           | 59/1000 [01:54<29:30,  1.88s/it]INFO:root:global_step: 59, logpy: -2937.804, kl: 690.187, loss: 2983.452\n",
      "  6%|████▊                                                                           | 60/1000 [01:55<28:40,  1.83s/it]INFO:root:global_step: 60, logpy: -2943.558, kl: 685.161, loss: 2989.894\n",
      "  6%|████▉                                                                           | 61/1000 [01:57<28:02,  1.79s/it]INFO:root:global_step: 61, logpy: -2951.115, kl: 680.107, loss: 2998.102\n",
      "  6%|████▉                                                                           | 62/1000 [01:59<27:57,  1.79s/it]INFO:root:global_step: 62, logpy: -2958.440, kl: 675.138, loss: 3006.111\n",
      "  6%|█████                                                                           | 63/1000 [02:01<28:05,  1.80s/it]INFO:root:global_step: 63, logpy: -2965.591, kl: 670.504, loss: 3014.140\n",
      "  6%|█████                                                                           | 64/1000 [02:02<28:05,  1.80s/it]INFO:root:global_step: 64, logpy: -2972.160, kl: 665.587, loss: 3021.386\n",
      "  6%|█████▏                                                                          | 65/1000 [02:04<27:48,  1.78s/it]INFO:root:global_step: 65, logpy: -2980.802, kl: 660.797, loss: 3030.768\n",
      "  7%|█████▎                                                                          | 66/1000 [02:06<27:23,  1.76s/it]INFO:root:global_step: 66, logpy: -2988.668, kl: 656.000, loss: 3039.347\n",
      "  7%|█████▎                                                                          | 67/1000 [02:08<27:13,  1.75s/it]INFO:root:global_step: 67, logpy: -2994.350, kl: 651.165, loss: 3045.695\n",
      "  7%|█████▍                                                                          | 68/1000 [02:09<27:08,  1.75s/it]INFO:root:global_step: 68, logpy: -3000.661, kl: 646.415, loss: 3052.708\n",
      "  7%|█████▌                                                                          | 69/1000 [02:11<27:39,  1.78s/it]INFO:root:global_step: 69, logpy: -3006.916, kl: 641.732, loss: 3059.690\n",
      "  7%|█████▌                                                                          | 70/1000 [02:13<27:53,  1.80s/it]INFO:root:global_step: 70, logpy: -3012.502, kl: 637.155, loss: 3066.055\n",
      "  7%|█████▋                                                                          | 71/1000 [02:15<27:36,  1.78s/it]INFO:root:global_step: 71, logpy: -3019.078, kl: 632.673, loss: 3073.455\n",
      "  7%|█████▊                                                                          | 72/1000 [02:17<27:26,  1.77s/it]INFO:root:global_step: 72, logpy: -3026.206, kl: 628.182, loss: 3081.380\n",
      "  7%|█████▊                                                                          | 73/1000 [02:18<27:27,  1.78s/it]INFO:root:global_step: 73, logpy: -3033.881, kl: 623.799, loss: 3089.908\n",
      "  7%|█████▉                                                                          | 74/1000 [02:20<26:56,  1.75s/it]INFO:root:global_step: 74, logpy: -3038.315, kl: 619.282, loss: 3095.073\n",
      "  8%|██████                                                                          | 75/1000 [02:22<26:38,  1.73s/it]INFO:root:global_step: 75, logpy: -3044.276, kl: 614.899, loss: 3101.842\n",
      "  8%|██████                                                                          | 76/1000 [02:24<27:08,  1.76s/it]INFO:root:global_step: 76, logpy: -3050.545, kl: 610.631, loss: 3108.983\n",
      "  8%|██████▏                                                                         | 77/1000 [02:25<26:58,  1.75s/it]INFO:root:global_step: 77, logpy: -3057.901, kl: 606.490, loss: 3117.288\n",
      "  8%|██████▏                                                                         | 78/1000 [02:27<27:06,  1.76s/it]INFO:root:global_step: 78, logpy: -3064.214, kl: 602.283, loss: 3124.474\n",
      "  8%|██████▎                                                                         | 79/1000 [02:29<27:12,  1.77s/it]INFO:root:global_step: 79, logpy: -3070.031, kl: 598.090, loss: 3131.153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▍                                                                         | 80/1000 [02:31<27:08,  1.77s/it]INFO:root:global_step: 80, logpy: -3074.764, kl: 593.798, loss: 3136.642\n",
      "  8%|██████▍                                                                         | 81/1000 [02:32<27:07,  1.77s/it]INFO:root:global_step: 81, logpy: -3080.606, kl: 589.678, loss: 3143.357\n",
      "  8%|██████▌                                                                         | 82/1000 [02:34<27:03,  1.77s/it]INFO:root:global_step: 82, logpy: -3088.573, kl: 585.860, loss: 3152.421\n",
      "  8%|██████▋                                                                         | 83/1000 [02:36<26:56,  1.76s/it]INFO:root:global_step: 83, logpy: -3095.120, kl: 581.985, loss: 3159.996\n",
      "  8%|██████▋                                                                         | 84/1000 [02:38<27:23,  1.79s/it]INFO:root:global_step: 84, logpy: -3099.781, kl: 577.805, loss: 3165.403\n",
      "  8%|██████▊                                                                         | 85/1000 [02:40<26:58,  1.77s/it]INFO:root:global_step: 85, logpy: -3107.232, kl: 573.973, loss: 3173.871\n",
      "  9%|██████▉                                                                         | 86/1000 [02:41<26:57,  1.77s/it]INFO:root:global_step: 86, logpy: -3112.637, kl: 570.028, loss: 3180.170\n",
      "  9%|██████▉                                                                         | 87/1000 [02:43<27:14,  1.79s/it]INFO:root:global_step: 87, logpy: -3117.622, kl: 566.165, loss: 3186.097\n",
      "  9%|███████                                                                         | 88/1000 [02:45<27:02,  1.78s/it]INFO:root:global_step: 88, logpy: -3123.276, kl: 562.365, loss: 3192.723\n",
      "  9%|███████                                                                         | 89/1000 [02:47<27:14,  1.79s/it]INFO:root:global_step: 89, logpy: -3126.138, kl: 558.455, loss: 3196.434\n",
      "  9%|███████▏                                                                        | 90/1000 [02:48<26:55,  1.78s/it]INFO:root:global_step: 90, logpy: -3132.371, kl: 554.835, loss: 3203.750\n",
      "  9%|███████▎                                                                        | 91/1000 [02:50<26:57,  1.78s/it]INFO:root:global_step: 91, logpy: -3138.490, kl: 551.067, loss: 3210.793\n",
      "  9%|███████▎                                                                        | 92/1000 [02:52<26:57,  1.78s/it]INFO:root:global_step: 92, logpy: -3145.719, kl: 547.520, loss: 3219.127\n",
      "  9%|███████▍                                                                        | 93/1000 [02:54<26:37,  1.76s/it]INFO:root:global_step: 93, logpy: -3151.217, kl: 544.048, loss: 3225.774\n",
      "  9%|███████▌                                                                        | 94/1000 [02:55<26:32,  1.76s/it]INFO:root:global_step: 94, logpy: -3156.416, kl: 540.354, loss: 3231.886\n",
      " 10%|███████▌                                                                        | 95/1000 [02:57<26:39,  1.77s/it]INFO:root:global_step: 95, logpy: -3163.206, kl: 536.792, loss: 3239.689\n",
      " 10%|███████▋                                                                        | 96/1000 [02:59<26:53,  1.78s/it]INFO:root:global_step: 96, logpy: -3169.030, kl: 533.539, loss: 3246.799\n",
      " 10%|███████▊                                                                        | 97/1000 [03:01<26:36,  1.77s/it]INFO:root:global_step: 97, logpy: -3175.298, kl: 530.174, loss: 3254.221\n",
      " 10%|███████▊                                                                        | 98/1000 [03:03<26:40,  1.77s/it]INFO:root:global_step: 98, logpy: -3178.491, kl: 526.684, loss: 3258.418\n",
      " 10%|███████▉                                                                        | 99/1000 [03:04<26:35,  1.77s/it]INFO:root:global_step: 99, logpy: -3183.897, kl: 523.229, loss: 3264.837\n",
      " 10%|███████▉                                                                       | 100/1000 [03:06<26:39,  1.78s/it]INFO:root:Saved figure at: ./sim/global_step_100.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 100, logpy: -3190.107, kl: 519.829, loss: 3272.070\n",
      " 10%|███████▉                                                                       | 101/1000 [03:14<55:08,  3.68s/it]INFO:root:global_step: 101, logpy: -3195.285, kl: 516.560, loss: 3278.358\n",
      " 10%|████████                                                                       | 102/1000 [03:16<46:32,  3.11s/it]INFO:root:global_step: 102, logpy: -3199.869, kl: 513.188, loss: 3283.905\n",
      " 10%|████████▏                                                                      | 103/1000 [03:18<40:27,  2.71s/it]INFO:root:global_step: 103, logpy: -3204.961, kl: 509.803, loss: 3289.902\n",
      " 10%|████████▏                                                                      | 104/1000 [03:20<36:16,  2.43s/it]INFO:root:global_step: 104, logpy: -3212.013, kl: 506.671, loss: 3298.071\n",
      " 10%|████████▎                                                                      | 105/1000 [03:21<33:17,  2.23s/it]INFO:root:global_step: 105, logpy: -3216.207, kl: 503.441, loss: 3303.242\n",
      " 11%|████████▎                                                                      | 106/1000 [03:23<31:03,  2.08s/it]INFO:root:global_step: 106, logpy: -3220.495, kl: 500.072, loss: 3308.324\n",
      " 11%|████████▍                                                                      | 107/1000 [03:25<29:52,  2.01s/it]INFO:root:global_step: 107, logpy: -3224.518, kl: 496.840, loss: 3313.238\n",
      " 11%|████████▌                                                                      | 108/1000 [03:27<28:40,  1.93s/it]INFO:root:global_step: 108, logpy: -3227.882, kl: 493.836, loss: 3317.679\n",
      " 11%|████████▌                                                                      | 109/1000 [03:28<27:53,  1.88s/it]INFO:root:global_step: 109, logpy: -3229.382, kl: 490.437, loss: 3319.821\n",
      " 11%|████████▋                                                                      | 110/1000 [03:30<27:12,  1.83s/it]INFO:root:global_step: 110, logpy: -3233.449, kl: 487.336, loss: 3324.787\n",
      " 11%|████████▊                                                                      | 111/1000 [03:32<27:15,  1.84s/it]INFO:root:global_step: 111, logpy: -3239.953, kl: 484.317, loss: 3332.231\n",
      " 11%|████████▊                                                                      | 112/1000 [03:34<27:05,  1.83s/it]INFO:root:global_step: 112, logpy: -3245.892, kl: 481.176, loss: 3338.950\n",
      " 11%|████████▉                                                                      | 113/1000 [03:36<26:39,  1.80s/it]INFO:root:global_step: 113, logpy: -3248.486, kl: 478.023, loss: 3342.272\n",
      " 11%|█████████                                                                      | 114/1000 [03:37<26:30,  1.79s/it]INFO:root:global_step: 114, logpy: -3253.480, kl: 475.177, loss: 3348.262\n",
      " 12%|█████████                                                                      | 115/1000 [03:39<26:22,  1.79s/it]INFO:root:global_step: 115, logpy: -3257.995, kl: 472.240, loss: 3353.644\n",
      " 12%|█████████▏                                                                     | 116/1000 [03:41<26:29,  1.80s/it]INFO:root:global_step: 116, logpy: -3261.461, kl: 469.374, loss: 3358.011\n",
      " 12%|█████████▏                                                                     | 117/1000 [03:43<26:35,  1.81s/it]INFO:root:global_step: 117, logpy: -3266.785, kl: 466.515, loss: 3364.204\n",
      " 12%|█████████▎                                                                     | 118/1000 [03:45<26:59,  1.84s/it]INFO:root:global_step: 118, logpy: -3269.692, kl: 463.662, loss: 3367.948\n",
      " 12%|█████████▍                                                                     | 119/1000 [03:46<26:46,  1.82s/it]INFO:root:global_step: 119, logpy: -3273.168, kl: 460.863, loss: 3372.281\n",
      " 12%|█████████▍                                                                     | 120/1000 [03:48<26:10,  1.78s/it]INFO:root:global_step: 120, logpy: -3276.276, kl: 458.085, loss: 3376.228\n",
      " 12%|█████████▌                                                                     | 121/1000 [03:50<26:11,  1.79s/it]INFO:root:global_step: 121, logpy: -3280.442, kl: 455.359, loss: 3381.249\n",
      " 12%|█████████▋                                                                     | 122/1000 [03:52<26:10,  1.79s/it]INFO:root:global_step: 122, logpy: -3286.202, kl: 452.824, loss: 3388.019\n",
      " 12%|█████████▋                                                                     | 123/1000 [03:54<26:05,  1.79s/it]INFO:root:global_step: 123, logpy: -3290.308, kl: 450.149, loss: 3392.960\n",
      " 12%|█████████▊                                                                     | 124/1000 [03:55<26:14,  1.80s/it]INFO:root:global_step: 124, logpy: -3295.378, kl: 447.615, loss: 3398.972\n",
      " 12%|█████████▉                                                                     | 125/1000 [03:57<26:01,  1.78s/it]INFO:root:global_step: 125, logpy: -3301.446, kl: 445.085, loss: 3405.949\n",
      " 13%|█████████▉                                                                     | 126/1000 [03:59<25:52,  1.78s/it]INFO:root:global_step: 126, logpy: -3305.765, kl: 442.543, loss: 3411.132\n",
      " 13%|██████████                                                                     | 127/1000 [04:01<25:57,  1.78s/it]INFO:root:global_step: 127, logpy: -3307.980, kl: 439.954, loss: 3414.130\n",
      " 13%|██████████                                                                     | 128/1000 [04:02<25:45,  1.77s/it]INFO:root:global_step: 128, logpy: -3311.783, kl: 437.352, loss: 3418.669\n",
      " 13%|██████████▏                                                                    | 129/1000 [04:04<25:43,  1.77s/it]INFO:root:global_step: 129, logpy: -3313.334, kl: 434.833, loss: 3421.006\n",
      " 13%|██████████▎                                                                    | 130/1000 [04:06<26:00,  1.79s/it]INFO:root:global_step: 130, logpy: -3318.644, kl: 432.407, loss: 3427.161\n",
      " 13%|██████████▎                                                                    | 131/1000 [04:08<25:58,  1.79s/it]INFO:root:global_step: 131, logpy: -3324.888, kl: 430.077, loss: 3434.315\n",
      " 13%|██████████▍                                                                    | 132/1000 [04:10<25:45,  1.78s/it]INFO:root:global_step: 132, logpy: -3327.314, kl: 427.584, loss: 3437.453\n",
      " 13%|██████████▌                                                                    | 133/1000 [04:11<25:35,  1.77s/it]INFO:root:global_step: 133, logpy: -3330.709, kl: 425.088, loss: 3441.527\n",
      " 13%|██████████▌                                                                    | 134/1000 [04:13<25:27,  1.76s/it]INFO:root:global_step: 134, logpy: -3334.760, kl: 422.725, loss: 3446.357\n",
      " 14%|██████████▋                                                                    | 135/1000 [04:15<25:21,  1.76s/it]INFO:root:global_step: 135, logpy: -3335.662, kl: 420.151, loss: 3447.797\n",
      " 14%|██████████▋                                                                    | 136/1000 [04:17<25:13,  1.75s/it]INFO:root:global_step: 136, logpy: -3338.873, kl: 417.861, loss: 3451.798\n",
      " 14%|██████████▊                                                                    | 137/1000 [04:18<25:31,  1.77s/it]INFO:root:global_step: 137, logpy: -3341.509, kl: 415.478, loss: 3455.100\n",
      " 14%|██████████▉                                                                    | 138/1000 [04:20<25:37,  1.78s/it]INFO:root:global_step: 138, logpy: -3344.742, kl: 413.003, loss: 3458.877\n",
      " 14%|██████████▉                                                                    | 139/1000 [04:22<25:25,  1.77s/it]INFO:root:global_step: 139, logpy: -3348.955, kl: 410.940, loss: 3464.016\n",
      " 14%|███████████                                                                    | 140/1000 [04:24<25:32,  1.78s/it]INFO:root:global_step: 140, logpy: -3351.878, kl: 408.740, loss: 3467.699\n",
      " 14%|███████████▏                                                                   | 141/1000 [04:25<25:15,  1.76s/it]INFO:root:global_step: 141, logpy: -3354.457, kl: 406.542, loss: 3471.008\n",
      " 14%|███████████▏                                                                   | 142/1000 [04:27<25:10,  1.76s/it]INFO:root:global_step: 142, logpy: -3358.544, kl: 404.299, loss: 3475.751\n",
      " 14%|███████████▎                                                                   | 143/1000 [04:29<25:24,  1.78s/it]INFO:root:global_step: 143, logpy: -3363.395, kl: 402.206, loss: 3481.381\n",
      " 14%|███████████▍                                                                   | 144/1000 [04:31<25:37,  1.80s/it]INFO:root:global_step: 144, logpy: -3367.727, kl: 400.107, loss: 3486.457\n",
      " 14%|███████████▍                                                                   | 145/1000 [04:33<25:29,  1.79s/it]INFO:root:global_step: 145, logpy: -3372.083, kl: 398.113, loss: 3491.631\n",
      " 15%|███████████▌                                                                   | 146/1000 [04:34<25:28,  1.79s/it]INFO:root:global_step: 146, logpy: -3374.988, kl: 396.000, loss: 3495.210\n",
      " 15%|███████████▌                                                                   | 147/1000 [04:36<25:19,  1.78s/it]INFO:root:global_step: 147, logpy: -3375.492, kl: 393.601, loss: 3496.073\n",
      " 15%|███████████▋                                                                   | 148/1000 [04:38<25:18,  1.78s/it]INFO:root:global_step: 148, logpy: -3377.526, kl: 391.623, loss: 3498.859\n",
      " 15%|███████████▊                                                                   | 149/1000 [04:40<25:40,  1.81s/it]INFO:root:global_step: 149, logpy: -3381.371, kl: 389.550, loss: 3503.333\n",
      " 15%|███████████▊                                                                   | 150/1000 [04:42<25:19,  1.79s/it]INFO:root:Saved figure at: ./sim/global_step_150.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 150, logpy: -3384.117, kl: 387.465, loss: 3506.671\n",
      " 15%|███████████▉                                                                   | 151/1000 [04:50<52:38,  3.72s/it]INFO:root:global_step: 151, logpy: -3389.551, kl: 385.653, loss: 3512.942\n",
      " 15%|████████████                                                                   | 152/1000 [04:52<44:04,  3.12s/it]INFO:root:global_step: 152, logpy: -3390.156, kl: 383.540, loss: 3514.056\n",
      " 15%|████████████                                                                   | 153/1000 [04:53<38:40,  2.74s/it]INFO:root:global_step: 153, logpy: -3391.927, kl: 381.493, loss: 3516.377\n",
      " 15%|████████████▏                                                                  | 154/1000 [04:55<34:51,  2.47s/it]INFO:root:global_step: 154, logpy: -3394.540, kl: 379.562, loss: 3519.629\n",
      " 16%|████████████▏                                                                  | 155/1000 [04:57<31:56,  2.27s/it]INFO:root:global_step: 155, logpy: -3398.875, kl: 377.736, loss: 3524.682\n",
      " 16%|████████████▎                                                                  | 156/1000 [04:59<29:33,  2.10s/it]INFO:root:global_step: 156, logpy: -3401.408, kl: 375.751, loss: 3527.750\n",
      " 16%|████████████▍                                                                  | 157/1000 [05:00<28:01,  1.99s/it]INFO:root:global_step: 157, logpy: -3405.548, kl: 373.864, loss: 3532.497\n",
      " 16%|████████████▍                                                                  | 158/1000 [05:02<27:22,  1.95s/it]INFO:root:global_step: 158, logpy: -3410.193, kl: 372.213, loss: 3537.961\n",
      " 16%|████████████▌                                                                  | 159/1000 [05:04<26:35,  1.90s/it]INFO:root:global_step: 159, logpy: -3413.048, kl: 370.373, loss: 3541.420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████▋                                                                  | 160/1000 [05:06<25:46,  1.84s/it]INFO:root:global_step: 160, logpy: -3415.909, kl: 368.695, loss: 3545.023\n",
      " 16%|████████████▋                                                                  | 161/1000 [05:08<25:39,  1.83s/it]INFO:root:global_step: 161, logpy: -3418.236, kl: 366.815, loss: 3547.865\n",
      " 16%|████████████▊                                                                  | 162/1000 [05:09<25:19,  1.81s/it]INFO:root:global_step: 162, logpy: -3422.826, kl: 365.139, loss: 3553.152\n",
      " 16%|████████████▉                                                                  | 163/1000 [05:11<25:19,  1.82s/it]INFO:root:global_step: 163, logpy: -3427.350, kl: 363.389, loss: 3558.273\n",
      " 16%|████████████▉                                                                  | 164/1000 [05:13<25:01,  1.80s/it]INFO:root:global_step: 164, logpy: -3430.843, kl: 361.587, loss: 3562.289\n",
      " 16%|█████████████                                                                  | 165/1000 [05:15<24:43,  1.78s/it]INFO:root:global_step: 165, logpy: -3435.483, kl: 360.022, loss: 3567.665\n",
      " 17%|█████████████                                                                  | 166/1000 [05:16<24:29,  1.76s/it]INFO:root:global_step: 166, logpy: -3437.948, kl: 358.393, loss: 3570.780\n",
      " 17%|█████████████▏                                                                 | 167/1000 [05:18<24:42,  1.78s/it]INFO:root:global_step: 167, logpy: -3439.722, kl: 356.641, loss: 3573.058\n",
      " 17%|█████████████▎                                                                 | 168/1000 [05:20<24:33,  1.77s/it]INFO:root:global_step: 168, logpy: -3442.270, kl: 354.911, loss: 3576.109\n",
      " 17%|█████████████▎                                                                 | 169/1000 [05:22<24:44,  1.79s/it]INFO:root:global_step: 169, logpy: -3444.689, kl: 353.205, loss: 3579.032\n",
      " 17%|█████████████▍                                                                 | 170/1000 [05:24<24:32,  1.77s/it]INFO:root:global_step: 170, logpy: -3447.842, kl: 351.667, loss: 3582.836\n",
      " 17%|█████████████▌                                                                 | 171/1000 [05:25<24:24,  1.77s/it]INFO:root:global_step: 171, logpy: -3450.590, kl: 349.981, loss: 3586.064\n",
      " 17%|█████████████▌                                                                 | 172/1000 [05:27<25:00,  1.81s/it]INFO:root:global_step: 172, logpy: -3454.008, kl: 348.348, loss: 3589.994\n",
      " 17%|█████████████▋                                                                 | 173/1000 [05:29<24:40,  1.79s/it]INFO:root:global_step: 173, logpy: -3455.992, kl: 346.838, loss: 3592.592\n",
      " 17%|█████████████▋                                                                 | 174/1000 [05:31<24:32,  1.78s/it]INFO:root:global_step: 174, logpy: -3457.522, kl: 345.193, loss: 3594.579\n",
      " 18%|█████████████▊                                                                 | 175/1000 [05:32<24:21,  1.77s/it]INFO:root:global_step: 175, logpy: -3459.491, kl: 343.607, loss: 3597.045\n",
      " 18%|█████████████▉                                                                 | 176/1000 [05:34<24:37,  1.79s/it]INFO:root:global_step: 176, logpy: -3463.098, kl: 342.081, loss: 3601.186\n",
      " 18%|█████████████▉                                                                 | 177/1000 [05:36<24:48,  1.81s/it]INFO:root:global_step: 177, logpy: -3466.364, kl: 340.536, loss: 3604.946\n",
      " 18%|██████████████                                                                 | 178/1000 [05:38<25:49,  1.89s/it]INFO:root:global_step: 178, logpy: -3469.036, kl: 339.073, loss: 3608.174\n",
      " 18%|██████████████▏                                                                | 179/1000 [05:40<25:22,  1.85s/it]INFO:root:global_step: 179, logpy: -3470.254, kl: 337.568, loss: 3609.887\n",
      " 18%|██████████████▏                                                                | 180/1000 [05:42<24:54,  1.82s/it]INFO:root:global_step: 180, logpy: -3474.227, kl: 335.935, loss: 3614.207\n",
      " 18%|██████████████▎                                                                | 181/1000 [05:43<24:27,  1.79s/it]INFO:root:global_step: 181, logpy: -3475.452, kl: 334.311, loss: 3615.767\n",
      " 18%|██████████████▍                                                                | 182/1000 [05:45<24:18,  1.78s/it]INFO:root:global_step: 182, logpy: -3477.003, kl: 332.803, loss: 3617.750\n",
      " 18%|██████████████▍                                                                | 183/1000 [05:47<24:36,  1.81s/it]INFO:root:global_step: 183, logpy: -3477.378, kl: 331.183, loss: 3618.426\n",
      " 18%|██████████████▌                                                                | 184/1000 [05:49<24:20,  1.79s/it]INFO:root:global_step: 184, logpy: -3478.883, kl: 329.686, loss: 3620.336\n",
      " 18%|██████████████▌                                                                | 185/1000 [05:51<24:13,  1.78s/it]INFO:root:global_step: 185, logpy: -3480.245, kl: 328.236, loss: 3622.129\n",
      " 19%|██████████████▋                                                                | 186/1000 [05:52<24:10,  1.78s/it]INFO:root:global_step: 186, logpy: -3481.561, kl: 326.758, loss: 3623.830\n",
      " 19%|██████████████▊                                                                | 187/1000 [05:54<24:10,  1.78s/it]INFO:root:global_step: 187, logpy: -3483.286, kl: 325.379, loss: 3626.021\n",
      " 19%|██████████████▊                                                                | 188/1000 [05:56<24:08,  1.78s/it]INFO:root:global_step: 188, logpy: -3485.011, kl: 323.938, loss: 3628.132\n",
      " 19%|██████████████▉                                                                | 189/1000 [05:58<23:53,  1.77s/it]INFO:root:global_step: 189, logpy: -3487.426, kl: 322.625, loss: 3631.042\n",
      " 19%|███████████████                                                                | 190/1000 [06:00<23:56,  1.77s/it]INFO:root:global_step: 190, logpy: -3489.389, kl: 321.329, loss: 3633.499\n",
      " 19%|███████████████                                                                | 191/1000 [06:01<23:50,  1.77s/it]INFO:root:global_step: 191, logpy: -3491.524, kl: 319.963, loss: 3636.040\n",
      " 19%|███████████████▏                                                               | 192/1000 [06:03<23:55,  1.78s/it]INFO:root:global_step: 192, logpy: -3494.159, kl: 318.572, loss: 3639.039\n",
      " 19%|███████████████▏                                                               | 193/1000 [06:05<23:55,  1.78s/it]INFO:root:global_step: 193, logpy: -3493.808, kl: 317.051, loss: 3638.905\n",
      " 19%|███████████████▎                                                               | 194/1000 [06:07<23:39,  1.76s/it]INFO:root:global_step: 194, logpy: -3495.033, kl: 315.616, loss: 3640.414\n",
      " 20%|███████████████▍                                                               | 195/1000 [06:08<23:42,  1.77s/it]INFO:root:global_step: 195, logpy: -3496.545, kl: 314.124, loss: 3642.136\n",
      " 20%|███████████████▍                                                               | 196/1000 [06:10<23:37,  1.76s/it]INFO:root:global_step: 196, logpy: -3497.043, kl: 312.817, loss: 3643.013\n",
      " 20%|███████████████▌                                                               | 197/1000 [06:12<23:32,  1.76s/it]INFO:root:global_step: 197, logpy: -3499.853, kl: 311.601, loss: 3646.274\n",
      " 20%|███████████████▋                                                               | 198/1000 [06:14<23:33,  1.76s/it]INFO:root:global_step: 198, logpy: -3501.769, kl: 310.483, loss: 3648.725\n",
      " 20%|███████████████▋                                                               | 199/1000 [06:15<23:22,  1.75s/it]INFO:root:global_step: 199, logpy: -3503.289, kl: 309.337, loss: 3650.734\n",
      " 20%|███████████████▊                                                               | 200/1000 [06:17<23:23,  1.75s/it]INFO:root:Saved figure at: ./sim/global_step_200.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:global_step: 200, logpy: -3505.524, kl: 308.134, loss: 3653.384\n",
      " 20%|███████████████▉                                                               | 201/1000 [06:25<49:13,  3.70s/it]INFO:root:global_step: 201, logpy: -3507.645, kl: 306.749, loss: 3655.723\n",
      " 20%|███████████████▉                                                               | 202/1000 [06:27<41:35,  3.13s/it]INFO:root:global_step: 202, logpy: -3510.144, kl: 305.625, loss: 3658.686\n",
      " 20%|████████████████                                                               | 203/1000 [06:29<36:16,  2.73s/it]INFO:root:global_step: 203, logpy: -3511.468, kl: 304.489, loss: 3660.445\n",
      " 20%|████████████████                                                               | 204/1000 [06:31<32:10,  2.43s/it]INFO:root:global_step: 204, logpy: -3512.092, kl: 303.349, loss: 3661.484\n",
      " 20%|████████████████▏                                                              | 205/1000 [06:32<29:30,  2.23s/it]INFO:root:global_step: 205, logpy: -3515.440, kl: 302.274, loss: 3665.295\n",
      " 21%|████████████████▎                                                              | 206/1000 [06:34<27:37,  2.09s/it]INFO:root:global_step: 206, logpy: -3517.083, kl: 301.037, loss: 3667.226\n",
      " 21%|████████████████▎                                                              | 207/1000 [06:36<26:34,  2.01s/it]INFO:root:global_step: 207, logpy: -3519.909, kl: 300.008, loss: 3670.532\n",
      " 21%|████████████████▍                                                              | 208/1000 [06:38<25:25,  1.93s/it]INFO:root:global_step: 208, logpy: -3520.505, kl: 298.776, loss: 3671.389\n",
      " 21%|████████████████▌                                                              | 209/1000 [06:39<24:37,  1.87s/it]INFO:root:global_step: 209, logpy: -3521.921, kl: 297.851, loss: 3673.360\n",
      " 21%|████████████████▌                                                              | 210/1000 [06:41<23:56,  1.82s/it]INFO:root:global_step: 210, logpy: -3524.486, kl: 296.927, loss: 3676.466\n",
      " 21%|████████████████▋                                                              | 211/1000 [06:43<23:51,  1.81s/it]INFO:root:global_step: 211, logpy: -3526.018, kl: 295.656, loss: 3678.175\n",
      " 21%|████████████████▋                                                              | 212/1000 [06:45<23:41,  1.80s/it]INFO:root:global_step: 212, logpy: -3525.958, kl: 294.423, loss: 3678.317\n",
      " 21%|████████████████▊                                                              | 213/1000 [06:47<23:34,  1.80s/it]INFO:root:global_step: 213, logpy: -3528.171, kl: 293.320, loss: 3680.848\n",
      " 21%|████████████████▉                                                              | 214/1000 [06:48<23:15,  1.78s/it]INFO:root:global_step: 214, logpy: -3531.038, kl: 292.090, loss: 3683.892\n",
      " 22%|████████████████▉                                                              | 215/1000 [06:50<23:02,  1.76s/it]INFO:root:global_step: 215, logpy: -3532.377, kl: 291.020, loss: 3685.553\n",
      " 22%|█████████████████                                                              | 216/1000 [06:52<22:56,  1.76s/it]INFO:root:global_step: 216, logpy: -3534.315, kl: 289.982, loss: 3687.831\n",
      " 22%|█████████████████▏                                                             | 217/1000 [06:53<22:55,  1.76s/it]INFO:root:global_step: 217, logpy: -3536.734, kl: 288.936, loss: 3690.569\n",
      " 22%|█████████████████▏                                                             | 218/1000 [06:55<22:56,  1.76s/it]INFO:root:global_step: 218, logpy: -3538.714, kl: 287.882, loss: 3692.846\n",
      " 22%|█████████████████▎                                                             | 219/1000 [06:57<22:43,  1.75s/it]INFO:root:global_step: 219, logpy: -3540.760, kl: 286.804, loss: 3695.152\n",
      " 22%|█████████████████▍                                                             | 220/1000 [06:59<22:36,  1.74s/it]INFO:root:global_step: 220, logpy: -3542.224, kl: 285.792, loss: 3696.928\n",
      " 22%|█████████████████▍                                                             | 221/1000 [07:01<22:57,  1.77s/it]INFO:root:global_step: 221, logpy: -3543.341, kl: 284.802, loss: 3698.365\n",
      " 22%|█████████████████▌                                                             | 222/1000 [07:02<22:54,  1.77s/it]INFO:root:global_step: 222, logpy: -3545.550, kl: 283.845, loss: 3700.915\n",
      " 22%|█████████████████▌                                                             | 223/1000 [07:04<22:41,  1.75s/it]INFO:root:global_step: 223, logpy: -3548.586, kl: 283.091, loss: 3704.482\n",
      " 22%|█████████████████▋                                                             | 224/1000 [07:06<22:37,  1.75s/it]INFO:root:global_step: 224, logpy: -3550.595, kl: 282.152, loss: 3706.824\n",
      " 22%|█████████████████▊                                                             | 225/1000 [07:08<22:40,  1.76s/it]INFO:root:global_step: 225, logpy: -3550.009, kl: 281.039, loss: 3706.384\n",
      " 23%|█████████████████▊                                                             | 226/1000 [07:09<22:31,  1.75s/it]INFO:root:global_step: 226, logpy: -3551.317, kl: 280.137, loss: 3708.037\n",
      " 23%|█████████████████▉                                                             | 227/1000 [07:11<22:25,  1.74s/it]INFO:root:global_step: 227, logpy: -3552.995, kl: 279.115, loss: 3709.927\n",
      " 23%|██████████████████                                                             | 228/1000 [07:13<22:42,  1.76s/it]INFO:root:global_step: 228, logpy: -3553.280, kl: 278.004, loss: 3710.323\n",
      " 23%|██████████████████                                                             | 229/1000 [07:15<22:30,  1.75s/it]INFO:root:global_step: 229, logpy: -3555.704, kl: 277.091, loss: 3713.044\n",
      " 23%|██████████████████▏                                                            | 230/1000 [07:16<22:50,  1.78s/it]INFO:root:global_step: 230, logpy: -3557.777, kl: 276.397, loss: 3715.619\n",
      " 23%|██████████████████▏                                                            | 231/1000 [07:18<22:48,  1.78s/it]INFO:root:global_step: 231, logpy: -3559.898, kl: 275.655, loss: 3718.185\n",
      " 23%|██████████████████▎                                                            | 232/1000 [07:20<22:49,  1.78s/it]INFO:root:global_step: 232, logpy: -3560.351, kl: 274.619, loss: 3718.775\n",
      " 23%|██████████████████▍                                                            | 233/1000 [07:22<22:58,  1.80s/it]INFO:root:global_step: 233, logpy: -3561.817, kl: 273.841, loss: 3720.626\n",
      " 23%|██████████████████▍                                                            | 234/1000 [07:24<23:03,  1.81s/it]INFO:root:global_step: 234, logpy: -3563.165, kl: 272.993, loss: 3722.276\n",
      " 24%|██████████████████▌                                                            | 235/1000 [07:25<23:11,  1.82s/it]INFO:root:global_step: 235, logpy: -3564.578, kl: 272.202, loss: 3724.036\n",
      " 24%|██████████████████▋                                                            | 236/1000 [07:27<22:59,  1.81s/it]INFO:root:global_step: 236, logpy: -3566.875, kl: 271.358, loss: 3726.616\n",
      " 24%|██████████████████▋                                                            | 237/1000 [07:29<22:42,  1.79s/it]INFO:root:global_step: 237, logpy: -3569.770, kl: 270.511, loss: 3729.781\n",
      " 24%|██████████████████▊                                                            | 238/1000 [07:31<22:54,  1.80s/it]INFO:root:global_step: 238, logpy: -3570.976, kl: 269.670, loss: 3731.251\n",
      " 24%|██████████████████▉                                                            | 239/1000 [07:33<22:58,  1.81s/it]INFO:root:global_step: 239, logpy: -3572.166, kl: 268.912, loss: 3732.777\n",
      " 24%|██████████████████▉                                                            | 240/1000 [07:34<22:56,  1.81s/it]INFO:root:global_step: 240, logpy: -3573.477, kl: 268.019, loss: 3734.278\n",
      " 24%|███████████████████                                                            | 241/1000 [07:36<22:49,  1.80s/it]INFO:root:global_step: 241, logpy: -3574.154, kl: 267.293, loss: 3735.301\n",
      " 24%|███████████████████                                                            | 242/1000 [07:38<22:43,  1.80s/it]INFO:root:global_step: 242, logpy: -3575.471, kl: 266.575, loss: 3736.961\n",
      " 24%|███████████████████▏                                                           | 243/1000 [07:40<22:57,  1.82s/it]INFO:root:global_step: 243, logpy: -3577.576, kl: 265.788, loss: 3739.330\n",
      " 24%|███████████████████▎                                                           | 244/1000 [07:42<22:35,  1.79s/it]INFO:root:global_step: 244, logpy: -3578.664, kl: 265.169, loss: 3740.840\n",
      " 24%|███████████████████▎                                                           | 245/1000 [07:43<22:37,  1.80s/it]INFO:root:global_step: 245, logpy: -3579.313, kl: 264.506, loss: 3741.855\n",
      " 25%|███████████████████▍                                                           | 246/1000 [07:45<22:35,  1.80s/it]INFO:root:global_step: 246, logpy: -3581.416, kl: 263.873, loss: 3744.345\n",
      " 25%|███████████████████▌                                                           | 247/1000 [07:47<22:31,  1.79s/it]INFO:root:global_step: 247, logpy: -3582.136, kl: 263.086, loss: 3745.287\n",
      " 25%|███████████████████▌                                                           | 248/1000 [07:49<22:32,  1.80s/it]INFO:root:global_step: 248, logpy: -3583.067, kl: 262.419, loss: 3746.550\n",
      " 25%|███████████████████▋                                                           | 249/1000 [07:51<22:32,  1.80s/it]INFO:root:global_step: 249, logpy: -3583.852, kl: 261.650, loss: 3747.557\n",
      " 25%|███████████████████▊                                                           | 250/1000 [07:52<22:30,  1.80s/it]INFO:root:Saved figure at: ./sim/global_step_250.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 250, logpy: -3586.987, kl: 260.894, loss: 3750.915\n",
      " 25%|███████████████████▊                                                           | 251/1000 [08:01<46:23,  3.72s/it]INFO:root:global_step: 251, logpy: -3588.778, kl: 260.085, loss: 3752.867\n",
      " 25%|███████████████████▉                                                           | 252/1000 [08:02<39:14,  3.15s/it]INFO:root:global_step: 252, logpy: -3590.124, kl: 259.456, loss: 3754.543\n",
      " 25%|███████████████████▉                                                           | 253/1000 [08:04<34:31,  2.77s/it]INFO:root:global_step: 253, logpy: -3591.379, kl: 258.791, loss: 3756.084\n",
      " 25%|████████████████████                                                           | 254/1000 [08:06<31:03,  2.50s/it]INFO:root:global_step: 254, logpy: -3593.485, kl: 258.152, loss: 3758.491\n",
      " 26%|████████████████████▏                                                          | 255/1000 [08:08<28:14,  2.27s/it]INFO:root:global_step: 255, logpy: -3595.213, kl: 257.513, loss: 3760.513\n",
      " 26%|████████████████████▏                                                          | 256/1000 [08:10<26:34,  2.14s/it]INFO:root:global_step: 256, logpy: -3596.424, kl: 256.851, loss: 3761.982\n",
      " 26%|████████████████████▎                                                          | 257/1000 [08:12<25:06,  2.03s/it]INFO:root:global_step: 257, logpy: -3598.740, kl: 256.170, loss: 3764.531\n",
      " 26%|████████████████████▍                                                          | 258/1000 [08:13<24:02,  1.94s/it]INFO:root:global_step: 258, logpy: -3599.692, kl: 255.556, loss: 3765.774\n",
      " 26%|████████████████████▍                                                          | 259/1000 [08:15<23:20,  1.89s/it]INFO:root:global_step: 259, logpy: -3600.291, kl: 254.795, loss: 3766.506\n",
      " 26%|████████████████████▌                                                          | 260/1000 [08:17<22:53,  1.86s/it]INFO:root:global_step: 260, logpy: -3603.252, kl: 254.021, loss: 3769.578\n",
      " 26%|████████████████████▌                                                          | 261/1000 [08:19<22:36,  1.84s/it]INFO:root:global_step: 261, logpy: -3604.416, kl: 253.230, loss: 3770.829\n",
      " 26%|████████████████████▋                                                          | 262/1000 [08:20<22:14,  1.81s/it]INFO:root:global_step: 262, logpy: -3603.947, kl: 252.503, loss: 3770.500\n",
      " 26%|████████████████████▊                                                          | 263/1000 [08:22<22:22,  1.82s/it]INFO:root:global_step: 263, logpy: -3604.198, kl: 251.651, loss: 3770.759\n",
      " 26%|████████████████████▊                                                          | 264/1000 [08:24<22:03,  1.80s/it]INFO:root:global_step: 264, logpy: -3605.220, kl: 251.079, loss: 3772.060\n",
      " 26%|████████████████████▉                                                          | 265/1000 [08:26<21:48,  1.78s/it]INFO:root:global_step: 265, logpy: -3608.156, kl: 250.559, loss: 3775.318\n",
      " 27%|█████████████████████                                                          | 266/1000 [08:27<21:44,  1.78s/it]INFO:root:global_step: 266, logpy: -3608.771, kl: 249.953, loss: 3776.161\n",
      " 27%|█████████████████████                                                          | 267/1000 [08:29<21:54,  1.79s/it]INFO:root:global_step: 267, logpy: -3609.922, kl: 249.319, loss: 3777.505\n",
      " 27%|█████████████████████▏                                                         | 268/1000 [08:31<21:42,  1.78s/it]INFO:root:global_step: 268, logpy: -3608.511, kl: 248.666, loss: 3776.257\n",
      " 27%|█████████████████████▎                                                         | 269/1000 [08:33<21:45,  1.79s/it]INFO:root:global_step: 269, logpy: -3607.614, kl: 247.779, loss: 3775.283\n",
      " 27%|█████████████████████▎                                                         | 270/1000 [08:35<21:29,  1.77s/it]INFO:root:global_step: 270, logpy: -3608.300, kl: 247.300, loss: 3776.291\n",
      " 27%|█████████████████████▍                                                         | 271/1000 [08:36<21:33,  1.77s/it]INFO:root:global_step: 271, logpy: -3608.538, kl: 246.669, loss: 3776.691\n",
      " 27%|█████████████████████▍                                                         | 272/1000 [08:38<21:21,  1.76s/it]INFO:root:global_step: 272, logpy: -3608.307, kl: 245.824, loss: 3776.400\n",
      " 27%|█████████████████████▌                                                         | 273/1000 [08:40<21:15,  1.75s/it]INFO:root:global_step: 273, logpy: -3609.536, kl: 245.239, loss: 3777.822\n",
      " 27%|█████████████████████▋                                                         | 274/1000 [08:42<21:15,  1.76s/it]INFO:root:global_step: 274, logpy: -3609.022, kl: 244.363, loss: 3777.201\n",
      " 28%|█████████████████████▋                                                         | 275/1000 [08:43<21:11,  1.75s/it]INFO:root:global_step: 275, logpy: -3610.493, kl: 243.870, loss: 3778.941\n",
      " 28%|█████████████████████▊                                                         | 276/1000 [08:45<21:26,  1.78s/it]INFO:root:global_step: 276, logpy: -3612.282, kl: 243.416, loss: 3781.030\n",
      " 28%|█████████████████████▉                                                         | 277/1000 [08:47<21:38,  1.80s/it]INFO:root:global_step: 277, logpy: -3613.117, kl: 242.695, loss: 3781.890\n",
      " 28%|█████████████████████▉                                                         | 278/1000 [08:49<21:56,  1.82s/it]INFO:root:global_step: 278, logpy: -3613.292, kl: 242.007, loss: 3782.117\n",
      " 28%|██████████████████████                                                         | 279/1000 [08:51<21:53,  1.82s/it]INFO:root:global_step: 279, logpy: -3616.449, kl: 241.525, loss: 3785.523\n",
      " 28%|██████████████████████                                                         | 280/1000 [08:52<21:41,  1.81s/it]INFO:root:global_step: 280, logpy: -3617.105, kl: 240.808, loss: 3786.186\n",
      " 28%|██████████████████████▏                                                        | 281/1000 [08:54<21:49,  1.82s/it]INFO:root:global_step: 281, logpy: -3618.568, kl: 240.208, loss: 3787.768\n",
      " 28%|██████████████████████▎                                                        | 282/1000 [08:56<21:39,  1.81s/it]INFO:root:global_step: 282, logpy: -3618.809, kl: 239.537, loss: 3788.047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██████████████████████▎                                                        | 283/1000 [08:58<21:35,  1.81s/it]INFO:root:global_step: 283, logpy: -3618.753, kl: 238.903, loss: 3788.060\n",
      " 28%|██████████████████████▍                                                        | 284/1000 [09:00<21:57,  1.84s/it]INFO:root:global_step: 284, logpy: -3619.584, kl: 238.588, loss: 3789.273\n",
      " 28%|██████████████████████▌                                                        | 285/1000 [09:02<21:43,  1.82s/it]INFO:root:global_step: 285, logpy: -3621.406, kl: 238.076, loss: 3791.272\n",
      " 29%|██████████████████████▌                                                        | 286/1000 [09:03<21:28,  1.81s/it]INFO:root:global_step: 286, logpy: -3621.197, kl: 237.418, loss: 3791.086\n",
      " 29%|██████████████████████▋                                                        | 287/1000 [09:05<21:28,  1.81s/it]INFO:root:global_step: 287, logpy: -3622.478, kl: 236.860, loss: 3792.484\n",
      " 29%|██████████████████████▊                                                        | 288/1000 [09:07<21:24,  1.80s/it]INFO:root:global_step: 288, logpy: -3623.496, kl: 236.541, loss: 3793.852\n",
      " 29%|██████████████████████▊                                                        | 289/1000 [09:09<21:14,  1.79s/it]INFO:root:global_step: 289, logpy: -3622.595, kl: 235.968, loss: 3793.041\n",
      " 29%|██████████████████████▉                                                        | 290/1000 [09:11<21:17,  1.80s/it]INFO:root:global_step: 290, logpy: -3624.171, kl: 235.547, loss: 3794.850\n",
      " 29%|██████████████████████▉                                                        | 291/1000 [09:12<21:14,  1.80s/it]INFO:root:global_step: 291, logpy: -3624.791, kl: 235.101, loss: 3795.673\n",
      " 29%|███████████████████████                                                        | 292/1000 [09:14<21:06,  1.79s/it]INFO:root:global_step: 292, logpy: -3624.228, kl: 234.634, loss: 3795.285\n",
      " 29%|███████████████████████▏                                                       | 293/1000 [09:16<21:02,  1.79s/it]INFO:root:global_step: 293, logpy: -3624.912, kl: 234.240, loss: 3796.210\n",
      " 29%|███████████████████████▏                                                       | 294/1000 [09:18<21:06,  1.79s/it]INFO:root:global_step: 294, logpy: -3624.570, kl: 233.795, loss: 3796.052\n",
      " 30%|███████████████████████▎                                                       | 295/1000 [09:19<20:53,  1.78s/it]INFO:root:global_step: 295, logpy: -3623.620, kl: 233.184, loss: 3795.116\n",
      " 30%|███████████████████████▍                                                       | 296/1000 [09:21<21:06,  1.80s/it]INFO:root:global_step: 296, logpy: -3625.761, kl: 232.675, loss: 3797.364\n",
      " 30%|███████████████████████▍                                                       | 297/1000 [09:23<21:21,  1.82s/it]INFO:root:global_step: 297, logpy: -3625.560, kl: 232.151, loss: 3797.250\n",
      " 30%|███████████████████████▌                                                       | 298/1000 [09:25<21:20,  1.82s/it]INFO:root:global_step: 298, logpy: -3625.086, kl: 231.656, loss: 3796.886\n",
      " 30%|███████████████████████▌                                                       | 299/1000 [09:27<21:19,  1.83s/it]INFO:root:global_step: 299, logpy: -3627.071, kl: 231.272, loss: 3799.085\n",
      " 30%|███████████████████████▋                                                       | 300/1000 [09:29<21:18,  1.83s/it]INFO:root:Saved figure at: ./sim/global_step_300.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 300, logpy: -3627.719, kl: 230.853, loss: 3799.907\n",
      " 30%|███████████████████████▊                                                       | 301/1000 [09:37<43:52,  3.77s/it]INFO:root:global_step: 301, logpy: -3631.714, kl: 230.419, loss: 3804.054\n",
      " 30%|███████████████████████▊                                                       | 302/1000 [09:39<36:47,  3.16s/it]INFO:root:global_step: 302, logpy: -3630.839, kl: 230.017, loss: 3803.358\n",
      " 30%|███████████████████████▉                                                       | 303/1000 [09:41<31:53,  2.75s/it]INFO:root:global_step: 303, logpy: -3633.195, kl: 229.749, loss: 3806.022\n",
      " 30%|████████████████████████                                                       | 304/1000 [09:42<28:11,  2.43s/it]INFO:root:global_step: 304, logpy: -3634.652, kl: 229.377, loss: 3807.675\n",
      " 30%|████████████████████████                                                       | 305/1000 [09:44<25:51,  2.23s/it]INFO:root:global_step: 305, logpy: -3636.424, kl: 228.909, loss: 3809.543\n",
      " 31%|████████████████████████▏                                                      | 306/1000 [09:46<24:05,  2.08s/it]INFO:root:global_step: 306, logpy: -3637.300, kl: 228.473, loss: 3810.542\n",
      " 31%|████████████████████████▎                                                      | 307/1000 [09:48<23:10,  2.01s/it]INFO:root:global_step: 307, logpy: -3637.584, kl: 228.011, loss: 3810.916\n",
      " 31%|████████████████████████▎                                                      | 308/1000 [09:49<22:20,  1.94s/it]INFO:root:global_step: 308, logpy: -3638.433, kl: 227.610, loss: 3811.910\n",
      " 31%|████████████████████████▍                                                      | 309/1000 [09:51<21:46,  1.89s/it]INFO:root:global_step: 309, logpy: -3638.109, kl: 227.153, loss: 3811.671\n",
      " 31%|████████████████████████▍                                                      | 310/1000 [09:53<21:30,  1.87s/it]INFO:root:global_step: 310, logpy: -3639.197, kl: 226.755, loss: 3812.897\n",
      " 31%|████████████████████████▌                                                      | 311/1000 [09:55<20:55,  1.82s/it]INFO:root:global_step: 311, logpy: -3638.791, kl: 226.268, loss: 3812.534\n",
      " 31%|████████████████████████▋                                                      | 312/1000 [09:56<20:35,  1.80s/it]INFO:root:global_step: 312, logpy: -3640.061, kl: 225.766, loss: 3813.828\n",
      " 31%|████████████████████████▋                                                      | 313/1000 [09:58<20:29,  1.79s/it]INFO:root:global_step: 313, logpy: -3640.630, kl: 225.215, loss: 3814.365\n",
      " 31%|████████████████████████▊                                                      | 314/1000 [10:00<20:04,  1.76s/it]INFO:root:global_step: 314, logpy: -3642.871, kl: 224.950, loss: 3816.856\n",
      " 32%|████████████████████████▉                                                      | 315/1000 [10:02<20:10,  1.77s/it]INFO:root:global_step: 315, logpy: -3643.352, kl: 224.456, loss: 3817.352\n",
      " 32%|████████████████████████▉                                                      | 316/1000 [10:03<19:54,  1.75s/it]INFO:root:global_step: 316, logpy: -3643.899, kl: 223.962, loss: 3817.910\n",
      " 32%|█████████████████████████                                                      | 317/1000 [10:05<19:56,  1.75s/it]INFO:root:global_step: 317, logpy: -3643.859, kl: 223.483, loss: 3817.890\n",
      " 32%|█████████████████████████                                                      | 318/1000 [10:07<19:53,  1.75s/it]INFO:root:global_step: 318, logpy: -3643.731, kl: 223.195, loss: 3817.969\n",
      " 32%|█████████████████████████▏                                                     | 319/1000 [10:09<19:42,  1.74s/it]INFO:root:global_step: 319, logpy: -3644.071, kl: 222.757, loss: 3818.360\n",
      " 32%|█████████████████████████▎                                                     | 320/1000 [10:10<19:29,  1.72s/it]INFO:root:global_step: 320, logpy: -3642.975, kl: 222.307, loss: 3817.300\n",
      " 32%|█████████████████████████▎                                                     | 321/1000 [10:12<19:34,  1.73s/it]INFO:root:global_step: 321, logpy: -3641.070, kl: 221.883, loss: 3815.450\n",
      " 32%|█████████████████████████▍                                                     | 322/1000 [10:14<19:38,  1.74s/it]INFO:root:global_step: 322, logpy: -3641.570, kl: 221.527, loss: 3816.069\n",
      " 32%|█████████████████████████▌                                                     | 323/1000 [10:16<19:50,  1.76s/it]INFO:root:global_step: 323, logpy: -3642.810, kl: 221.175, loss: 3817.428\n",
      " 32%|█████████████████████████▌                                                     | 324/1000 [10:17<19:44,  1.75s/it]INFO:root:global_step: 324, logpy: -3641.775, kl: 220.611, loss: 3816.294\n",
      " 32%|█████████████████████████▋                                                     | 325/1000 [10:19<19:41,  1.75s/it]INFO:root:global_step: 325, logpy: -3642.258, kl: 220.303, loss: 3816.930\n",
      " 33%|█████████████████████████▊                                                     | 326/1000 [10:21<19:31,  1.74s/it]INFO:root:global_step: 326, logpy: -3642.997, kl: 219.841, loss: 3817.663\n",
      " 33%|█████████████████████████▊                                                     | 327/1000 [10:23<19:42,  1.76s/it]INFO:root:global_step: 327, logpy: -3646.278, kl: 219.646, loss: 3821.200\n",
      " 33%|█████████████████████████▉                                                     | 328/1000 [10:24<19:48,  1.77s/it]INFO:root:global_step: 328, logpy: -3647.523, kl: 219.304, loss: 3822.551\n",
      " 33%|█████████████████████████▉                                                     | 329/1000 [10:26<19:56,  1.78s/it]INFO:root:global_step: 329, logpy: -3646.733, kl: 218.867, loss: 3821.767\n",
      " 33%|██████████████████████████                                                     | 330/1000 [10:28<20:14,  1.81s/it]INFO:root:global_step: 330, logpy: -3644.889, kl: 218.395, loss: 3819.889\n",
      " 33%|██████████████████████████▏                                                    | 331/1000 [10:30<20:02,  1.80s/it]INFO:root:global_step: 331, logpy: -3645.242, kl: 218.007, loss: 3820.288\n",
      " 33%|██████████████████████████▏                                                    | 332/1000 [10:32<20:04,  1.80s/it]INFO:root:global_step: 332, logpy: -3644.821, kl: 217.423, loss: 3819.713\n",
      " 33%|██████████████████████████▎                                                    | 333/1000 [10:33<19:55,  1.79s/it]INFO:root:global_step: 333, logpy: -3646.624, kl: 216.958, loss: 3821.476\n",
      " 33%|██████████████████████████▍                                                    | 334/1000 [10:35<19:37,  1.77s/it]INFO:root:global_step: 334, logpy: -3646.636, kl: 216.755, loss: 3821.706\n",
      " 34%|██████████████████████████▍                                                    | 335/1000 [10:37<19:41,  1.78s/it]INFO:root:global_step: 335, logpy: -3645.647, kl: 216.277, loss: 3820.656\n",
      " 34%|██████████████████████████▌                                                    | 336/1000 [10:39<19:44,  1.78s/it]INFO:root:global_step: 336, logpy: -3648.644, kl: 216.171, loss: 3823.960\n",
      " 34%|██████████████████████████▌                                                    | 337/1000 [10:40<19:45,  1.79s/it]INFO:root:global_step: 337, logpy: -3650.020, kl: 215.945, loss: 3825.518\n",
      " 34%|██████████████████████████▋                                                    | 338/1000 [10:42<19:43,  1.79s/it]INFO:root:global_step: 338, logpy: -3650.069, kl: 215.686, loss: 3825.713\n",
      " 34%|██████████████████████████▊                                                    | 339/1000 [10:44<19:38,  1.78s/it]INFO:root:global_step: 339, logpy: -3650.739, kl: 215.498, loss: 3826.596\n",
      " 34%|██████████████████████████▊                                                    | 340/1000 [10:46<19:33,  1.78s/it]INFO:root:global_step: 340, logpy: -3651.386, kl: 215.125, loss: 3827.265\n",
      " 34%|██████████████████████████▉                                                    | 341/1000 [10:48<19:30,  1.78s/it]INFO:root:global_step: 341, logpy: -3650.924, kl: 214.707, loss: 3826.777\n",
      " 34%|███████████████████████████                                                    | 342/1000 [10:49<19:41,  1.80s/it]INFO:root:global_step: 342, logpy: -3651.210, kl: 214.494, loss: 3827.239\n",
      " 34%|███████████████████████████                                                    | 343/1000 [10:51<19:40,  1.80s/it]INFO:root:global_step: 343, logpy: -3652.197, kl: 214.013, loss: 3828.131\n",
      " 34%|███████████████████████████▏                                                   | 344/1000 [10:53<19:24,  1.77s/it]INFO:root:global_step: 344, logpy: -3651.200, kl: 213.661, loss: 3827.162\n",
      " 34%|███████████████████████████▎                                                   | 345/1000 [10:55<19:19,  1.77s/it]INFO:root:global_step: 345, logpy: -3652.225, kl: 213.330, loss: 3828.233\n",
      " 35%|███████████████████████████▎                                                   | 346/1000 [10:56<19:23,  1.78s/it]INFO:root:global_step: 346, logpy: -3653.249, kl: 213.098, loss: 3829.398\n",
      " 35%|███████████████████████████▍                                                   | 347/1000 [10:58<19:23,  1.78s/it]INFO:root:global_step: 347, logpy: -3654.795, kl: 212.855, loss: 3831.070\n",
      " 35%|███████████████████████████▍                                                   | 348/1000 [11:00<19:32,  1.80s/it]INFO:root:global_step: 348, logpy: -3656.854, kl: 212.669, loss: 3833.310\n",
      " 35%|███████████████████████████▌                                                   | 349/1000 [11:02<19:23,  1.79s/it]INFO:root:global_step: 349, logpy: -3659.055, kl: 212.547, loss: 3835.751\n",
      " 35%|███████████████████████████▋                                                   | 350/1000 [11:04<19:18,  1.78s/it]INFO:root:Saved figure at: ./sim/global_step_350.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 350, logpy: -3658.858, kl: 212.369, loss: 3835.735\n",
      " 35%|███████████████████████████▋                                                   | 351/1000 [11:12<40:21,  3.73s/it]INFO:root:global_step: 351, logpy: -3658.277, kl: 211.998, loss: 3835.138\n",
      " 35%|███████████████████████████▊                                                   | 352/1000 [11:14<34:11,  3.17s/it]INFO:root:global_step: 352, logpy: -3658.099, kl: 211.590, loss: 3834.903\n",
      " 35%|███████████████████████████▉                                                   | 353/1000 [11:16<29:47,  2.76s/it]INFO:root:global_step: 353, logpy: -3658.756, kl: 211.593, loss: 3835.911\n",
      " 35%|███████████████████████████▉                                                   | 354/1000 [11:17<26:37,  2.47s/it]INFO:root:global_step: 354, logpy: -3658.878, kl: 211.284, loss: 3836.068\n",
      " 36%|████████████████████████████                                                   | 355/1000 [11:19<24:37,  2.29s/it]INFO:root:global_step: 355, logpy: -3658.406, kl: 211.041, loss: 3835.694\n",
      " 36%|████████████████████████████                                                   | 356/1000 [11:21<23:08,  2.16s/it]INFO:root:global_step: 356, logpy: -3656.713, kl: 210.593, loss: 3833.891\n",
      " 36%|████████████████████████████▏                                                  | 357/1000 [11:23<21:59,  2.05s/it]INFO:root:global_step: 357, logpy: -3657.658, kl: 210.405, loss: 3834.981\n",
      " 36%|████████████████████████████▎                                                  | 358/1000 [11:25<20:59,  1.96s/it]INFO:root:global_step: 358, logpy: -3658.063, kl: 210.181, loss: 3835.494\n",
      " 36%|████████████████████████████▎                                                  | 359/1000 [11:26<20:24,  1.91s/it]INFO:root:global_step: 359, logpy: -3658.625, kl: 209.930, loss: 3836.132\n",
      " 36%|████████████████████████████▍                                                  | 360/1000 [11:28<19:47,  1.86s/it]INFO:root:global_step: 360, logpy: -3658.674, kl: 209.602, loss: 3836.176\n",
      " 36%|████████████████████████████▌                                                  | 361/1000 [11:30<19:34,  1.84s/it]INFO:root:global_step: 361, logpy: -3659.641, kl: 209.403, loss: 3837.266\n",
      " 36%|████████████████████████████▌                                                  | 362/1000 [11:32<19:26,  1.83s/it]INFO:root:global_step: 362, logpy: -3659.442, kl: 209.239, loss: 3837.221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|████████████████████████████▋                                                  | 363/1000 [11:34<19:20,  1.82s/it]INFO:root:global_step: 363, logpy: -3659.076, kl: 209.061, loss: 3836.991\n",
      " 36%|████████████████████████████▊                                                  | 364/1000 [11:35<19:11,  1.81s/it]INFO:root:global_step: 364, logpy: -3659.568, kl: 208.835, loss: 3837.569\n",
      " 36%|████████████████████████████▊                                                  | 365/1000 [11:37<19:00,  1.80s/it]INFO:root:global_step: 365, logpy: -3659.159, kl: 208.531, loss: 3837.164\n",
      " 37%|████████████████████████████▉                                                  | 366/1000 [11:39<18:50,  1.78s/it]INFO:root:global_step: 366, logpy: -3659.471, kl: 208.497, loss: 3837.748\n",
      " 37%|████████████████████████████▉                                                  | 367/1000 [11:41<18:35,  1.76s/it]INFO:root:global_step: 367, logpy: -3659.165, kl: 208.138, loss: 3837.384\n",
      " 37%|█████████████████████████████                                                  | 368/1000 [11:42<18:39,  1.77s/it]INFO:root:global_step: 368, logpy: -3657.958, kl: 207.906, loss: 3836.245\n",
      " 37%|█████████████████████████████▏                                                 | 369/1000 [11:44<18:26,  1.75s/it]INFO:root:global_step: 369, logpy: -3656.775, kl: 207.782, loss: 3835.234\n",
      " 37%|█████████████████████████████▏                                                 | 370/1000 [11:46<18:25,  1.75s/it]INFO:root:global_step: 370, logpy: -3657.167, kl: 207.652, loss: 3835.788\n",
      " 37%|█████████████████████████████▎                                                 | 371/1000 [11:48<18:11,  1.74s/it]INFO:root:global_step: 371, logpy: -3657.192, kl: 207.412, loss: 3835.864\n",
      " 37%|█████████████████████████████▍                                                 | 372/1000 [11:49<18:15,  1.75s/it]INFO:root:global_step: 372, logpy: -3658.868, kl: 207.238, loss: 3837.655\n",
      " 37%|█████████████████████████████▍                                                 | 373/1000 [11:51<18:17,  1.75s/it]INFO:root:global_step: 373, logpy: -3658.913, kl: 207.081, loss: 3837.826\n",
      " 37%|█████████████████████████████▌                                                 | 374/1000 [11:53<18:25,  1.77s/it]INFO:root:global_step: 374, logpy: -3660.399, kl: 206.992, loss: 3839.506\n",
      " 38%|█████████████████████████████▋                                                 | 375/1000 [11:55<18:35,  1.78s/it]INFO:root:global_step: 375, logpy: -3659.045, kl: 206.482, loss: 3837.921\n",
      " 38%|█████████████████████████████▋                                                 | 376/1000 [11:57<18:38,  1.79s/it]INFO:root:global_step: 376, logpy: -3658.697, kl: 206.343, loss: 3837.708\n",
      " 38%|█████████████████████████████▊                                                 | 377/1000 [11:58<18:27,  1.78s/it]INFO:root:global_step: 377, logpy: -3659.890, kl: 206.098, loss: 3838.930\n",
      " 38%|█████████████████████████████▊                                                 | 378/1000 [12:00<18:27,  1.78s/it]INFO:root:global_step: 378, logpy: -3657.871, kl: 205.925, loss: 3837.008\n",
      " 38%|█████████████████████████████▉                                                 | 379/1000 [12:02<18:19,  1.77s/it]INFO:root:global_step: 379, logpy: -3658.583, kl: 205.637, loss: 3837.700\n",
      " 38%|██████████████████████████████                                                 | 380/1000 [12:04<18:46,  1.82s/it]INFO:root:global_step: 380, logpy: -3658.351, kl: 205.339, loss: 3837.436\n",
      " 38%|██████████████████████████████                                                 | 381/1000 [12:05<18:39,  1.81s/it]INFO:root:global_step: 381, logpy: -3658.854, kl: 205.241, loss: 3838.103\n",
      " 38%|██████████████████████████████▏                                                | 382/1000 [12:07<18:39,  1.81s/it]INFO:root:global_step: 382, logpy: -3660.486, kl: 205.193, loss: 3839.947\n",
      " 38%|██████████████████████████████▎                                                | 383/1000 [12:09<18:31,  1.80s/it]INFO:root:global_step: 383, logpy: -3659.241, kl: 204.685, loss: 3838.451\n",
      " 38%|██████████████████████████████▎                                                | 384/1000 [12:11<18:36,  1.81s/it]INFO:root:global_step: 384, logpy: -3660.252, kl: 204.332, loss: 3839.364\n",
      " 38%|██████████████████████████████▍                                                | 385/1000 [12:13<18:34,  1.81s/it]INFO:root:global_step: 385, logpy: -3660.433, kl: 204.209, loss: 3839.675\n",
      " 39%|██████████████████████████████▍                                                | 386/1000 [12:15<18:22,  1.80s/it]INFO:root:global_step: 386, logpy: -3658.416, kl: 203.888, loss: 3837.586\n",
      " 39%|██████████████████████████████▌                                                | 387/1000 [12:16<18:24,  1.80s/it]INFO:root:global_step: 387, logpy: -3658.189, kl: 203.740, loss: 3837.459\n",
      " 39%|██████████████████████████████▋                                                | 388/1000 [12:18<18:26,  1.81s/it]INFO:root:global_step: 388, logpy: -3657.040, kl: 203.583, loss: 3836.397\n",
      " 39%|██████████████████████████████▋                                                | 389/1000 [12:20<18:15,  1.79s/it]INFO:root:global_step: 389, logpy: -3658.776, kl: 203.348, loss: 3838.140\n",
      " 39%|██████████████████████████████▊                                                | 390/1000 [12:22<18:16,  1.80s/it]INFO:root:global_step: 390, logpy: -3659.129, kl: 203.022, loss: 3838.408\n",
      " 39%|██████████████████████████████▉                                                | 391/1000 [12:24<18:19,  1.80s/it]INFO:root:global_step: 391, logpy: -3660.423, kl: 202.951, loss: 3839.868\n",
      " 39%|██████████████████████████████▉                                                | 392/1000 [12:25<18:06,  1.79s/it]INFO:root:global_step: 392, logpy: -3660.628, kl: 202.791, loss: 3840.148\n",
      " 39%|███████████████████████████████                                                | 393/1000 [12:27<18:21,  1.82s/it]INFO:root:global_step: 393, logpy: -3660.868, kl: 202.491, loss: 3840.321\n",
      " 39%|███████████████████████████████▏                                               | 394/1000 [12:29<18:19,  1.81s/it]INFO:root:global_step: 394, logpy: -3660.831, kl: 202.464, loss: 3840.488\n",
      " 40%|███████████████████████████████▏                                               | 395/1000 [12:31<18:20,  1.82s/it]INFO:root:global_step: 395, logpy: -3662.233, kl: 202.441, loss: 3842.094\n",
      " 40%|███████████████████████████████▎                                               | 396/1000 [12:33<18:14,  1.81s/it]INFO:root:global_step: 396, logpy: -3663.583, kl: 202.393, loss: 3843.622\n",
      " 40%|███████████████████████████████▎                                               | 397/1000 [12:34<18:00,  1.79s/it]INFO:root:global_step: 397, logpy: -3662.622, kl: 202.086, loss: 3842.577\n",
      " 40%|███████████████████████████████▍                                               | 398/1000 [12:36<17:56,  1.79s/it]INFO:root:global_step: 398, logpy: -3661.199, kl: 201.887, loss: 3841.177\n",
      " 40%|███████████████████████████████▌                                               | 399/1000 [12:38<17:50,  1.78s/it]INFO:root:global_step: 399, logpy: -3661.227, kl: 201.731, loss: 3841.267\n",
      " 40%|███████████████████████████████▌                                               | 400/1000 [12:40<17:38,  1.76s/it]INFO:root:Saved figure at: ./sim/global_step_400.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 400, logpy: -3659.931, kl: 201.498, loss: 3839.956\n",
      " 40%|███████████████████████████████▋                                               | 401/1000 [12:48<37:15,  3.73s/it]INFO:root:global_step: 401, logpy: -3659.658, kl: 201.263, loss: 3839.662\n",
      " 40%|███████████████████████████████▊                                               | 402/1000 [12:50<31:29,  3.16s/it]INFO:root:global_step: 402, logpy: -3661.610, kl: 201.244, loss: 3841.808\n",
      " 40%|███████████████████████████████▊                                               | 403/1000 [12:52<27:14,  2.74s/it]INFO:root:global_step: 403, logpy: -3660.860, kl: 200.878, loss: 3840.902\n",
      " 40%|███████████████████████████████▉                                               | 404/1000 [12:53<24:31,  2.47s/it]INFO:root:global_step: 404, logpy: -3661.611, kl: 200.852, loss: 3841.836\n",
      " 40%|███████████████████████████████▉                                               | 405/1000 [12:55<22:26,  2.26s/it]INFO:root:global_step: 405, logpy: -3662.924, kl: 200.882, loss: 3843.385\n",
      " 41%|████████████████████████████████                                               | 406/1000 [12:57<20:50,  2.10s/it]INFO:root:global_step: 406, logpy: -3663.628, kl: 200.853, loss: 3844.264\n",
      " 41%|████████████████████████████████▏                                              | 407/1000 [12:59<19:43,  2.00s/it]INFO:root:global_step: 407, logpy: -3662.219, kl: 200.507, loss: 3842.711\n",
      " 41%|████████████████████████████████▏                                              | 408/1000 [13:00<19:11,  1.95s/it]INFO:root:global_step: 408, logpy: -3663.149, kl: 200.333, loss: 3843.668\n",
      " 41%|████████████████████████████████▎                                              | 409/1000 [13:02<19:01,  1.93s/it]INFO:root:global_step: 409, logpy: -3663.309, kl: 199.920, loss: 3843.613\n",
      " 41%|████████████████████████████████▍                                              | 410/1000 [13:04<18:44,  1.91s/it]INFO:root:global_step: 410, logpy: -3663.929, kl: 199.892, loss: 3844.400\n",
      " 41%|████████████████████████████████▍                                              | 411/1000 [13:06<18:17,  1.86s/it]INFO:root:global_step: 411, logpy: -3664.178, kl: 199.801, loss: 3844.754\n",
      " 41%|████████████████████████████████▌                                              | 412/1000 [13:08<18:08,  1.85s/it]INFO:root:global_step: 412, logpy: -3664.878, kl: 199.661, loss: 3845.505\n",
      " 41%|████████████████████████████████▋                                              | 413/1000 [13:10<18:01,  1.84s/it]INFO:root:global_step: 413, logpy: -3664.078, kl: 199.517, loss: 3844.751\n",
      " 41%|████████████████████████████████▋                                              | 414/1000 [13:11<17:49,  1.83s/it]INFO:root:global_step: 414, logpy: -3665.206, kl: 199.301, loss: 3845.852\n",
      " 42%|████████████████████████████████▊                                              | 415/1000 [13:13<17:40,  1.81s/it]INFO:root:global_step: 415, logpy: -3665.328, kl: 199.182, loss: 3846.041\n",
      " 42%|████████████████████████████████▊                                              | 416/1000 [13:15<17:40,  1.82s/it]INFO:root:global_step: 416, logpy: -3666.831, kl: 199.177, loss: 3847.724\n",
      " 42%|████████████████████████████████▉                                              | 417/1000 [13:17<17:35,  1.81s/it]INFO:root:global_step: 417, logpy: -3665.887, kl: 199.147, loss: 3846.933\n",
      " 42%|█████████████████████████████████                                              | 418/1000 [13:19<17:28,  1.80s/it]INFO:root:global_step: 418, logpy: -3665.588, kl: 199.031, loss: 3846.699\n",
      " 42%|█████████████████████████████████                                              | 419/1000 [13:20<17:18,  1.79s/it]INFO:root:global_step: 419, logpy: -3664.638, kl: 198.746, loss: 3845.643\n",
      " 42%|█████████████████████████████████▏                                             | 420/1000 [13:22<17:30,  1.81s/it]INFO:root:global_step: 420, logpy: -3664.547, kl: 198.655, loss: 3845.639\n",
      " 42%|█████████████████████████████████▎                                             | 421/1000 [13:24<17:25,  1.81s/it]INFO:root:global_step: 421, logpy: -3666.051, kl: 198.319, loss: 3846.982\n",
      " 42%|█████████████████████████████████▎                                             | 422/1000 [13:26<17:18,  1.80s/it]INFO:root:global_step: 422, logpy: -3666.059, kl: 198.202, loss: 3847.047\n",
      " 42%|█████████████████████████████████▍                                             | 423/1000 [13:28<17:19,  1.80s/it]INFO:root:global_step: 423, logpy: -3666.070, kl: 198.157, loss: 3847.186\n",
      " 42%|█████████████████████████████████▍                                             | 424/1000 [13:29<17:13,  1.79s/it]INFO:root:global_step: 424, logpy: -3664.686, kl: 198.021, loss: 3845.836\n",
      " 42%|█████████████████████████████████▌                                             | 425/1000 [13:31<17:18,  1.81s/it]INFO:root:global_step: 425, logpy: -3665.153, kl: 197.944, loss: 3846.395\n",
      " 43%|█████████████████████████████████▋                                             | 426/1000 [13:33<17:08,  1.79s/it]INFO:root:global_step: 426, logpy: -3667.044, kl: 198.067, loss: 3848.576\n",
      " 43%|█████████████████████████████████▋                                             | 427/1000 [13:35<17:10,  1.80s/it]INFO:root:global_step: 427, logpy: -3666.805, kl: 197.812, loss: 3848.247\n",
      " 43%|█████████████████████████████████▊                                             | 428/1000 [13:37<17:16,  1.81s/it]INFO:root:global_step: 428, logpy: -3667.846, kl: 197.732, loss: 3849.371\n",
      " 43%|█████████████████████████████████▉                                             | 429/1000 [13:38<17:16,  1.82s/it]INFO:root:global_step: 429, logpy: -3668.142, kl: 197.752, loss: 3849.849\n",
      " 43%|█████████████████████████████████▉                                             | 430/1000 [13:40<17:14,  1.81s/it]INFO:root:global_step: 430, logpy: -3667.023, kl: 197.549, loss: 3848.688\n",
      " 43%|██████████████████████████████████                                             | 431/1000 [13:42<17:15,  1.82s/it]INFO:root:global_step: 431, logpy: -3666.179, kl: 197.482, loss: 3847.937\n",
      " 43%|██████████████████████████████████▏                                            | 432/1000 [13:44<17:00,  1.80s/it]INFO:root:global_step: 432, logpy: -3667.534, kl: 197.325, loss: 3849.291\n",
      " 43%|██████████████████████████████████▏                                            | 433/1000 [13:46<16:52,  1.79s/it]INFO:root:global_step: 433, logpy: -3667.440, kl: 197.210, loss: 3849.238\n",
      " 43%|██████████████████████████████████▎                                            | 434/1000 [13:47<16:44,  1.77s/it]INFO:root:global_step: 434, logpy: -3668.225, kl: 197.129, loss: 3850.096\n",
      " 44%|██████████████████████████████████▎                                            | 435/1000 [13:49<16:45,  1.78s/it]INFO:root:global_step: 435, logpy: -3667.685, kl: 196.987, loss: 3849.566\n",
      " 44%|██████████████████████████████████▍                                            | 436/1000 [13:51<16:59,  1.81s/it]INFO:root:global_step: 436, logpy: -3669.052, kl: 196.940, loss: 3851.038\n",
      " 44%|██████████████████████████████████▌                                            | 437/1000 [13:53<16:49,  1.79s/it]INFO:root:global_step: 437, logpy: -3668.695, kl: 196.854, loss: 3850.744\n",
      " 44%|██████████████████████████████████▌                                            | 438/1000 [13:54<16:41,  1.78s/it]INFO:root:global_step: 438, logpy: -3669.585, kl: 196.805, loss: 3851.734\n",
      " 44%|██████████████████████████████████▋                                            | 439/1000 [13:56<16:45,  1.79s/it]INFO:root:global_step: 439, logpy: -3670.275, kl: 196.707, loss: 3852.472\n",
      " 44%|██████████████████████████████████▊                                            | 440/1000 [13:58<16:39,  1.79s/it]INFO:root:global_step: 440, logpy: -3670.913, kl: 196.607, loss: 3853.154\n",
      " 44%|██████████████████████████████████▊                                            | 441/1000 [14:00<16:35,  1.78s/it]INFO:root:global_step: 441, logpy: -3670.675, kl: 196.365, loss: 3852.818\n",
      " 44%|██████████████████████████████████▉                                            | 442/1000 [14:02<16:46,  1.80s/it]INFO:root:global_step: 442, logpy: -3671.647, kl: 196.271, loss: 3853.839\n",
      " 44%|██████████████████████████████████▉                                            | 443/1000 [14:04<16:48,  1.81s/it]INFO:root:global_step: 443, logpy: -3671.370, kl: 196.379, loss: 3853.811\n",
      " 44%|███████████████████████████████████                                            | 444/1000 [14:05<16:30,  1.78s/it]INFO:root:global_step: 444, logpy: -3670.951, kl: 196.139, loss: 3853.290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|███████████████████████████████████▏                                           | 445/1000 [14:07<16:38,  1.80s/it]INFO:root:global_step: 445, logpy: -3669.834, kl: 195.882, loss: 3852.055\n",
      " 45%|███████████████████████████████████▏                                           | 446/1000 [14:09<16:41,  1.81s/it]INFO:root:global_step: 446, logpy: -3671.421, kl: 195.747, loss: 3853.644\n",
      " 45%|███████████████████████████████████▎                                           | 447/1000 [14:11<16:44,  1.82s/it]INFO:root:global_step: 447, logpy: -3670.960, kl: 195.636, loss: 3853.206\n",
      " 45%|███████████████████████████████████▍                                           | 448/1000 [14:13<16:40,  1.81s/it]INFO:root:global_step: 448, logpy: -3671.060, kl: 195.556, loss: 3853.361\n",
      " 45%|███████████████████████████████████▍                                           | 449/1000 [14:14<16:40,  1.82s/it]INFO:root:global_step: 449, logpy: -3669.848, kl: 195.362, loss: 3852.087\n",
      " 45%|███████████████████████████████████▌                                           | 450/1000 [14:16<16:43,  1.82s/it]INFO:root:Saved figure at: ./sim/global_step_450.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 450, logpy: -3670.721, kl: 195.312, loss: 3853.042\n",
      " 45%|███████████████████████████████████▋                                           | 451/1000 [14:24<34:06,  3.73s/it]INFO:root:global_step: 451, logpy: -3671.128, kl: 195.249, loss: 3853.515\n",
      " 45%|███████████████████████████████████▋                                           | 452/1000 [14:26<28:41,  3.14s/it]INFO:root:global_step: 452, logpy: -3671.024, kl: 195.154, loss: 3853.445\n",
      " 45%|███████████████████████████████████▊                                           | 453/1000 [14:28<24:48,  2.72s/it]INFO:root:global_step: 453, logpy: -3671.555, kl: 195.019, loss: 3853.968\n",
      " 45%|███████████████████████████████████▊                                           | 454/1000 [14:30<22:11,  2.44s/it]INFO:root:global_step: 454, logpy: -3669.886, kl: 194.825, loss: 3852.232\n",
      " 46%|███████████████████████████████████▉                                           | 455/1000 [14:32<20:36,  2.27s/it]INFO:root:global_step: 455, logpy: -3669.862, kl: 194.757, loss: 3852.264\n",
      " 46%|████████████████████████████████████                                           | 456/1000 [14:33<19:19,  2.13s/it]INFO:root:global_step: 456, logpy: -3670.990, kl: 194.842, loss: 3853.601\n",
      " 46%|████████████████████████████████████                                           | 457/1000 [14:35<18:15,  2.02s/it]INFO:root:global_step: 457, logpy: -3673.091, kl: 195.014, loss: 3855.996\n",
      " 46%|████████████████████████████████████▏                                          | 458/1000 [14:37<17:29,  1.94s/it]INFO:root:global_step: 458, logpy: -3674.041, kl: 194.865, loss: 3856.918\n",
      " 46%|████████████████████████████████████▎                                          | 459/1000 [14:39<17:14,  1.91s/it]INFO:root:global_step: 459, logpy: -3673.613, kl: 194.553, loss: 3856.298\n",
      " 46%|████████████████████████████████████▎                                          | 460/1000 [14:41<17:11,  1.91s/it]INFO:root:global_step: 460, logpy: -3673.989, kl: 194.316, loss: 3856.556\n",
      " 46%|████████████████████████████████████▍                                          | 461/1000 [14:42<16:50,  1.87s/it]INFO:root:global_step: 461, logpy: -3676.623, kl: 194.367, loss: 3859.359\n",
      " 46%|████████████████████████████████████▍                                          | 462/1000 [14:44<16:46,  1.87s/it]INFO:root:global_step: 462, logpy: -3676.857, kl: 194.243, loss: 3859.585\n",
      " 46%|████████████████████████████████████▌                                          | 463/1000 [14:46<16:45,  1.87s/it]INFO:root:global_step: 463, logpy: -3676.424, kl: 194.101, loss: 3859.125\n",
      " 46%|████████████████████████████████████▋                                          | 464/1000 [14:48<16:27,  1.84s/it]INFO:root:global_step: 464, logpy: -3676.697, kl: 193.781, loss: 3859.192\n",
      " 46%|████████████████████████████████████▋                                          | 465/1000 [14:50<16:13,  1.82s/it]INFO:root:global_step: 465, logpy: -3674.404, kl: 193.575, loss: 3856.806\n",
      " 47%|████████████████████████████████████▊                                          | 466/1000 [14:52<16:12,  1.82s/it]INFO:root:global_step: 466, logpy: -3672.768, kl: 193.492, loss: 3855.199\n",
      " 47%|████████████████████████████████████▉                                          | 467/1000 [14:53<16:06,  1.81s/it]INFO:root:global_step: 467, logpy: -3672.300, kl: 193.422, loss: 3854.771\n",
      " 47%|████████████████████████████████████▉                                          | 468/1000 [14:55<16:00,  1.81s/it]INFO:root:global_step: 468, logpy: -3672.857, kl: 193.322, loss: 3855.337\n",
      " 47%|█████████████████████████████████████                                          | 469/1000 [14:57<15:57,  1.80s/it]INFO:root:global_step: 469, logpy: -3673.277, kl: 193.249, loss: 3855.793\n",
      " 47%|█████████████████████████████████████▏                                         | 470/1000 [14:59<16:06,  1.82s/it]INFO:root:global_step: 470, logpy: -3672.258, kl: 193.117, loss: 3854.749\n",
      " 47%|█████████████████████████████████████▏                                         | 471/1000 [15:01<15:56,  1.81s/it]INFO:root:global_step: 471, logpy: -3673.464, kl: 193.194, loss: 3856.138\n",
      " 47%|█████████████████████████████████████▎                                         | 472/1000 [15:02<15:49,  1.80s/it]INFO:root:global_step: 472, logpy: -3674.637, kl: 193.159, loss: 3857.382\n",
      " 47%|█████████████████████████████████████▎                                         | 473/1000 [15:04<15:38,  1.78s/it]INFO:root:global_step: 473, logpy: -3675.055, kl: 193.183, loss: 3857.927\n",
      " 47%|█████████████████████████████████████▍                                         | 474/1000 [15:06<15:38,  1.79s/it]INFO:root:global_step: 474, logpy: -3674.787, kl: 193.019, loss: 3857.598\n",
      " 48%|█████████████████████████████████████▌                                         | 475/1000 [15:08<15:42,  1.79s/it]INFO:root:global_step: 475, logpy: -3674.976, kl: 193.072, loss: 3857.943\n",
      " 48%|█████████████████████████████████████▌                                         | 476/1000 [15:09<15:41,  1.80s/it]INFO:root:global_step: 476, logpy: -3674.638, kl: 192.913, loss: 3857.546\n",
      " 48%|█████████████████████████████████████▋                                         | 477/1000 [15:11<15:34,  1.79s/it]INFO:root:global_step: 477, logpy: -3675.811, kl: 192.946, loss: 3858.852\n",
      " 48%|█████████████████████████████████████▊                                         | 478/1000 [15:13<15:46,  1.81s/it]INFO:root:global_step: 478, logpy: -3675.157, kl: 192.683, loss: 3858.035\n",
      " 48%|█████████████████████████████████████▊                                         | 479/1000 [15:15<15:45,  1.82s/it]INFO:root:global_step: 479, logpy: -3675.455, kl: 192.705, loss: 3858.454\n",
      " 48%|█████████████████████████████████████▉                                         | 480/1000 [15:17<15:43,  1.81s/it]INFO:root:global_step: 480, logpy: -3675.182, kl: 192.456, loss: 3858.028\n",
      " 48%|█████████████████████████████████████▉                                         | 481/1000 [15:19<15:39,  1.81s/it]INFO:root:global_step: 481, logpy: -3675.468, kl: 192.588, loss: 3858.542\n",
      " 48%|██████████████████████████████████████                                         | 482/1000 [15:20<15:26,  1.79s/it]INFO:root:global_step: 482, logpy: -3675.500, kl: 192.259, loss: 3858.340\n",
      " 48%|██████████████████████████████████████▏                                        | 483/1000 [15:22<15:37,  1.81s/it]INFO:root:global_step: 483, logpy: -3675.722, kl: 192.144, loss: 3858.542\n",
      " 48%|██████████████████████████████████████▏                                        | 484/1000 [15:24<15:35,  1.81s/it]INFO:root:global_step: 484, logpy: -3675.145, kl: 192.245, loss: 3858.159\n",
      " 48%|██████████████████████████████████████▎                                        | 485/1000 [15:26<15:33,  1.81s/it]INFO:root:global_step: 485, logpy: -3673.986, kl: 192.009, loss: 3856.856\n",
      " 49%|██████████████████████████████████████▍                                        | 486/1000 [15:28<15:40,  1.83s/it]INFO:root:global_step: 486, logpy: -3675.050, kl: 191.967, loss: 3857.969\n",
      " 49%|██████████████████████████████████████▍                                        | 487/1000 [15:29<15:38,  1.83s/it]INFO:root:global_step: 487, logpy: -3675.764, kl: 191.841, loss: 3858.648\n",
      " 49%|██████████████████████████████████████▌                                        | 488/1000 [15:31<15:26,  1.81s/it]INFO:root:global_step: 488, logpy: -3677.424, kl: 191.925, loss: 3860.481\n",
      " 49%|██████████████████████████████████████▋                                        | 489/1000 [15:33<15:11,  1.78s/it]INFO:root:global_step: 489, logpy: -3676.335, kl: 191.736, loss: 3859.293\n",
      " 49%|██████████████████████████████████████▋                                        | 490/1000 [15:35<15:20,  1.81s/it]INFO:root:global_step: 490, logpy: -3676.460, kl: 191.739, loss: 3859.508\n",
      " 49%|██████████████████████████████████████▊                                        | 491/1000 [15:37<15:11,  1.79s/it]INFO:root:global_step: 491, logpy: -3675.215, kl: 191.657, loss: 3858.267\n",
      " 49%|██████████████████████████████████████▊                                        | 492/1000 [15:38<15:11,  1.79s/it]INFO:root:global_step: 492, logpy: -3676.347, kl: 191.544, loss: 3859.373\n",
      " 49%|██████████████████████████████████████▉                                        | 493/1000 [15:40<15:04,  1.78s/it]INFO:root:global_step: 493, logpy: -3676.298, kl: 191.336, loss: 3859.201\n",
      " 49%|███████████████████████████████████████                                        | 494/1000 [15:42<15:21,  1.82s/it]INFO:root:global_step: 494, logpy: -3678.813, kl: 191.321, loss: 3861.786\n",
      " 50%|███████████████████████████████████████                                        | 495/1000 [15:44<15:18,  1.82s/it]INFO:root:global_step: 495, logpy: -3679.263, kl: 191.259, loss: 3862.257\n",
      " 50%|███████████████████████████████████████▏                                       | 496/1000 [15:46<15:21,  1.83s/it]INFO:root:global_step: 496, logpy: -3679.917, kl: 191.383, loss: 3863.118\n",
      " 50%|███████████████████████████████████████▎                                       | 497/1000 [15:47<15:09,  1.81s/it]INFO:root:global_step: 497, logpy: -3680.315, kl: 191.357, loss: 3863.572\n",
      " 50%|███████████████████████████████████████▎                                       | 498/1000 [15:49<15:05,  1.80s/it]INFO:root:global_step: 498, logpy: -3678.883, kl: 191.236, loss: 3862.100\n",
      " 50%|███████████████████████████████████████▍                                       | 499/1000 [15:51<15:02,  1.80s/it]INFO:root:global_step: 499, logpy: -3678.031, kl: 191.064, loss: 3861.156\n",
      " 50%|███████████████████████████████████████▌                                       | 500/1000 [15:53<15:02,  1.81s/it]INFO:root:Saved figure at: ./sim/global_step_500.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 500, logpy: -3677.626, kl: 191.011, loss: 3860.777\n",
      " 50%|███████████████████████████████████████▌                                       | 501/1000 [16:01<31:16,  3.76s/it]INFO:root:global_step: 501, logpy: -3678.107, kl: 190.960, loss: 3861.285\n",
      " 50%|███████████████████████████████████████▋                                       | 502/1000 [16:03<26:23,  3.18s/it]INFO:root:global_step: 502, logpy: -3678.845, kl: 190.892, loss: 3862.033\n",
      " 50%|███████████████████████████████████████▋                                       | 503/1000 [16:05<22:44,  2.75s/it]INFO:root:global_step: 503, logpy: -3678.386, kl: 190.949, loss: 3861.708\n",
      " 50%|███████████████████████████████████████▊                                       | 504/1000 [16:07<20:29,  2.48s/it]INFO:root:global_step: 504, logpy: -3677.963, kl: 190.944, loss: 3861.357\n",
      " 50%|███████████████████████████████████████▉                                       | 505/1000 [16:08<18:38,  2.26s/it]INFO:root:global_step: 505, logpy: -3678.831, kl: 190.855, loss: 3862.211\n",
      " 51%|███████████████████████████████████████▉                                       | 506/1000 [16:10<17:26,  2.12s/it]INFO:root:global_step: 506, logpy: -3678.442, kl: 190.825, loss: 3861.867\n",
      " 51%|████████████████████████████████████████                                       | 507/1000 [16:12<16:44,  2.04s/it]INFO:root:global_step: 507, logpy: -3679.283, kl: 190.826, loss: 3862.783\n",
      " 51%|████████████████████████████████████████▏                                      | 508/1000 [16:14<16:14,  1.98s/it]INFO:root:global_step: 508, logpy: -3681.185, kl: 190.894, loss: 3864.827\n",
      " 51%|████████████████████████████████████████▏                                      | 509/1000 [16:16<15:41,  1.92s/it]INFO:root:global_step: 509, logpy: -3681.118, kl: 190.563, loss: 3864.501\n",
      " 51%|████████████████████████████████████████▎                                      | 510/1000 [16:17<15:23,  1.88s/it]INFO:root:global_step: 510, logpy: -3681.603, kl: 190.475, loss: 3864.970\n",
      " 51%|████████████████████████████████████████▎                                      | 511/1000 [16:19<15:02,  1.85s/it]INFO:root:global_step: 511, logpy: -3680.675, kl: 190.319, loss: 3863.957\n",
      " 51%|████████████████████████████████████████▍                                      | 512/1000 [16:21<14:48,  1.82s/it]INFO:root:global_step: 512, logpy: -3677.605, kl: 190.050, loss: 3860.689\n",
      " 51%|████████████████████████████████████████▌                                      | 513/1000 [16:23<14:39,  1.81s/it]INFO:root:global_step: 513, logpy: -3677.682, kl: 189.919, loss: 3860.703\n",
      " 51%|████████████████████████████████████████▌                                      | 514/1000 [16:25<14:40,  1.81s/it]INFO:root:global_step: 514, logpy: -3676.414, kl: 189.762, loss: 3859.348\n",
      " 52%|████████████████████████████████████████▋                                      | 515/1000 [16:26<14:32,  1.80s/it]INFO:root:global_step: 515, logpy: -3678.657, kl: 189.686, loss: 3861.583\n",
      " 52%|████████████████████████████████████████▊                                      | 516/1000 [16:28<14:25,  1.79s/it]INFO:root:global_step: 516, logpy: -3679.256, kl: 189.652, loss: 3862.216\n",
      " 52%|████████████████████████████████████████▊                                      | 517/1000 [16:30<14:17,  1.77s/it]INFO:root:global_step: 517, logpy: -3677.034, kl: 189.610, loss: 3860.018\n",
      " 52%|████████████████████████████████████████▉                                      | 518/1000 [16:32<14:15,  1.77s/it]INFO:root:global_step: 518, logpy: -3675.875, kl: 189.512, loss: 3858.828\n",
      " 52%|█████████████████████████████████████████                                      | 519/1000 [16:33<14:18,  1.79s/it]INFO:root:global_step: 519, logpy: -3676.116, kl: 189.449, loss: 3859.071\n",
      " 52%|█████████████████████████████████████████                                      | 520/1000 [16:35<14:23,  1.80s/it]INFO:root:global_step: 520, logpy: -3675.638, kl: 189.369, loss: 3858.579\n",
      " 52%|█████████████████████████████████████████▏                                     | 521/1000 [16:37<14:35,  1.83s/it]INFO:root:global_step: 521, logpy: -3675.026, kl: 189.293, loss: 3857.954\n",
      " 52%|█████████████████████████████████████████▏                                     | 522/1000 [16:39<14:35,  1.83s/it]INFO:root:global_step: 522, logpy: -3675.836, kl: 189.293, loss: 3858.829\n",
      " 52%|█████████████████████████████████████████▎                                     | 523/1000 [16:41<14:31,  1.83s/it]INFO:root:global_step: 523, logpy: -3676.469, kl: 189.359, loss: 3859.590\n",
      " 52%|█████████████████████████████████████████▍                                     | 524/1000 [16:43<14:29,  1.83s/it]INFO:root:global_step: 524, logpy: -3675.308, kl: 189.258, loss: 3858.391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████████████████████████████████████████▍                                     | 525/1000 [16:44<14:24,  1.82s/it]INFO:root:global_step: 525, logpy: -3675.232, kl: 189.309, loss: 3858.428\n",
      " 53%|█████████████████████████████████████████▌                                     | 526/1000 [16:46<14:17,  1.81s/it]INFO:root:global_step: 526, logpy: -3673.748, kl: 189.116, loss: 3856.811\n",
      " 53%|█████████████████████████████████████████▋                                     | 527/1000 [16:48<14:25,  1.83s/it]INFO:root:global_step: 527, logpy: -3675.343, kl: 189.216, loss: 3858.567\n",
      " 53%|█████████████████████████████████████████▋                                     | 528/1000 [16:50<14:03,  1.79s/it]INFO:root:global_step: 528, logpy: -3676.194, kl: 189.149, loss: 3859.411\n",
      " 53%|█████████████████████████████████████████▊                                     | 529/1000 [16:52<14:09,  1.80s/it]INFO:root:global_step: 529, logpy: -3677.010, kl: 189.124, loss: 3860.262\n",
      " 53%|█████████████████████████████████████████▊                                     | 530/1000 [16:53<14:11,  1.81s/it]INFO:root:global_step: 530, logpy: -3678.515, kl: 189.167, loss: 3861.868\n",
      " 53%|█████████████████████████████████████████▉                                     | 531/1000 [16:55<14:01,  1.79s/it]INFO:root:global_step: 531, logpy: -3677.280, kl: 189.107, loss: 3860.632\n",
      " 53%|██████████████████████████████████████████                                     | 532/1000 [16:57<14:01,  1.80s/it]INFO:root:global_step: 532, logpy: -3678.084, kl: 189.293, loss: 3861.678\n",
      " 53%|██████████████████████████████████████████                                     | 533/1000 [16:59<13:56,  1.79s/it]INFO:root:global_step: 533, logpy: -3678.637, kl: 189.292, loss: 3862.288\n",
      " 53%|██████████████████████████████████████████▏                                    | 534/1000 [17:00<13:47,  1.78s/it]INFO:root:global_step: 534, logpy: -3678.795, kl: 189.151, loss: 3862.361\n",
      " 54%|██████████████████████████████████████████▎                                    | 535/1000 [17:02<13:43,  1.77s/it]INFO:root:global_step: 535, logpy: -3679.045, kl: 189.008, loss: 3862.523\n",
      " 54%|██████████████████████████████████████████▎                                    | 536/1000 [17:04<13:43,  1.77s/it]INFO:root:global_step: 536, logpy: -3678.295, kl: 188.977, loss: 3861.798\n",
      " 54%|██████████████████████████████████████████▍                                    | 537/1000 [17:06<13:44,  1.78s/it]INFO:root:global_step: 537, logpy: -3678.567, kl: 189.027, loss: 3862.175\n",
      " 54%|██████████████████████████████████████████▌                                    | 538/1000 [17:08<13:48,  1.79s/it]INFO:root:global_step: 538, logpy: -3679.277, kl: 188.879, loss: 3862.790\n",
      " 54%|██████████████████████████████████████████▌                                    | 539/1000 [17:09<13:41,  1.78s/it]INFO:root:global_step: 539, logpy: -3679.075, kl: 188.811, loss: 3862.575\n",
      " 54%|██████████████████████████████████████████▋                                    | 540/1000 [17:11<13:39,  1.78s/it]INFO:root:global_step: 540, logpy: -3678.467, kl: 188.807, loss: 3862.016\n",
      " 54%|██████████████████████████████████████████▋                                    | 541/1000 [17:13<13:42,  1.79s/it]INFO:root:global_step: 541, logpy: -3679.226, kl: 189.091, loss: 3863.111\n",
      " 54%|██████████████████████████████████████████▊                                    | 542/1000 [17:15<13:34,  1.78s/it]INFO:root:global_step: 542, logpy: -3677.199, kl: 188.904, loss: 3860.950\n",
      " 54%|██████████████████████████████████████████▉                                    | 543/1000 [17:17<13:43,  1.80s/it]INFO:root:global_step: 543, logpy: -3675.913, kl: 188.807, loss: 3859.619\n",
      " 54%|██████████████████████████████████████████▉                                    | 544/1000 [17:18<13:41,  1.80s/it]INFO:root:global_step: 544, logpy: -3675.927, kl: 188.610, loss: 3859.487\n",
      " 55%|███████████████████████████████████████████                                    | 545/1000 [17:20<13:39,  1.80s/it]INFO:root:global_step: 545, logpy: -3674.107, kl: 188.426, loss: 3857.532\n",
      " 55%|███████████████████████████████████████████▏                                   | 546/1000 [17:22<13:33,  1.79s/it]INFO:root:global_step: 546, logpy: -3674.432, kl: 188.328, loss: 3857.810\n",
      " 55%|███████████████████████████████████████████▏                                   | 547/1000 [17:24<13:34,  1.80s/it]INFO:root:global_step: 547, logpy: -3674.159, kl: 188.279, loss: 3857.538\n",
      " 55%|███████████████████████████████████████████▎                                   | 548/1000 [17:26<13:35,  1.81s/it]INFO:root:global_step: 548, logpy: -3675.321, kl: 188.341, loss: 3858.810\n",
      " 55%|███████████████████████████████████████████▎                                   | 549/1000 [17:27<13:34,  1.81s/it]INFO:root:global_step: 549, logpy: -3675.727, kl: 188.195, loss: 3859.119\n",
      " 55%|███████████████████████████████████████████▍                                   | 550/1000 [17:29<13:38,  1.82s/it]INFO:root:Saved figure at: ./sim/global_step_550.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 550, logpy: -3675.875, kl: 188.285, loss: 3859.405\n",
      " 55%|███████████████████████████████████████████▌                                   | 551/1000 [17:38<28:09,  3.76s/it]INFO:root:global_step: 551, logpy: -3673.963, kl: 188.097, loss: 3857.352\n",
      " 55%|███████████████████████████████████████████▌                                   | 552/1000 [17:39<23:39,  3.17s/it]INFO:root:global_step: 552, logpy: -3674.513, kl: 188.156, loss: 3858.008\n",
      " 55%|███████████████████████████████████████████▋                                   | 553/1000 [17:41<20:28,  2.75s/it]INFO:root:global_step: 553, logpy: -3676.128, kl: 188.266, loss: 3859.780\n",
      " 55%|███████████████████████████████████████████▊                                   | 554/1000 [17:43<18:20,  2.47s/it]INFO:root:global_step: 554, logpy: -3675.122, kl: 188.084, loss: 3858.638\n",
      " 56%|███████████████████████████████████████████▊                                   | 555/1000 [17:45<16:42,  2.25s/it]INFO:root:global_step: 555, logpy: -3673.301, kl: 187.961, loss: 3856.740\n",
      " 56%|███████████████████████████████████████████▉                                   | 556/1000 [17:46<15:38,  2.11s/it]INFO:root:global_step: 556, logpy: -3673.614, kl: 187.957, loss: 3857.094\n",
      " 56%|████████████████████████████████████████████                                   | 557/1000 [17:48<14:40,  1.99s/it]INFO:root:global_step: 557, logpy: -3672.216, kl: 187.839, loss: 3855.623\n",
      " 56%|████████████████████████████████████████████                                   | 558/1000 [17:50<14:10,  1.92s/it]INFO:root:global_step: 558, logpy: -3672.460, kl: 187.832, loss: 3855.904\n",
      " 56%|████████████████████████████████████████████▏                                  | 559/1000 [17:52<13:38,  1.86s/it]INFO:root:global_step: 559, logpy: -3673.889, kl: 187.754, loss: 3857.300\n",
      " 56%|████████████████████████████████████████████▏                                  | 560/1000 [17:53<13:17,  1.81s/it]INFO:root:global_step: 560, logpy: -3673.558, kl: 187.772, loss: 3857.029\n",
      " 56%|████████████████████████████████████████████▎                                  | 561/1000 [17:55<13:07,  1.79s/it]INFO:root:global_step: 561, logpy: -3674.359, kl: 187.719, loss: 3857.821\n",
      " 56%|████████████████████████████████████████████▍                                  | 562/1000 [17:57<13:11,  1.81s/it]INFO:root:global_step: 562, logpy: -3676.525, kl: 187.963, loss: 3860.272\n",
      " 56%|████████████████████████████████████████████▍                                  | 563/1000 [17:59<12:59,  1.78s/it]INFO:root:global_step: 563, logpy: -3677.273, kl: 187.954, loss: 3861.054\n",
      " 56%|████████████████████████████████████████████▌                                  | 564/1000 [18:00<12:54,  1.78s/it]INFO:root:global_step: 564, logpy: -3676.451, kl: 187.881, loss: 3860.201\n",
      " 56%|████████████████████████████████████████████▋                                  | 565/1000 [18:02<12:43,  1.76s/it]INFO:root:global_step: 565, logpy: -3676.172, kl: 187.756, loss: 3859.838\n",
      " 57%|████████████████████████████████████████████▋                                  | 566/1000 [18:04<12:40,  1.75s/it]INFO:root:global_step: 566, logpy: -3677.811, kl: 187.826, loss: 3861.588\n",
      " 57%|████████████████████████████████████████████▊                                  | 567/1000 [18:06<12:27,  1.73s/it]INFO:root:global_step: 567, logpy: -3677.584, kl: 187.730, loss: 3861.306\n",
      " 57%|████████████████████████████████████████████▊                                  | 568/1000 [18:07<12:30,  1.74s/it]INFO:root:global_step: 568, logpy: -3679.285, kl: 187.751, loss: 3863.067\n",
      " 57%|████████████████████████████████████████████▉                                  | 569/1000 [18:09<12:23,  1.72s/it]INFO:root:global_step: 569, logpy: -3678.014, kl: 187.654, loss: 3861.739\n",
      " 57%|█████████████████████████████████████████████                                  | 570/1000 [18:11<12:35,  1.76s/it]INFO:root:global_step: 570, logpy: -3679.790, kl: 187.781, loss: 3863.681\n",
      " 57%|█████████████████████████████████████████████                                  | 571/1000 [18:13<12:27,  1.74s/it]INFO:root:global_step: 571, logpy: -3679.676, kl: 187.699, loss: 3863.524\n",
      " 57%|█████████████████████████████████████████████▏                                 | 572/1000 [18:14<12:28,  1.75s/it]INFO:root:global_step: 572, logpy: -3679.524, kl: 187.511, loss: 3863.223\n",
      " 57%|█████████████████████████████████████████████▎                                 | 573/1000 [18:16<12:32,  1.76s/it]INFO:root:global_step: 573, logpy: -3681.795, kl: 187.601, loss: 3865.623\n",
      " 57%|█████████████████████████████████████████████▎                                 | 574/1000 [18:18<12:28,  1.76s/it]INFO:root:global_step: 574, logpy: -3680.437, kl: 187.238, loss: 3863.939\n",
      " 57%|█████████████████████████████████████████████▍                                 | 575/1000 [18:20<12:26,  1.76s/it]INFO:root:global_step: 575, logpy: -3680.414, kl: 187.256, loss: 3863.971\n",
      " 58%|█████████████████████████████████████████████▌                                 | 576/1000 [18:21<12:17,  1.74s/it]INFO:root:global_step: 576, logpy: -3681.007, kl: 187.155, loss: 3864.500\n",
      " 58%|█████████████████████████████████████████████▌                                 | 577/1000 [18:23<12:15,  1.74s/it]INFO:root:global_step: 577, logpy: -3681.941, kl: 187.232, loss: 3865.547\n",
      " 58%|█████████████████████████████████████████████▋                                 | 578/1000 [18:25<12:14,  1.74s/it]INFO:root:global_step: 578, logpy: -3680.291, kl: 187.143, loss: 3863.845\n",
      " 58%|█████████████████████████████████████████████▋                                 | 579/1000 [18:27<12:33,  1.79s/it]INFO:root:global_step: 579, logpy: -3677.913, kl: 187.068, loss: 3861.428\n",
      " 58%|█████████████████████████████████████████████▊                                 | 580/1000 [18:28<12:30,  1.79s/it]INFO:root:global_step: 580, logpy: -3676.514, kl: 187.122, loss: 3860.118\n",
      " 58%|█████████████████████████████████████████████▉                                 | 581/1000 [18:30<12:22,  1.77s/it]INFO:root:global_step: 581, logpy: -3675.998, kl: 187.176, loss: 3859.691\n",
      " 58%|█████████████████████████████████████████████▉                                 | 582/1000 [18:32<12:27,  1.79s/it]INFO:root:global_step: 582, logpy: -3676.847, kl: 187.411, loss: 3860.811\n",
      " 58%|██████████████████████████████████████████████                                 | 583/1000 [18:34<12:28,  1.79s/it]INFO:root:global_step: 583, logpy: -3678.036, kl: 187.491, loss: 3862.114\n",
      " 58%|██████████████████████████████████████████████▏                                | 584/1000 [18:36<12:24,  1.79s/it]INFO:root:global_step: 584, logpy: -3676.525, kl: 187.236, loss: 3860.382\n",
      " 58%|██████████████████████████████████████████████▏                                | 585/1000 [18:37<12:27,  1.80s/it]INFO:root:global_step: 585, logpy: -3675.507, kl: 187.151, loss: 3859.312\n",
      " 59%|██████████████████████████████████████████████▎                                | 586/1000 [18:39<12:28,  1.81s/it]INFO:root:global_step: 586, logpy: -3674.300, kl: 186.892, loss: 3857.880\n",
      " 59%|██████████████████████████████████████████████▎                                | 587/1000 [18:41<12:34,  1.83s/it]INFO:root:global_step: 587, logpy: -3672.275, kl: 186.669, loss: 3855.666\n",
      " 59%|██████████████████████████████████████████████▍                                | 588/1000 [18:43<12:27,  1.81s/it]INFO:root:global_step: 588, logpy: -3670.388, kl: 186.523, loss: 3853.665\n",
      " 59%|██████████████████████████████████████████████▌                                | 589/1000 [18:45<12:23,  1.81s/it]INFO:root:global_step: 589, logpy: -3669.242, kl: 186.549, loss: 3852.578\n",
      " 59%|██████████████████████████████████████████████▌                                | 590/1000 [18:46<12:18,  1.80s/it]INFO:root:global_step: 590, logpy: -3669.191, kl: 186.453, loss: 3852.462\n",
      " 59%|██████████████████████████████████████████████▋                                | 591/1000 [18:48<12:23,  1.82s/it]INFO:root:global_step: 591, logpy: -3669.594, kl: 186.356, loss: 3852.801\n",
      " 59%|██████████████████████████████████████████████▊                                | 592/1000 [18:50<12:13,  1.80s/it]INFO:root:global_step: 592, logpy: -3669.190, kl: 186.251, loss: 3852.323\n",
      " 59%|██████████████████████████████████████████████▊                                | 593/1000 [18:52<12:05,  1.78s/it]INFO:root:global_step: 593, logpy: -3666.971, kl: 186.111, loss: 3849.995\n",
      " 59%|██████████████████████████████████████████████▉                                | 594/1000 [18:54<12:02,  1.78s/it]INFO:root:global_step: 594, logpy: -3667.430, kl: 186.098, loss: 3850.473\n",
      " 60%|███████████████████████████████████████████████                                | 595/1000 [18:55<11:55,  1.77s/it]INFO:root:global_step: 595, logpy: -3666.272, kl: 185.970, loss: 3849.218\n",
      " 60%|███████████████████████████████████████████████                                | 596/1000 [18:57<11:56,  1.77s/it]INFO:root:global_step: 596, logpy: -3665.050, kl: 185.756, loss: 3847.811\n",
      " 60%|███████████████████████████████████████████████▏                               | 597/1000 [18:59<11:49,  1.76s/it]INFO:root:global_step: 597, logpy: -3665.071, kl: 185.832, loss: 3847.938\n",
      " 60%|███████████████████████████████████████████████▏                               | 598/1000 [19:01<11:55,  1.78s/it]INFO:root:global_step: 598, logpy: -3666.082, kl: 185.844, loss: 3848.990\n",
      " 60%|███████████████████████████████████████████████▎                               | 599/1000 [19:03<12:00,  1.80s/it]INFO:root:global_step: 599, logpy: -3666.758, kl: 185.838, loss: 3849.689\n",
      " 60%|███████████████████████████████████████████████▍                               | 600/1000 [19:04<12:03,  1.81s/it]INFO:root:Saved figure at: ./sim/global_step_600.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 600, logpy: -3665.811, kl: 185.934, loss: 3848.868\n",
      " 60%|███████████████████████████████████████████████▍                               | 601/1000 [19:13<25:02,  3.77s/it]INFO:root:global_step: 601, logpy: -3666.763, kl: 185.928, loss: 3849.843\n",
      " 60%|███████████████████████████████████████████████▌                               | 602/1000 [19:15<21:06,  3.18s/it]INFO:root:global_step: 602, logpy: -3667.470, kl: 185.910, loss: 3850.560\n",
      " 60%|███████████████████████████████████████████████▋                               | 603/1000 [19:16<18:16,  2.76s/it]INFO:root:global_step: 603, logpy: -3668.896, kl: 185.994, loss: 3852.099\n",
      " 60%|███████████████████████████████████████████████▋                               | 604/1000 [19:18<16:20,  2.48s/it]INFO:root:global_step: 604, logpy: -3668.585, kl: 185.928, loss: 3851.749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████████████████████████▊                               | 605/1000 [19:20<15:04,  2.29s/it]INFO:root:global_step: 605, logpy: -3669.141, kl: 185.784, loss: 3852.189\n",
      " 61%|███████████████████████████████████████████████▊                               | 606/1000 [19:22<14:14,  2.17s/it]INFO:root:global_step: 606, logpy: -3668.896, kl: 185.702, loss: 3851.889\n",
      " 61%|███████████████████████████████████████████████▉                               | 607/1000 [19:24<13:25,  2.05s/it]INFO:root:global_step: 607, logpy: -3667.778, kl: 185.503, loss: 3850.599\n",
      " 61%|████████████████████████████████████████████████                               | 608/1000 [19:25<12:57,  1.98s/it]INFO:root:global_step: 608, logpy: -3668.175, kl: 185.707, loss: 3851.227\n",
      " 61%|████████████████████████████████████████████████                               | 609/1000 [19:27<12:31,  1.92s/it]INFO:root:global_step: 609, logpy: -3668.965, kl: 185.806, loss: 3852.143\n",
      " 61%|████████████████████████████████████████████████▏                              | 610/1000 [19:29<12:30,  1.92s/it]INFO:root:global_step: 610, logpy: -3670.008, kl: 185.870, loss: 3853.276\n",
      " 61%|████████████████████████████████████████████████▎                              | 611/1000 [19:31<12:15,  1.89s/it]INFO:root:global_step: 611, logpy: -3671.352, kl: 185.855, loss: 3854.631\n",
      " 61%|████████████████████████████████████████████████▎                              | 612/1000 [19:33<12:01,  1.86s/it]INFO:root:global_step: 612, logpy: -3672.290, kl: 185.951, loss: 3855.690\n",
      " 61%|████████████████████████████████████████████████▍                              | 613/1000 [19:35<11:53,  1.84s/it]INFO:root:global_step: 613, logpy: -3674.027, kl: 185.976, loss: 3857.478\n",
      " 61%|████████████████████████████████████████████████▌                              | 614/1000 [19:36<11:41,  1.82s/it]INFO:root:global_step: 614, logpy: -3675.012, kl: 185.975, loss: 3858.488\n",
      " 62%|████████████████████████████████████████████████▌                              | 615/1000 [19:38<11:39,  1.82s/it]INFO:root:global_step: 615, logpy: -3673.682, kl: 185.953, loss: 3857.161\n",
      " 62%|████████████████████████████████████████████████▋                              | 616/1000 [19:40<11:34,  1.81s/it]INFO:root:global_step: 616, logpy: -3670.257, kl: 185.688, loss: 3853.495\n",
      " 62%|████████████████████████████████████████████████▋                              | 617/1000 [19:42<11:34,  1.81s/it]INFO:root:global_step: 617, logpy: -3669.205, kl: 185.571, loss: 3852.351\n",
      " 62%|████████████████████████████████████████████████▊                              | 618/1000 [19:44<11:37,  1.83s/it]INFO:root:global_step: 618, logpy: -3669.127, kl: 185.416, loss: 3852.142\n",
      " 62%|████████████████████████████████████████████████▉                              | 619/1000 [19:45<11:28,  1.81s/it]INFO:root:global_step: 619, logpy: -3670.792, kl: 185.451, loss: 3853.866\n",
      " 62%|████████████████████████████████████████████████▉                              | 620/1000 [19:47<11:30,  1.82s/it]INFO:root:global_step: 620, logpy: -3671.336, kl: 185.641, loss: 3854.624\n",
      " 62%|█████████████████████████████████████████████████                              | 621/1000 [19:49<11:29,  1.82s/it]INFO:root:global_step: 621, logpy: -3672.561, kl: 185.632, loss: 3855.864\n",
      " 62%|█████████████████████████████████████████████████▏                             | 622/1000 [19:51<11:26,  1.81s/it]INFO:root:global_step: 622, logpy: -3671.644, kl: 185.563, loss: 3854.901\n",
      " 62%|█████████████████████████████████████████████████▏                             | 623/1000 [19:53<11:20,  1.80s/it]INFO:root:global_step: 623, logpy: -3672.759, kl: 185.684, loss: 3856.161\n",
      " 62%|█████████████████████████████████████████████████▎                             | 624/1000 [19:54<11:16,  1.80s/it]INFO:root:global_step: 624, logpy: -3673.506, kl: 185.781, loss: 3857.027\n",
      " 62%|█████████████████████████████████████████████████▍                             | 625/1000 [19:56<11:08,  1.78s/it]INFO:root:global_step: 625, logpy: -3673.810, kl: 185.812, loss: 3857.385\n",
      " 63%|█████████████████████████████████████████████████▍                             | 626/1000 [19:58<11:04,  1.78s/it]INFO:root:global_step: 626, logpy: -3674.663, kl: 185.884, loss: 3858.332\n",
      " 63%|█████████████████████████████████████████████████▌                             | 627/1000 [20:00<11:18,  1.82s/it]INFO:root:global_step: 627, logpy: -3673.661, kl: 185.699, loss: 3857.167\n",
      " 63%|█████████████████████████████████████████████████▌                             | 628/1000 [20:02<11:16,  1.82s/it]INFO:root:global_step: 628, logpy: -3674.375, kl: 185.743, loss: 3857.947\n",
      " 63%|█████████████████████████████████████████████████▋                             | 629/1000 [20:03<11:15,  1.82s/it]INFO:root:global_step: 629, logpy: -3672.892, kl: 185.650, loss: 3856.392\n",
      " 63%|█████████████████████████████████████████████████▊                             | 630/1000 [20:05<11:11,  1.81s/it]INFO:root:global_step: 630, logpy: -3673.568, kl: 185.727, loss: 3857.167\n",
      " 63%|█████████████████████████████████████████████████▊                             | 631/1000 [20:07<11:02,  1.80s/it]INFO:root:global_step: 631, logpy: -3673.808, kl: 185.749, loss: 3857.450\n",
      " 63%|█████████████████████████████████████████████████▉                             | 632/1000 [20:09<11:09,  1.82s/it]INFO:root:global_step: 632, logpy: -3674.578, kl: 185.729, loss: 3858.220\n",
      " 63%|██████████████████████████████████████████████████                             | 633/1000 [20:11<11:02,  1.81s/it]INFO:root:global_step: 633, logpy: -3673.312, kl: 185.600, loss: 3856.847\n",
      " 63%|██████████████████████████████████████████████████                             | 634/1000 [20:13<11:02,  1.81s/it]INFO:root:global_step: 634, logpy: -3674.614, kl: 185.707, loss: 3858.277\n",
      " 64%|██████████████████████████████████████████████████▏                            | 635/1000 [20:14<11:01,  1.81s/it]INFO:root:global_step: 635, logpy: -3675.159, kl: 185.611, loss: 3858.746\n",
      " 64%|██████████████████████████████████████████████████▏                            | 636/1000 [20:16<11:05,  1.83s/it]INFO:root:global_step: 636, logpy: -3675.632, kl: 185.581, loss: 3859.209\n",
      " 64%|██████████████████████████████████████████████████▎                            | 637/1000 [20:18<10:57,  1.81s/it]INFO:root:global_step: 637, logpy: -3676.266, kl: 185.761, loss: 3860.043\n",
      " 64%|██████████████████████████████████████████████████▍                            | 638/1000 [20:20<10:53,  1.80s/it]INFO:root:global_step: 638, logpy: -3677.292, kl: 185.791, loss: 3861.120\n",
      " 64%|██████████████████████████████████████████████████▍                            | 639/1000 [20:22<10:44,  1.79s/it]INFO:root:global_step: 639, logpy: -3677.913, kl: 185.793, loss: 3861.762\n",
      " 64%|██████████████████████████████████████████████████▌                            | 640/1000 [20:23<10:38,  1.77s/it]INFO:root:global_step: 640, logpy: -3677.687, kl: 185.789, loss: 3861.552\n",
      " 64%|██████████████████████████████████████████████████▋                            | 641/1000 [20:25<10:39,  1.78s/it]INFO:root:global_step: 641, logpy: -3679.301, kl: 185.977, loss: 3863.373\n",
      " 64%|██████████████████████████████████████████████████▋                            | 642/1000 [20:27<10:42,  1.79s/it]INFO:root:global_step: 642, logpy: -3679.591, kl: 186.031, loss: 3863.735\n",
      " 64%|██████████████████████████████████████████████████▊                            | 643/1000 [20:29<10:42,  1.80s/it]INFO:root:global_step: 643, logpy: -3679.734, kl: 185.862, loss: 3863.729\n",
      " 64%|██████████████████████████████████████████████████▉                            | 644/1000 [20:31<10:48,  1.82s/it]INFO:root:global_step: 644, logpy: -3678.538, kl: 185.728, loss: 3862.417\n",
      " 64%|██████████████████████████████████████████████████▉                            | 645/1000 [20:32<10:46,  1.82s/it]INFO:root:global_step: 645, logpy: -3677.542, kl: 185.721, loss: 3861.433\n",
      " 65%|███████████████████████████████████████████████████                            | 646/1000 [20:34<10:33,  1.79s/it]INFO:root:global_step: 646, logpy: -3678.879, kl: 185.841, loss: 3862.908\n",
      " 65%|███████████████████████████████████████████████████                            | 647/1000 [20:36<10:30,  1.79s/it]INFO:root:global_step: 647, logpy: -3678.685, kl: 185.733, loss: 3862.624\n",
      " 65%|███████████████████████████████████████████████████▏                           | 648/1000 [20:38<10:25,  1.78s/it]INFO:root:global_step: 648, logpy: -3677.127, kl: 185.626, loss: 3860.977\n",
      " 65%|███████████████████████████████████████████████████▎                           | 649/1000 [20:39<10:27,  1.79s/it]INFO:root:global_step: 649, logpy: -3677.119, kl: 185.607, loss: 3860.968\n",
      " 65%|███████████████████████████████████████████████████▎                           | 650/1000 [20:41<10:37,  1.82s/it]INFO:root:Saved figure at: ./sim/global_step_650.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 650, logpy: -3678.694, kl: 185.618, loss: 3862.572\n",
      " 65%|███████████████████████████████████████████████████▍                           | 651/1000 [20:50<21:52,  3.76s/it]INFO:root:global_step: 651, logpy: -3678.641, kl: 185.563, loss: 3862.481\n",
      " 65%|███████████████████████████████████████████████████▌                           | 652/1000 [20:52<18:33,  3.20s/it]INFO:root:global_step: 652, logpy: -3680.031, kl: 185.662, loss: 3863.988\n",
      " 65%|███████████████████████████████████████████████████▌                           | 653/1000 [20:53<16:01,  2.77s/it]INFO:root:global_step: 653, logpy: -3679.194, kl: 185.655, loss: 3863.161\n",
      " 65%|███████████████████████████████████████████████████▋                           | 654/1000 [20:55<14:15,  2.47s/it]INFO:root:global_step: 654, logpy: -3679.481, kl: 185.590, loss: 3863.400\n",
      " 66%|███████████████████████████████████████████████████▋                           | 655/1000 [20:57<13:05,  2.28s/it]INFO:root:global_step: 655, logpy: -3680.155, kl: 185.598, loss: 3864.097\n",
      " 66%|███████████████████████████████████████████████████▊                           | 656/1000 [20:59<12:07,  2.11s/it]INFO:root:global_step: 656, logpy: -3679.932, kl: 185.500, loss: 3863.794\n",
      " 66%|███████████████████████████████████████████████████▉                           | 657/1000 [21:01<11:43,  2.05s/it]INFO:root:global_step: 657, logpy: -3679.227, kl: 185.445, loss: 3863.050\n",
      " 66%|███████████████████████████████████████████████████▉                           | 658/1000 [21:02<11:20,  1.99s/it]INFO:root:global_step: 658, logpy: -3677.126, kl: 185.482, loss: 3861.001\n",
      " 66%|████████████████████████████████████████████████████                           | 659/1000 [21:04<10:53,  1.92s/it]INFO:root:global_step: 659, logpy: -3676.919, kl: 185.513, loss: 3860.842\n",
      " 66%|████████████████████████████████████████████████████▏                          | 660/1000 [21:06<10:39,  1.88s/it]INFO:root:global_step: 660, logpy: -3677.059, kl: 185.504, loss: 3860.989\n",
      " 66%|████████████████████████████████████████████████████▏                          | 661/1000 [21:08<10:28,  1.85s/it]INFO:root:global_step: 661, logpy: -3677.479, kl: 185.413, loss: 3861.334\n",
      " 66%|████████████████████████████████████████████████████▎                          | 662/1000 [21:09<10:19,  1.83s/it]INFO:root:global_step: 662, logpy: -3677.432, kl: 185.428, loss: 3861.317\n",
      " 66%|████████████████████████████████████████████████████▍                          | 663/1000 [21:11<10:17,  1.83s/it]INFO:root:global_step: 663, logpy: -3680.734, kl: 185.627, loss: 3864.833\n",
      " 66%|████████████████████████████████████████████████████▍                          | 664/1000 [21:13<10:07,  1.81s/it]INFO:root:global_step: 664, logpy: -3681.449, kl: 185.668, loss: 3865.605\n",
      " 66%|████████████████████████████████████████████████████▌                          | 665/1000 [21:15<10:09,  1.82s/it]INFO:root:global_step: 665, logpy: -3682.579, kl: 185.692, loss: 3866.773\n",
      " 67%|████████████████████████████████████████████████████▌                          | 666/1000 [21:17<10:05,  1.81s/it]INFO:root:global_step: 666, logpy: -3682.905, kl: 185.526, loss: 3866.949\n",
      " 67%|████████████████████████████████████████████████████▋                          | 667/1000 [21:18<09:54,  1.79s/it]INFO:root:global_step: 667, logpy: -3683.156, kl: 185.663, loss: 3867.352\n",
      " 67%|████████████████████████████████████████████████████▊                          | 668/1000 [21:20<09:53,  1.79s/it]INFO:root:global_step: 668, logpy: -3684.983, kl: 185.794, loss: 3869.324\n",
      " 67%|████████████████████████████████████████████████████▊                          | 669/1000 [21:22<10:01,  1.82s/it]INFO:root:global_step: 669, logpy: -3686.815, kl: 185.802, loss: 3871.179\n",
      " 67%|████████████████████████████████████████████████████▉                          | 670/1000 [21:24<09:56,  1.81s/it]INFO:root:global_step: 670, logpy: -3687.538, kl: 185.821, loss: 3871.935\n",
      " 67%|█████████████████████████████████████████████████████                          | 671/1000 [21:26<09:57,  1.82s/it]INFO:root:global_step: 671, logpy: -3688.863, kl: 185.878, loss: 3873.331\n",
      " 67%|█████████████████████████████████████████████████████                          | 672/1000 [21:27<09:50,  1.80s/it]INFO:root:global_step: 672, logpy: -3690.556, kl: 186.122, loss: 3875.283\n",
      " 67%|█████████████████████████████████████████████████████▏                         | 673/1000 [21:29<09:46,  1.79s/it]INFO:root:global_step: 673, logpy: -3690.642, kl: 186.074, loss: 3875.334\n",
      " 67%|█████████████████████████████████████████████████████▏                         | 674/1000 [21:31<09:55,  1.83s/it]INFO:root:global_step: 674, logpy: -3689.147, kl: 185.929, loss: 3873.709\n",
      " 68%|█████████████████████████████████████████████████████▎                         | 675/1000 [21:33<09:51,  1.82s/it]INFO:root:global_step: 675, logpy: -3687.297, kl: 185.931, loss: 3871.874\n",
      " 68%|█████████████████████████████████████████████████████▍                         | 676/1000 [21:35<09:46,  1.81s/it]INFO:root:global_step: 676, logpy: -3688.099, kl: 186.016, loss: 3872.775\n",
      " 68%|█████████████████████████████████████████████████████▍                         | 677/1000 [21:37<09:44,  1.81s/it]INFO:root:global_step: 677, logpy: -3688.142, kl: 186.140, loss: 3872.955\n",
      " 68%|█████████████████████████████████████████████████████▌                         | 678/1000 [21:38<09:40,  1.80s/it]INFO:root:global_step: 678, logpy: -3687.023, kl: 186.149, loss: 3871.858\n",
      " 68%|█████████████████████████████████████████████████████▋                         | 679/1000 [21:40<09:31,  1.78s/it]INFO:root:global_step: 679, logpy: -3688.736, kl: 186.142, loss: 3873.578\n",
      " 68%|█████████████████████████████████████████████████████▋                         | 680/1000 [21:42<09:24,  1.76s/it]INFO:root:global_step: 680, logpy: -3690.758, kl: 186.244, loss: 3875.715\n",
      " 68%|█████████████████████████████████████████████████████▊                         | 681/1000 [21:44<09:24,  1.77s/it]INFO:root:global_step: 681, logpy: -3690.806, kl: 186.296, loss: 3875.827\n",
      " 68%|█████████████████████████████████████████████████████▉                         | 682/1000 [21:45<09:22,  1.77s/it]INFO:root:global_step: 682, logpy: -3690.672, kl: 186.161, loss: 3875.571\n",
      " 68%|█████████████████████████████████████████████████████▉                         | 683/1000 [21:47<09:27,  1.79s/it]INFO:root:global_step: 683, logpy: -3690.055, kl: 186.288, loss: 3875.093\n",
      " 68%|██████████████████████████████████████████████████████                         | 684/1000 [21:49<09:30,  1.80s/it]INFO:root:global_step: 684, logpy: -3689.871, kl: 186.091, loss: 3874.725\n",
      " 68%|██████████████████████████████████████████████████████                         | 685/1000 [21:51<09:34,  1.82s/it]INFO:root:global_step: 685, logpy: -3689.312, kl: 186.014, loss: 3874.102\n",
      " 69%|██████████████████████████████████████████████████████▏                        | 686/1000 [21:53<09:25,  1.80s/it]INFO:root:global_step: 686, logpy: -3690.504, kl: 186.239, loss: 3875.530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████████████████████████████████████████████████████▎                        | 687/1000 [21:54<09:22,  1.80s/it]INFO:root:global_step: 687, logpy: -3692.078, kl: 186.330, loss: 3877.207\n",
      " 69%|██████████████████████████████████████████████████████▎                        | 688/1000 [21:56<09:17,  1.79s/it]INFO:root:global_step: 688, logpy: -3691.353, kl: 186.245, loss: 3876.410\n",
      " 69%|██████████████████████████████████████████████████████▍                        | 689/1000 [21:58<09:14,  1.78s/it]INFO:root:global_step: 689, logpy: -3689.377, kl: 186.059, loss: 3874.259\n",
      " 69%|██████████████████████████████████████████████████████▌                        | 690/1000 [22:00<09:07,  1.76s/it]INFO:root:global_step: 690, logpy: -3689.237, kl: 186.021, loss: 3874.093\n",
      " 69%|██████████████████████████████████████████████████████▌                        | 691/1000 [22:02<09:10,  1.78s/it]INFO:root:global_step: 691, logpy: -3689.460, kl: 185.973, loss: 3874.280\n",
      " 69%|██████████████████████████████████████████████████████▋                        | 692/1000 [22:03<09:12,  1.79s/it]INFO:root:global_step: 692, logpy: -3689.878, kl: 186.144, loss: 3874.881\n",
      " 69%|██████████████████████████████████████████████████████▋                        | 693/1000 [22:05<09:05,  1.78s/it]INFO:root:global_step: 693, logpy: -3688.987, kl: 186.244, loss: 3874.102\n",
      " 69%|██████████████████████████████████████████████████████▊                        | 694/1000 [22:07<09:06,  1.78s/it]INFO:root:global_step: 694, logpy: -3691.264, kl: 186.268, loss: 3876.414\n",
      " 70%|██████████████████████████████████████████████████████▉                        | 695/1000 [22:09<09:10,  1.80s/it]INFO:root:global_step: 695, logpy: -3692.067, kl: 186.243, loss: 3877.203\n",
      " 70%|██████████████████████████████████████████████████████▉                        | 696/1000 [22:11<09:06,  1.80s/it]INFO:root:global_step: 696, logpy: -3693.871, kl: 186.372, loss: 3879.147\n",
      " 70%|███████████████████████████████████████████████████████                        | 697/1000 [22:12<09:05,  1.80s/it]INFO:root:global_step: 697, logpy: -3690.736, kl: 186.382, loss: 3876.033\n",
      " 70%|███████████████████████████████████████████████████████▏                       | 698/1000 [22:14<09:07,  1.81s/it]INFO:root:global_step: 698, logpy: -3691.653, kl: 186.492, loss: 3877.071\n",
      " 70%|███████████████████████████████████████████████████████▏                       | 699/1000 [22:16<08:59,  1.79s/it]INFO:root:global_step: 699, logpy: -3690.102, kl: 186.516, loss: 3875.554\n",
      " 70%|███████████████████████████████████████████████████████▎                       | 700/1000 [22:18<08:55,  1.79s/it]INFO:root:Saved figure at: ./sim/global_step_700.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 700, logpy: -3691.446, kl: 186.602, loss: 3876.995\n",
      " 70%|███████████████████████████████████████████████████████▍                       | 701/1000 [22:26<18:40,  3.75s/it]INFO:root:global_step: 701, logpy: -3691.786, kl: 186.524, loss: 3877.267\n",
      " 70%|███████████████████████████████████████████████████████▍                       | 702/1000 [22:28<15:39,  3.15s/it]INFO:root:global_step: 702, logpy: -3692.402, kl: 186.477, loss: 3877.846\n",
      " 70%|███████████████████████████████████████████████████████▌                       | 703/1000 [22:30<13:35,  2.74s/it]INFO:root:global_step: 703, logpy: -3691.500, kl: 186.404, loss: 3876.882\n",
      " 70%|███████████████████████████████████████████████████████▌                       | 704/1000 [22:31<12:13,  2.48s/it]INFO:root:global_step: 704, logpy: -3692.148, kl: 186.567, loss: 3877.704\n",
      " 70%|███████████████████████████████████████████████████████▋                       | 705/1000 [22:33<11:16,  2.29s/it]INFO:root:global_step: 705, logpy: -3693.718, kl: 186.751, loss: 3879.467\n",
      " 71%|███████████████████████████████████████████████████████▊                       | 706/1000 [22:35<10:27,  2.13s/it]INFO:root:global_step: 706, logpy: -3692.107, kl: 186.596, loss: 3877.712\n",
      " 71%|███████████████████████████████████████████████████████▊                       | 707/1000 [22:37<09:53,  2.03s/it]INFO:root:global_step: 707, logpy: -3693.281, kl: 186.749, loss: 3879.048\n",
      " 71%|███████████████████████████████████████████████████████▉                       | 708/1000 [22:39<09:34,  1.97s/it]INFO:root:global_step: 708, logpy: -3693.647, kl: 186.743, loss: 3879.417\n",
      " 71%|████████████████████████████████████████████████████████                       | 709/1000 [22:40<09:14,  1.90s/it]INFO:root:global_step: 709, logpy: -3692.337, kl: 186.767, loss: 3878.142\n",
      " 71%|████████████████████████████████████████████████████████                       | 710/1000 [22:42<09:03,  1.87s/it]INFO:root:global_step: 710, logpy: -3691.090, kl: 186.642, loss: 3876.780\n",
      " 71%|████████████████████████████████████████████████████████▏                      | 711/1000 [22:44<08:59,  1.87s/it]INFO:root:global_step: 711, logpy: -3691.548, kl: 186.664, loss: 3877.270\n",
      " 71%|████████████████████████████████████████████████████████▏                      | 712/1000 [22:46<08:53,  1.85s/it]INFO:root:global_step: 712, logpy: -3690.865, kl: 186.669, loss: 3876.600\n",
      " 71%|████████████████████████████████████████████████████████▎                      | 713/1000 [22:48<08:53,  1.86s/it]INFO:root:global_step: 713, logpy: -3691.053, kl: 186.595, loss: 3876.724\n",
      " 71%|████████████████████████████████████████████████████████▍                      | 714/1000 [22:50<08:47,  1.84s/it]INFO:root:global_step: 714, logpy: -3687.970, kl: 186.480, loss: 3873.535\n",
      " 72%|████████████████████████████████████████████████████████▍                      | 715/1000 [22:51<08:47,  1.85s/it]INFO:root:global_step: 715, logpy: -3687.660, kl: 186.360, loss: 3873.114\n",
      " 72%|████████████████████████████████████████████████████████▌                      | 716/1000 [22:53<08:39,  1.83s/it]INFO:root:global_step: 716, logpy: -3688.544, kl: 186.490, loss: 3874.137\n",
      " 72%|████████████████████████████████████████████████████████▋                      | 717/1000 [22:55<08:29,  1.80s/it]INFO:root:global_step: 717, logpy: -3689.417, kl: 186.416, loss: 3874.945\n",
      " 72%|████████████████████████████████████████████████████████▋                      | 718/1000 [22:57<08:32,  1.82s/it]INFO:root:global_step: 718, logpy: -3690.598, kl: 186.459, loss: 3876.178\n",
      " 72%|████████████████████████████████████████████████████████▊                      | 719/1000 [22:59<08:33,  1.83s/it]INFO:root:global_step: 719, logpy: -3690.723, kl: 186.420, loss: 3876.273\n",
      " 72%|████████████████████████████████████████████████████████▉                      | 720/1000 [23:00<08:28,  1.82s/it]INFO:root:global_step: 720, logpy: -3690.726, kl: 186.478, loss: 3876.343\n",
      " 72%|████████████████████████████████████████████████████████▉                      | 721/1000 [23:02<08:27,  1.82s/it]INFO:root:global_step: 721, logpy: -3690.494, kl: 186.583, loss: 3876.224\n",
      " 72%|█████████████████████████████████████████████████████████                      | 722/1000 [23:04<08:24,  1.81s/it]INFO:root:global_step: 722, logpy: -3690.740, kl: 186.571, loss: 3876.467\n",
      " 72%|█████████████████████████████████████████████████████████                      | 723/1000 [23:06<08:18,  1.80s/it]INFO:root:global_step: 723, logpy: -3691.236, kl: 186.557, loss: 3876.957\n",
      " 72%|█████████████████████████████████████████████████████████▏                     | 724/1000 [23:08<08:22,  1.82s/it]INFO:root:global_step: 724, logpy: -3691.724, kl: 186.648, loss: 3877.545\n",
      " 72%|█████████████████████████████████████████████████████████▎                     | 725/1000 [23:10<08:20,  1.82s/it]INFO:root:global_step: 725, logpy: -3690.275, kl: 186.470, loss: 3875.926\n",
      " 73%|█████████████████████████████████████████████████████████▎                     | 726/1000 [23:11<08:14,  1.81s/it]INFO:root:global_step: 726, logpy: -3690.193, kl: 186.516, loss: 3875.898\n",
      " 73%|█████████████████████████████████████████████████████████▍                     | 727/1000 [23:13<08:11,  1.80s/it]INFO:root:global_step: 727, logpy: -3690.408, kl: 186.472, loss: 3876.077\n",
      " 73%|█████████████████████████████████████████████████████████▌                     | 728/1000 [23:15<08:09,  1.80s/it]INFO:root:global_step: 728, logpy: -3689.685, kl: 186.300, loss: 3875.191\n",
      " 73%|█████████████████████████████████████████████████████████▌                     | 729/1000 [23:17<08:07,  1.80s/it]INFO:root:global_step: 729, logpy: -3688.873, kl: 186.071, loss: 3874.157\n",
      " 73%|█████████████████████████████████████████████████████████▋                     | 730/1000 [23:18<08:06,  1.80s/it]INFO:root:global_step: 730, logpy: -3688.381, kl: 186.020, loss: 3873.622\n",
      " 73%|█████████████████████████████████████████████████████████▋                     | 731/1000 [23:20<08:01,  1.79s/it]INFO:root:global_step: 731, logpy: -3687.636, kl: 185.874, loss: 3872.739\n",
      " 73%|█████████████████████████████████████████████████████████▊                     | 732/1000 [23:22<07:56,  1.78s/it]INFO:root:global_step: 732, logpy: -3687.294, kl: 185.715, loss: 3872.245\n",
      " 73%|█████████████████████████████████████████████████████████▉                     | 733/1000 [23:24<07:52,  1.77s/it]INFO:root:global_step: 733, logpy: -3690.084, kl: 185.833, loss: 3875.161\n",
      " 73%|█████████████████████████████████████████████████████████▉                     | 734/1000 [23:26<07:54,  1.79s/it]INFO:root:global_step: 734, logpy: -3691.247, kl: 185.904, loss: 3876.403\n",
      " 74%|██████████████████████████████████████████████████████████                     | 735/1000 [23:27<07:55,  1.80s/it]INFO:root:global_step: 735, logpy: -3690.991, kl: 185.733, loss: 3875.983\n",
      " 74%|██████████████████████████████████████████████████████████▏                    | 736/1000 [23:29<07:54,  1.80s/it]INFO:root:global_step: 736, logpy: -3691.342, kl: 185.733, loss: 3876.341\n",
      " 74%|██████████████████████████████████████████████████████████▏                    | 737/1000 [23:31<07:54,  1.80s/it]INFO:root:global_step: 737, logpy: -3690.770, kl: 185.890, loss: 3875.935\n",
      " 74%|██████████████████████████████████████████████████████████▎                    | 738/1000 [23:33<07:50,  1.80s/it]INFO:root:global_step: 738, logpy: -3688.977, kl: 185.931, loss: 3874.190\n",
      " 74%|██████████████████████████████████████████████████████████▍                    | 739/1000 [23:35<07:53,  1.81s/it]INFO:root:global_step: 739, logpy: -3690.485, kl: 185.981, loss: 3875.754\n",
      " 74%|██████████████████████████████████████████████████████████▍                    | 740/1000 [23:36<07:51,  1.81s/it]INFO:root:global_step: 740, logpy: -3690.618, kl: 186.110, loss: 3876.024\n",
      " 74%|██████████████████████████████████████████████████████████▌                    | 741/1000 [23:38<07:54,  1.83s/it]INFO:root:global_step: 741, logpy: -3693.047, kl: 186.189, loss: 3878.538\n",
      " 74%|██████████████████████████████████████████████████████████▌                    | 742/1000 [23:40<07:47,  1.81s/it]INFO:root:global_step: 742, logpy: -3694.130, kl: 186.144, loss: 3879.584\n",
      " 74%|██████████████████████████████████████████████████████████▋                    | 743/1000 [23:42<07:45,  1.81s/it]INFO:root:global_step: 743, logpy: -3693.573, kl: 186.118, loss: 3879.008\n",
      " 74%|██████████████████████████████████████████████████████████▊                    | 744/1000 [23:44<07:43,  1.81s/it]INFO:root:global_step: 744, logpy: -3693.886, kl: 186.026, loss: 3879.235\n",
      " 74%|██████████████████████████████████████████████████████████▊                    | 745/1000 [23:45<07:38,  1.80s/it]INFO:root:global_step: 745, logpy: -3692.216, kl: 186.072, loss: 3877.619\n",
      " 75%|██████████████████████████████████████████████████████████▉                    | 746/1000 [23:47<07:35,  1.79s/it]INFO:root:global_step: 746, logpy: -3691.970, kl: 186.040, loss: 3877.347\n",
      " 75%|███████████████████████████████████████████████████████████                    | 747/1000 [23:49<07:32,  1.79s/it]INFO:root:global_step: 747, logpy: -3692.381, kl: 186.136, loss: 3877.860\n",
      " 75%|███████████████████████████████████████████████████████████                    | 748/1000 [23:51<07:41,  1.83s/it]INFO:root:global_step: 748, logpy: -3692.805, kl: 186.201, loss: 3878.355\n",
      " 75%|███████████████████████████████████████████████████████████▏                   | 749/1000 [23:53<07:36,  1.82s/it]INFO:root:global_step: 749, logpy: -3691.410, kl: 186.165, loss: 3876.931\n",
      " 75%|███████████████████████████████████████████████████████████▎                   | 750/1000 [23:55<07:36,  1.83s/it]INFO:root:Saved figure at: ./sim/global_step_750.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 750, logpy: -3692.370, kl: 186.264, loss: 3877.998\n",
      " 75%|███████████████████████████████████████████████████████████▎                   | 751/1000 [24:03<15:27,  3.73s/it]INFO:root:global_step: 751, logpy: -3693.357, kl: 186.219, loss: 3878.946\n",
      " 75%|███████████████████████████████████████████████████████████▍                   | 752/1000 [24:05<13:05,  3.17s/it]INFO:root:global_step: 752, logpy: -3691.425, kl: 186.150, loss: 3876.950\n",
      " 75%|███████████████████████████████████████████████████████████▍                   | 753/1000 [24:06<11:20,  2.76s/it]INFO:root:global_step: 753, logpy: -3691.075, kl: 185.970, loss: 3876.427\n",
      " 75%|███████████████████████████████████████████████████████████▌                   | 754/1000 [24:08<10:08,  2.47s/it]INFO:root:global_step: 754, logpy: -3693.094, kl: 186.267, loss: 3878.749\n",
      " 76%|███████████████████████████████████████████████████████████▋                   | 755/1000 [24:10<09:16,  2.27s/it]INFO:root:global_step: 755, logpy: -3693.124, kl: 186.360, loss: 3878.878\n",
      " 76%|███████████████████████████████████████████████████████████▋                   | 756/1000 [24:12<08:42,  2.14s/it]INFO:root:global_step: 756, logpy: -3693.453, kl: 186.344, loss: 3879.197\n",
      " 76%|███████████████████████████████████████████████████████████▊                   | 757/1000 [24:14<08:11,  2.02s/it]INFO:root:global_step: 757, logpy: -3695.266, kl: 186.342, loss: 3881.015\n",
      " 76%|███████████████████████████████████████████████████████████▉                   | 758/1000 [24:15<07:49,  1.94s/it]INFO:root:global_step: 758, logpy: -3693.068, kl: 186.138, loss: 3878.617\n",
      " 76%|███████████████████████████████████████████████████████████▉                   | 759/1000 [24:17<07:35,  1.89s/it]INFO:root:global_step: 759, logpy: -3693.211, kl: 186.010, loss: 3878.639\n",
      " 76%|████████████████████████████████████████████████████████████                   | 760/1000 [24:19<07:26,  1.86s/it]INFO:root:global_step: 760, logpy: -3691.628, kl: 185.920, loss: 3876.971\n",
      " 76%|████████████████████████████████████████████████████████████                   | 761/1000 [24:21<07:13,  1.82s/it]INFO:root:global_step: 761, logpy: -3692.401, kl: 185.955, loss: 3877.785\n",
      " 76%|████████████████████████████████████████████████████████████▏                  | 762/1000 [24:22<07:08,  1.80s/it]INFO:root:global_step: 762, logpy: -3695.752, kl: 185.870, loss: 3881.057\n",
      " 76%|████████████████████████████████████████████████████████████▎                  | 763/1000 [24:24<06:59,  1.77s/it]INFO:root:global_step: 763, logpy: -3697.414, kl: 185.926, loss: 3882.781\n",
      " 76%|████████████████████████████████████████████████████████████▎                  | 764/1000 [24:26<06:59,  1.78s/it]INFO:root:global_step: 764, logpy: -3698.766, kl: 185.986, loss: 3884.198\n",
      " 76%|████████████████████████████████████████████████████████████▍                  | 765/1000 [24:28<07:00,  1.79s/it]INFO:root:global_step: 765, logpy: -3698.368, kl: 185.955, loss: 3883.775\n",
      " 77%|████████████████████████████████████████████████████████████▌                  | 766/1000 [24:29<06:54,  1.77s/it]INFO:root:global_step: 766, logpy: -3699.108, kl: 186.049, loss: 3884.615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|████████████████████████████████████████████████████████████▌                  | 767/1000 [24:31<06:48,  1.75s/it]INFO:root:global_step: 767, logpy: -3697.740, kl: 186.183, loss: 3883.386\n",
      " 77%|████████████████████████████████████████████████████████████▋                  | 768/1000 [24:33<06:46,  1.75s/it]INFO:root:global_step: 768, logpy: -3698.040, kl: 186.198, loss: 3883.707\n",
      " 77%|████████████████████████████████████████████████████████████▊                  | 769/1000 [24:35<06:50,  1.78s/it]INFO:root:global_step: 769, logpy: -3699.238, kl: 186.326, loss: 3885.038\n",
      " 77%|████████████████████████████████████████████████████████████▊                  | 770/1000 [24:36<06:45,  1.76s/it]INFO:root:global_step: 770, logpy: -3698.603, kl: 186.401, loss: 3884.482\n",
      " 77%|████████████████████████████████████████████████████████████▉                  | 771/1000 [24:38<06:40,  1.75s/it]INFO:root:global_step: 771, logpy: -3699.544, kl: 186.462, loss: 3885.490\n",
      " 77%|████████████████████████████████████████████████████████████▉                  | 772/1000 [24:40<06:41,  1.76s/it]INFO:root:global_step: 772, logpy: -3698.923, kl: 186.606, loss: 3885.018\n",
      " 77%|█████████████████████████████████████████████████████████████                  | 773/1000 [24:42<06:41,  1.77s/it]INFO:root:global_step: 773, logpy: -3699.643, kl: 186.592, loss: 3885.730\n",
      " 77%|█████████████████████████████████████████████████████████████▏                 | 774/1000 [24:44<06:38,  1.76s/it]INFO:root:global_step: 774, logpy: -3700.045, kl: 186.499, loss: 3886.044\n",
      " 78%|█████████████████████████████████████████████████████████████▏                 | 775/1000 [24:45<06:36,  1.76s/it]INFO:root:global_step: 775, logpy: -3700.296, kl: 186.439, loss: 3886.239\n",
      " 78%|█████████████████████████████████████████████████████████████▎                 | 776/1000 [24:47<06:32,  1.75s/it]INFO:root:global_step: 776, logpy: -3702.412, kl: 186.511, loss: 3888.432\n",
      " 78%|█████████████████████████████████████████████████████████████▍                 | 777/1000 [24:49<06:34,  1.77s/it]INFO:root:global_step: 777, logpy: -3701.676, kl: 186.542, loss: 3887.732\n",
      " 78%|█████████████████████████████████████████████████████████████▍                 | 778/1000 [24:51<06:40,  1.80s/it]INFO:root:global_step: 778, logpy: -3703.572, kl: 186.579, loss: 3889.670\n",
      " 78%|█████████████████████████████████████████████████████████████▌                 | 779/1000 [24:53<06:45,  1.84s/it]INFO:root:global_step: 779, logpy: -3707.186, kl: 186.701, loss: 3893.411\n",
      " 78%|█████████████████████████████████████████████████████████████▌                 | 780/1000 [24:54<06:43,  1.83s/it]INFO:root:global_step: 780, logpy: -3705.829, kl: 186.549, loss: 3891.907\n",
      " 78%|█████████████████████████████████████████████████████████████▋                 | 781/1000 [24:56<06:38,  1.82s/it]INFO:root:global_step: 781, logpy: -3704.968, kl: 186.422, loss: 3890.923\n",
      " 78%|█████████████████████████████████████████████████████████████▊                 | 782/1000 [24:58<06:33,  1.81s/it]INFO:root:global_step: 782, logpy: -3702.944, kl: 186.195, loss: 3888.677\n",
      " 78%|█████████████████████████████████████████████████████████████▊                 | 783/1000 [25:00<06:31,  1.80s/it]INFO:root:global_step: 783, logpy: -3703.355, kl: 186.205, loss: 3889.103\n",
      " 78%|█████████████████████████████████████████████████████████████▉                 | 784/1000 [25:02<06:31,  1.81s/it]INFO:root:global_step: 784, logpy: -3703.744, kl: 186.213, loss: 3889.505\n",
      " 78%|██████████████████████████████████████████████████████████████                 | 785/1000 [25:03<06:26,  1.80s/it]INFO:root:global_step: 785, logpy: -3702.731, kl: 186.196, loss: 3888.479\n",
      " 79%|██████████████████████████████████████████████████████████████                 | 786/1000 [25:05<06:24,  1.80s/it]INFO:root:global_step: 786, logpy: -3700.344, kl: 186.081, loss: 3885.981\n",
      " 79%|██████████████████████████████████████████████████████████████▏                | 787/1000 [25:07<06:32,  1.84s/it]INFO:root:global_step: 787, logpy: -3700.750, kl: 186.081, loss: 3886.392\n",
      " 79%|██████████████████████████████████████████████████████████████▎                | 788/1000 [25:09<06:27,  1.83s/it]INFO:root:global_step: 788, logpy: -3701.630, kl: 186.060, loss: 3887.254\n",
      " 79%|██████████████████████████████████████████████████████████████▎                | 789/1000 [25:11<06:22,  1.81s/it]INFO:root:global_step: 789, logpy: -3701.838, kl: 186.087, loss: 3887.494\n",
      " 79%|██████████████████████████████████████████████████████████████▍                | 790/1000 [25:12<06:18,  1.80s/it]INFO:root:global_step: 790, logpy: -3701.366, kl: 186.198, loss: 3887.137\n",
      " 79%|██████████████████████████████████████████████████████████████▍                | 791/1000 [25:14<06:12,  1.78s/it]INFO:root:global_step: 791, logpy: -3701.936, kl: 186.310, loss: 3887.825\n",
      " 79%|██████████████████████████████████████████████████████████████▌                | 792/1000 [25:16<06:13,  1.80s/it]INFO:root:global_step: 792, logpy: -3701.471, kl: 186.297, loss: 3887.350\n",
      " 79%|██████████████████████████████████████████████████████████████▋                | 793/1000 [25:18<06:07,  1.78s/it]INFO:root:global_step: 793, logpy: -3699.771, kl: 186.177, loss: 3885.534\n",
      " 79%|██████████████████████████████████████████████████████████████▋                | 794/1000 [25:20<06:09,  1.79s/it]INFO:root:global_step: 794, logpy: -3700.835, kl: 186.209, loss: 3886.635\n",
      " 80%|██████████████████████████████████████████████████████████████▊                | 795/1000 [25:21<06:06,  1.79s/it]INFO:root:global_step: 795, logpy: -3700.309, kl: 186.303, loss: 3886.206\n",
      " 80%|██████████████████████████████████████████████████████████████▉                | 796/1000 [25:23<06:01,  1.77s/it]INFO:root:global_step: 796, logpy: -3700.906, kl: 186.427, loss: 3886.932\n",
      " 80%|██████████████████████████████████████████████████████████████▉                | 797/1000 [25:25<06:06,  1.80s/it]INFO:root:global_step: 797, logpy: -3700.843, kl: 186.441, loss: 3886.887\n",
      " 80%|███████████████████████████████████████████████████████████████                | 798/1000 [25:27<06:01,  1.79s/it]INFO:root:global_step: 798, logpy: -3701.144, kl: 186.413, loss: 3887.164\n",
      " 80%|███████████████████████████████████████████████████████████████                | 799/1000 [25:29<06:00,  1.79s/it]INFO:root:global_step: 799, logpy: -3699.966, kl: 186.363, loss: 3885.940\n",
      " 80%|███████████████████████████████████████████████████████████████▏               | 800/1000 [25:30<06:00,  1.80s/it]INFO:root:Saved figure at: ./sim/global_step_800.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 800, logpy: -3700.057, kl: 186.512, loss: 3886.184\n",
      " 80%|███████████████████████████████████████████████████████████████▎               | 801/1000 [25:39<12:25,  3.74s/it]INFO:root:global_step: 801, logpy: -3698.924, kl: 186.377, loss: 3884.919\n",
      " 80%|███████████████████████████████████████████████████████████████▎               | 802/1000 [25:40<10:25,  3.16s/it]INFO:root:global_step: 802, logpy: -3700.898, kl: 186.467, loss: 3886.987\n",
      " 80%|███████████████████████████████████████████████████████████████▍               | 803/1000 [25:42<09:02,  2.75s/it]INFO:root:global_step: 803, logpy: -3699.460, kl: 186.513, loss: 3885.599\n",
      " 80%|███████████████████████████████████████████████████████████████▌               | 804/1000 [25:44<08:02,  2.46s/it]INFO:root:global_step: 804, logpy: -3701.027, kl: 186.710, loss: 3887.366\n",
      " 80%|███████████████████████████████████████████████████████████████▌               | 805/1000 [25:46<07:18,  2.25s/it]INFO:root:global_step: 805, logpy: -3700.105, kl: 186.598, loss: 3886.337\n",
      " 81%|███████████████████████████████████████████████████████████████▋               | 806/1000 [25:48<06:52,  2.12s/it]INFO:root:global_step: 806, logpy: -3700.284, kl: 186.634, loss: 3886.555\n",
      " 81%|███████████████████████████████████████████████████████████████▊               | 807/1000 [25:49<06:27,  2.01s/it]INFO:root:global_step: 807, logpy: -3701.996, kl: 186.727, loss: 3888.364\n",
      " 81%|███████████████████████████████████████████████████████████████▊               | 808/1000 [25:51<06:09,  1.92s/it]INFO:root:global_step: 808, logpy: -3701.600, kl: 186.665, loss: 3887.910\n",
      " 81%|███████████████████████████████████████████████████████████████▉               | 809/1000 [25:53<06:02,  1.90s/it]INFO:root:global_step: 809, logpy: -3701.064, kl: 186.553, loss: 3887.265\n",
      " 81%|███████████████████████████████████████████████████████████████▉               | 810/1000 [25:55<05:53,  1.86s/it]INFO:root:global_step: 810, logpy: -3701.452, kl: 186.441, loss: 3887.544\n",
      " 81%|████████████████████████████████████████████████████████████████               | 811/1000 [25:56<05:46,  1.84s/it]INFO:root:global_step: 811, logpy: -3703.476, kl: 186.382, loss: 3889.513\n",
      " 81%|████████████████████████████████████████████████████████████████▏              | 812/1000 [25:58<05:45,  1.84s/it]INFO:root:global_step: 812, logpy: -3703.956, kl: 186.590, loss: 3890.204\n",
      " 81%|████████████████████████████████████████████████████████████████▏              | 813/1000 [26:00<05:37,  1.81s/it]INFO:root:global_step: 813, logpy: -3703.954, kl: 186.668, loss: 3890.283\n",
      " 81%|████████████████████████████████████████████████████████████████▎              | 814/1000 [26:02<05:34,  1.80s/it]INFO:root:global_step: 814, logpy: -3702.748, kl: 186.662, loss: 3889.075\n",
      " 82%|████████████████████████████████████████████████████████████████▍              | 815/1000 [26:04<05:30,  1.79s/it]INFO:root:global_step: 815, logpy: -3702.803, kl: 186.643, loss: 3889.115\n",
      " 82%|████████████████████████████████████████████████████████████████▍              | 816/1000 [26:05<05:28,  1.79s/it]INFO:root:global_step: 816, logpy: -3703.304, kl: 186.708, loss: 3889.684\n",
      " 82%|████████████████████████████████████████████████████████████████▌              | 817/1000 [26:07<05:25,  1.78s/it]INFO:root:global_step: 817, logpy: -3703.772, kl: 186.656, loss: 3890.103\n",
      " 82%|████████████████████████████████████████████████████████████████▌              | 818/1000 [26:09<05:24,  1.78s/it]INFO:root:global_step: 818, logpy: -3701.985, kl: 186.549, loss: 3888.212\n",
      " 82%|████████████████████████████████████████████████████████████████▋              | 819/1000 [26:11<05:26,  1.80s/it]INFO:root:global_step: 819, logpy: -3700.701, kl: 186.469, loss: 3886.852\n",
      " 82%|████████████████████████████████████████████████████████████████▊              | 820/1000 [26:13<05:23,  1.80s/it]INFO:root:global_step: 820, logpy: -3699.763, kl: 186.362, loss: 3885.810\n",
      " 82%|████████████████████████████████████████████████████████████████▊              | 821/1000 [26:14<05:21,  1.80s/it]INFO:root:global_step: 821, logpy: -3699.024, kl: 186.426, loss: 3885.138\n",
      " 82%|████████████████████████████████████████████████████████████████▉              | 822/1000 [26:16<05:16,  1.78s/it]INFO:root:global_step: 822, logpy: -3697.895, kl: 186.448, loss: 3884.034\n",
      " 82%|█████████████████████████████████████████████████████████████████              | 823/1000 [26:18<05:13,  1.77s/it]INFO:root:global_step: 823, logpy: -3699.873, kl: 186.453, loss: 3886.020\n",
      " 82%|█████████████████████████████████████████████████████████████████              | 824/1000 [26:20<05:13,  1.78s/it]INFO:root:global_step: 824, logpy: -3700.384, kl: 186.532, loss: 3886.613\n",
      " 82%|█████████████████████████████████████████████████████████████████▏             | 825/1000 [26:21<05:14,  1.79s/it]INFO:root:global_step: 825, logpy: -3699.373, kl: 186.677, loss: 3885.750\n",
      " 83%|█████████████████████████████████████████████████████████████████▎             | 826/1000 [26:23<05:15,  1.81s/it]INFO:root:global_step: 826, logpy: -3698.104, kl: 186.362, loss: 3884.169\n",
      " 83%|█████████████████████████████████████████████████████████████████▎             | 827/1000 [26:25<05:18,  1.84s/it]INFO:root:global_step: 827, logpy: -3699.906, kl: 186.376, loss: 3885.988\n",
      " 83%|█████████████████████████████████████████████████████████████████▍             | 828/1000 [26:27<05:16,  1.84s/it]INFO:root:global_step: 828, logpy: -3699.606, kl: 186.376, loss: 3885.691\n",
      " 83%|█████████████████████████████████████████████████████████████████▍             | 829/1000 [26:29<05:14,  1.84s/it]INFO:root:global_step: 829, logpy: -3698.824, kl: 186.327, loss: 3884.863\n",
      " 83%|█████████████████████████████████████████████████████████████████▌             | 830/1000 [26:31<05:13,  1.84s/it]INFO:root:global_step: 830, logpy: -3699.385, kl: 186.422, loss: 3885.522\n",
      " 83%|█████████████████████████████████████████████████████████████████▋             | 831/1000 [26:33<05:06,  1.82s/it]INFO:root:global_step: 831, logpy: -3699.367, kl: 186.469, loss: 3885.554\n",
      " 83%|█████████████████████████████████████████████████████████████████▋             | 832/1000 [26:34<05:01,  1.80s/it]INFO:root:global_step: 832, logpy: -3697.603, kl: 186.230, loss: 3883.553\n",
      " 83%|█████████████████████████████████████████████████████████████████▊             | 833/1000 [26:36<05:00,  1.80s/it]INFO:root:global_step: 833, logpy: -3697.775, kl: 186.228, loss: 3883.727\n",
      " 83%|█████████████████████████████████████████████████████████████████▉             | 834/1000 [26:38<04:57,  1.79s/it]INFO:root:global_step: 834, logpy: -3700.098, kl: 186.333, loss: 3886.158\n",
      " 84%|█████████████████████████████████████████████████████████████████▉             | 835/1000 [26:40<04:54,  1.78s/it]INFO:root:global_step: 835, logpy: -3701.038, kl: 186.551, loss: 3887.318\n",
      " 84%|██████████████████████████████████████████████████████████████████             | 836/1000 [26:41<04:54,  1.79s/it]INFO:root:global_step: 836, logpy: -3701.881, kl: 186.504, loss: 3888.117\n",
      " 84%|██████████████████████████████████████████████████████████████████             | 837/1000 [26:43<04:52,  1.79s/it]INFO:root:global_step: 837, logpy: -3700.955, kl: 186.363, loss: 3887.052\n",
      " 84%|██████████████████████████████████████████████████████████████████▏            | 838/1000 [26:45<04:49,  1.79s/it]INFO:root:global_step: 838, logpy: -3703.616, kl: 186.562, loss: 3889.915\n",
      " 84%|██████████████████████████████████████████████████████████████████▎            | 839/1000 [26:47<04:51,  1.81s/it]INFO:root:global_step: 839, logpy: -3703.674, kl: 186.574, loss: 3889.988\n",
      " 84%|██████████████████████████████████████████████████████████████████▎            | 840/1000 [26:49<04:53,  1.84s/it]INFO:root:global_step: 840, logpy: -3703.274, kl: 186.536, loss: 3889.553\n",
      " 84%|██████████████████████████████████████████████████████████████████▍            | 841/1000 [26:51<04:50,  1.82s/it]INFO:root:global_step: 841, logpy: -3702.475, kl: 186.556, loss: 3888.776\n",
      " 84%|██████████████████████████████████████████████████████████████████▌            | 842/1000 [26:52<04:47,  1.82s/it]INFO:root:global_step: 842, logpy: -3702.977, kl: 186.493, loss: 3889.217\n",
      " 84%|██████████████████████████████████████████████████████████████████▌            | 843/1000 [26:54<04:44,  1.81s/it]INFO:root:global_step: 843, logpy: -3702.342, kl: 186.500, loss: 3888.591\n",
      " 84%|██████████████████████████████████████████████████████████████████▋            | 844/1000 [26:56<04:41,  1.80s/it]INFO:root:global_step: 844, logpy: -3704.216, kl: 186.666, loss: 3890.634\n",
      " 84%|██████████████████████████████████████████████████████████████████▊            | 845/1000 [26:58<04:44,  1.84s/it]INFO:root:global_step: 845, logpy: -3704.380, kl: 186.656, loss: 3890.791\n",
      " 85%|██████████████████████████████████████████████████████████████████▊            | 846/1000 [27:00<04:38,  1.81s/it]INFO:root:global_step: 846, logpy: -3705.284, kl: 186.520, loss: 3891.562\n",
      " 85%|██████████████████████████████████████████████████████████████████▉            | 847/1000 [27:01<04:34,  1.79s/it]INFO:root:global_step: 847, logpy: -3706.565, kl: 186.782, loss: 3893.106\n",
      " 85%|██████████████████████████████████████████████████████████████████▉            | 848/1000 [27:03<04:32,  1.79s/it]INFO:root:global_step: 848, logpy: -3706.222, kl: 186.683, loss: 3892.667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|███████████████████████████████████████████████████████████████████            | 849/1000 [27:05<04:30,  1.79s/it]INFO:root:global_step: 849, logpy: -3705.119, kl: 186.615, loss: 3891.499\n",
      " 85%|███████████████████████████████████████████████████████████████████▏           | 850/1000 [27:07<04:28,  1.79s/it]INFO:root:Saved figure at: ./sim/global_step_850.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 850, logpy: -3704.726, kl: 186.389, loss: 3890.883\n",
      " 85%|███████████████████████████████████████████████████████████████████▏           | 851/1000 [27:15<09:20,  3.76s/it]INFO:root:global_step: 851, logpy: -3705.600, kl: 186.440, loss: 3891.809\n",
      " 85%|███████████████████████████████████████████████████████████████████▎           | 852/1000 [27:17<07:51,  3.18s/it]INFO:root:global_step: 852, logpy: -3705.250, kl: 186.438, loss: 3891.459\n",
      " 85%|███████████████████████████████████████████████████████████████████▍           | 853/1000 [27:19<06:45,  2.76s/it]INFO:root:global_step: 853, logpy: -3706.103, kl: 186.639, loss: 3892.517\n",
      " 85%|███████████████████████████████████████████████████████████████████▍           | 854/1000 [27:21<06:02,  2.48s/it]INFO:root:global_step: 854, logpy: -3705.378, kl: 186.526, loss: 3891.680\n",
      " 86%|███████████████████████████████████████████████████████████████████▌           | 855/1000 [27:22<05:31,  2.28s/it]INFO:root:global_step: 855, logpy: -3705.215, kl: 186.431, loss: 3891.424\n",
      " 86%|███████████████████████████████████████████████████████████████████▌           | 856/1000 [27:24<05:07,  2.14s/it]INFO:root:global_step: 856, logpy: -3704.860, kl: 186.306, loss: 3890.947\n",
      " 86%|███████████████████████████████████████████████████████████████████▋           | 857/1000 [27:26<04:54,  2.06s/it]INFO:root:global_step: 857, logpy: -3704.323, kl: 186.206, loss: 3890.311\n",
      " 86%|███████████████████████████████████████████████████████████████████▊           | 858/1000 [27:28<04:41,  1.98s/it]INFO:root:global_step: 858, logpy: -3703.536, kl: 186.158, loss: 3889.479\n",
      " 86%|███████████████████████████████████████████████████████████████████▊           | 859/1000 [27:30<04:33,  1.94s/it]INFO:root:global_step: 859, logpy: -3703.322, kl: 186.140, loss: 3889.249\n",
      " 86%|███████████████████████████████████████████████████████████████████▉           | 860/1000 [27:31<04:25,  1.89s/it]INFO:root:global_step: 860, logpy: -3703.257, kl: 186.121, loss: 3889.167\n",
      " 86%|████████████████████████████████████████████████████████████████████           | 861/1000 [27:33<04:19,  1.87s/it]INFO:root:global_step: 861, logpy: -3702.075, kl: 185.959, loss: 3887.826\n",
      " 86%|████████████████████████████████████████████████████████████████████           | 862/1000 [27:35<04:14,  1.85s/it]INFO:root:global_step: 862, logpy: -3700.294, kl: 185.861, loss: 3885.948\n",
      " 86%|████████████████████████████████████████████████████████████████████▏          | 863/1000 [27:37<04:09,  1.82s/it]INFO:root:global_step: 863, logpy: -3700.613, kl: 185.761, loss: 3886.169\n",
      " 86%|████████████████████████████████████████████████████████████████████▎          | 864/1000 [27:39<04:05,  1.81s/it]INFO:root:global_step: 864, logpy: -3701.657, kl: 186.002, loss: 3887.456\n",
      " 86%|████████████████████████████████████████████████████████████████████▎          | 865/1000 [27:40<04:01,  1.79s/it]INFO:root:global_step: 865, logpy: -3701.937, kl: 186.059, loss: 3887.796\n",
      " 87%|████████████████████████████████████████████████████████████████████▍          | 866/1000 [27:42<03:58,  1.78s/it]INFO:root:global_step: 866, logpy: -3701.452, kl: 186.054, loss: 3887.306\n",
      " 87%|████████████████████████████████████████████████████████████████████▍          | 867/1000 [27:44<03:55,  1.77s/it]INFO:root:global_step: 867, logpy: -3703.240, kl: 186.089, loss: 3889.132\n",
      " 87%|████████████████████████████████████████████████████████████████████▌          | 868/1000 [27:46<03:53,  1.77s/it]INFO:root:global_step: 868, logpy: -3703.978, kl: 186.088, loss: 3889.872\n",
      " 87%|████████████████████████████████████████████████████████████████████▋          | 869/1000 [27:47<03:54,  1.79s/it]INFO:root:global_step: 869, logpy: -3704.358, kl: 186.090, loss: 3890.256\n",
      " 87%|████████████████████████████████████████████████████████████████████▋          | 870/1000 [27:49<03:52,  1.79s/it]INFO:root:global_step: 870, logpy: -3704.890, kl: 186.080, loss: 3890.779\n",
      " 87%|████████████████████████████████████████████████████████████████████▊          | 871/1000 [27:51<03:51,  1.79s/it]INFO:root:global_step: 871, logpy: -3706.163, kl: 186.266, loss: 3892.240\n",
      " 87%|████████████████████████████████████████████████████████████████████▉          | 872/1000 [27:53<03:46,  1.77s/it]INFO:root:global_step: 872, logpy: -3705.230, kl: 186.094, loss: 3891.137\n",
      " 87%|████████████████████████████████████████████████████████████████████▉          | 873/1000 [27:55<03:45,  1.77s/it]INFO:root:global_step: 873, logpy: -3706.856, kl: 186.261, loss: 3892.932\n",
      " 87%|█████████████████████████████████████████████████████████████████████          | 874/1000 [27:56<03:44,  1.78s/it]INFO:root:global_step: 874, logpy: -3706.639, kl: 186.145, loss: 3892.601\n",
      " 88%|█████████████████████████████████████████████████████████████████████▏         | 875/1000 [27:58<03:44,  1.80s/it]INFO:root:global_step: 875, logpy: -3706.389, kl: 186.047, loss: 3892.255\n",
      " 88%|█████████████████████████████████████████████████████████████████████▏         | 876/1000 [28:00<03:43,  1.81s/it]INFO:root:global_step: 876, logpy: -3706.171, kl: 186.000, loss: 3891.991\n",
      " 88%|█████████████████████████████████████████████████████████████████████▎         | 877/1000 [28:02<03:42,  1.81s/it]INFO:root:global_step: 877, logpy: -3707.779, kl: 186.069, loss: 3893.671\n",
      " 88%|█████████████████████████████████████████████████████████████████████▎         | 878/1000 [28:04<03:39,  1.80s/it]INFO:root:global_step: 878, logpy: -3708.153, kl: 185.866, loss: 3893.843\n",
      " 88%|█████████████████████████████████████████████████████████████████████▍         | 879/1000 [28:05<03:37,  1.79s/it]INFO:root:global_step: 879, logpy: -3707.371, kl: 185.905, loss: 3893.102\n",
      " 88%|█████████████████████████████████████████████████████████████████████▌         | 880/1000 [28:07<03:37,  1.81s/it]INFO:root:global_step: 880, logpy: -3706.036, kl: 185.849, loss: 3891.713\n",
      " 88%|█████████████████████████████████████████████████████████████████████▌         | 881/1000 [28:09<03:36,  1.82s/it]INFO:root:global_step: 881, logpy: -3707.973, kl: 186.001, loss: 3893.803\n",
      " 88%|█████████████████████████████████████████████████████████████████████▋         | 882/1000 [28:11<03:33,  1.81s/it]INFO:root:global_step: 882, logpy: -3708.236, kl: 186.076, loss: 3894.144\n",
      " 88%|█████████████████████████████████████████████████████████████████████▊         | 883/1000 [28:13<03:28,  1.79s/it]INFO:root:global_step: 883, logpy: -3708.377, kl: 185.985, loss: 3894.194\n",
      " 88%|█████████████████████████████████████████████████████████████████████▊         | 884/1000 [28:14<03:26,  1.78s/it]INFO:root:global_step: 884, logpy: -3708.593, kl: 185.866, loss: 3894.294\n",
      " 88%|█████████████████████████████████████████████████████████████████████▉         | 885/1000 [28:16<03:26,  1.79s/it]INFO:root:global_step: 885, logpy: -3706.714, kl: 185.915, loss: 3892.466\n",
      " 89%|█████████████████████████████████████████████████████████████████████▉         | 886/1000 [28:18<03:25,  1.80s/it]INFO:root:global_step: 886, logpy: -3706.976, kl: 185.912, loss: 3892.726\n",
      " 89%|██████████████████████████████████████████████████████████████████████         | 887/1000 [28:20<03:25,  1.82s/it]INFO:root:global_step: 887, logpy: -3705.638, kl: 185.848, loss: 3891.325\n",
      " 89%|██████████████████████████████████████████████████████████████████████▏        | 888/1000 [28:22<03:22,  1.81s/it]INFO:root:global_step: 888, logpy: -3705.305, kl: 185.798, loss: 3890.944\n",
      " 89%|██████████████████████████████████████████████████████████████████████▏        | 889/1000 [28:23<03:20,  1.80s/it]INFO:root:global_step: 889, logpy: -3703.417, kl: 185.600, loss: 3888.859\n",
      " 89%|██████████████████████████████████████████████████████████████████████▎        | 890/1000 [28:25<03:17,  1.80s/it]INFO:root:global_step: 890, logpy: -3703.676, kl: 185.661, loss: 3889.181\n",
      " 89%|██████████████████████████████████████████████████████████████████████▍        | 891/1000 [28:27<03:15,  1.80s/it]INFO:root:global_step: 891, logpy: -3703.523, kl: 185.718, loss: 3889.087\n",
      " 89%|██████████████████████████████████████████████████████████████████████▍        | 892/1000 [28:29<03:13,  1.79s/it]INFO:root:global_step: 892, logpy: -3701.135, kl: 185.643, loss: 3886.625\n",
      " 89%|██████████████████████████████████████████████████████████████████████▌        | 893/1000 [28:31<03:13,  1.81s/it]INFO:root:global_step: 893, logpy: -3701.819, kl: 185.615, loss: 3887.283\n",
      " 89%|██████████████████████████████████████████████████████████████████████▋        | 894/1000 [28:32<03:12,  1.82s/it]INFO:root:global_step: 894, logpy: -3700.971, kl: 185.573, loss: 3886.394\n",
      " 90%|██████████████████████████████████████████████████████████████████████▋        | 895/1000 [28:34<03:11,  1.82s/it]INFO:root:global_step: 895, logpy: -3699.046, kl: 185.574, loss: 3884.472\n",
      " 90%|██████████████████████████████████████████████████████████████████████▊        | 896/1000 [28:36<03:07,  1.81s/it]INFO:root:global_step: 896, logpy: -3698.519, kl: 185.547, loss: 3883.919\n",
      " 90%|██████████████████████████████████████████████████████████████████████▊        | 897/1000 [28:38<03:05,  1.81s/it]INFO:root:global_step: 897, logpy: -3699.948, kl: 185.635, loss: 3885.438\n",
      " 90%|██████████████████████████████████████████████████████████████████████▉        | 898/1000 [28:40<03:03,  1.80s/it]INFO:root:global_step: 898, logpy: -3699.624, kl: 185.587, loss: 3885.067\n",
      " 90%|███████████████████████████████████████████████████████████████████████        | 899/1000 [28:41<03:02,  1.80s/it]INFO:root:global_step: 899, logpy: -3699.863, kl: 185.446, loss: 3885.167\n",
      " 90%|███████████████████████████████████████████████████████████████████████        | 900/1000 [28:43<02:59,  1.79s/it]INFO:root:Saved figure at: ./sim/global_step_900.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 900, logpy: -3700.457, kl: 185.402, loss: 3885.718\n",
      " 90%|███████████████████████████████████████████████████████████████████████▏       | 901/1000 [28:52<06:10,  3.75s/it]INFO:root:global_step: 901, logpy: -3698.388, kl: 185.065, loss: 3883.313\n",
      " 90%|███████████████████████████████████████████████████████████████████████▎       | 902/1000 [28:53<05:08,  3.15s/it]INFO:root:global_step: 902, logpy: -3699.237, kl: 185.061, loss: 3884.160\n",
      " 90%|███████████████████████████████████████████████████████████████████████▎       | 903/1000 [28:55<04:24,  2.73s/it]INFO:root:global_step: 903, logpy: -3700.082, kl: 185.040, loss: 3884.985\n",
      " 90%|███████████████████████████████████████████████████████████████████████▍       | 904/1000 [28:57<03:56,  2.46s/it]INFO:root:global_step: 904, logpy: -3700.798, kl: 185.020, loss: 3885.683\n",
      " 90%|███████████████████████████████████████████████████████████████████████▍       | 905/1000 [28:59<03:35,  2.27s/it]INFO:root:global_step: 905, logpy: -3699.347, kl: 184.904, loss: 3884.117\n",
      " 91%|███████████████████████████████████████████████████████████████████████▌       | 906/1000 [29:01<03:23,  2.16s/it]INFO:root:global_step: 906, logpy: -3698.522, kl: 185.005, loss: 3883.395\n",
      " 91%|███████████████████████████████████████████████████████████████████████▋       | 907/1000 [29:02<03:08,  2.03s/it]INFO:root:global_step: 907, logpy: -3699.837, kl: 185.007, loss: 3884.713\n",
      " 91%|███████████████████████████████████████████████████████████████████████▋       | 908/1000 [29:04<03:00,  1.96s/it]INFO:root:global_step: 908, logpy: -3698.948, kl: 185.052, loss: 3883.870\n",
      " 91%|███████████████████████████████████████████████████████████████████████▊       | 909/1000 [29:06<02:54,  1.92s/it]INFO:root:global_step: 909, logpy: -3700.952, kl: 184.934, loss: 3885.758\n",
      " 91%|███████████████████████████████████████████████████████████████████████▉       | 910/1000 [29:08<02:47,  1.86s/it]INFO:root:global_step: 910, logpy: -3699.902, kl: 184.858, loss: 3884.632\n",
      " 91%|███████████████████████████████████████████████████████████████████████▉       | 911/1000 [29:10<02:45,  1.86s/it]INFO:root:global_step: 911, logpy: -3702.363, kl: 185.002, loss: 3887.239\n",
      " 91%|████████████████████████████████████████████████████████████████████████       | 912/1000 [29:11<02:40,  1.82s/it]INFO:root:global_step: 912, logpy: -3703.191, kl: 184.941, loss: 3888.007\n",
      " 91%|████████████████████████████████████████████████████████████████████████▏      | 913/1000 [29:13<02:39,  1.83s/it]INFO:root:global_step: 913, logpy: -3703.453, kl: 185.116, loss: 3888.445\n",
      " 91%|████████████████████████████████████████████████████████████████████████▏      | 914/1000 [29:15<02:35,  1.81s/it]INFO:root:global_step: 914, logpy: -3704.316, kl: 185.269, loss: 3889.462\n",
      " 92%|████████████████████████████████████████████████████████████████████████▎      | 915/1000 [29:17<02:34,  1.81s/it]INFO:root:global_step: 915, logpy: -3703.865, kl: 185.385, loss: 3889.128\n",
      " 92%|████████████████████████████████████████████████████████████████████████▎      | 916/1000 [29:18<02:30,  1.79s/it]INFO:root:global_step: 916, logpy: -3703.157, kl: 185.495, loss: 3888.532\n",
      " 92%|████████████████████████████████████████████████████████████████████████▍      | 917/1000 [29:20<02:28,  1.79s/it]INFO:root:global_step: 917, logpy: -3702.125, kl: 185.637, loss: 3887.644\n",
      " 92%|████████████████████████████████████████████████████████████████████████▌      | 918/1000 [29:22<02:27,  1.80s/it]INFO:root:global_step: 918, logpy: -3702.652, kl: 185.733, loss: 3888.267\n",
      " 92%|████████████████████████████████████████████████████████████████████████▌      | 919/1000 [29:24<02:26,  1.81s/it]INFO:root:global_step: 919, logpy: -3703.460, kl: 185.963, loss: 3889.306\n",
      " 92%|████████████████████████████████████████████████████████████████████████▋      | 920/1000 [29:26<02:23,  1.80s/it]INFO:root:global_step: 920, logpy: -3702.994, kl: 186.073, loss: 3888.952\n",
      " 92%|████████████████████████████████████████████████████████████████████████▊      | 921/1000 [29:27<02:20,  1.78s/it]INFO:root:global_step: 921, logpy: -3702.272, kl: 185.973, loss: 3888.130\n",
      " 92%|████████████████████████████████████████████████████████████████████████▊      | 922/1000 [29:29<02:18,  1.78s/it]INFO:root:global_step: 922, logpy: -3701.186, kl: 185.829, loss: 3886.902\n",
      " 92%|████████████████████████████████████████████████████████████████████████▉      | 923/1000 [29:31<02:17,  1.78s/it]INFO:root:global_step: 923, logpy: -3700.866, kl: 185.768, loss: 3886.522\n",
      " 92%|████████████████████████████████████████████████████████████████████████▉      | 924/1000 [29:33<02:15,  1.78s/it]INFO:root:global_step: 924, logpy: -3700.945, kl: 185.699, loss: 3886.534\n",
      " 92%|█████████████████████████████████████████████████████████████████████████      | 925/1000 [29:35<02:15,  1.81s/it]INFO:root:global_step: 925, logpy: -3699.685, kl: 185.539, loss: 3885.115\n",
      " 93%|█████████████████████████████████████████████████████████████████████████▏     | 926/1000 [29:36<02:13,  1.81s/it]INFO:root:global_step: 926, logpy: -3698.831, kl: 185.640, loss: 3884.362\n",
      " 93%|█████████████████████████████████████████████████████████████████████████▏     | 927/1000 [29:38<02:13,  1.82s/it]INFO:root:global_step: 927, logpy: -3697.443, kl: 185.721, loss: 3883.057\n",
      " 93%|█████████████████████████████████████████████████████████████████████████▎     | 928/1000 [29:40<02:09,  1.80s/it]INFO:root:global_step: 928, logpy: -3698.881, kl: 185.835, loss: 3884.609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████████████████████████████████████████████████████████████████████▍     | 929/1000 [29:42<02:09,  1.82s/it]INFO:root:global_step: 929, logpy: -3699.945, kl: 185.767, loss: 3885.607\n",
      " 93%|█████████████████████████████████████████████████████████████████████████▍     | 930/1000 [29:44<02:07,  1.82s/it]INFO:root:global_step: 930, logpy: -3703.438, kl: 185.758, loss: 3889.091\n",
      " 93%|█████████████████████████████████████████████████████████████████████████▌     | 931/1000 [29:46<02:06,  1.83s/it]INFO:root:global_step: 931, logpy: -3703.799, kl: 185.591, loss: 3889.287\n",
      " 93%|█████████████████████████████████████████████████████████████████████████▋     | 932/1000 [29:47<02:03,  1.82s/it]INFO:root:global_step: 932, logpy: -3702.323, kl: 185.537, loss: 3887.758\n",
      " 93%|█████████████████████████████████████████████████████████████████████████▋     | 933/1000 [29:49<01:59,  1.78s/it]INFO:root:global_step: 933, logpy: -3702.981, kl: 185.538, loss: 3888.418\n",
      " 93%|█████████████████████████████████████████████████████████████████████████▊     | 934/1000 [29:51<01:57,  1.77s/it]INFO:root:global_step: 934, logpy: -3702.209, kl: 185.383, loss: 3887.492\n",
      " 94%|█████████████████████████████████████████████████████████████████████████▊     | 935/1000 [29:53<01:55,  1.78s/it]INFO:root:global_step: 935, logpy: -3701.968, kl: 185.206, loss: 3887.075\n",
      " 94%|█████████████████████████████████████████████████████████████████████████▉     | 936/1000 [29:55<01:56,  1.81s/it]INFO:root:global_step: 936, logpy: -3702.559, kl: 185.302, loss: 3887.763\n",
      " 94%|██████████████████████████████████████████████████████████████████████████     | 937/1000 [29:56<01:52,  1.79s/it]INFO:root:global_step: 937, logpy: -3703.009, kl: 185.305, loss: 3888.217\n",
      " 94%|██████████████████████████████████████████████████████████████████████████     | 938/1000 [29:58<01:49,  1.77s/it]INFO:root:global_step: 938, logpy: -3704.804, kl: 185.543, loss: 3890.251\n",
      " 94%|██████████████████████████████████████████████████████████████████████████▏    | 939/1000 [30:00<01:48,  1.77s/it]INFO:root:global_step: 939, logpy: -3703.814, kl: 185.510, loss: 3889.228\n",
      " 94%|██████████████████████████████████████████████████████████████████████████▎    | 940/1000 [30:02<01:46,  1.77s/it]INFO:root:global_step: 940, logpy: -3702.556, kl: 185.488, loss: 3887.950\n",
      " 94%|██████████████████████████████████████████████████████████████████████████▎    | 941/1000 [30:03<01:44,  1.78s/it]INFO:root:global_step: 941, logpy: -3700.582, kl: 185.374, loss: 3885.863\n",
      " 94%|██████████████████████████████████████████████████████████████████████████▍    | 942/1000 [30:05<01:43,  1.79s/it]INFO:root:global_step: 942, logpy: -3701.704, kl: 185.647, loss: 3887.259\n",
      " 94%|██████████████████████████████████████████████████████████████████████████▍    | 943/1000 [30:07<01:41,  1.77s/it]INFO:root:global_step: 943, logpy: -3701.680, kl: 185.503, loss: 3887.091\n",
      " 94%|██████████████████████████████████████████████████████████████████████████▌    | 944/1000 [30:09<01:39,  1.77s/it]INFO:root:global_step: 944, logpy: -3702.366, kl: 185.571, loss: 3887.847\n",
      " 94%|██████████████████████████████████████████████████████████████████████████▋    | 945/1000 [30:10<01:38,  1.79s/it]INFO:root:global_step: 945, logpy: -3701.925, kl: 185.596, loss: 3887.431\n",
      " 95%|██████████████████████████████████████████████████████████████████████████▋    | 946/1000 [30:12<01:37,  1.80s/it]INFO:root:global_step: 946, logpy: -3701.954, kl: 185.551, loss: 3887.415\n",
      " 95%|██████████████████████████████████████████████████████████████████████████▊    | 947/1000 [30:14<01:34,  1.78s/it]INFO:root:global_step: 947, logpy: -3701.266, kl: 185.500, loss: 3886.678\n",
      " 95%|██████████████████████████████████████████████████████████████████████████▉    | 948/1000 [30:16<01:34,  1.82s/it]INFO:root:global_step: 948, logpy: -3700.195, kl: 185.479, loss: 3885.587\n",
      " 95%|██████████████████████████████████████████████████████████████████████████▉    | 949/1000 [30:18<01:32,  1.82s/it]INFO:root:global_step: 949, logpy: -3699.197, kl: 185.492, loss: 3884.602\n",
      " 95%|███████████████████████████████████████████████████████████████████████████    | 950/1000 [30:20<01:30,  1.80s/it]INFO:root:Saved figure at: ./sim/global_step_950.png\n",
      "C:\\Users\\15197\\anaconda3\\lib\\site-packages\\torchsde\\_core\\sdeint.py:278: UserWarning: Numerical solution is not guaranteed to converge to the correct solution when using adaptive time-stepping with the Euler--Maruyama method with non-additive noise.\n",
      "  warnings.warn(f\"Numerical solution is not guaranteed to converge to the correct solution when using adaptive \"\n",
      "INFO:root:global_step: 950, logpy: -3698.445, kl: 185.715, loss: 3884.074\n",
      " 95%|███████████████████████████████████████████████████████████████████████████▏   | 951/1000 [30:28<03:06,  3.80s/it]INFO:root:global_step: 951, logpy: -3700.075, kl: 185.762, loss: 3885.753\n",
      " 95%|███████████████████████████████████████████████████████████████████████████▏   | 952/1000 [30:30<02:33,  3.19s/it]INFO:root:global_step: 952, logpy: -3698.030, kl: 185.691, loss: 3883.638\n",
      " 95%|███████████████████████████████████████████████████████████████████████████▎   | 953/1000 [30:32<02:11,  2.80s/it]INFO:root:global_step: 953, logpy: -3699.388, kl: 185.683, loss: 3884.988\n",
      " 95%|███████████████████████████████████████████████████████████████████████████▎   | 954/1000 [30:33<01:55,  2.50s/it]INFO:root:global_step: 954, logpy: -3698.319, kl: 185.741, loss: 3883.978\n",
      " 96%|███████████████████████████████████████████████████████████████████████████▍   | 955/1000 [30:35<01:43,  2.31s/it]INFO:root:global_step: 955, logpy: -3698.461, kl: 185.758, loss: 3884.137\n",
      " 96%|███████████████████████████████████████████████████████████████████████████▌   | 956/1000 [30:37<01:34,  2.14s/it]INFO:root:global_step: 956, logpy: -3698.378, kl: 185.807, loss: 3884.105\n",
      " 96%|███████████████████████████████████████████████████████████████████████████▌   | 957/1000 [30:39<01:28,  2.05s/it]INFO:root:global_step: 957, logpy: -3699.505, kl: 185.879, loss: 3885.304\n",
      " 96%|███████████████████████████████████████████████████████████████████████████▋   | 958/1000 [30:41<01:23,  1.99s/it]INFO:root:global_step: 958, logpy: -3699.376, kl: 185.864, loss: 3885.161\n",
      " 96%|███████████████████████████████████████████████████████████████████████████▊   | 959/1000 [30:43<01:19,  1.95s/it]INFO:root:global_step: 959, logpy: -3697.235, kl: 185.756, loss: 3882.913\n",
      " 96%|███████████████████████████████████████████████████████████████████████████▊   | 960/1000 [30:44<01:15,  1.89s/it]INFO:root:global_step: 960, logpy: -3699.173, kl: 185.893, loss: 3884.990\n",
      " 96%|███████████████████████████████████████████████████████████████████████████▉   | 961/1000 [30:46<01:11,  1.84s/it]INFO:root:global_step: 961, logpy: -3697.183, kl: 185.715, loss: 3882.821\n",
      " 96%|███████████████████████████████████████████████████████████████████████████▉   | 962/1000 [30:48<01:09,  1.84s/it]INFO:root:global_step: 962, logpy: -3697.507, kl: 185.666, loss: 3883.097\n",
      " 96%|████████████████████████████████████████████████████████████████████████████   | 963/1000 [30:50<01:07,  1.82s/it]INFO:root:global_step: 963, logpy: -3696.747, kl: 185.487, loss: 3882.160\n",
      " 96%|████████████████████████████████████████████████████████████████████████████▏  | 964/1000 [30:51<01:04,  1.80s/it]INFO:root:global_step: 964, logpy: -3697.488, kl: 185.462, loss: 3882.876\n",
      " 96%|████████████████████████████████████████████████████████████████████████████▏  | 965/1000 [30:53<01:02,  1.78s/it]INFO:root:global_step: 965, logpy: -3695.948, kl: 185.448, loss: 3881.322\n",
      " 97%|████████████████████████████████████████████████████████████████████████████▎  | 966/1000 [30:55<01:00,  1.77s/it]INFO:root:global_step: 966, logpy: -3695.812, kl: 185.455, loss: 3881.195\n",
      " 97%|████████████████████████████████████████████████████████████████████████████▍  | 967/1000 [30:57<00:58,  1.77s/it]INFO:root:global_step: 967, logpy: -3697.803, kl: 185.548, loss: 3883.279\n",
      " 97%|████████████████████████████████████████████████████████████████████████████▍  | 968/1000 [30:59<00:57,  1.79s/it]INFO:root:global_step: 968, logpy: -3697.801, kl: 185.554, loss: 3883.284\n",
      " 97%|████████████████████████████████████████████████████████████████████████████▌  | 969/1000 [31:00<00:55,  1.79s/it]INFO:root:global_step: 969, logpy: -3698.030, kl: 185.722, loss: 3883.682\n",
      " 97%|████████████████████████████████████████████████████████████████████████████▋  | 970/1000 [31:02<00:53,  1.79s/it]INFO:root:global_step: 970, logpy: -3698.434, kl: 185.753, loss: 3884.117\n",
      " 97%|████████████████████████████████████████████████████████████████████████████▋  | 971/1000 [31:04<00:51,  1.77s/it]INFO:root:global_step: 971, logpy: -3697.599, kl: 185.834, loss: 3883.364\n",
      " 97%|████████████████████████████████████████████████████████████████████████████▊  | 972/1000 [31:06<00:50,  1.80s/it]INFO:root:global_step: 972, logpy: -3696.450, kl: 185.704, loss: 3882.086\n",
      " 97%|████████████████████████████████████████████████████████████████████████████▊  | 973/1000 [31:07<00:48,  1.80s/it]INFO:root:global_step: 973, logpy: -3696.576, kl: 185.676, loss: 3882.184\n",
      " 97%|████████████████████████████████████████████████████████████████████████████▉  | 974/1000 [31:09<00:47,  1.82s/it]INFO:root:global_step: 974, logpy: -3697.628, kl: 185.779, loss: 3883.340\n",
      " 98%|█████████████████████████████████████████████████████████████████████████████  | 975/1000 [31:11<00:45,  1.80s/it]INFO:root:global_step: 975, logpy: -3695.456, kl: 185.558, loss: 3880.947\n",
      " 98%|█████████████████████████████████████████████████████████████████████████████  | 976/1000 [31:13<00:42,  1.79s/it]INFO:root:global_step: 976, logpy: -3695.555, kl: 185.571, loss: 3881.060\n",
      " 98%|█████████████████████████████████████████████████████████████████████████████▏ | 977/1000 [31:15<00:41,  1.80s/it]INFO:root:global_step: 977, logpy: -3694.602, kl: 185.485, loss: 3880.022\n",
      " 98%|█████████████████████████████████████████████████████████████████████████████▎ | 978/1000 [31:17<00:39,  1.81s/it]INFO:root:global_step: 978, logpy: -3695.273, kl: 185.683, loss: 3880.892\n",
      " 98%|█████████████████████████████████████████████████████████████████████████████▎ | 979/1000 [31:18<00:38,  1.82s/it]INFO:root:global_step: 979, logpy: -3693.143, kl: 185.694, loss: 3878.773\n",
      " 98%|█████████████████████████████████████████████████████████████████████████████▍ | 980/1000 [31:20<00:35,  1.79s/it]INFO:root:global_step: 980, logpy: -3693.842, kl: 185.781, loss: 3879.560\n",
      " 98%|█████████████████████████████████████████████████████████████████████████████▍ | 981/1000 [31:22<00:34,  1.79s/it]INFO:root:global_step: 981, logpy: -3694.314, kl: 185.712, loss: 3879.963\n",
      " 98%|█████████████████████████████████████████████████████████████████████████████▌ | 982/1000 [31:24<00:32,  1.78s/it]INFO:root:global_step: 982, logpy: -3694.313, kl: 185.763, loss: 3880.014\n",
      " 98%|█████████████████████████████████████████████████████████████████████████████▋ | 983/1000 [31:25<00:30,  1.78s/it]INFO:root:global_step: 983, logpy: -3696.250, kl: 185.811, loss: 3882.000\n",
      " 98%|█████████████████████████████████████████████████████████████████████████████▋ | 984/1000 [31:27<00:28,  1.79s/it]INFO:root:global_step: 984, logpy: -3695.785, kl: 185.813, loss: 3881.537\n",
      " 98%|█████████████████████████████████████████████████████████████████████████████▊ | 985/1000 [31:29<00:26,  1.77s/it]INFO:root:global_step: 985, logpy: -3695.573, kl: 185.524, loss: 3881.037\n",
      " 99%|█████████████████████████████████████████████████████████████████████████████▉ | 986/1000 [31:31<00:25,  1.81s/it]INFO:root:global_step: 986, logpy: -3696.641, kl: 185.578, loss: 3882.160\n",
      " 99%|█████████████████████████████████████████████████████████████████████████████▉ | 987/1000 [31:33<00:23,  1.82s/it]INFO:root:global_step: 987, logpy: -3696.436, kl: 185.460, loss: 3881.837\n",
      " 99%|██████████████████████████████████████████████████████████████████████████████ | 988/1000 [31:34<00:21,  1.81s/it]INFO:root:global_step: 988, logpy: -3696.742, kl: 185.476, loss: 3882.160\n",
      " 99%|██████████████████████████████████████████████████████████████████████████████▏| 989/1000 [31:36<00:19,  1.81s/it]INFO:root:global_step: 989, logpy: -3695.670, kl: 185.511, loss: 3881.123\n",
      " 99%|██████████████████████████████████████████████████████████████████████████████▏| 990/1000 [31:38<00:17,  1.80s/it]INFO:root:global_step: 990, logpy: -3694.330, kl: 185.437, loss: 3879.710\n",
      " 99%|██████████████████████████████████████████████████████████████████████████████▎| 991/1000 [31:40<00:16,  1.80s/it]INFO:root:global_step: 991, logpy: -3695.496, kl: 185.501, loss: 3880.940\n",
      " 99%|██████████████████████████████████████████████████████████████████████████████▎| 992/1000 [31:42<00:14,  1.80s/it]INFO:root:global_step: 992, logpy: -3696.303, kl: 185.584, loss: 3881.831\n",
      " 99%|██████████████████████████████████████████████████████████████████████████████▍| 993/1000 [31:43<00:12,  1.79s/it]INFO:root:global_step: 993, logpy: -3696.816, kl: 185.457, loss: 3882.218\n",
      " 99%|██████████████████████████████████████████████████████████████████████████████▌| 994/1000 [31:45<00:10,  1.80s/it]INFO:root:global_step: 994, logpy: -3697.317, kl: 185.374, loss: 3882.636\n",
      "100%|██████████████████████████████████████████████████████████████████████████████▌| 995/1000 [31:47<00:08,  1.79s/it]INFO:root:global_step: 995, logpy: -3697.630, kl: 185.400, loss: 3882.976\n",
      "100%|██████████████████████████████████████████████████████████████████████████████▋| 996/1000 [31:49<00:07,  1.78s/it]INFO:root:global_step: 996, logpy: -3698.174, kl: 185.460, loss: 3883.580\n",
      "100%|██████████████████████████████████████████████████████████████████████████████▊| 997/1000 [31:51<00:05,  1.79s/it]INFO:root:global_step: 997, logpy: -3700.063, kl: 185.429, loss: 3885.439\n",
      "100%|██████████████████████████████████████████████████████████████████████████████▊| 998/1000 [31:52<00:03,  1.80s/it]INFO:root:global_step: 998, logpy: -3699.864, kl: 185.377, loss: 3885.188\n",
      "100%|██████████████████████████████████████████████████████████████████████████████▉| 999/1000 [31:54<00:01,  1.78s/it]INFO:root:global_step: 999, logpy: -3697.764, kl: 185.296, loss: 3883.007\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [31:56<00:00,  1.92s/it]\n"
     ]
    }
   ],
   "source": [
    "manual_seed(args['seed'])\n",
    "\n",
    "if args['debug']:\n",
    "    logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "ckpt_dir = os.path.join('./sim/', 'ckpts')\n",
    "os.makedirs(ckpt_dir, exist_ok=True)\n",
    "\n",
    "sdeint_fn = torchsde.sdeint_adjoint if args['adjoint'] else torchsde.sdeint\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c356ad31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7712260f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
